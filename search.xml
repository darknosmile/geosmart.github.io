<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[Spark学习笔记]]></title>
      <url>http://geosmart.github.io/2017/07/23/Spark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<hr>
<a id="more"></a> 
<p>目前的大数据处理可以分为如以下三个类型。 </p>
<ol>
<li>复杂的批量数据处理（batch data processing），通常的时间跨度在数十分钟到数小时之间。</li>
<li>基于历史数据的交互式查询（interactive query），通常的时间跨度在数十秒到数分钟之间。</li>
<li>基于实时数据流的数据处理（streaming data processing），通常的时间跨度在数百毫秒到数秒之间。 </li>
</ol>
<p>目前已有很多相对成熟的开源软件来处理以上三种情景，</p>
<ul>
<li>我们可以利用MapReduce来进行批量数据处理，</li>
<li>可以用Impala来进行交互式查询，</li>
<li>对于流式数据处理，我们可以采用Storm。</li>
</ul>
<p><a href="https://www.gitbook.com/book/yourtion/sparkinternals">Apache Spark 的设计与实现</a></p>
<p><a href="http://ifeve.com/category/spark/">spark系列博客</a></p>
<p><a href="http://spark.apache.org/docs/latest/api/java/index.html">spark java api doc</a></p>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="csv-转-parquet"><a href="#csv-转-parquet" class="headerlink" title="csv 转 parquet"></a>csv 转 parquet</h2><h2 id="parquet-转csv"><a href="#parquet-转csv" class="headerlink" title="parquet 转csv"></a>parquet 转csv</h2><h2 id="parquet-join操作"><a href="#parquet-join操作" class="headerlink" title="parquet join操作"></a>parquet join操作</h2>]]></content>
      
        <categories>
            
            <category> 人工智能 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[深层神经网络]]></title>
      <url>http://geosmart.github.io/2017/07/20/%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      <content type="html"><![CDATA[<a id="more"></a> 
<h1 id="深度学习与深层神经网络"><a href="#深度学习与深层神经网络" class="headerlink" title="深度学习与深层神经网络"></a>深度学习与深层神经网络</h1><h1 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h1><h2 id="经典损失函数"><a href="#经典损失函数" class="headerlink" title="经典损失函数"></a>经典损失函数</h2><h3 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h3><blockquote>
<p>如何判断输出向量和期望向量之间的接近程度？<br>交叉熵是常用的评判方法，其刻画了两个概率分布之间的距离，它是分类问题中使用较广的一种损失函数；</p>
<h3 id="Softmax回归"><a href="#Softmax回归" class="headerlink" title="Softmax回归"></a>Softmax回归</h3><p>如何将神经网络前向传播得到的结果也变成概率分布？<br>Softmax回归是一个非常常用的方法<br>公式：</p>
</blockquote>
<p>tensorflow 实现交叉熵</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">cross_entropy=-tf.reduce_mean(y_*tf.log(tf.clip_by_value(y,<span class="number">1e-10</span>,<span class="number">1.0</span>)))</div><div class="line"><span class="comment"># y_：正确结果</span></div><div class="line"><span class="comment"># y:预测结果</span></div><div class="line"><span class="comment"># tf.clip_by_value：将一个张量的数值限制在一个范围内，避免一些运算错误，如log0</span></div><div class="line"><span class="comment"># tf.log：对张量中的数据依次就对数</span></div><div class="line"><span class="comment"># * ：乘法，每个位置上对应元素的乘积，不是矩阵乘法</span></div></pre></td></tr></table></figure>
<p>因为交叉熵一般会与softmax回归一起使用，所以tensorflow对这两个功能进行了统一封装，并提供了<code>tf.nn.softmax_cross_entropy_with_logists(y,y_)</code></p>
<p>对于回归问题，最常用的损失函数是均方差（MSE,mean squared error）；</p>
]]></content>
      
        <categories>
            
            <category> 人工智能 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[机器学习基础概念]]></title>
      <url>http://geosmart.github.io/2017/07/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/</url>
      <content type="html"><![CDATA[<p>监督学习、非监督学习、神经网络……<br><a id="more"></a> </p>
<h1 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h1><h2 id="分类问题和回归问题"><a href="#分类问题和回归问题" class="headerlink" title="分类问题和回归问题"></a>分类问题和回归问题</h2><p>分类问题希望解决的是将不同的样本分到事先定义好的类别中；</p>
<ul>
<li>分类（Classification）和回归（Regression）的区别在于输出变量的类型。</li>
<li>定量输出称为回归，或者说是连续变量（continous）预测；</li>
<li>定性输出称为分类，或者说是离散变量（discrete）预测。</li>
</ul>
<blockquote>
<p>对Regression回归一词的理解<br>出自高尔顿种豆子的实验，通过大量数据统计，他发现个体小的豆子往往倾向于产生比其更大的子代，而个体大的豆子则倾向于产生比其小的子代，然后高尔顿认为这是由于新个体在向这种豆子的平均尺寸“回归”，大概的意思就是事物总是倾向于朝着某种“平均”发展，也可以说是回归于事物本来的面目。<br>C.R.Rao等在Linear Models and Generalizations: Least Squares and Alternatives中解释道：the literature meaning of REGRESSION is “ to move in the backward direction”，<br>看以下两个陈述：<br>S1: model generates data or<br>S2: data generates model.<br>Rao认为很明显陈述S1才是对的，因为模型实际上本来就是存在的，<br>只不过我们不知道(model exists in nature but is unknown to the experimenter)，先有模型所以我们知道X就能得到Y：<br>先有模型 –&gt; 有了X就有Y（S1），而“回归”的意思就是我们通过收集X与Y来确定实际上存在的关系模型：<br>收集X与Y –&gt; 确定模型（S2），与S1相比，S2就是一个“回到”模型的过程，所以就叫做“regression”。</p>
</blockquote>
<h1 id="非监督学习"><a href="#非监督学习" class="headerlink" title="非监督学习"></a>非监督学习</h1><p>We can derive this structure by clustering the data based on relationships among the variables in the data.<br>Clustering：基因分组<br>Non-clustering: The “Cocktail Party Algorithm”,音频分离</p>
<h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><h2 id="RNN梯度消散问题"><a href="#RNN梯度消散问题" class="headerlink" title="RNN梯度消散问题"></a>RNN梯度消散问题</h2><h1 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h1><h1 id="MLP（Multi-Layer-Perceptron-）"><a href="#MLP（Multi-Layer-Perceptron-）" class="headerlink" title="MLP（Multi Layer Perceptron ）"></a>MLP（Multi Layer Perceptron ）</h1><p>多层感知器，是一种前向结构的人工神经网络，映射一组输入向量到一组输出向量。MLP可以被看做是一个有向图，由多个节点层组成，每一层全连接到下一层。除了输入节点，每个节点都是一个带有非线性激活函数的神经元（或称处理单元）。一种被称为反向传播算法的监督学习方法常被用来训练MLP。MLP是感知器的推广，克服了感知器不能对线性不可分数据进行识别的弱点。</p>
<h1 id="CUDA-Compute-Unified-Device-Architecture"><a href="#CUDA-Compute-Unified-Device-Architecture" class="headerlink" title="CUDA(Compute Unified Device Architecture)"></a>CUDA(Compute Unified Device Architecture)</h1><p>CUDA是显卡厂商NVIDIA推出的运算平台。 CUDA™是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。 它包含了CUDA指令集架构（ISA）以及GPU内部的并行计算引擎。<br> 开发人员现在可以使用C语言来为CUDA™架构编写程序，C语言是应用最广泛的一种高级编程语言。所编写出的程序于是就可以在支持CUDA™的处理器上以超高性能运行。CUDA3.0已经开始支持C++和FORTRAN。</p>
<h1 id="State-of-the-art"><a href="#State-of-the-art" class="headerlink" title="State of the art"></a>State of the art</h1><p>对应国内文献里的“研究现状”,当前的最高研究水平。</p>
]]></content>
      
        <categories>
            
            <category> 人工智能 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Machine Leaning </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Machine Learning课程笔记Week1-损失函数]]></title>
      <url>http://geosmart.github.io/2017/07/08/Machine%20Learning%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0Week1-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</url>
      <content type="html"><![CDATA[<p><a href="https://www.coursera.org/learn/machine-learning/supplement/cRa2m/model-representation">Coursera斯坦福大学机器学习（Machine Leaning）课程第一周</a>课程笔记</p>
<blockquote>
<p>given a training set, to learn a function h : X → Y so that h(x) is a “good” predictor for the corresponding value of y. For historical reasons, this function h is called a hypothesis. </p>
</blockquote>
<hr>
<a id="more"></a> 
<h1 id="监督学习模型"><a href="#监督学习模型" class="headerlink" title="监督学习模型"></a>监督学习模型</h1><p><img src="监督学习模型.jpg" alt="supervised learning problem"></p>
<blockquote>
<p>When the target variable that we’re trying to predict is continuous, such as in our housing example, we call the learning problem a regression problem. When y can take on only a small number of discrete values (such as if, given the living area, we wanted to predict if a dwelling is a house or an apartment, say), we call it a classification problem.</p>
</blockquote>
<h1 id="损失函数（Cost-Function）"><a href="#损失函数（Cost-Function）" class="headerlink" title="损失函数（Cost Function）"></a>损失函数（Cost Function）</h1><p><img src="损失函数公式.jpg" alt="损失函数公式"><br>$$ J(\theta|_0,\theta|_1) $$</p>
<p><img src="损失函数推演过程.jpg" alt="损失函数推演过程"></p>
<p>示例：线性回归-单变量</p>
<h1 id="梯度下降法（Gradiant-Discent）"><a href="#梯度下降法（Gradiant-Discent）" class="headerlink" title="梯度下降法（Gradiant Discent）"></a>梯度下降法（Gradiant Discent）</h1><p>梯度下降法求解线性回归问题，即求解最小化损失函数J</p>
<p><img src="线性回归问题求解.jpg" alt="线性回归问题求解"></p>
<p><img src="梯度下降法求解线性回归问题.jpg" alt="梯度下降法求解线性回归问题"></p>
<p><img src="梯度下降法可视化.jpg" alt="梯度下降法-轮廓图"></p>
<blockquote>
<p>θ0 on the x axis and θ1 on the y axis, with the cost function on the vertical z axis. The points on our graph will be the result of the cost function using our hypothesis with those specific theta parameters.</p>
</blockquote>
<p><img src="梯度下降法公式.jpg" alt="梯度下降法公式"></p>
<ul>
<li>learning rate：The size of each step is determined by the parameter α,</li>
<li>j=0,1 represents the feature index number.</li>
<li>At each iteration j, one should <strong>simultaneously</strong> update the parameters θ1,θ2,…,θn. Updating a specific parameter prior to calculating another one on the j(th) iteration would yield to a wrong implementation.</li>
</ul>
<h2 id="Learning-Rate"><a href="#Learning-Rate" class="headerlink" title="Learning Rate"></a>Learning Rate</h2><blockquote>
<p>Debugging gradient descent. Make a plot with number of iterations on the x-axis. Now plot the cost function, J(θ) over the number of iterations of gradient descent. If J(θ) ever increases, then you probably need to decrease α.</p>
<p>Automatic convergence test. Declare convergence if J(θ) decreases by less than E in one iteration, where E is some small value such as 10−3. However in practice it’s difficult to choose this threshold value.</p>
</blockquote>
<p>To summarize:</p>
<ul>
<li>If α is too small: slow convergence.</li>
<li>If α is too large: ￼may not decrease on every iteration and thus may not converge.</li>
</ul>
<h2 id="批量梯度下降（batch-gradient-descent）"><a href="#批量梯度下降（batch-gradient-descent）" class="headerlink" title="批量梯度下降（batch gradient descent）"></a>批量梯度下降（batch gradient descent）</h2><p><a href="https://www.coursera.org/learn/machine-learning/supplement/U90DX/gradient-descent-for-linear-regression">https://www.coursera.org/learn/machine-learning/supplement/U90DX/gradient-descent-for-linear-regression</a></p>
<p>凸二次函数（convex quadratic function）</p>
<h2 id="特征选择和多项式回归"><a href="#特征选择和多项式回归" class="headerlink" title="特征选择和多项式回归"></a>特征选择和多项式回归</h2><p>Features and Polynomial Regression</p>
<ul>
<li>多个特征可合并为一个新特征</li>
<li>线性假设函数效果不好时，可以用平方，立方，平方根或其他形式来改变函数曲线</li>
</ul>
<blockquote>
<p>One important thing to keep in mind is, if you choose your features this way then feature scaling becomes very important.<br>eg. if x1 has range 1 - 1000 then range of x21 becomes 1 - 1000000 and that of x31 becomes 1 - 1000000000</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> 人工智能 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Machine Leaning </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[机器学习数学基础]]></title>
      <url>http://geosmart.github.io/2017/07/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/</url>
      <content type="html"><![CDATA[<hr>
<a id="more"></a> 
<h1 id="Variance-方差"><a href="#Variance-方差" class="headerlink" title="Variance(方差)"></a>Variance(方差)</h1><blockquote>
<p>方差（Variance），应用数学里的专有名词。<br>在概率论和统计学中，一个随机变量的方差描述的是它的离散程度，也就是该变量离其期望值的距离。方差越大，数据的分布越分散。<br>一个实随机变量的方差也称为它的二阶矩或二阶中心动差，恰巧也是它的二阶累积量。<br>说白了，就是将各个误差将之平方（而非取绝对值），使之肯定为正数，相加之后再除以总数，透过这样的方式来算出各个数据分布、零散（相对中心点）的程度。<br>继续延伸的话，方差的算术平方根称为该随机变量的标准差（此为相对各个数据点间）。</p>
</blockquote>
<p>总体方差计算公式：  </p>
<h1 id="Bias-偏差"><a href="#Bias-偏差" class="headerlink" title="Bias(偏差)"></a>Bias(偏差)</h1><p>偏差：描述的是预测值（估计值）的期望与真实值之间的差距。偏差越大，越偏离真实数据，<br>方差，是形容数据分散程度的，算是“无监督的”，客观的指标，<br>偏差，形容数据跟我们期望的中心差得有多远，算是“有监督的”，有人的知识参与的指标。</p>
<h1 id="Standard-Deviation-标准差"><a href="#Standard-Deviation-标准差" class="headerlink" title="Standard Deviation(标准差)"></a>Standard Deviation(标准差)</h1><blockquote>
<p>标准差（Standard Deviation，SD）又常称均方差，数学符号 σ（sigma），在概率统计中最常使用作为测量一组数值的离散程度之用。<br>标准差定义：标准差是方差的算术平方根。标准差能反映一个数据集的离散程度。平均数相同的两组数据，标准差未必相同。  </p>
</blockquote>
<p>标准差也被称为标准偏差，或者实验标准差，公式为<br><img src="http://c.hiphotos.baidu.com/baike/s%3D150/sign=49a3c31e8f1001e94a3c100a880f7b06/d058ccbf6c81800af3b703f9b33533fa838b47f3.jpg" alt="标准差公式"></p>
<h1 id="导数"><a href="#导数" class="headerlink" title="导数"></a>导数</h1><h1 id="微分"><a href="#微分" class="headerlink" title="微分"></a>微分</h1><h1 id="正态分布"><a href="#正态分布" class="headerlink" title="正态分布"></a>正态分布</h1><h1 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h1><h2 id="矩阵的性质"><a href="#矩阵的性质" class="headerlink" title="矩阵的性质"></a>矩阵的性质</h2><ul>
<li>不满足交换律</li>
<li>方阵：行列相等</li>
<li>单位矩阵：xx对角线都为1</li>
<li>逆矩阵：I<em>A=A</em>I=A</li>
<li>奇异矩阵/退化矩阵（singular/degenerate）：没有逆矩阵，如零矩阵（矩阵元素都为0）<h2 id="矩阵的乘法"><a href="#矩阵的乘法" class="headerlink" title="矩阵的乘法"></a>矩阵的乘法</h2><h2 id="矩阵的转置（transpose）"><a href="#矩阵的转置（transpose）" class="headerlink" title="矩阵的转置（transpose）"></a>矩阵的转置（transpose）</h2></li>
</ul>
]]></content>
      
        <categories>
            
            <category> 人工智能 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Machine Leaning </tag>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[R学习笔记]]></title>
      <url>http://geosmart.github.io/2017/07/04/R%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<blockquote>
<p>R is a tool for statistics and data modeling. The R programming language is elegant, versatile, and has a highly expressive syntax designed around working with data. R is more than that, though — it also includes extremely powerful graphics capabilities.</p>
</blockquote>
<hr>
<a id="more"></a> 
<p><a href="http://tryr.codeschool.com/">Try R</a></p>
<h1 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h1><p>定义： x&lt;-42，x赋值为42</p>
<h1 id="向量（Vectors）"><a href="#向量（Vectors）" class="headerlink" title="向量（Vectors）"></a>向量（Vectors）</h1><p>定义： c(1,T,”three”)</p>
<h2 id="Sequence-Vectors"><a href="#Sequence-Vectors" class="headerlink" title="Sequence Vectors"></a>Sequence Vectors</h2><p>输入：seq(5,9)或5:9<br>输出：[1] 5 6 7 8 9</p>
<h2 id="设置步长-increments"><a href="#设置步长-increments" class="headerlink" title="设置步长-increments"></a>设置步长-increments</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;seq(<span class="number">5</span>,<span class="number">9</span>,<span class="number">0.5</span>)</div><div class="line">[<span class="number">1</span>] <span class="number">5.0</span> <span class="number">5.5</span> <span class="number">6.0</span> <span class="number">6.5</span> <span class="number">7.0</span> <span class="number">7.5</span> <span class="number">8.0</span> <span class="number">8.5</span> <span class="number">9.0</span></div></pre></td></tr></table></figure>
<h2 id="向量访问"><a href="#向量访问" class="headerlink" title="向量访问"></a>向量访问</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&gt; sentence &lt;- c(<span class="string">'walk'</span>, <span class="string">'the'</span>, <span class="string">'plank'</span>)</div></pre></td></tr></table></figure>
<ul>
<li><p>索引访问:R索引从1开始 </p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; sentence[<span class="number">3</span>]</div><div class="line">[<span class="number">1</span>] <span class="string">"plank"</span></div></pre></td></tr></table></figure>
</li>
<li><p>定义向量访问： </p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; sentence[c(<span class="number">1</span>,<span class="number">3</span>)]</div><div class="line">[<span class="number">1</span>] <span class="string">"walk"</span> <span class="string">"dog"</span></div></pre></td></tr></table></figure>
</li>
<li><p>范围访问： </p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; sentence[<span class="number">2</span>:<span class="number">4</span>]  </div><div class="line">[<span class="number">1</span>] <span class="string">"the"</span> <span class="string">"dog"</span> <span class="string">"to"</span></div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="修改向量值"><a href="#修改向量值" class="headerlink" title="修改向量值"></a>修改向量值</h2><ul>
<li><p>单个修改</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&gt; sentence[<span class="number">3</span>]&lt;-<span class="string">"dog"</span></div></pre></td></tr></table></figure>
</li>
<li><p>批量修改</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&gt; sentence[<span class="number">5</span>:<span class="number">7</span>]&lt;-c(<span class="string">'the'</span>,<span class="string">'poop'</span>,<span class="string">'deck'</span>)</div></pre></td></tr></table></figure>
</li>
<li><p>新增向量</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sentence[<span class="number">4</span>]&lt;-<span class="string">"to"</span></div></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="绘图"><a href="#绘图" class="headerlink" title="绘图"></a>绘图</h1><p>barplot直方图<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; vesselsSunk &lt;- c(<span class="number">4</span>, <span class="number">5</span>, <span class="number">1</span>)</div><div class="line">&gt; barplot(vesselsSunk)</div></pre></td></tr></table></figure></p>
<p>scatter plots散点图<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&gt; values &lt;- -<span class="number">10</span>:<span class="number">10</span></div><div class="line">&gt; absolutes &lt;- abs(values)</div><div class="line">&gt; plot(values, absolutes)</div></pre></td></tr></table></figure></p>
<h1 id="NA"><a href="#NA" class="headerlink" title="NA"></a>NA</h1><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">&gt; a &lt;- c(<span class="number">1</span>, <span class="number">3</span>, <span class="literal">NA</span>, <span class="number">7</span>, <span class="number">9</span>)</div><div class="line">&gt; sum(a)</div><div class="line">[<span class="number">1</span>] <span class="literal">NA</span></div><div class="line">&gt; sum(a,na.rm=<span class="literal">T</span>)</div><div class="line">[<span class="number">1</span>] <span class="number">20</span></div></pre></td></tr></table></figure>
<h1 id="matrix"><a href="#matrix" class="headerlink" title="matrix"></a>matrix</h1><p>定义：3行4列，值都为0<br>matrix(0,3,4)</p>
<p>升维：dim设置matrix维度<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&gt; plank  &lt;- <span class="number">1</span>:<span class="number">8</span></div><div class="line">&gt; dim(plank) &lt;- c(<span class="number">2</span>,<span class="number">4</span>)</div><div class="line">&gt; print(plank)</div><div class="line">     [,<span class="number">1</span>] [,<span class="number">2</span>] [,<span class="number">3</span>] [,<span class="number">4</span>]</div><div class="line">[<span class="number">1</span>,]    <span class="number">1</span>    <span class="number">3</span>    <span class="number">5</span>    <span class="number">7</span></div><div class="line">[<span class="number">2</span>,]    <span class="number">2</span>    <span class="number">4</span>    <span class="number">6</span>    <span class="number">8</span></div></pre></td></tr></table></figure></p>
<p>赋值：&gt; plank[1,4] &lt;- 0</p>
<h2 id="matrix访问"><a href="#matrix访问" class="headerlink" title="matrix访问"></a>matrix访问</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&gt; print(plank)</div><div class="line">     [,<span class="number">1</span>] [,<span class="number">2</span>] [,<span class="number">3</span>] [,<span class="number">4</span>]</div><div class="line">[<span class="number">1</span>,]    <span class="number">1</span>    <span class="number">3</span>    <span class="number">5</span>    <span class="number">7</span></div><div class="line">[<span class="number">2</span>,]    <span class="number">2</span>    <span class="number">4</span>    <span class="number">6</span>    <span class="number">8</span></div></pre></td></tr></table></figure>
<ul>
<li><p>单个元素</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; plank[<span class="number">2</span>,<span class="number">3</span>]</div><div class="line">[<span class="number">1</span>] <span class="number">6</span></div></pre></td></tr></table></figure>
</li>
<li><p>列</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; plank[,<span class="number">4</span>]</div><div class="line">[<span class="number">1</span>] <span class="number">7</span> <span class="number">8</span></div></pre></td></tr></table></figure>
</li>
<li><p>指定范围</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&gt; plank[,<span class="number">2</span>:<span class="number">4</span>]</div><div class="line">     [,<span class="number">1</span>] [,<span class="number">2</span>] [,<span class="number">3</span>]</div><div class="line">[<span class="number">1</span>,]    <span class="number">3</span>    <span class="number">5</span>    <span class="number">7</span></div><div class="line">[<span class="number">2</span>,]    <span class="number">4</span>    <span class="number">6</span>    <span class="number">8</span></div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="绘图-1"><a href="#绘图-1" class="headerlink" title="绘图"></a>绘图</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; elevation &lt;- matrix(<span class="number">1</span>, <span class="number">10</span>, <span class="number">10</span>)</div><div class="line">&gt; elevation[<span class="number">4</span>, <span class="number">6</span>] &lt;- <span class="number">0</span></div></pre></td></tr></table></figure>
<ul>
<li><p>轮廓图</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&gt; contour(elevation)</div></pre></td></tr></table></figure>
</li>
<li><p>三维轮廓图</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; persp(elevation)</div><div class="line">&gt; persp(elevation, expand=<span class="number">0.2</span>)</div></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="统计函数"><a href="#统计函数" class="headerlink" title="统计函数"></a>统计函数</h1><h2 id="Mean-平均值"><a href="#Mean-平均值" class="headerlink" title="Mean 平均值"></a>Mean 平均值</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">limbs &lt;- c(<span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>)</div><div class="line">names(limbs) &lt;- c(<span class="string">'One-Eye'</span>, <span class="string">'Peg-Leg'</span>, <span class="string">'Smitty'</span>, <span class="string">'Hook'</span>, <span class="string">'Scooter'</span>, <span class="string">'Dan'</span>, <span class="string">'Mikey'</span>, <span class="string">'Blackbeard'</span>)</div><div class="line">&gt; mean(limbs)</div><div class="line"><span class="comment"># 平均值柱状图</span></div><div class="line">&gt; barplot(limbs)</div><div class="line"><span class="comment"># 平均值柱状图 + 平均值水平线</span></div><div class="line">&gt; abline(h=mean(limbs)</div></pre></td></tr></table></figure>
<h2 id="Median-中位数"><a href="#Median-中位数" class="headerlink" title="Median 中位数"></a>Median 中位数</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&gt; limbs &lt;- c(<span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">14</span>)</div><div class="line">&gt; names(limbs) &lt;- c(<span class="string">'One-Eye'</span>, <span class="string">'Peg-Leg'</span>, <span class="string">'Smitty'</span>, <span class="string">'Hook'</span>, <span class="string">'Scooter'</span>, <span class="string">'Dan'</span>, <span class="string">'Mikey'</span>, <span class="string">'Davy Jones'</span>)</div><div class="line">&gt; mean(limbs)</div><div class="line">[<span class="number">1</span>] <span class="number">4.75</span></div><div class="line">&gt; barplot(limbs)</div><div class="line">&gt; abline(h = mean(limbs))</div></pre></td></tr></table></figure>
<blockquote>
<p>It may be factually accurate to say that our crew has an average of 4.75 limbs, but it’s probably also misleading.<br>For situations like this, it’s probably more useful to talk about the “median” value.<br>The median is calculated by sorting the values and choosing the middle one (for sets with an even number of values, the middle two values are averaged).</p>
</blockquote>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; median(limbs)</div><div class="line">[<span class="number">1</span>] <span class="number">4</span></div></pre></td></tr></table></figure>
<h2 id="Standard-Deviation-标准偏差"><a href="#Standard-Deviation-标准偏差" class="headerlink" title="Standard Deviation 标准偏差"></a>Standard Deviation 标准偏差</h2><blockquote>
<p>Statisticians use the concept of “standard deviation” from the mean to describe the range of typical values for a data set. For a group of numbers, it shows how much they typically vary from the average value. To calculate the standard deviation, you calculate the mean of the values, then subtract the mean from each number and square the result, then average those squares, and take the square root of that average.</p>
</blockquote>
<h1 id="Data-Frames"><a href="#Data-Frames" class="headerlink" title="Data Frames"></a>Data Frames</h1><blockquote>
<p>R has a structure for just this purpose: the data frame. You can think of a data frame as something akin to a database table or an Excel spreadsheet. It has a specific number of columns, each of which is expected to contain values of a particular type. It also has an indeterminate number of rows - sets of related values for each column.</p>
</blockquote>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">&gt; treasure &lt;- data.frame(weights, prices, types)</div><div class="line">&gt; print(treasure)</div><div class="line">  weights prices  types</div><div class="line"><span class="number">1</span>     <span class="number">300</span>   <span class="number">9000</span>   gold</div><div class="line"><span class="number">2</span>     <span class="number">200</span>   <span class="number">5000</span> silver</div><div class="line"><span class="number">3</span>     <span class="number">100</span>  <span class="number">12000</span>   gems</div><div class="line"><span class="number">4</span>     <span class="number">250</span>   <span class="number">7500</span>   gold</div><div class="line"><span class="number">5</span>     <span class="number">150</span>  <span class="number">18000</span>   gems</div></pre></td></tr></table></figure>
<h2 id="数据访问"><a href="#数据访问" class="headerlink" title="数据访问"></a>数据访问</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">&gt; treasure[[<span class="number">2</span>]]</div><div class="line">[<span class="number">1</span>]  <span class="number">9000</span>  <span class="number">5000</span> <span class="number">12000</span>  <span class="number">7500</span> <span class="number">18000</span></div><div class="line"></div><div class="line">&gt; treasure[[<span class="string">"weights"</span>]]</div><div class="line">[<span class="number">1</span>] <span class="number">300</span> <span class="number">200</span> <span class="number">100</span> <span class="number">250</span> <span class="number">150</span></div><div class="line"></div><div class="line">&gt; treasure$prices</div><div class="line">[<span class="number">1</span>]  <span class="number">9000</span>  <span class="number">5000</span> <span class="number">12000</span>  <span class="number">7500</span> <span class="number">18000</span></div></pre></td></tr></table></figure>
<h1 id="文件IO"><a href="#文件IO" class="headerlink" title="文件IO"></a>文件IO</h1><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; piracy &lt;- read.csv(<span class="string">"piracy.csv"</span>)</div><div class="line">&gt; gdp &lt;- read.table(<span class="string">"gdp.txt"</span>, sep=<span class="string">"  "</span>, header=<span class="literal">TRUE</span>)</div></pre></td></tr></table></figure>
<h1 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h1><h2 id="cor-test"><a href="#cor-test" class="headerlink" title="cor.test"></a>cor.test</h2><p>R can test for correlation between two vectors with the cor.test function.<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&gt; cor.test(countries$GDP, countries$Piracy)</div></pre></td></tr></table></figure></p>
<h2 id="lm"><a href="#lm" class="headerlink" title="lm"></a>lm</h2><p>if we calculate the linear model that best represents all our data points (with a certain degree of error).<br>The lm function takes a model formula, which is represented by a response variable (piracy rate), a tilde character (~), and a predictor variable (GDP). (Note that the response variable comes first.)</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; line &lt;- lm(countries$Piracy ~ countries$GDP)</div><div class="line">&gt; abline(line)</div></pre></td></tr></table></figure>
<h1 id="扩展安装"><a href="#扩展安装" class="headerlink" title="扩展安装"></a>扩展安装</h1><p>install.packages(“ggplot2”)</p>
]]></content>
      
        <categories>
            
            <category> 人工智能 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> R </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Machine Learning课程笔记Week1-基础概念]]></title>
      <url>http://geosmart.github.io/2017/07/03/Machine%20Leaning%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0Week1-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/</url>
      <content type="html"><![CDATA[<p><a href="https://www.coursera.org/learn/machine-learning/home/week/1">Coursera斯坦福大学机器学习（Machine Leaning）课程第一周</a>课程笔记</p>
<blockquote>
<p>A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.</p>
</blockquote>
<p>“对于某类任务T和性能度量P，如果一个计算机程序在T上以P衡量的性能随着经验E而自我完善，那么我们称这个计算机程序在从经验E学习。”</p>
<hr>
<a id="more"></a> 
<h1 id="机器学习定义"><a href="#机器学习定义" class="headerlink" title="机器学习定义"></a>机器学习定义</h1><p>机器学习有下面几种定义：</p>
<ul>
<li>机器学习是一门人工智能的科学，该领域的主要研究对象是人工智能，特别是如何在经验学习中改善具体算法的性能。</li>
<li>机器学习是对能通过经验自动改进的计算机算法的研究。</li>
<li>机器学习是用数据或以往的经验，以此优化计算机程序的性能标准。<blockquote>
<p>What is Machine Learning?<br>Two definitions of Machine Learning are offered. Arthur Samuel described it as: “the field of study that gives computers the ability to learn without being explicitly programmed.” This is an older, informal definition.<br>Tom Mitchell provides a more modern definition: “A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.”<br>Example: playing checkers.<br>E = the experience of playing many games of checkers<br>T = the task of playing checkers.<br>P = the probability that the program will win the next game.<br>In general, any machine learning problem can be assigned to one of two broad classifications: Supervised learning and Unsupervised learning.</p>
</blockquote>
</li>
</ul>
<h1 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h1><p>监督学习从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数预测结果。<br>监督学习的训练集要求是包括输入和输出，也可以说是特征和目标。训练集中的目标是由人标注的。  </p>
<p>常见的监督学习算法包括回归分析和统计分类。</p>
<h2 id="回归分析（连续）"><a href="#回归分析（连续）" class="headerlink" title="回归分析（连续）"></a>回归分析（连续）</h2><p>房价预测</p>
<h2 id="统计分类（离散）"><a href="#统计分类（离散）" class="headerlink" title="统计分类（离散）"></a>统计分类（离散）</h2><p>癌症良恶性判断</p>
<blockquote>
<p>分类（Classification）和回归（Regression）的区别在于输出变量的类型。<br>定量输出称为回归，或者说是连续变量（continous）预测；<br>定性输出称为分类，或者说是离散变量（discrete）预测。</p>
</blockquote>
<h1 id="非监督学习"><a href="#非监督学习" class="headerlink" title="非监督学习"></a>非监督学习</h1><p>We can derive this structure by clustering the data based on relationships among<br>the variables in the data.</p>
<p>应用场景：</p>
<ul>
<li>市场细分</li>
<li>组织计算集群</li>
<li>社交网络分析</li>
<li>天文数据分析</li>
</ul>
<p>无监督学习与监督学习相比，训练集没有人为标注的结果。常见的无监督学习算法有聚类。</p>
<h2 id="聚类问题"><a href="#聚类问题" class="headerlink" title="聚类问题"></a>聚类问题</h2><p>基因数据分组</p>
<h2 id="非聚类问题"><a href="#非聚类问题" class="headerlink" title="非聚类问题"></a>非聚类问题</h2><p>鸡尾酒会问题（音频分离）</p>
<h1 id="原型工具"><a href="#原型工具" class="headerlink" title="原型工具"></a>原型工具</h1><h2 id="matlab"><a href="#matlab" class="headerlink" title="matlab"></a>matlab</h2><h2 id="octave"><a href="#octave" class="headerlink" title="octave"></a><a href="https://www.gnu.org/software/octave/doc/interpreter/">octave</a></h2>]]></content>
      
        <categories>
            
            <category> 人工智能 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Machine Leaning </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[TensorFlow实现神经网络]]></title>
      <url>http://geosmart.github.io/2017/07/03/TensorFlow%E5%AE%9E%E7%8E%B0%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      <content type="html"><![CDATA[<p><a href="http://playground.tensorflow.org/">神经网络可视化示例-TensorFlow游乐场</a><br>一个最简单的神经元的结构的输出就是所有输入的<strong>加权和</strong>，而不同输入的权重就是神经元的参数。神经网络的优化过程就是优化神经元中参数的取值过程。</p>
<hr>
<a id="more"></a> 
<h1 id="神经网络数据结构"><a href="#神经网络数据结构" class="headerlink" title="神经网络数据结构"></a>神经网络数据结构</h1><p>第一层是输入层，代表特征向量中每一个特征的取值；<br>在输入层和输出层之间的神经网络叫隐藏层；<br>一般一个神经网络的隐藏层越多，这个神经网络就越’深’；</p>
<p><img src="三层神经网络结构图.jpg" alt="判断零件是否合格的三层神经网络结构图"></p>
<h1 id="神经网络解决分类问题的步骤："><a href="#神经网络解决分类问题的步骤：" class="headerlink" title="神经网络解决分类问题的步骤："></a>神经网络解决分类问题的步骤：</h1><p>神经网络解决分类问题主要分为以下4个步骤：</p>
<ol>
<li>提取问题中实体的特征向量作为神经网络的输入。</li>
<li>定义神经网络的结构，并定义如何从神经网络的输入得到输出；</li>
<li>通过训练数据来调整神经网络中参数的取值，这就是训练神经网络的过程。</li>
<li>使用训练好的神经网络来预测未知数据；</li>
</ol>
<h1 id="前向传播算法"><a href="#前向传播算法" class="headerlink" title="前向传播算法"></a>前向传播算法</h1><h2 id="神经元"><a href="#神经元" class="headerlink" title="神经元"></a>神经元</h2><p>神经元是构成一个神经网络的最小单元。</p>
<ul>
<li>一个神经元有多个输入和一个输出；</li>
<li>每个神经元的输入既可以是其他神经元的输出，也可以是整个个神经网络的输入；</li>
<li>神经网络的结构即不同神经元之间的连接结构；<br>一个最简单的神经元的结构的输出就是所有输入的<strong>加权和</strong>，而不同输入的权重就是神经元的参数。神经网络的优化过程就是优化神经元中参数的取值过程。</li>
</ul>
<h2 id="前向传播算法（forward-propagation）"><a href="#前向传播算法（forward-propagation）" class="headerlink" title="前向传播算法（forward-propagation）"></a>前向传播算法（forward-propagation）</h2><p>计算神经网络的前向传播算法需3部分信息：</p>
<ol>
<li>神经网络的输入，即从实体中提取的特征向量；</li>
<li>神经网络的连接结构</li>
<li>神经元中的参数；</li>
</ol>
<p>给定神经网络的输入，神经网络的结构以及边上权重，就可以通过前向传播算法来计算神经网络的输出。<br><img src="神经网络前向传播算法示意图.jpg" alt="神经网络前向传播算法示意图"><br>在TensorFlow中实现<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># matmul为矩阵乘法函数</span></div><div class="line">a= tf.matmul(x1 , w1)</div><div class="line">y= tf.matmul(a , w2)</div></pre></td></tr></table></figure></p>
<p>前向传播算法可以表示为矩阵乘法，将输入x1,x2组织成一个1x2的矩阵x=[x1,x2]，而W(1)组织成一个2x3的矩阵：<br><img src="前向传播算法计算公式.jpg" alt="前向传播算法计算公式"></p>
<h1 id="神经网络参数与TensorFlow变量"><a href="#神经网络参数与TensorFlow变量" class="headerlink" title="神经网络参数与TensorFlow变量"></a>神经网络参数与TensorFlow变量</h1><h1 id="通过TensorFlow训练神经网络模型"><a href="#通过TensorFlow训练神经网络模型" class="headerlink" title="通过TensorFlow训练神经网络模型"></a>通过TensorFlow训练神经网络模型</h1><h1 id="完整神经网络示例程序"><a href="#完整神经网络示例程序" class="headerlink" title="完整神经网络示例程序"></a>完整神经网络示例程序</h1>]]></content>
      
        <categories>
            
            <category> 人工智能 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[TensorFlow基础概念]]></title>
      <url>http://geosmart.github.io/2017/07/03/TensorFlow%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/</url>
      <content type="html"><![CDATA[<p>TensorFlow最重要的两个概念-Tensor和Flow；<br>Tensor就是张量，可简单理解为多维数组；<br>Flow直观表达Tensor之间通过计算相互转换的过程；<br>TensorFlow是一个通过计算图的形式来表述计算的编程系统。TensorFlow中的每个计算都是计算图上的一个节点，而节点之间的边描述了计算之间的依赖关系。</p>
<hr>
<a id="more"></a> 
<h1 id="TensorFlow的计算模型-计算图"><a href="#TensorFlow的计算模型-计算图" class="headerlink" title="TensorFlow的计算模型-计算图"></a>TensorFlow的计算模型-计算图</h1><h2 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h2><ul>
<li>tf.get_default_grapph()：获取当前默认计算图；</li>
<li>tf.Graph()：生成新的计算图；</li>
<li>tf.Graph.device(‘device’)：指定运行计算的设备；</li>
</ul>
<h1 id="TensorFlow的数据模型-张量"><a href="#TensorFlow的数据模型-张量" class="headerlink" title="TensorFlow的数据模型-张量"></a>TensorFlow的数据模型-张量</h1><p>TensorFlow中所有运算的输入、输出都是张量（Tensor）。张量本身并不存储任何数据，它是对运算结果的引用。Tensor可简单理解为多维数组； </p>
<ul>
<li>零阶张量-标量（scalar）</li>
<li>第一阶张量-向量（vector）</li>
<li>第n阶张量（n维数组）</li>
</ul>
<p>TensorFlow中的每一个计算是计算图上的一个节点，而节点之间的边描述了计算之间的依赖关系；<br>不同计算图中的张量和运算都不会共享；</p>
<h2 id="张量的数据结构"><a href="#张量的数据结构" class="headerlink" title="张量的数据结构"></a>张量的数据结构</h2><p>示例：Tensor( “add:0” , shape=(2,) , dtype=float32 )</p>
<h3 id="名字（name）"><a href="#名字（name）" class="headerlink" title="名字（name）"></a>名字（name）</h3><p>node:src_output</p>
<h3 id="维度（shape）"><a href="#维度（shape）" class="headerlink" title="维度（shape）"></a>维度（shape）</h3><h3 id="类型（type）"><a href="#类型（type）" class="headerlink" title="类型（type）"></a>类型（type）</h3><ul>
<li>实数（tf.float32、tf.float64）</li>
<li>整数（tf.int8、tf.int16、tf.int32、tf.int64、tf.uint8）</li>
<li>布尔型（tf.bool）</li>
<li>复数（tf.complex64、tf.complex128） </li>
</ul>
<h2 id="张量的使用"><a href="#张量的使用" class="headerlink" title="张量的使用"></a>张量的使用</h2><p>通过Tensor可更好的组织TensorFlow程序</p>
<ul>
<li>对中间结果的引用，提供代码可读性</li>
<li>当计算图构造完成后，通过张量获取计算结果</li>
</ul>
<h1 id="TensorFlow的运算模型-会话（session）"><a href="#TensorFlow的运算模型-会话（session）" class="headerlink" title="TensorFlow的运算模型-会话（session）"></a>TensorFlow的运算模型-会话（session）</h1><h2 id="session的使用模式"><a href="#session的使用模式" class="headerlink" title="session的使用模式"></a>session的使用模式</h2><h3 id="明确调用会话生成函数和关闭会话函数"><a href="#明确调用会话生成函数和关闭会话函数" class="headerlink" title="明确调用会话生成函数和关闭会话函数"></a>明确调用会话生成函数和关闭会话函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">session=tf.Session()</div><div class="line">sess.run(...)</div><div class="line">sess.close()</div></pre></td></tr></table></figure>
<h3 id="Python上下文管理器管理会话"><a href="#Python上下文管理器管理会话" class="headerlink" title="Python上下文管理器管理会话"></a>Python上下文管理器管理会话</h3><p>将所有计算放在with内部<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess</div><div class="line">    sess.run(...)</div></pre></td></tr></table></figure></p>
<p>优点：  </p>
<ul>
<li>解决异常退出时资源释放问题，</li>
<li>解决忘记调用Session.close函数而产生的资源泄露问题；</li>
</ul>
<h3 id="默认会话"><a href="#默认会话" class="headerlink" title="默认会话"></a>默认会话</h3><ul>
<li>手动指定session为默认会话</li>
<li>交互式环境以tf.InteractiveSession配置会话</li>
</ul>
<h2 id="ConfigProto配置会话"><a href="#ConfigProto配置会话" class="headerlink" title="ConfigProto配置会话"></a>ConfigProto配置会话</h2><h3 id="常用参数"><a href="#常用参数" class="headerlink" title="常用参数"></a>常用参数</h3><ul>
<li>allow_soft_placement（bool）：当运算无法被当前GPU支持时，可以自动切换到CPU上；</li>
<li>log_device_placemnet（bool）：日志中将会记录每个节点被安排在那个设备上以方便调试。</li>
</ul>
<h3 id="ConfigProto可配参数"><a href="#ConfigProto可配参数" class="headerlink" title="ConfigProto可配参数"></a>ConfigProto可配参数</h3><ul>
<li>并行线程数</li>
<li>GPU分配策略</li>
<li>运算超时时间</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 人工智能 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[TensorFlow环境搭建]]></title>
      <url>http://geosmart.github.io/2017/07/01/TensorFlow%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<p>将近一年未更新博客，期间专注做互联网金融领域的身份识别类产品（身份证OCR、活体检测、人脸比对），现在产品线趋于成熟，可以静下心来研究神往已久的深度学习了。</p>
<hr>
<a id="more"></a>
<h1 id="Anaconda安装"><a href="#Anaconda安装" class="headerlink" title="Anaconda安装"></a>Anaconda安装</h1><p>Anaconda是一个和Canopy类似的Python科学计算环境，但用起来更加方便。</p>
<ul>
<li>下载：<code>wget https://repo.continuum.io/archive/Anaconda3-4.4.0-Linux-x86_64.sh</code></li>
<li>安装：<code>bash Anaconda3-4.4.0-Linux-x86_64.sh</code></li>
<li>配置：<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 将anaconda的bin目录加入PATH</span></div><div class="line"><span class="built_in">echo</span> <span class="string">'export PATH="~/anaconda3/bin:$PATH"'</span> &gt;&gt; ~/.bashrc</div><div class="line"><span class="comment"># 更新bashrc以立即生效</span></div><div class="line"><span class="built_in">source</span> ~/.bashrc</div><div class="line">配置好PATH后，可以通过 <span class="built_in">which</span> conda 或 conda --version 命令检查是否正确；</div><div class="line"><span class="comment"># 配置镜像</span></div><div class="line">安装完以后，打开Anaconda Prompt，输入清华的仓库镜像，更新包更快；</div><div class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</div><div class="line">conda config --<span class="built_in">set</span> show_channel_urls yes</div></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="TensorFlow安装"><a href="#TensorFlow安装" class="headerlink" title="TensorFlow安装"></a>TensorFlow安装</h1><ul>
<li>打开Anaconda Prompt，输入：<code>conda create -n tensorflow python=3.6</code></li>
<li>查看已安装环境列表: <code>conda env list</code>；</li>
<li>激活环境：<ul>
<li>linux：<code>source activate tensorflow</code>；</li>
<li>windows：<code>activate tensorflow</code>；</li>
</ul>
</li>
<li>安装tensorflow的CPU版本，<ul>
<li>linux安装：<code>pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.2.1-cp36-cp36m-linux_x86_64.whl</code></li>
<li>windows安装：<code>pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.2.1-cp36-cp36m-win_amd64.whl</code></li>
</ul>
</li>
</ul>
<h1 id="HelloWorld示例"><a href="#HelloWorld示例" class="headerlink" title="HelloWorld示例"></a>HelloWorld示例</h1><p>一个TensorFlow示例实现两个向量求和<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line">a=tf.constant([<span class="number">1.0</span>,<span class="number">2.0</span>],name=<span class="string">"a"</span>)</div><div class="line">b=tf.constant([<span class="number">2.0</span>,<span class="number">3.0</span>],name=<span class="string">"b"</span>)</div><div class="line">result=a+b</div><div class="line">sess=tf.Session() </div><div class="line">sess.run(result)</div></pre></td></tr></table></figure></p>
<h1 id="开发环境"><a href="#开发环境" class="headerlink" title="开发环境"></a>开发环境</h1><p>IDE：pycharm 2017<br>注册服务器：<a href="http://idea.iteblog.com/key.php">http://idea.iteblog.com/key.php</a>  </p>
<h2 id="pycharm远程调试"><a href="#pycharm远程调试" class="headerlink" title="pycharm远程调试"></a>pycharm远程调试</h2><p>以pycharm配置remote interpreter远程开发调试，并以ssh自动上传本地程序到测试/生产环境；<br>配置参考<a href="https://blog.jetbrains.com/pycharm/2015/03/feature-spotlight-python-remote-development-with-pycharm/">feature-spotlight-python-remote-development-with-pycharm</a></p>
<h1 id="归档环境"><a href="#归档环境" class="headerlink" title="归档环境"></a>归档环境</h1><p><a href="http://jupyter.org/">Jupyter Notebook</a><br><a href="http://nbviewer.jupyter.org/github/masinoa/machine_learning/tree/master/">Jupyter Notebook-machine_learning</a></p>
<ol>
<li>一次运行, 多次阅读,保存运行结果</li>
<li>交互式编程, 边看边写</li>
<li>可以添加各种元素,比如图片,视频, 链接, 文档(比代码注释要好看), 相当于PPT<br><a href="http://python.jobbole.com/87527/?repeat=w3tc">ref</a><h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 人工智能 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Python </tag>
            
            <tag> TensorFlow </tag>
            
            <tag> Anaconda </tag>
            
            <tag> Jupyter </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[实时计算系统Storm学习笔记]]></title>
      <url>http://geosmart.github.io/2016/09/13/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9FStorm%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<h1 id="Storm简介"><a href="#Storm简介" class="headerlink" title="Storm简介"></a>Storm简介</h1><p>Storm是一个开源的分布式实时计算系统，可以简单、可靠的处理大量的数据流。<br>而且支持水平扩展，具有高容错性，保证每个消息都会得到处理。<br>Storm处理速度很快（在一个小集群中，每个结点每秒可以处理数以百万计的消息）。<br>Storm的部署和运维都很便捷，更为重要的是可以使用任意编程语言来开发应用。</p>
<p>目前国内一般采用阿里巴巴开源的JStorm版本；</p>
<hr>
<a id="more"></a>
<p><a href="http://os.51cto.com/art/201312/422708.htm">参考教程</a><br><a href="http://ifeve.com/getting-started-with-stom-index/">getting-started-with-stom-index</a></p>
<h1 id="Storm典型应用案例？"><a href="#Storm典型应用案例？" class="headerlink" title="Storm典型应用案例？"></a>Storm典型应用案例？</h1><ul>
<li>数据处理流；不像其它的流处理系统，Storm不需要中间队列。</li>
<li>连续计算：连续发送数据到客户端，使它们能够实时更新并显示结果，如网站指标。</li>
<li>分布式远程过程调用：频繁的CPU密集型操作并行化。</li>
</ul>
<h1 id="Storm组件"><a href="#Storm组件" class="headerlink" title="Storm组件"></a>Storm组件</h1><p>在Storm集群中，有两类节点：主节点master node和工作节点worker nodes。主节点运行着一个叫做Nimbus的守护进程。这个守护进程负责在集群中分发代码，为工作节点分配任务，并监控故障。Supervisor守护进程作为拓扑的一部分运行在工作节点上。一个Storm拓扑结构在不同的机器上运行着众多的工作节点。<br>因为Storm在Zookeeper或本地磁盘上维持所有的集群状态，守护进程可以是无状态的而且失效或重启时不会影响整个系统的健康；</p>
<ul>
<li>NimBus: 责资源分配和任务调度</li>
<li>Supervisor:负责接受nimbus分配的任务，启动和停止属于自己管理的worker进程</li>
<li>Work:运行具体处理组件逻辑的进程</li>
<li>Task: worker中每一个spout/bolt的线程称为一个task</li>
</ul>
<h2 id="0mq"><a href="#0mq" class="headerlink" title="0mq"></a>0mq</h2><p>在系统底层，Storm使用了zeromq(0mq)。这是一种先进的，可嵌入的网络通讯库，它提供的绝妙功能使Storm成为可能。<br>zeromq的特性：</p>
<ul>
<li>一个并发架构的Socket库</li>
<li>对于集群产品和超级计算，比TCP要快</li>
<li>可通过inproc（进程内）, IPC（进程间）, TCP和multicast(多播协议)通信</li>
<li>异步I / O的可扩展的多核消息传递应用程序</li>
<li>利用扇出(fanout), 发布订阅（PUB-SUB）,管道（pipeline）, 请求应答（REQ-REP），等方式实现N-N连接</li>
</ul>
<p><img src="storm_framework.jpg" alt="storm整体框架"></p>
<ul>
<li>客户端提交拓扑到nimbus。</li>
<li>Nimbus针对该拓扑建立本地的目录根据topology的配置计算task，分配task，在zookeeper上建立assignments节点存储task和supervisor机器节点中woker的对应关系；</li>
<li>在zookeeper上创建taskbeats节点来监控task的心跳；启动topology。</li>
<li>Supervisor去zookeeper上获取分配的tasks，启动多个woker进行，每个woker生成task，一个task一个线程；根据topology信息初始化建立task之间的连接;Task和Task之间是通过zeroMQ管理的；后整个拓扑运行起来。</li>
</ul>
<h1 id="Storm特点"><a href="#Storm特点" class="headerlink" title="Storm特点"></a>Storm特点</h1><p><a href="storm特性.pdf">storm特性</a><br>使用场景：如实时分析，在线机器学习，持续计算，分布式RPC，ETL等等。</p>
<p>Storm有如下特点：</p>
<h2 id="编程模型简单"><a href="#编程模型简单" class="headerlink" title="编程模型简单"></a>编程模型简单</h2><p>在大数据处理方面相信大家对hadoop已经耳熟能详，基于Google Map/Reduce来实现的Hadoop为开发者提供了map、reduce原语，使并行批处理程序变得非常地简单和优美。<br>同样，Storm也为大数据的实时计算提供了一些简单优美的原语，这大大降低了开发并行实时处理的任务的复杂性，帮助你快速、高效的开发应用。</p>
<p>##可扩展<br>在Storm集群中真正运行topology的主要有三个实体：工作进程、线程和任务。<br>Storm集群中的每台机器上都可以运行多个工作进程，每个工作进程又可创建多个线程，每个线程可以执行多个任务，任务是真正进行数据处理的实体，我们开发的spout、bolt就是作为一个或者多个任务的方式执行的。<br>因此，计算任务在多个线程、进程和服务器之间并行进行，支持灵活的水平扩展。</p>
<h2 id="高可靠性"><a href="#高可靠性" class="headerlink" title="高可靠性"></a>高可靠性</h2><p>Storm可以保证spout发出的每条消息都能被“完全处理”，这也是直接区别于其他实时系统的地方，如S4。<br>请注意，spout发出的消息后续可能会触发产生成千上万条消息，可以形象的理解为一棵消息树，其中spout发出的消息为树根，Storm会跟踪这棵消息树的处理情况，只有当这棵消息树中的所有消息都被处理了，Storm才会认为spout发出的这个消息已经被“完全处理”。如果这棵消息树中的任何一个消息处理失败了，或者整棵消息树在限定的时间内没有“完全处理”，那么spout发出的消息就会重发。</p>
<p>考虑到尽可能减少对内存的消耗，Storm并不会跟踪消息树中的每个消息，而是采用了一些特殊的策略，它把消息树当作一个整体来跟踪，对消息树中所有消息的唯一id进行异或计算，通过是否为零来判定spout发出的消息是否被“完全处理”，这极大的节约了内存和简化了判定逻辑，后面会对这种机制进行详细介绍。</p>
<p>这种模式，每发送一个消息，都会同步发送一个ack/fail，对于网络的带宽会有一定的消耗，如果对于可靠性要求不高，可通过使用不同的emit接口关闭该模式。</p>
<p>上面所说的，Storm保证了每个消息至少被处理一次，但是对于有些计算场合，会严格要求每个消息只被处理一次，幸而Storm的0.7.0引入了事务性拓扑，解决了这个问题。</p>
<h2 id="高容错性"><a href="#高容错性" class="headerlink" title="高容错性"></a>高容错性</h2><p>如果在消息处理过程中出了一些异常，Storm会重新安排这个出问题的处理单元。Storm保证一个处理单元永远运行（除非你显式杀掉这个处理单元）。</p>
<p>当然，如果处理单元中存储了中间状态，那么当处理单元重新被Storm启动的时候，需要应用自己处理中间状态的恢复。</p>
<h2 id="支持多种编程语言"><a href="#支持多种编程语言" class="headerlink" title="支持多种编程语言"></a>支持多种编程语言</h2><p>除了用java实现spout和bolt，你还可以使用任何你熟悉的编程语言来完成这项工作，这一切得益于Storm所谓的多语言协议。多语言协议是Storm内部的一种特殊协议，允许spout或者bolt使用标准输入和标准输出来进行消息传递，传递的消息为单行文本或者是json编码的多行。</p>
<p>Storm支持多语言编程主要是通过ShellBolt, ShellSpout和ShellProcess这些类来实现的，这些类都实现了IBolt 和 ISpout接口，以及让shell通过java的ProcessBuilder类来执行脚本或者程序的协议。</p>
<p>可以看到，采用这种方式，每个tuple在处理的时候都需要进行json的编解码，因此在吞吐量上会有较大影响。</p>
<p>##支持本地模式<br>Storm有一种“本地模式”，也就是在进程中模拟一个Storm集群的所有功能，以本地模式运行topology跟在集群上运行topology类似，这对于我们开发和测试来说非常有用。</p>
<h2 id="高效"><a href="#高效" class="headerlink" title="高效"></a>高效</h2><p>用ZeroMQ作为底层消息队列, 保证消息能快速被处理。</p>
<h1 id="Storm基本慨念"><a href="#Storm基本慨念" class="headerlink" title="Storm基本慨念"></a>Storm基本慨念</h1><p>Storm集群和Hadoop集群表面上看很类似。但是Hadoop上运行的是MapReduce jobs，而在Storm上运行的是拓扑（topology），这两者之间是非常不一样的。Topology的定义是一个Thrift结构，并且Nimbus就是一个Thrift服务， 你可以提交由任何语言创建的topology。</p>
<h2 id="Topologies"><a href="#Topologies" class="headerlink" title="Topologies"></a>Topologies</h2><p>一个topology是spouts和bolts组成的图， 通过stream groupings将图中的spouts和bolts连接起来;<br>一个topology会一直运行直到你手动kill掉，Storm自动重新分配执行失败的任务， 并且Storm可以保证你不会有数据丢失（如果开启了高可靠性的话）。如果一些机器意外停机它上面的所有任务会被转移到其他机器上。<br>运行一个topology很简单。首先，把你所有的代码以及所依赖的jar打进一个jar包。然后运行类似下面的这个命令：<br>storm jar all-my-code.jar backtype.storm.MyTopology arg1 arg2<br>这个命令会运行主类: backtype.strom.MyTopology, 参数是arg1, arg2。这个类的main函数定义这个topology并且把它提交给Nimbus。storm jar负责连接到Nimbus并且上传jar包。</p>
<p>Topology的定义是一个Thrift结构，并且Nimbus就是一个Thrift服务， 你可以提交由任何语言创建的topology。上面的方面是用JVM-based语言提交的最简单的方法。</p>
<h2 id="Streams"><a href="#Streams" class="headerlink" title="Streams"></a>Streams</h2><p>消息流stream是storm里的关键抽象。一个消息流是一个没有边界的tuple序列， 而这些tuple序列会以一种分布式的方式并行地创建和处理。通过对stream中tuple序列中每个字段命名来定义stream。在默认的情况下，tuple的字段类型可以是：integer，long，short， byte，string，double，float，boolean和byte array。你也可以自定义类型（只要实现相应的序列化器）。</p>
<p>每个消息流在定义的时候会被分配给一个id，因为单向消息流使用的相当普遍， OutputFieldsDeclarer定义了一些方法让你可以定义一个stream而不用指定这个id。在这种情况下这个stream会分配个值为‘default’默认的id 。</p>
<p>Storm提供的最基本的处理stream的原语是spout和bolt。你可以实现spout和bolt提供的接口来处理你的业务逻辑。</p>
<h2 id="Nimbus"><a href="#Nimbus" class="headerlink" title="Nimbus"></a>Nimbus</h2><p>nimbus 雨云，主节点的守护进程，负责为工作节点分发任务。</p>
<h2 id="Spouts（消息源）"><a href="#Spouts（消息源）" class="headerlink" title="Spouts（消息源）"></a>Spouts（消息源）</h2><p><code>spout 龙卷，读取原始数据为bolt提供数据</code>；<br>消息源spout是Storm里面一个topology里面的消息生产者。一般来说消息源会从一个外部源读取数据（如MQ）并且向topology里面发出消息：tuple。Spout可以是可靠的也可以是不可靠的。如果这个tuple没有被storm成功处理，可靠的消息源spouts可以重新发射一个tuple， 但是不可靠的消息源spouts一旦发出一个tuple就不能重发了。</p>
<p>消息源可以发射多条消息流stream。使用OutputFieldsDeclarer.declareStream来定义多个stream，然后使用SpoutOutputCollector来发射指定的stream。</p>
<p>Spout类里面最重要的方法是nextTuple。要么发射一个新的tuple到topology里面或者简单的返回如果已经没有新的tuple。要注意的是nextTuple方法不能阻塞，因为storm在同一个线程上面调用所有消息源spout的方法。</p>
<p>另外两个比较重要的spout方法是ack和fail。storm在检测到一个tuple被整个topology成功处理的时候调用ack，否则调用fail。storm只对可靠的spout调用ack和fail。</p>
<h2 id="消息流中的Tuple"><a href="#消息流中的Tuple" class="headerlink" title="消息流中的Tuple"></a>消息流中的Tuple</h2><p>Tuple是一次消息传递的基本单元，tuple里的每个字段一个名字,并且不同tuple的对应字段的类型必须一样。<br>tuple的字段类型可以是： integer, long, short, byte, string, double, float, boolean和byte array；<br>还可以自定义类型 — 只要实现对应的序列化器。<br>每个消息流中包括若干个tuple。</p>
<h2 id="Bolts（消息处理者）"><a href="#Bolts（消息处理者）" class="headerlink" title="Bolts（消息处理者）"></a>Bolts（消息处理者）</h2><p><code>bolt 雷电，从spout或其它bolt接收数据，并处理数据，处理结果可作为其它bolt的数据源或最终结果</code>；<br>所有的消息处理逻辑被封装在bolts里面。Bolts可以做很多事情：过滤，聚合，查询数据库等等。</p>
<p>Bolts可以简单的做消息流的传递。复杂的消息流处理往往需要很多步骤，从而也就需要经过很多bolts。比如算出一堆图片里面被转发最多的图片就至少需要两步：第一步算出每个图片的转发数量。第二步找出转发最多的前10个图片。（如果要把这个过程做得更具有扩展性那么可能需要更多的步骤）。<br>Bolts可以发射多条消息流， 使用OutputFieldsDeclarer.declareStream定义stream，使用OutputCollector.emit来选择要发射的stream。</p>
<p>Bolts的主要方法是execute, 它以一个tuple作为输入，bolts使用OutputCollector来发射tuple，bolts必须要为它处理的每一个tuple调用OutputCollector的ack方法，以通知Storm这个tuple被处理完成了，从而通知这个tuple的发射者spouts。 一般的流程是： bolts处理一个输入tuple,  发射0个或者多个tuple, 然后调用ack通知storm自己已经处理过这个tuple了。storm提供了一个IBasicBolt会自动调用ack。</p>
<h2 id="Stream-groupings（消息分发策略）"><a href="#Stream-groupings（消息分发策略）" class="headerlink" title="Stream groupings（消息分发策略）"></a>Stream groupings（消息分发策略）</h2><p>定义一个topology的其中一步是定义每个bolt接收什么样的流作为输入。stream grouping就是用来定义一个stream应该如何分配数据给bolts上面的多个tasks。</p>
<p>Storm里面有7种类型的stream grouping</p>
<pre><code>1. Shuffle Grouping: 随机分组， 随机派发stream里面的tuple，保证每个bolt接收到的tuple数目大致相同。
2. Fields Grouping：按字段分组， 比如按userid来分组， 具有同样userid的tuple会被分到相同的Bolts里的一个task， 而不同的userid则会被分配到不同的bolts里的task。
3. All Grouping：广播发送，对于每一个tuple，所有的bolts都会收到。
4. Global Grouping：全局分组， 这个tuple被分配到storm中的一个bolt的其中一个task。再具体一点就是分配给id值最低的那个task。
5. Non Grouping：不分组，这个分组的意思是说stream不关心到底谁会收到它的tuple。目前这种分组和Shuffle grouping是一样的效果， 有一点不同的是storm会把这个bolt放到这个bolt的订阅者同一个线程里面去执行。
6. Direct Grouping： 直接分组， 这是一种比较特别的分组方法，用这种分组意味着消息的发送者指定由消息接收者的哪个task处理这个消息。 只有被声明为Direct Stream的消息流可以声明这种分组方法。而且这种消息tuple必须使用emitDirect方法来发射。消息处理者可以通过TopologyContext来获取处理它的消息的task的id （OutputCollector.emit方法也会返回task的id）。
7. Local or shuffle grouping：如果目标bolt有一个或者多个task在同一个工作进程中，tuple将会被随机发生给这些tasks。否则，和普通的Shuffle Grouping行为一致。
</code></pre><h2 id="Reliability"><a href="#Reliability" class="headerlink" title="Reliability"></a>Reliability</h2><p>Storm保证每个tuple会被topology完整的执行。Storm会追踪由每个spout tuple所产生的tuple树（一个bolt处理一个tuple之后可能会发射别的tuple从而形成树状结构），并且跟踪这棵tuple树什么时候成功处理完。每个topology都有一个消息超时的设置，如果storm在这个超时的时间内检测不到某个tuple树到底有没有执行成功， 那么topology会把这个tuple标记为执行失败，并且过一会儿重新发射这个tuple。</p>
<p>为了利用Storm的可靠性特性，在你发出一个新的tuple以及你完成处理一个tuple的时候你必须要通知storm。这一切是由OutputCollector来完成的。通过emit方法来通知一个新的tuple产生了，通过ack方法通知一个tuple处理完成了。</p>
<h2 id="Tasks"><a href="#Tasks" class="headerlink" title="Tasks"></a>Tasks</h2><p>每一个spout和bolt会被当作很多task在整个集群里执行。<br>每一个executor对应到一个线程，在这个线程上运行多个task，而stream grouping则是定义怎么从一堆task发射tuple到另外一堆task。<br>你可以调用TopologyBuilder类的setSpout和setBolt来设置并行度（也就是有多少个task）。</p>
<h2 id="Workers"><a href="#Workers" class="headerlink" title="Workers"></a>Workers</h2><p>一个topology可能会在一个或者多个worker（工作进程）里面执行，每个worker是一个物理JVM并且执行整个topology的一部分。<br>比如，对于并行度是300的topology来说，如果我们使用50个工作进程来执行，那么每个工作进程会处理其中的6个tasks。<br>Storm会尽量均匀的工作分配给所有的worker。</p>
<h2 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h2><p>Storm里面有一堆参数可以配置来调整Nimbus, Supervisor以及正在运行的topology的行为，一些配置是系统级别的，一些配置是topology级别的。<br>default.yaml里面有所有的默认配置。你可以通过定义个storm.yaml在你的classpath里来覆盖这些默认配置。并且你也可以在代码里面设置一些topology相关的配置信息（使用StormSubmitter）。</p>
]]></content>
      
        <categories>
            
            <category> 后端技术 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Storm </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Centos7安装MySQL5.6]]></title>
      <url>http://geosmart.github.io/2016/09/10/Centos7%E5%AE%89%E8%A3%85MySQL5-6/</url>
      <content type="html"><![CDATA[<p>Centos7系统，以rpm方式安装MySQL5.6</p>
<hr>
<a id="more"></a>
<p><a href="http://blog.csdn.net/liumm0000/article/details/18841197/">参考教程</a></p>
<h1 id="卸载MySQL"><a href="#卸载MySQL" class="headerlink" title="卸载MySQL"></a>卸载MySQL</h1><p>rpm -qa | grep MySQL<br>rpm -e –nodeps mysql MySQL-server-5<br>rpm -e –allmatches MySQL-client-5.6.33-1.el7.x86_64<br>rpm -e –allmatches MySQL-devel-5.6.33-1.el7.x86_64<br>rpm -e –allmatches MySQL-server-5.6.33-1.el7.x86_64<br>chkconfig –del mysql<br>rm -rf /user/local/mysql<br>rm -rf /etc/my.cnf<br>rm -rf /var/lib/mysql</p>
<h1 id="准备mysql安装文件"><a href="#准备mysql安装文件" class="headerlink" title="准备mysql安装文件"></a>准备mysql安装文件</h1><p>下载 mysql包：<code>wget http://cdn.mysql.com//Downloads/MySQL-5.6/mysql-5.6.33-winx64.zip</code><br>解压缩：<code>tar -xvf mysql-5.6.33-winx64.zip</code></p>
<h1 id="安装MySQL"><a href="#安装MySQL" class="headerlink" title="安装MySQL"></a>安装MySQL</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">su mysql</div><div class="line">rpm -ivh MySQL-server-5.6.33-1.el7.x86_64.rpm</div><div class="line">rpm -ivh MySQL-devel-5.6.33-1.el7.x86_64.rpm</div><div class="line">rpm -ivh MySQL-client-5.6.33-1.el7.x86_64.rpm</div></pre></td></tr></table></figure>
<h1 id="修改配置文件位置"><a href="#修改配置文件位置" class="headerlink" title="修改配置文件位置"></a>修改配置文件位置</h1><p><code>cp /usr/share/mysql/my-default.cnf /etc/my.cnf</code></p>
<h1 id="初始化MySQL及设置密码"><a href="#初始化MySQL及设置密码" class="headerlink" title="初始化MySQL及设置密码"></a>初始化MySQL及设置密码</h1><p>安装server会自动执行数据库初始化（perl）：/usr/bin/mysql_install_db<br>启动服务：service mysql start<br>查看默认密码：<code>cat /root/.mysql_secret</code><br>修改root密码：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mysql -uroot -pFiXBgAhVDgythr6B</div><div class="line">SET PASSWORD = PASSWORD(<span class="string">'root'</span>);   </div><div class="line"><span class="built_in">exit</span></div></pre></td></tr></table></figure></p>
<h1 id="允许远程登陆"><a href="#允许远程登陆" class="headerlink" title="允许远程登陆"></a>允许远程登陆</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">mysql -uroot -proot</div><div class="line"><span class="keyword">use</span> mysql;</div><div class="line"><span class="keyword">update</span> <span class="keyword">user</span> <span class="keyword">set</span> host=<span class="string">'%'</span> <span class="keyword">where</span> <span class="keyword">user</span>=<span class="string">'root'</span> <span class="keyword">and</span> host=<span class="string">'localhost'</span>;</div><div class="line"><span class="keyword">flush</span> <span class="keyword">privileges</span>;</div><div class="line">exit</div></pre></td></tr></table></figure>
<h1 id="设置开机自启动"><a href="#设置开机自启动" class="headerlink" title="设置开机自启动"></a>设置开机自启动</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">chkconfig mysql on</div><div class="line">chkconfig --list | grep mysql</div></pre></td></tr></table></figure>
<h1 id="配置-etc-my-cnf"><a href="#配置-etc-my-cnf" class="headerlink" title="配置/etc/my.cnf"></a>配置/etc/my.cnf</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#  whereis my.ini</span></div><div class="line">[server]</div><div class="line"><span class="built_in">bind</span>-address           = 0.0.0.0</div><div class="line">character-set-server   = utf8</div><div class="line">collation-server       = utf8_unicode_ci</div><div class="line">init_connect           = <span class="string">'SET NAMES utf8'</span></div><div class="line">max_connections = 5000</div><div class="line">max_allowed_packet = 20M</div><div class="line">max_connect_errors= 1000</div><div class="line">lower_case_table_names=2</div><div class="line"></div><div class="line">[mysqld]</div><div class="line">data=/usr/<span class="built_in">local</span>/mysql/data</div><div class="line">socket=/var/lib/mysql/mysql.sock </div><div class="line"></div><div class="line">innodb_file_per_table = 1</div><div class="line">innodb_flush_method=O_DIRECT</div><div class="line">innodb_log_file_size=1G</div><div class="line">innodb_buffer_pool_size=4G</div><div class="line"></div><div class="line">[mysqld_safe]</div><div class="line"><span class="built_in">log</span>-error=/var/<span class="built_in">log</span>/mysqld.log</div><div class="line">long_query_time =1</div><div class="line"><span class="built_in">log</span>-slow-queries=slowqueris.log</div><div class="line"><span class="built_in">log</span>-queries-not-using-indexes = nouseindex.log</div><div class="line"><span class="built_in">log</span>=mylog.log</div></pre></td></tr></table></figure>
<h1 id="mysql数据目录设置权限"><a href="#mysql数据目录设置权限" class="headerlink" title="mysql数据目录设置权限"></a>mysql数据目录设置权限</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">su root</div><div class="line">chown -R root:root /usr/<span class="built_in">local</span>/mysql/data</div><div class="line">chown -R root:root /var/lib/mysql</div></pre></td></tr></table></figure>]]></content>
      
        <categories>
            
            <category> 后端技术 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Drools学习笔记]]></title>
      <url>http://geosmart.github.io/2016/08/22/Drools%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<blockquote>
<p>You can build a simple rules engine yourself. All you need is to create a bunch of objects with conditions and actions, store them in a collection, and run through them to evaluate the conditions and execute the actions.<br>                -Martin Fowler</p>
<hr>
<a id="more"></a> 
<h1 id="为什么会有规则引擎-？"><a href="#为什么会有规则引擎-？" class="headerlink" title="为什么会有规则引擎 ？"></a>为什么会有规则引擎 ？</h1><p>背景：复杂企业级项目的开发以及其中随外部条件不断变化的业务规则（business logic），迫切需要分离商业决策者的商业决策逻辑和应用开发者的技术决策，并把这些商业决策放在中心数据库或其他统一的地方，让它们能在运行时（即商务时间）可以动态地管理和修改从而提供软件系统的柔性和适应性。规则引擎正是应用于上述动态环境中的一种解决方法。</p>
</blockquote>
<p>企业管理者对企业级IT系统的开发有着如下的要求：</p>
<ul>
<li>为提高效率，管理流程必须自动化，即使现代商业规则异常复杂；</li>
<li>市场要求业务规则经常变化，IT系统必须依据业务规则的变化快速、低成本的更新；</li>
<li>为了快速、低成本的更新，业务人员应能直接管理IT系统中的规则，不需要程序开发人员参与；</li>
</ul>
<h1 id="什么是规则引擎-？"><a href="#什么是规则引擎-？" class="headerlink" title="什么是规则引擎 ？"></a>什么是规则引擎 ？</h1><p>也许这又是一种“先有蛋还是先有鸡”哲学争论，在JSR-94种也几乎没有定义,规则引擎这个术语是非常不明确的，因为任何以任意形式使用能够应用于数据生成结果的规则的系统都可以称为规则引擎。包括像表单验证和动态表达式引擎这样的简单系统都可以称之为规则引擎。<br>可以这样理解规则引擎由推理引擎发展而来，是一种嵌入在应用程序中的组件，实现了将业务决策从应用程序代码中分离出来，并使用预定义的语义模块编写业务决策。接受数据输入，解释业务规则，并根据规则做出业务决策。</p>
<blockquote>
<p>Drools is Rule Engine or a Production Rule System（产生式规则系统） that uses the rule-based approach to implement and Expert System. Expert Systems（专家系统） are knowledge-based systems that use knowledge representation（知识表达） to process acquired knowledge into a knowledge base（知识库） that can be used for reasoning（推理）.<br>A Production Rule System is Turing complete with a focus on knowledge representation to express propositional and first-order logic in a concise, non-ambiguous and declarative manner.<br>The brain of a Production Rules System is an Inference Engine（推理机） that can scale to a large number of rules and facts. The Inference Engine matches facts and data against Production Rules（根据规则匹配数据和事实）<br>– also called Productions or just Rules – to infer conclusions which result in actions.<br>A Production Rule is a two-part structure that uses first-order logic（一阶逻辑） for reasoning over knowledge representation.<br>A business rule engine（商业规则引擎） is a software system that executes one or more business rules in a runtime production environment.<br>A Rule Engine（定义做什么而不是怎么做） allows you to define “What to Do”（声明式编程） and not “How to do it.”（命令式编程）</p>
</blockquote>
<h2 id="规则引擎的优点"><a href="#规则引擎的优点" class="headerlink" title="规则引擎的优点"></a>规则引擎的优点</h2><h3 id="Declarative-Programming（声明式编程）"><a href="#Declarative-Programming（声明式编程）" class="headerlink" title="Declarative Programming（声明式编程）"></a>Declarative Programming（声明式编程）</h3><p>规则引擎允许你描述做什么而不是如何去做。<br>这里的主要优点是使用规则更加容易对复杂的问题进行表述，并得到验证。 (规则比编码更容易阅读).<br>规则系统能够解决非常非常困难的问题，并提供了方案怎样达到和在解决问题的方向上所作的每一个决定的原因（这对于类似神经网络这样的AI系统来说不容易达到）<br>与code不同，DSL易于编写复杂业务逻辑，对复杂问题的描述也变得简单化，且更易于阅读，理解和核查。<br>如SQL和D3.js也是声明式编程</p>
<h3 id="Logic-and-Data-Separation（逻辑与数据分离）"><a href="#Logic-and-Data-Separation（逻辑与数据分离）" class="headerlink" title="Logic and Data Separation（逻辑与数据分离）"></a>Logic and Data Separation（逻辑与数据分离）</h3><p>The data resides in the Domain Objects and the business logic resides in the Rules. Depending upon the kind of project, this kind of separation can be very advantageous.<br>数据保存在系统对象中，逻辑保存在规则中。这根本性的打破了面向对象系统中将数据和逻辑耦合起来的局面，这点是有利的也是不利的，在于你的观察角度。<br>这样做的结果是，未来逻辑发生改变时更容易被维护，因为逻辑保存在规则中，这点在逻辑是跨领域或多领域中使用时尤其有用。<br>通过将逻辑集中在一个或数个清晰的规则文件中，取代了之前分散在代码中的局面。</p>
<h3 id="Speed-and-Scalability（速度和可测量性）"><a href="#Speed-and-Scalability（速度和可测量性）" class="headerlink" title="Speed and Scalability（速度和可测量性）"></a>Speed and Scalability（速度和可测量性）</h3><p>The Rete OO algorithm on which Drools is written is already a proven algorithm. With the help of Drools, your application becomes very scalable. If there are frequent change requests, one can add new rules without having to modify the existing rules.<br>Rete算法、Leaps算法,以及由此衍生出来的 Drools的 Rete、Leaps算法，提供了对系统数据对象非常有效率的匹配。这些都是高效率尤其当你的数据是不完全的改变（规则引擎能够记得之前的匹配）。这些算法经过了大量实际考验的证明。</p>
<h3 id="Centralization-of-Knowledge（集中化知识管理）"><a href="#Centralization-of-Knowledge（集中化知识管理）" class="headerlink" title="Centralization of Knowledge（集中化知识管理）"></a>Centralization of Knowledge（集中化知识管理）</h3><p>By using Rules, you create a repository of knowledge (a knowledge base) which is executable. It is a single point of truth for business policy. Ideally, Rules are so readable that they can also serve as documentation.<br>通过使用规则，将建立一个可执行的规则库。这意味着规则库代表着现实中的业务策略的唯一对应，理想情况下可读性高的规则还可以被当作文档使用。</p>
<h3 id="Tool-Integration（工具集成）"><a href="#Tool-Integration（工具集成）" class="headerlink" title="Tool Integration（工具集成）"></a>Tool Integration（工具集成）</h3><p>Tools such as Eclipse provide ways to edit and manage rules and get immediate feedback, validation, and content assistance. Auditing and debugging tools are also available.<br>例如Eclipse（将来可能在基于Web的界面上）这样的工具为规则的修改与管理、即时获得反馈、内容验证与修补提供了办法。审查与调试工具同样也可用了。</p>
<h1 id="什么情况下使用规则引擎-？"><a href="#什么情况下使用规则引擎-？" class="headerlink" title="什么情况下使用规则引擎 ？"></a>什么情况下使用规则引擎 ？</h1><p>最简短的回答就是“当没有令人满意的传统的程序设计方法能够解决这个问题时”。<br>下面对这个所谓的传统解决方法的一个描述：</p>
<ul>
<li>对于传统代码来说，问题需要的精确度太高。</li>
<li>这种问题可能并不复杂，但是你找不到一种稳定的方法去建立它。</li>
<li>问题超越了任何有明显运算法则的方案。</li>
<li>它是一个难以解决的复杂问题，没有明显的传统解决方案或者问题没有一个准确的定论。</li>
<li>业务逻辑经常发生改变：逻辑本身是简单的（但不是指过于简单），但是规则经常发生变化。在许多软件组织中正式版本的间隔是较长并且较少的，规则可以在适当的安全前提下帮助提供一定的敏捷性。</li>
<li>领域专家（或者业务分析师）是非技术人员：领域专家通常对业务规则和流程具有很好的认知。他们通常是不了解软件技术的人员，但是具有很好的逻辑性。规则能够让他们用自己的术语来描述业务逻辑。当然他们仍然需要严密的思考和良好的逻辑思维能力（许多在非软件技术型岗位上的人没有进行过形式逻辑的训练，因此在和他们工作时要特别小心，在将业务知识编撰成规则时，要特别注意业务规则和流程应当是当前能够理解的）。</li>
</ul>
<h1 id="什么情况下不能使用规则引擎-？"><a href="#什么情况下不能使用规则引擎-？" class="headerlink" title="什么情况下不能使用规则引擎 ？"></a>什么情况下不能使用规则引擎 ？</h1><ul>
<li>因为规则引擎是动态的 (动态的在这里意味着规则可以象数据一样保存、管理和更新),它们通常被看作发布软件系统的一种解决方案(大多数IT部门似乎存在的目的是防止软件系统被遗弃)。如果这是你希望使用规则引擎的原因，应当意识到在可以写出公开发布的规则时，规则引擎能够以最佳方式工作。</li>
<li>另一个方面，你也可以考虑使用数据驱动的设计（查找表）或者脚本/流程引擎等有能够在数据库中管理并能够动态更新的脚本。对特定的工作要使用恰当的工具。<br>当然，必要时老虎钳可以当作锤子用，但那并不是发明老虎钳的本意。”</li>
</ul>
<h1 id="Drools"><a href="#Drools" class="headerlink" title="Drools"></a>Drools</h1><p>一个应用程序一般可分为3部分：一个和用户交互的前台(UI), 一个和后台系统，例如数据库交互的服务层(DAO)，以及他们中间的业务逻辑(BLL)。<br>使用框架构建前台和后台系统已经成为普遍共识，如 Spring , Struts，Hibernate，Mybatis等；<br>而没有一个标准的方法来构建业务逻辑，为什么没有一个框架来替换冗繁，易错的if…then语句呢，这个框架应该和其它前台或后台框架一样，易于配置，具有可读性和重用性。<br>Drools 规则引擎就是解决我们这个问题的框架。 </p>
<p>Drools是一个基于java的规则引擎，开源的，可以将复杂多变的规则从硬编码中解放出来，以规则脚本的形式存放在文件中，使得规则的变更不需要修正代码重启机器就可以立即在线上环境生效。</p>
<blockquote>
<p>Drools is a business rule management system (BRMS) with a forward and backward chaining inference based rules engine, more correctly known as a production rule system, using an enhanced implementation of the Rete algorithm.</p>
<p>KIE (Knowledge Is Everything) is the new umbrella name to drools, optaPlanner, jBPM, Guvnor, uberFire and related technologies.<br>Drools supports the JSR-94 standard for its business rule engine and enterprise framework for the construction, maintenance, and enforcement of business policies in an organization, application, or service.</p>
<p>Drools is a Business Logic integration Platform (BLiP). It is written in Java. It is an open source project that is backed by JBoss and Red Hat, Inc. It extends and implements the Rete Pattern matching algorithm（实现并扩展了Rete模式匹配算法）.<br>In layman’s terms, Drools is a collection of tools that allow us to separate and reason over logic and data found within business processes（分离数据与业务逻辑，推理）. The two important keywords we need to notice are Logic and Data.</p>
</blockquote>
<p>Drools 分为两个主要部分：构建（ Authoring ）和运行时（ Runtime ）。</p>
<h2 id="Authoring（构建）"><a href="#Authoring（构建）" class="headerlink" title="Authoring（构建）"></a>Authoring（构建）</h2><p>构建的过程涉及到.drl或.xml规则文件的创建，它们被读入一个解析器，使用ANTLR3语法进行解析。<br>解析器对语法进行正确性的检查，然后产生一种中间结构“ descr ”， descr 用 AST 来描述规则。<br>AST 然后被传到PackageBuilder ，由 PackagBuilder 来产生 Packaged 对象。<br>PackageBuilder 还承担着一些代码产生和编译的工作，这些对于产生 Package 对象都时必需的。<br>Package 对象是一个可以配置的，可序列化的，由一个或多个规则组成的对象。</p>
<h2 id="Runtime（运行时）"><a href="#Runtime（运行时）" class="headerlink" title="Runtime（运行时）"></a>Runtime（运行时）</h2><p>It involves the creation of working memory(被推理机进行匹配的数据称为 WorkingMemory) and handling the activation.</p>
<h1 id="Rule（规则）"><a href="#Rule（规则）" class="headerlink" title="Rule（规则）"></a>Rule（规则）</h1><p>Rules are pieces of knowledge often expressed as, “When some conditions occur, then do some tasks.”<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">rule  <span class="string">"&lt;name&gt;"</span></div><div class="line">      &lt;attribute&gt; &lt;value&gt;</div><div class="line">      </div><div class="line">      when</div><div class="line">         &lt;conditions&gt;</div><div class="line">      </div><div class="line">      <span class="keyword">then</span></div><div class="line">         &lt;actions&gt;</div><div class="line">end</div></pre></td></tr></table></figure></p>
<h1 id="Pattern-Matching（模式匹配）"><a href="#Pattern-Matching（模式匹配）" class="headerlink" title="Pattern Matching（模式匹配）"></a>Pattern Matching（模式匹配）</h1><p>对新的数据和被修改的数据进行规则的匹配称为模式匹配（ Pattern Matching ）。进行匹配的引擎称为推理机（Inference Engine ）。被访问的规则称为 ProductionMemory ，被推理机进行匹配的数据称为 WorkingMemory。 Agenda 管理被匹配规则的执行。<br>推理机所采用的模式匹配算法有下列几种： Linear，RETE，Treat，Leaps。<br>DroDrools是为Java量身定制的基于Charles  Forgy的RETE算法的规则引擎的实现。具有了OO接口的RETE,使得商业规则有了更自然的表达。</p>
<p>在规则引擎中，将知识表达为规则（rules），要分析的情况定义为事实（facts）。<br>二者在内存中的存储分别称为<code>Production Memory</code>和<code>Working Memory</code>，如下图：<br><img src="rules-inference_engine-facts.png" alt="rules-inference_engine-facts"><br>rules和facts是规则引擎接受的输入参数，而规则引擎本身包括两个组成部分：<code>Pattern Matcher</code>和<code>Agenda</code>。Pattern Matcher根据facts找到匹配的rules，Agenda管理PatternMatcher挑选出来的规则的执行次序。在外围，还会有一个执行引擎（Execution Engine）负责根据Agenda输出的rules执行具体的操作。</p>
<p>其中Pattern Matcher是规则引擎负责推理的核心。和人类的思维相对应，<br>规则引擎中也存在两种推理方式：<code>正向推理（Forward-Chaining）</code>和<code>反向推理（Backward-Chaining）</code>。</p>
<ul>
<li>正向推理也叫演绎法，由事实驱动，从 一个初始的事实出发，不断地应用规则得出结论。首先在候选队列中选择一条规则作为启用规则进行推理，记录其结论作为下一步推理时的证据。如此重复这个过程，直到再无可用规则可被选用或者求得了所要求的解为止。</li>
<li>反向推理也叫归纳法，由目标驱动，首先提出某个假设，然后寻找支持该假设的证据，若所需的证据都能找到，说明原假设是正确的；若无论如何都找不到所需要的证据，则说明原假设不成立，此时需要另做新的假设。</li>
</ul>
<p><a href="http://www.blogjava.net/guangnian0412/archive/2006/06/01/49712.html">RETE算法</a></p>
<h1 id="Drools-常用术语"><a href="#Drools-常用术语" class="headerlink" title="Drools-常用术语"></a>Drools-常用术语</h1><h2 id="Rules（规则）"><a href="#Rules（规则）" class="headerlink" title="Rules（规则）"></a>Rules（规则）</h2><p>The heart of the Rules Engine where you specify conditions (if ‘a’ then ‘b’).</p>
<p>业务调研中很重要的内容就是了解业务规则。在企业流程中，可能还会接触到流程规则。<br>在IT技术领域，很多地方也应用了规则，比如路由表，防火墙策略，乃至角色权限控制(RBAC)，或者Web框架中的URL匹配。<br>不管是哪种规则，都规定了一组确定的条件和此条件所产生的结果。</p>
<ul>
<li>每条规则都是一组条件决定的一系列结果；</li>
<li>一条规则可能与其他规则共同决定最终结果；</li>
<li>可能存在条件互相交叉的规则，此时有必要规定规则的优先级；</li>
</ul>
<h2 id="Facts（事实）"><a href="#Facts（事实）" class="headerlink" title="Facts（事实）"></a>Facts（事实）</h2><p>Facts are the data on which the rules will act upon.<br>From Java perspective, Facts are the POJO (Plain Old Java Object).</p>
<h2 id="KnowledgeBuilder"><a href="#KnowledgeBuilder" class="headerlink" title="KnowledgeBuilder"></a>KnowledgeBuilder</h2><p>KnowledgeBuilder是用来在业务代码中收集已经编好的规则，找到这些规则并把这些规则文件进行编译，<br>最终产生一批编译好的KnowledgePackage（规则包）给其它的应用程序使用。<br>创建KnowledgeBuilder对象使用的是KnowledgeBuilderFactory的newKnowledgeBuilder方法。</p>
<h2 id="Knowledge-Base"><a href="#Knowledge-Base" class="headerlink" title="Knowledge Base"></a>Knowledge Base</h2><ul>
<li>Knowledge Base是管理一系列rules, processes和 internal types的接口. 它在<code>org.drools.KnowledgeBase</code>包中；</li>
<li>KnowledgeBase 是Drools提供的用来收集应用当中知识（Knowledge）定义的知识库对象，在一个KnowledgeBase当中可以包含普通的规则、规则流、函数定义、用户自定义对象等；</li>
<li>KnowledgeBase本身不包含任何业务数据对象(fact 对象)，业务对象都是插入到由KnowledgeBase产生的两种类型的session对象；</li>
<li>一系列Knowledge definitions组成knowledge packages；</li>
<li>Knowledge definitions 可以新增和移除；</li>
<li>Knowledge Base的主要目的是为了重用，因为Knowledge definitions成本很高； </li>
<li>Knowledge Base 提供新建knowledge sessions的方法；</li>
</ul>
<h2 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h2><p>knowledge session是激发规则的核心组件，knowledge session容纳所有规则和资源， knowledge session由KnowledgeBase创建。<br>规则引擎工作时会将facts插入session中，当满足特定的condition时，对应的rule就会被激发。<br>knowledge session从knowledge base中获取，是与drools规则引擎交互的主要接口，knowledge session有两种类型:</p>
<h3 id="Stateful-Knowledge-Session"><a href="#Stateful-Knowledge-Session" class="headerlink" title="Stateful Knowledge Session"></a>Stateful Knowledge Session</h3><p>StatefulKnowledgeSession对象是一种最常用的与规则引擎进行交互的方式，它可以与规则引擎建立一个持续的交互通道。<br>StatefulKnowledgeSession执行完之后一定要调用dispose()方法释放资源。<br>StatefulKnowledgeSession可以接受外部插入(insert方法)的业务数据——也叫fact，一个对象通常可以对应一个普通的POJO, 而一个POJO有若干个属性来描述这个业务对象，比如一个PeopleEvent中包含了isComing(人是否进来属性), roomed(房间号)，每一个属性对应getter和setter方法，供规则定义来使用（注意：在规则定义中isComing默认的getter方法是getIsComing()）。<br>如果规则当中需要有数据传出，那么可以通过在StatefulKnowledgeSession当中设置global对象来实现，一个global对象也是一个普通的Java对象，在向StatefulKnowledgeSession当中设置global对象时不用insert方法而用setGlobal方法实现。</p>
<p>一些stateless session常用的用例：</p>
<ul>
<li>Monitoring 监控<br>Stock market monitoring and analysis for semi-automatic buying.</li>
<li>Diagnostics 诊断<br>Fault finding, medical diagnostics</li>
<li>Logistics<br>Parcel tracking and delivery provisioning  </li>
</ul>
<h3 id="Stateless-Knowledge-Session"><a href="#Stateless-Knowledge-Session" class="headerlink" title="Stateless Knowledge Session"></a>Stateless Knowledge Session</h3><p>Stateless Knowledge Session是一个无状态的session，形成最简单的用例，不利用推理<br>Stateless Knowledge Session可以像function一样被调用，可传入一些数据和接收一些结果。<br>一般 stateless session包括:</p>
<ul>
<li>Validation 验证<br>Is this person eligible for a mortgage?</li>
<li>Calculation 计算<br>Compute a mortgage premium.</li>
<li>Routing and Filtering 路由和过滤<br>Filter incoming messages, such as emails, into folders.<br>Send incoming messages to a destination</li>
</ul>
<h3 id="Stateless和Stateful两种session的区别"><a href="#Stateless和Stateful两种session的区别" class="headerlink" title="Stateless和Stateful两种session的区别"></a>Stateless和Stateful两种session的区别</h3><ul>
<li>StatelessKnowledgeSession是在StatefulKnowledgeSession基础上进行进一步的封装，</li>
<li>StatelessKnowledgeSession跟StatefulKnowledgeSession的区别就是它不需要调用dispose方法释放内存资源了，</li>
<li>StatelessKnowledgeSession不能重复的执行插入fact的操作、也不能重复的调用fireAllRules方法来执行所有的规则，因为它不能保存状态，<br>对应的这些要完成的工作在StatelessKnowledgeSession当中只有execute方法，通过这个方法可以实现插入所有的fact并且可以同时执行所有的规则或规则流。</li>
</ul>
<h2 id="MVEL（MVFLEX-Expression-Language-）"><a href="#MVEL（MVFLEX-Expression-Language-）" class="headerlink" title="MVEL（MVFLEX Expression Language ）"></a>MVEL（MVFLEX Expression Language ）</h2><p>MVEL is a hybrid dynamic/statically typed, embeddable Expression Language and runtime for the Java Platform.<br>MVEL is particularly ideal for restrictive environments that can’t use bytecode generation due to <code>memory restrictions</code> or sand boxing. Instead of trying to re-invent Java, it instead aims to provide a familiar syntax for Java programmers while also adding <code>syntactic sugar</code> for short and concise expressions.</p>
<h1 id="Rule-Attributes"><a href="#Rule-Attributes" class="headerlink" title="Rule Attributes"></a>Rule Attributes</h1><h2 id="ruleflow-group"><a href="#ruleflow-group" class="headerlink" title="ruleflow-group"></a>ruleflow-group</h2><h2 id="agenda-group"><a href="#agenda-group" class="headerlink" title="agenda-group"></a>agenda-group</h2><h2 id="activation-group"><a href="#activation-group" class="headerlink" title="activation-group"></a>activation-group</h2><h2 id="salience"><a href="#salience" class="headerlink" title="salience"></a>salience</h2><h2 id="no-loop"><a href="#no-loop" class="headerlink" title="no-loop"></a>no-loop</h2><h2 id="lock-on-action"><a href="#lock-on-action" class="headerlink" title="lock-on-action"></a>lock-on-action</h2><h2 id="Agenda"><a href="#Agenda" class="headerlink" title="Agenda"></a>Agenda</h2><p>The Agenda is a Rete feature. It maintains set of rules that are able to execute, its job is to schedule that execution in a deterministic order.</p>
<p>It’s a logical concept. The agenda is the logical place where activations are waiting to be fired.<br>Agenda是一个逻辑概念，逻辑上存储待执行规则（activations）。</p>
<h2 id="Activations（被匹配的规则）"><a href="#Activations（被匹配的规则）" class="headerlink" title="Activations（被匹配的规则）"></a>Activations（被匹配的规则）</h2><p>Activations are the ‘then’ part of the rule. Activations are placed in the agenda where the appropriate rule is fired.<br>Activations是rule的’then’部分，存储在Agenda中的已匹配但未激发的rule，即Activations；</p>
<h2 id="DRL规则文件的语法"><a href="#DRL规则文件的语法" class="headerlink" title="DRL规则文件的语法"></a>DRL规则文件的语法</h2><h2 id="Package"><a href="#Package" class="headerlink" title="Package"></a>Package</h2><p>Every Rule starts with a package name. The package acts as a namespace for Rules. Rule names within a package must be unique. Packages in Rules are similar to packages in Java.<br>package是Rules的命名空间，且必须唯一</p>
<h2 id="Import-statement"><a href="#Import-statement" class="headerlink" title="Import statement"></a>Import statement</h2><p>Whatever facts you want to apply the rule on, those facts needs to be imported.<br>导入定义Fatcs的className</p>
<h2 id="Rule-Definition"><a href="#Rule-Definition" class="headerlink" title="Rule Definition"></a>Rule Definition</h2><ul>
<li>Rule consists of the Rule Name, the condition, and the Consequence. </li>
<li>Drools keywords： rule, when, then,  end. </li>
<li>The when part is the condition in both the rules and the then part is the consequence. </li>
<li>In rule terminology, the when part is also called as LHS (left hand side) and the then part as the RHS (right hand side) of the rule.</li>
</ul>
<h1 id="Drools-API"><a href="#Drools-API" class="headerlink" title="Drools API"></a>Drools API</h1><p>规则引擎中，将知识表达为规则（rules），要分析的情况定义为事实（facts）。二者在内存中的存储分别称为Production Memory和Working Memory。在外围，还会有一个执行引擎（Execution Engine）。<br>与此对应，规则引擎API也分成三个部分。在Drools中，分别叫做Knowledge API，Fact API和Execution API。</p>
<h2 id="Knowledge-API"><a href="#Knowledge-API" class="headerlink" title="Knowledge API"></a>Knowledge API</h2><p>Drools将知识库(KnowledgeBase)作为JSR94中的规则执行集(RuleExecutionSet)。知识库中的知识以包(KnowledgePackage)为单位组合而成。每个包中聚合多个规则(Rule)。<br>通常，一个包中的内容会在一个或多个资源(Resource)中保存。资源的类型可以有很多种,如.drl 文件、.dslr 文件或 xls 文件等。<br>规则包还可以从规则流(rule flow) 文件中获取。</p>
<h2 id="Fact-API"><a href="#Fact-API" class="headerlink" title="Fact API"></a>Fact API</h2><p>要操作Working Memory，首先要建立规则引擎的一个会话。<br>Drools中的有状态会话和无状态会话分别为StatefulKnowledgeSession和StatelessKnowledgeSession，都可以由KnowledgeBase建立。<br>通过会话可以进行操作Fact对象，执行规则等交互。</p>
<h2 id="Execution-API"><a href="#Execution-API" class="headerlink" title="Execution API"></a>Execution API</h2><p>插入到WorkingMemory中的对象，并不是克隆，而是对原对象的引用。这就意味着引擎中可以改变外部的对象，这是引擎与外部数据交互的一个通道。<br>此外，insert()方法还会返回一个FactHandler，作为引擎中该Fact对象的一个句柄。<br>最后，session上可以注册AgendaEventListener、ProcessEventListener和WorkingMemoryEventListener，这也是常用的交互方式。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="http://www.iigrowing.cn/java_gui_ze_yin_qing_zong_jie.html">JAVA规则引擎总结</a><br><a href="http://holbrook.github.io/pages/tags.html#规则引擎-ref">心内求法-规则引擎系列博客</a><br><a href="http://martinfowler.com/bliki/RulesEngine.html">martinfowler-RulesEngine</a></p>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="drl逻辑编译问题"><a href="#drl逻辑编译问题" class="headerlink" title="drl逻辑编译问题"></a>drl逻辑编译问题</h2><p>据说drl中写的逻辑明明是对的，但是编译判断还是会有问题，待验证</p>
]]></content>
      
        <categories>
            
            <category> 后端技术 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Drools </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Elasticsearch常用API]]></title>
      <url>http://geosmart.github.io/2016/07/30/Elasticsearch%E5%B8%B8%E7%94%A8API/</url>
      <content type="html"><![CDATA[<hr>
<a id="more"></a> 
<p>/_nodes/ 下有一个监控接口：<br>curl -XGET ‘<a href="http://127.0.0.1:9200/_nodes/_local/hot_threads?interval=60s">http://127.0.0.1:9200/_nodes/_local/hot_threads?interval=60s</a>‘<br>该接口会返回在 interval 时长内，该节点消耗资源最多的前三个线程的堆栈情况。这对于性能调优初期，采集现状数据，极为有用。<br>默认的，资源消耗是按照 CPU 来衡量，还可以用 ?type=wait 或者 ?type=block 来查看在等待和堵塞状态的当前线程排名。</p>
<p>curl -XGET ‘<a href="http://v3es1:9200/_nodes/v3es1/stats/jvm">http://v3es1:9200/_nodes/v3es1/stats/jvm</a>‘<br>查看：JVM stats, memory pool information, garbage collection, buffer pools, number of loaded/unloaded classes<br>你看看目前jvm状态如何</p>
<p>如果你的 ES 集群监控里发现经常有很耗时的 GC，说明集群负载很重，内存不足。<br>严重情况下，这些 GC 导致节点无法正确响应集群之间的 ping ，可能就直接从集群里退出了。<br>然后数据分片也随之在集群中重新迁移，引发更大的网络和磁盘 IO，正常的写入和搜索也会受到影响。</p>
<h1 id="动态修改Replica"><a href="#动态修改Replica" class="headerlink" title="动态修改Replica"></a>动态修改Replica</h1><p>curl -XPUT ‘localhost:9200/my_index/_settings’ -d ‘<br>{<br>    “index” : {<br>        “number_of_replicas” : 1<br>    }<br>}’</p>
<h1 id="修改-queue-size"><a href="#修改-queue-size" class="headerlink" title="修改 queue_size"></a>修改 queue_size</h1><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-update-settings.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-update-settings.html</a><br>curl -XPUT  _cluster/settings -d ‘{<br>    “persistent” : {<br>        “threadpool.bulk.queue_size” : 1000<br>    }<br>}’</p>
<p>参考：<a href="http://jfzhang.blog.51cto.com/1934093/1685530">http://jfzhang.blog.51cto.com/1934093/1685530</a></p>
<h1 id="ES高频写优化配置"><a href="#ES高频写优化配置" class="headerlink" title="ES高频写优化配置"></a>ES高频写优化配置</h1><pre><code>http://edgeofsanity.net/article/2012/12/26/elasticsearch-for-logging.html
</code></pre>]]></content>
      
        <categories>
            
            <category> 后端技术 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Elasticsearch </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[JMS学习笔记]]></title>
      <url>http://geosmart.github.io/2016/07/27/JMS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>JMS即Java消息服务（Java Message Service）应用程序接口是一个Java平台中关于面向消息中间件（MOM）的API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。<br>Java消息服务是一个与具体平台无关的API，绝大多数MOM提供商都对JMS提供支持。</p>
<blockquote>
<p>JMS (Java Message Service) is an API that provides the facility to create， send and read messages。<br>It provides loosely coupled（松耦合）， reliable（可靠） and asynchronous（异步） communication。</p>
</blockquote>
<hr>
<a id="more"></a> 
<h1 id="JMS简介"><a href="#JMS简介" class="headerlink" title="JMS简介"></a>JMS简介</h1><p>JMS全称是Java Message Service。其是JavaEE技术规范中的一个重要组成部分，是一种企业消息处理的规范。它的作用就像一个智能交换机，负责路由分布式应用中各个组件所发出的消息；</p>
<ul>
<li>JMS提供了一组通用的Java API，开发者可以通过API来 创建，发送，接收，读取 、消息；</li>
<li>JMS是一种和具体实现厂商无关的API。它的作用类似于JDBC。不管底层采用何种消息服务器的实现，应用程序总是面向通用的JMS API编程；</li>
<li>常用的有apache的ActiveMQ，Jboss的HornetQ</li>
</ul>
<h1 id="JMS优势"><a href="#JMS优势" class="headerlink" title="JMS优势"></a>JMS优势</h1><p>1。 异步 Asynchronous: To receive the message， client is not required to send request。 Message will arrive automatically to the client。 消息采用异步处理机制，避免客户机等待。<br>2。 可靠 Reliable: It provides assurance that message is delivered。<br>JMS可以持久的保存消息，因而提高系统的可靠性。<br>3。 效率：JMS允许一条消息同时发给多个接受者，更具效率。</p>
<h1 id="JMS总体架构"><a href="#JMS总体架构" class="headerlink" title="JMS总体架构"></a>JMS总体架构</h1><p>JMS的架构总体架构分3部分：<br>1。 JMS服务器，路由消息的服务系统，广义上说就是服务器，比如JBOSS，GLASSFISH，WAS8；<br>2。 JMS生产者，负责创建并发送消息的程序组件；<br>3。 JMS消费者，负责读取并处理消息的程序组件。</p>
<h1 id="JMS的消息机制模型"><a href="#JMS的消息机制模型" class="headerlink" title="JMS的消息机制模型"></a>JMS的消息机制模型</h1><p>JMS的消息机制模型主要分2类:</p>
<h2 id="点对点PTP模型"><a href="#点对点PTP模型" class="headerlink" title="点对点PTP模型"></a>点对点PTP模型</h2><ul>
<li>PTP消息处理模型为应用中的各个逻辑处理单元提供可靠的通信支持；</li>
<li>在PTP通信中，JMS把每一个消息传递给一个消息消费者；</li>
<li>JMS系统保证消息传递给消费者，消息不会同时被多个消费者接受；</li>
<li>如果消息消费者不在连接范围内，JMS会自动保证消息不会丢失。直到消息消费者进入连接，消息将自动送达。因此JMS需要将消息保存到永久介质上如数据库；</li>
</ul>
<h2 id="发布-订阅Pub-Sub模型"><a href="#发布-订阅Pub-Sub模型" class="headerlink" title="发布/订阅Pub-Sub模型"></a>发布/订阅Pub-Sub模型</h2><ul>
<li>在这种模型中，每个消息被发送到一个消息主题，该主题可以拥有多个订阅者。</li>
<li>JMS系统负责将消息的副本传给该主题的每个订阅者。</li>
</ul>
<hr>
<h1 id="Point-to-Point-PTP-Messaging-Domain"><a href="#Point-to-Point-PTP-Messaging-Domain" class="headerlink" title="Point-to-Point (PTP) Messaging Domain"></a>Point-to-Point (PTP) Messaging Domain</h1><p>Point-to-Point (PTP) Messaging Domain(点对点通信模型)是基于队列(Queue)的，对于PTP消息模型而言，它的消息目的是一个消息队列(Queue)，消息生产者每次发送消息总是把消息送入消息队列中，消息消费者总是从消息队列中读取消息。先进队列的消息将先被消息消费者读取。<br><img src="JMS_PTP_Model.png" alt="JMS PTP Model"></p>
<blockquote>
<p>In PTP model， one message is delivered to one receiver only。 Here，<br>Queue is used as a message oriented middleware (MOM) 面向消息的中间件。<br>The Queue is responsible to hold the message until receiver is ready。（串行）<br>In PTP model， there is no timing dependency between sender and receiver。</p>
</blockquote>
<h2 id="PTP模型的对象的主要概念和方法"><a href="#PTP模型的对象的主要概念和方法" class="headerlink" title="PTP模型的对象的主要概念和方法"></a>PTP模型的对象的主要概念和方法</h2><h3 id="Queue（队列）"><a href="#Queue（队列）" class="headerlink" title="Queue（队列）"></a>Queue（队列）</h3><p>Queue由JMS Provider 管理，队列由队列名识别，客户端可以通过JNDI 接口用队列名得到一个队列对象。</p>
<h3 id="TemporaryQueue（临时队列）"><a href="#TemporaryQueue（临时队列）" class="headerlink" title="TemporaryQueue（临时队列）"></a>TemporaryQueue（临时队列）</h3><p>由QueueConnection 创建，而且只能由创建它的QueueConnection 使用。</p>
<h3 id="QueueConnectionFactory"><a href="#QueueConnectionFactory" class="headerlink" title="QueueConnectionFactory"></a>QueueConnectionFactory</h3><p>客户端用QueueConnectionFactory 创建QueueConnection 对象。</p>
<h3 id="QueueConnection"><a href="#QueueConnection" class="headerlink" title="QueueConnection"></a>QueueConnection</h3><p>一个到JMS PTP provider 的连接，客户端可以用QueueConnection 创建QueueSession 来发送和接收消息。</p>
<h3 id="QueueSession"><a href="#QueueSession" class="headerlink" title="QueueSession"></a>QueueSession</h3><p>QueueSession提供一些方法创建QueueReceiver，QueueSender，QueueBrowser 和TemporaryQueue。<br>如果在QueueSession 关闭时，有一些消息已经被收到，但还没有被签收(acknowledged)，那么，当接收者下次连接到相同的队列时，这些消息还会被再次接收。</p>
<h3 id="QueueReceiver"><a href="#QueueReceiver" class="headerlink" title="QueueReceiver"></a>QueueReceiver</h3><p>客户端用QueueReceiver 接收队列中的消息，如果用户在QueueReceiver中设定了消息选择条件，那么不符合条件的消息会留在队列中，不会被接收到。</p>
<h3 id="QueueSender"><a href="#QueueSender" class="headerlink" title="QueueSender"></a>QueueSender</h3><p>客户端用QueueSender 发送消息到队列</p>
<h3 id="QueueBrowser"><a href="#QueueBrowser" class="headerlink" title="QueueBrowser"></a>QueueBrowser</h3><p>客户端可以QueueBrowser 浏览队列中的消息，但不会收走消息。</p>
<h3 id="QueueRequestor"><a href="#QueueRequestor" class="headerlink" title="QueueRequestor"></a>QueueRequestor</h3><p>JMS 提供QueueRequestor 类简化消息的收发过程。<br>QueueRequestor 的构造函数有两个参数:QueueSession 和queue，QueueRequestor 通过创建一个临时队列来完成最终的收发消息请求。</p>
<h3 id="Reliability可靠性"><a href="#Reliability可靠性" class="headerlink" title="Reliability可靠性"></a>Reliability可靠性</h3><p>队列可以长久地保存消息直到接收者收到消息。<br>接收者不需要因为担心消息会丢失而时刻和队列保持激活的连接状态，充分体现了异步传输模式的优势。</p>
<hr>
<h1 id="Publisher-Subscriber-Pub-Sub-Messaging-Domain"><a href="#Publisher-Subscriber-Pub-Sub-Messaging-Domain" class="headerlink" title="Publisher/Subscriber (Pub/Sub) Messaging Domain"></a>Publisher/Subscriber (Pub/Sub) Messaging Domain</h1><p>JMS Publisher/Subscriber (Pub/Sub) Messaging Domain(出版者/订阅者模型)模型定义了如何向一个内容节点发布和订阅消息，这些节点被称作主题(topic)。</p>
<ul>
<li>主题可以被认为是消息的传输中介；</li>
<li>发布者(publisher)发布消息到主题；</li>
<li>订阅者(subscribe) 从主题订阅消息；</li>
<li>主题使得消息订阅者和消息发布者保持互相独立，不需要接触即可保证消息的传送。</li>
</ul>
<p><img src="JMS_Pub-Sub_Model.png" alt="JMS Pub/Sub Model"></p>
<blockquote>
<p>In Pub/Sub model， one message is delivered to all the subscribers。 It is like broadcasting。 Here，<br>Topic（主题） is used as a message oriented middleware that is responsible to hold and deliver messages。<br>In PTP model， there is timing dependency between publisher and subscriber。</p>
</blockquote>
<h2 id="JMS-Pub-Sub-模型中的主要概念和对象"><a href="#JMS-Pub-Sub-模型中的主要概念和对象" class="headerlink" title="JMS Pub/Sub 模型中的主要概念和对象"></a>JMS Pub/Sub 模型中的主要概念和对象</h2><h3 id="subscription（订阅）"><a href="#subscription（订阅）" class="headerlink" title="subscription（订阅）"></a>subscription（订阅）</h3><p>消息订阅分为非持久订阅(non-durable subscription)和持久订阅(durable subscrip-tion)：</p>
<ul>
<li>非持久订阅只有当客户端处于激活状态，也就是和JMS Provider 保持连接状态才能收到发送到某个主题的消息，而当客户端处于离线状态，这个时间段发到主题的消息将会丢失，永远不会收到。</li>
<li>持久订阅时，客户端向JMS 注册一个识别自己身份的ID，当这个客户端处于离线时，JMS Provider 会为这个ID 保存所有发送到主题的消息，当客户再次连接到JMS Provider时，会根据自己的ID 得到所有当自己处于离线时发送到主题的消息。</li>
</ul>
<h3 id="Topic（主题）"><a href="#Topic（主题）" class="headerlink" title="Topic（主题）"></a>Topic（主题）</h3><ul>
<li>Topic主题由JMS Provider 管理，</li>
<li>主题由主题名识别</li>
<li>客户端可以通过JNDI 接口用主题名得到一个主题对象。</li>
<li>JMS没有给出主题的组织和层次结构的定义，由JMS Provider 自己定义</li>
</ul>
<h3 id="TemporaryTopic（临时主题）"><a href="#TemporaryTopic（临时主题）" class="headerlink" title="TemporaryTopic（临时主题）"></a>TemporaryTopic（临时主题）</h3><p>临时主题由TopicConnection创建，而且只能由创建它的TopicConnection使用。临时主题不能提供持久订阅功能。</p>
<h3 id="TopicConnectionFactory"><a href="#TopicConnectionFactory" class="headerlink" title="TopicConnectionFactory"></a>TopicConnectionFactory</h3><p>客户端用TopicConnectionFactory创建TopicConnection对象。</p>
<h3 id="TopicConnection"><a href="#TopicConnection" class="headerlink" title="TopicConnection"></a>TopicConnection</h3><p>TopicConnection是一个到JMS Pub/Sub provider的连接，客户端可以用TopicConnection创建TopicSession 来发布和订阅消息。</p>
<h3 id="TopicSession"><a href="#TopicSession" class="headerlink" title="TopicSession"></a>TopicSession</h3><p>TopicSession 提供一些方法创建TopicPublisher，TopicSubscriber，TemporaryTopic。它还提供unsubscribe方法取消消息的持久订阅。</p>
<h3 id="TopicPublisher"><a href="#TopicPublisher" class="headerlink" title="TopicPublisher"></a>TopicPublisher</h3><p>客户端用TopicPublisher 发布消息到主题。</p>
<h3 id="TopicSubscriber"><a href="#TopicSubscriber" class="headerlink" title="TopicSubscriber"></a>TopicSubscriber</h3><p>客户端用TopicSubscriber 接收发布到主题上的消息。可以在TopicSubscriber 中设置消息过滤功能，这样，不符合要求的消息不会被接收。</p>
<h3 id="Durable-TopicSubscriber"><a href="#Durable-TopicSubscriber" class="headerlink" title="Durable TopicSubscriber"></a>Durable TopicSubscriber</h3><p>如果一个客户端需要持久订阅消息，可以使用Durable TopicSubscriber，TopSession 提供一个方法createDurableSubscriber创建Durable TopicSubscriber 对象。</p>
<h3 id="Recovery-and-Redelivery（恢复和重新派送）"><a href="#Recovery-and-Redelivery（恢复和重新派送）" class="headerlink" title="Recovery and Redelivery（恢复和重新派送）"></a>Recovery and Redelivery（恢复和重新派送）</h3><p>恢复和重新派送非持久订阅状态下，不能恢复或重新派送一个未签收的消息。只有持久订阅才能恢复或重新派送一个未签收的消息</p>
<h3 id="TopicRequestor"><a href="#TopicRequestor" class="headerlink" title="TopicRequestor"></a>TopicRequestor</h3><ul>
<li>JMS 提供TopicRequestor 类简化消息的收发过程。</li>
<li>TopicRequestor的构造函数有两个参数:TopicSession和topic。</li>
<li>TopicRequestor 通过创建一个临时主题来完成最终的发布和接收消息请求。</li>
</ul>
<h3 id="Reliability（可靠性）"><a href="#Reliability（可靠性）" class="headerlink" title="Reliability（可靠性）"></a>Reliability（可靠性）</h3><ul>
<li>当所有的消息必须被接收，则用持久订阅模式。</li>
<li>当丢失消息能够被容忍，则用非持久订阅模式。</li>
</ul>
<hr>
<h1 id="JMS-Programming-Model（JMS编程模型）"><a href="#JMS-Programming-Model（JMS编程模型）" class="headerlink" title="JMS Programming Model（JMS编程模型）"></a>JMS Programming Model（JMS编程模型）</h1><p><img src="JMS_Programming_Model.png" alt="JMS Programming Model"></p>
<h2 id="ConnectionFactory（连接工厂）"><a href="#ConnectionFactory（连接工厂）" class="headerlink" title="ConnectionFactory（连接工厂）"></a>ConnectionFactory（连接工厂）</h2><p>它由服务器管理员创建，并绑定到JNDI树上，JMS客户端使用JNDI查找，定位连接工厂，然后利用连接工厂创建JMS连接。</p>
<h2 id="Connection（JMS连接）"><a href="#Connection（JMS连接）" class="headerlink" title="Connection（JMS连接）"></a>Connection（JMS连接）</h2><p>连接表示客户机和服务器之间的活动连接。JMS通过连接工厂创建连接。JMS是一个相当重要的对象。通常，每个客户机使用单独的连接，而每个连接则可以连接多个JMS目的。</p>
<h2 id="Session（JMS会话）"><a href="#Session（JMS会话）" class="headerlink" title="Session（JMS会话）"></a>Session（JMS会话）</h2><p>会话表示客户机与JMS服务器之间的通信状态。JMS会话建立在连接之上，表示JMS客户机与服务器之间的通信线程。会话定义了消息的顺序。JMS使用会话进行事务性的消息处理。</p>
<h2 id="Destination（JMS消息目的地）"><a href="#Destination（JMS消息目的地）" class="headerlink" title="Destination（JMS消息目的地）"></a>Destination（JMS消息目的地）</h2><p>Destination即消息生产者发送消息的目的地，也就是消息消费者获取消息的消息源。</p>
<h2 id="Message-Producer-（JMS消息生产者）"><a href="#Message-Producer-（JMS消息生产者）" class="headerlink" title="Message Producer （JMS消息生产者）"></a>Message Producer （JMS消息生产者）</h2><p>消息生产者负责创建消息并将消息发送到消息目的。</p>
<h2 id="Message-Consumer-（JMS消息消费者）"><a href="#Message-Consumer-（JMS消息消费者）" class="headerlink" title="Message Consumer （JMS消息消费者）"></a>Message Consumer （JMS消息消费者）</h2><p>消息消费者负责接收消息并读取消息内容。</p>
<h1 id="JMS消息的确认方式"><a href="#JMS消息的确认方式" class="headerlink" title="JMS消息的确认方式"></a>JMS消息的确认方式</h1><p>消息的确认是指消息接受者接到消息，并做出了对应的处理之后，它将回送一个确认消息。<br>对于 <strong>非事务性</strong> 会话，创建会话时应该指定确定方式，JMS定义了3种确认方式:</p>
<h2 id="Auto-ACKnowledge-自动通知"><a href="#Auto-ACKnowledge-自动通知" class="headerlink" title="Auto_ACKnowledge    自动通知"></a>Auto_ACKnowledge    自动通知</h2><p>对于同步消费者，Receive方法调用返回，且没有异常发生时，将自动对收到的消息予以确认。<br>对于异步消息，当onMessage方法返回，且没有异常发生时，即对收到的消息自动确认。  </p>
<h2 id="Client-AcKnowledge-客户端自行决定通知时机"><a href="#Client-AcKnowledge-客户端自行决定通知时机" class="headerlink" title="Client_AcKnowledge    客户端自行决定通知时机"></a>Client_AcKnowledge    客户端自行决定通知时机</h2><p>这种方式要求客户端使用javax。jms。Message。acknowledge()方法完成确认。  </p>
<h2 id="Dups-OK-ACKnowledge-延时-批量通知"><a href="#Dups-OK-ACKnowledge-延时-批量通知" class="headerlink" title="Dups_OK_ACKnowledge    延时/批量通知"></a>Dups_OK_ACKnowledge    延时/批量通知</h2><p>这种确认方式允许JMS不必急于确认收到的消息，允许在收到多个消息之后一次完成确认，<br>与Auto_AcKnowledge相比，这种确认方式在某些情况下可能更有效，因为没有确认，当系统崩溃或者网络出现故障的时候，消息可以被重新传递。 </p>
<hr>
<p>参考阅读<br><a href="http://docs.oracle.com/cd/E19148-01/820-0533/aeraq/index.html">Sun Java System Message Queue</a><br><a href="http://www.javatpoint.com/jms-tutorial">jms-tutorial</a>  </p>
]]></content>
      
        <categories>
            
            <category> 后端技术 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> JMS </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Elasticsearch批量插入测试]]></title>
      <url>http://geosmart.github.io/2016/07/25/Elasticsearch%E6%89%B9%E9%87%8F%E6%8F%92%E5%85%A5%E6%B5%8B%E8%AF%95/</url>
      <content type="html"><![CDATA[<p>Elasticsearch批量插入测试<br>数据：10万结构化document（json），每个1.3k；<br>测试结果：bulkProcess性能最优(4s)，bulkRequest次之（1m）；indexAPI适用于单条插入。<br>测试项目源码见<a href="https://github.com/geosmart/me.demo.elasticsearch">me.demo.elasticsearch</a> </p>
<hr>
<a id="more"></a> 
<h1 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h1><p>两个Node(8G/4核)</p>
<h1 id="JMeter测试框架"><a href="#JMeter测试框架" class="headerlink" title="JMeter测试框架"></a>JMeter测试框架</h1><p>TODO：模拟http测试rest</p>
<h1 id="单条插入测试"><a href="#单条插入测试" class="headerlink" title="单条插入测试"></a>单条插入测试</h1><p>以IndicesAdminClient新建Index,Type；以IndexAPI插入document(fields);</p>
<ul>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/client/java-api/2.3/java-admin-indices.html">IndicesAdminClient </a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/client/java-api/2.3/java-docs-index.html">Index API</a></li>
</ul>
<h1 id="批量插入性能测试"><a href="#批量插入性能测试" class="headerlink" title="批量插入性能测试"></a>批量插入性能测试</h1><p>以Bulk API进行手动批量插入，或采用BulkProcessor 进行自动分段插入；</p>
<ul>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/client/java-api/2.3/java-docs-bulk.html">bulk-api</a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/client/java-api/2.3/java-docs-bulk-processor.html">bulk-processor</a></li>
<li><a href="http://www.programcreek.com/java-api-examples/index.php?api=org.elasticsearch.action.bulk.BulkRequestBuilder">bulk-api-examples</a></li>
</ul>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="EsRejectedExecutionException"><a href="#EsRejectedExecutionException" class="headerlink" title="EsRejectedExecutionException"></a>EsRejectedExecutionException</h2><p>bulkProcess执行成功，但设置.setConcurrentRequests(4)后，断开线程连接时会抛出如下错误<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">transport: [Orchid] failed to notify response handler on rejection</div></pre></td></tr></table></figure></p>
<p>解决：todo</p>
<h2 id="ProcessClusterEventTimeoutException"><a href="#ProcessClusterEventTimeoutException" class="headerlink" title="ProcessClusterEventTimeoutException"></a>ProcessClusterEventTimeoutException</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"><span class="comment">#################################################################</span></span></div><div class="line"><span class="meta">#</span><span class="bash"> /etc/elasticsearch/elasticsearch.yml</span></div><div class="line"><span class="meta">#</span><span class="bash"></span></div><div class="line"><span class="meta">#</span><span class="bash"> Base configuration <span class="keyword">for</span> a write heavy cluster</span></div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> Force all memory to be locked, forcing the JVM to never swap</span></div><div class="line">bootstrap.mlockall: true</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Threadpool Settings ##</span></span></div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> Search pool</span></div><div class="line">threadpool.search.type: fixed</div><div class="line">threadpool.search.size: 20</div><div class="line">threadpool.search.queue_size: 100</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> Bulk pool</span></div><div class="line">threadpool.bulk.type: fixed</div><div class="line">threadpool.bulk.size: 60</div><div class="line">threadpool.bulk.queue_size: 300</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> Index pool</span></div><div class="line">threadpool.index.type: fixed</div><div class="line">threadpool.index.size: 20</div><div class="line">threadpool.index.queue_size: 100</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> Indices settings</span></div><div class="line">indices.memory.index_buffer_size: 30%</div><div class="line">indices.memory.min_shard_index_buffer_size: 12mb</div><div class="line">indices.memory.min_index_buffer_size: 96mb</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> Cache Sizes</span></div><div class="line">indices.fielddata.cache.size: 15%</div><div class="line">indices.fielddata.cache.expire: 6h</div><div class="line">indices.cache.filter.size: 15%</div><div class="line">indices.cache.filter.expire: 6h</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> Indexing Settings <span class="keyword">for</span> Writes</span></div><div class="line">index.refresh_interval: 30s</div><div class="line">index.translog.flush_threshold_ops: 50000</div></pre></td></tr></table></figure>
<p>请教个es插入速度优化的问题，刚开始很快，但是现在目前每秒只能平均处理2个doc，<br>bulkProcess批量插入document，每个doc 25个字段，每个doc大小4k左右，3个Node(6个share,1个replica)；node配置（8G,4核）<br>配置了ES_HEAP_SIZE=3G</p>
<p>ElasticSearch索引优化<br><a href="http://m635674608.iteye.com/blog/2289439">http://m635674608.iteye.com/blog/2289439</a></p>
]]></content>
      
        <categories>
            
            <category> 后端技术 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Elasticsearch </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Elasticsearch集群部署]]></title>
      <url>http://geosmart.github.io/2016/07/23/Elasticsearch%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</url>
      <content type="html"><![CDATA[<p>Elasticsearch V2.3.4 集群部署记录：3个Node，6个Shard，2个Replica，能保证一台服务器宕机服务还能正常运行，且后期容易扩展到6个Node；</p>
<hr>
<a id="more"></a> 
<h1 id="安装Java"><a href="#安装Java" class="headerlink" title="安装Java"></a>安装Java</h1><p>sudo yum install java-1.8.0-openjdk.x86_64<br>Centos7自带openJdk8</p>
<h1 id="swap配置"><a href="#swap配置" class="headerlink" title="swap配置"></a>swap配置</h1><p><a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html#_swapping_is_the_death_of_performance">swapping_is_the_death_of_performance</a>,<br>ElasticSearch建议将 /proc/sys/vm/swappiness 设置为 0。默认设置为30。<br>查看当前swap分区设置<code>cat /proc/sys/vm/swappiness</code><br>临时修改值：<code>sudo sysctl vm.swappiness=0</code> / <code>sudo swapoff -a</code><br>永久修改值：<code>vim /etc/sysctl.conf</code>，在最后加一行<code>vm.swappiness = 0</code></p>
<h1 id="修改hostname"><a href="#修改hostname" class="headerlink" title="修改hostname"></a>修改hostname</h1><p>设置hostname为v3es1，并查看修改结果<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">es1</span></div><div class="line">hostnamectl set-hostname es1</div><div class="line">hostnamectl set-hostname es1 --static</div><div class="line">hostnamectl status</div></pre></td></tr></table></figure></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">es2</span></div><div class="line">hostnamectl set-hostname es2</div><div class="line">hostnamectl set-hostname es2 --static</div><div class="line">hostnamectl status</div></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">es3</span></div><div class="line">hostnamectl set-hostname es3</div><div class="line">hostnamectl set-hostname es3 --static</div><div class="line">hostnamectl status</div></pre></td></tr></table></figure>
<p><code>vim  /etc/hosts</code><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> es节点配置</span></div><div class="line">193.168.201.213 es1.es.com es1</div><div class="line">193.168.201.85  es2.es.com es2</div><div class="line">193.168.201.117 es3.es.com es3</div></pre></td></tr></table></figure></p>
<h2 id="局域网hosts配置"><a href="#局域网hosts配置" class="headerlink" title="局域网hosts配置"></a>局域网hosts配置</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> 局域网hosts配置es</span></div><div class="line">193.168.201.223 es1.es.com</div><div class="line">193.168.201.223 www.es1.es.com</div><div class="line">193.168.201.252  es2.es.com</div><div class="line">193.168.201.252  www.es2.es.com</div><div class="line">193.168.201.117  es3.es.com</div><div class="line">193.168.201.117  www.es3.es.com</div></pre></td></tr></table></figure>
<h1 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">停止firewall</span></div><div class="line">systemctl stop firewalld.service</div><div class="line"><span class="meta">#</span><span class="bash">禁止firewall开机启动 </span></div><div class="line">systemctl disable firewalld.service</div></pre></td></tr></table></figure>
<h1 id="新增用户"><a href="#新增用户" class="headerlink" title="新增用户"></a>新增用户</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">mkdir -p /data/elasticsearch/&#123;data,work,plugins,scripts&#125; </div><div class="line">useradd elasticsearch -s /bin/bash </div><div class="line"><span class="meta">#</span><span class="bash"> 1</span></div><div class="line">passwd elasticsearch</div><div class="line">vim /etc/sudoers	</div><div class="line"><span class="meta">#</span><span class="bash"> 新增</span></div><div class="line">elasticsearch    ALL=(ALL)       ALL</div><div class="line"><span class="meta">#</span><span class="bash"> 授权</span></div><div class="line">mkdir /var/log/elasticsearch</div><div class="line">chown -R elasticsearch:elasticsearch /var/log/elasticsearch /data/elasticsearch</div></pre></td></tr></table></figure>
<h1 id="安装elasticsearch"><a href="#安装elasticsearch" class="headerlink" title="安装elasticsearch"></a>安装elasticsearch</h1><p><a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-elasticsearch-on-centos-7">how-to-install-and-configure-elasticsearch-on-centos-7</a></p>
<h2 id="下载rpm包"><a href="#下载rpm包" class="headerlink" title="下载rpm包"></a>下载rpm包</h2><p>cd /mnt<br><code>wget https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/rpm/elasticsearch/2.3.4/elasticsearch-2.3.4.rpm</code></p>
<h2 id="yum本地安装"><a href="#yum本地安装" class="headerlink" title="yum本地安装"></a>yum本地安装</h2><p><code>cd /mnt &amp;&amp; sudo yum localinstall elasticsearch-2.3.4.rpm</code> </p>
<h2 id="设置自启动"><a href="#设置自启动" class="headerlink" title="设置自启动"></a>设置自启动</h2><p><code>sudo systemctl daemon-reload</code><br><code>sudo systemctl enable elasticsearch.service</code></p>
<h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p><code>vim /etc/elasticsearch/elasticsearch.yml</code></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="string">cluster.name:</span> <span class="string">cloudx_web</span></div><div class="line"><span class="string">node.name:</span> <span class="string">$&#123;HOSTNAME&#125;</span></div><div class="line"><span class="string">node.master:</span> <span class="literal">true</span></div><div class="line"><span class="string">node.data:</span> <span class="literal">true</span></div><div class="line"><span class="string">index.number_of_shards:</span> <span class="number">6</span></div><div class="line"><span class="string">index.number_of_replicas:</span> <span class="number">2</span></div><div class="line"><span class="string">network.host:</span> <span class="string">$&#123;HOSTNAME&#125;</span></div><div class="line"><span class="string">index.max_result_window:</span> <span class="number">10000000</span></div><div class="line"><span class="string">discovery.zen.minimum_master_nodes:</span> <span class="number">2</span></div><div class="line"><span class="string">discovery.zen.ping.unicast.hosts:</span> <span class="string">[es1,es2,es3]</span></div><div class="line"><span class="string">discovery.zen.ping.multicast.enabled:</span> <span class="literal">true</span></div><div class="line"><span class="string">path.data:</span> <span class="string">/data/elasticsearch</span> </div><div class="line"><span class="string">http.cors.allow-origin:</span> <span class="string">"*"</span></div><div class="line"><span class="string">http.cors.enabled:</span> <span class="literal">true</span></div></pre></td></tr></table></figure>
<p>复制到集群：<code>scp  /etc/elasticsearch/elasticsearch.yml root@es1:/etc/elasticsearch/</code></p>
<blockquote>
<p>理想状态下，3个Node，6个Shard，2个Replica，能保证一台服务器宕机服务还能正常运行，且后期容易扩展到6个Node；<br>但如果存储成本高，可改为1个Replica<br>另配置<code>discovery.zen.minimum_master_nodes=2</code>可保证不会出现脑裂问题；  </p>
</blockquote>
<p>3个节点正常运行<br><img src="es_cluster_shard1.png" alt="3个节点正常运行"><br>节点3挂了<br><img src="es_cluster_shard2.png" alt="节点3挂了"><br>replica自动复制迁移<br><img src="es_cluster_shard3.png" alt="replica自动复制迁移"><br>节点3恢复正常<br><img src="es_cluster_shard4.png" alt="节点3恢复正常"></p>
<h2 id="配置elasticsearch-heap大小"><a href="#配置elasticsearch-heap大小" class="headerlink" title="配置elasticsearch heap大小"></a>配置elasticsearch heap大小</h2><p><code>vim /etc/sysconfig/elasticsearch</code><br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="string">ES_HEAP_SIZE=3G</span></div><div class="line"><span class="string">MAX_OPEN_FILES=65535</span></div></pre></td></tr></table></figure></p>
<h2 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h2><p>su elasticsearch<br><code>sudo systemctl start elasticsearch.service</code> </p>
<h2 id="查看运行状态"><a href="#查看运行状态" class="headerlink" title="查看运行状态"></a>查看运行状态</h2><p><code>service elasticsearch status</code></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="string">●</span> <span class="string">elasticsearch.service</span> <span class="bullet">-</span> <span class="string">Elasticsearch</span></div><div class="line"><span class="attr">   Loaded:</span> <span class="string">loaded</span> <span class="string">(/usr/lib/systemd/system/elasticsearch.service;</span> <span class="string">enabled;</span> <span class="string">vendor</span> <span class="attr">preset:</span> <span class="string">disabled)</span></div><div class="line"><span class="attr">   Active:</span> <span class="string">active</span> <span class="string">(running)</span> <span class="string">since</span> <span class="string">日</span> <span class="number">2016</span><span class="bullet">-07</span><span class="bullet">-24</span> <span class="number">19</span><span class="string">:56:07</span> <span class="string">CST;</span> <span class="number">8</span><span class="string">min</span> <span class="string">ago</span></div><div class="line"><span class="attr">     Docs:</span> <span class="attr">http://www.elastic.co</span></div><div class="line"><span class="attr">  Process:</span> <span class="number">9370</span> <span class="string">ExecStartPre=/usr/share/elasticsearch/bin/elasticsearch-systemd-pre-exec</span> <span class="string">(code=exited,</span> <span class="string">status=0/SUCCESS)</span></div><div class="line"> <span class="string">Main</span> <span class="attr">PID:</span> <span class="number">9374</span> <span class="string">(java)</span></div><div class="line"><span class="attr">   CGroup:</span> <span class="string">/system.slice/elasticsearch.service</span></div><div class="line">           <span class="string">└─9374</span> <span class="string">/bin/java</span> <span class="bullet">-Xms256m</span> <span class="bullet">-Xmx1g</span> <span class="bullet">-Djava.awt.headless=true</span> <span class="attr">-XX:+UseParNewGC</span> <span class="attr">-XX:+UseC...</span></div></pre></td></tr></table></figure>
<h2 id="测试是否成功"><a href="#测试是否成功" class="headerlink" title="测试是否成功"></a>测试是否成功</h2><p>curl -X GET ‘<a href="http://localhost:9200">http://localhost:9200</a>‘<br>curl -X GET ‘<a href="http://193.168.201.250:9200">http://193.168.201.250:9200</a>‘<br>curl -X GET ‘<a href="http://193.168.201.252:9200">http://193.168.201.252:9200</a>‘<br>curl -X GET ‘<a href="http://193.168.201.117:9200">http://193.168.201.117:9200</a>‘</p>
<h2 id="插入测试"><a href="#插入测试" class="headerlink" title="插入测试"></a>插入测试</h2><p>curl -X POST ‘<a href="http://es1:9200/tutorial/helloworld/1">http://es1:9200/tutorial/helloworld/1</a>‘ -d ‘{ “message”: “Hello World!” }’<br>curl -X GET ‘<a href="http://es1:9200/tutorial/helloworld/1?pretty">http://es1:9200/tutorial/helloworld/1?pretty</a>‘</p>
<h2 id="查看日志"><a href="#查看日志" class="headerlink" title="查看日志"></a>查看日志</h2><p><code>tail -f  200 /var/log/elasticsearch/cloudx_web.log</code></p>
<h1 id="安装信息"><a href="#安装信息" class="headerlink" title="安装信息"></a>安装信息</h1><ul>
<li>安装目录：<code>/usr/share/elasticsearch/</code></li>
<li>配置目录：<code>/etc/elasticsearch</code></li>
<li>启动初始化脚本：<code>/etc/init.d/elasticsearch</code> </li>
<li>日志目录：<code>/var/log/elasticsearch</code></li>
<li>配置参数(<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-service.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-service.html</a>)</li>
</ul>
<h1 id="删除elasticsearch"><a href="#删除elasticsearch" class="headerlink" title="删除elasticsearch"></a>删除elasticsearch</h1><p><code>yum remove  elasticsearch</code><br><code>find / -name &quot;elasticsearch&quot; -exec  rm -rf {} \;</code></p>
<h1 id="ElasticSearch插件"><a href="#ElasticSearch插件" class="headerlink" title="ElasticSearch插件"></a>ElasticSearch插件</h1><h2 id="Elastic-HQ"><a href="#Elastic-HQ" class="headerlink" title="Elastic-HQ"></a>Elastic-HQ</h2><blockquote>
<p>Monitoring, Management, and Querying Web Interface for ElasticSearch instances and clusters.<br>Benefits:</p>
<ul>
<li>Active real-time monitoring of ElasticSearch clusters and nodes.</li>
<li>Manage Indices, Mappings, Shards, Aliases, and Nodes.</li>
<li>Query UI for searching one or multiple Indices.</li>
<li>REST UI, eliminates the need for cURL and cumbersome JSON formats.</li>
<li>No software to install/download. 100% web browser-based.</li>
<li>Optimized to work on mobile phones, tablets, and other small screen devices.</li>
<li>Easy to use and attractive user interface.</li>
<li>Free (as in Beer)</li>
</ul>
</blockquote>
<ul>
<li>安装：<code>cd /usr/share/elasticsearch/bin &amp;&amp; ./plugin install royrusso/elasticsearch-HQ</code>  </li>
<li>地址：<a href="http://es1.es.com9200/_plugin/hq/">http://es1.es.com9200/_plugin/hq/</a> </li>
</ul>
<h2 id="ElasticSearch-Kopf"><a href="#ElasticSearch-Kopf" class="headerlink" title="ElasticSearch-Kopf"></a>ElasticSearch-Kopf</h2><blockquote>
<p>Kopf是一个ElasticSearch的管理工具，它也提供了对ES集群操作的API。</p>
</blockquote>
<ul>
<li>安装：<code>cd /usr/share/elasticsearch/bin &amp;&amp; ./plugin install lmenezes/elasticsearch-kopf</code> </li>
<li>地址：<a href="http://es1.es.com:9200/_plugin/kopf/">http://es1.es.com:9200/_plugin/kopf/</a></li>
</ul>
<h2 id="Elasticsearch-head"><a href="#Elasticsearch-head" class="headerlink" title="Elasticsearch-head"></a>Elasticsearch-head</h2><blockquote>
<p>A web front end for an Elasticsearch cluster，查看集群状态</p>
</blockquote>
<ul>
<li>安装：<code>cd /usr/share/elasticsearch/bin &amp;&amp; ./plugin install mobz/elasticsearch-head</code>  </li>
</ul>
<h2 id="ElasticSearch-Paramedic"><a href="#ElasticSearch-Paramedic" class="headerlink" title="ElasticSearch-Paramedic"></a>ElasticSearch-Paramedic</h2><blockquote>
<p>Paramedic is a simple yet sexy tool to monitor and inspect ElasticSearch clusters.<br>It displays real-time statistics and information about your nodes and indices, as well as shard allocation within the cluster.<br>The application is written in JavaScript, using the Ember.js framework for sanity and the Cubism.js library for visuals. While the project is useful, the codebase, with most logic in controllers, lacking proper component separation and test suite, can’t be considered mature enough, yet.</p>
</blockquote>
<ul>
<li>安装：cd /usr/share/elasticsearch/bin &amp;&amp; ./plugin install karmi/elasticsearch-paramedic/</li>
<li>地址：<a href="http://es1.es.com:9200/_plugin/paramedic">http://es1.es.com:9200/_plugin/paramedic</a></li>
</ul>
<h2 id="ElasticSearch-Whatson"><a href="#ElasticSearch-Whatson" class="headerlink" title="ElasticSearch-Whatson"></a>ElasticSearch-Whatson</h2><blockquote>
<p>Whatson is an elasticsearch plugin to visualize the state of a cluster. It’s inpired by other excellent plugins:<br>xyu/elasticsearch-whatson</p>
</blockquote>
<ul>
<li>安装：<code>cd /usr/share/elasticsearch/bin &amp;&amp; ./plugin install xyu/elasticsearch-whatson</code>  </li>
<li>地址：<a href="http://es1.es.com:9200/_plugin/whatson">http://es1.es.com:9200/_plugin/whatson</a></li>
</ul>
<h1 id="安装问题"><a href="#安装问题" class="headerlink" title="安装问题"></a>安装问题</h1><h2 id="服务启动问题-Failed-to-created-node-environment"><a href="#服务启动问题-Failed-to-created-node-environment" class="headerlink" title="服务启动问题-Failed to created node environment"></a>服务启动问题-Failed to created node environment</h2><p>启动权限问题，必须以elasticsearch用户启动服务，不能以root启动</p>
<h2 id="配置问题-discovery-zen-ping-unicast-hosts"><a href="#配置问题-discovery-zen-ping-unicast-hosts" class="headerlink" title="配置问题-discovery.zen.ping.unicast.hosts"></a>配置问题-discovery.zen.ping.unicast.hosts</h2><p>Likely root cause: java.net.UnknownHostException: v3es1: unknown error<br>hostname -f查看fqdn</p>
<h2 id="ElasticHQ安装问题"><a href="#ElasticHQ安装问题" class="headerlink" title="ElasticHQ安装问题"></a>ElasticHQ安装问题</h2><p>关闭防火墙，设置好fqdn，关闭VPN</p>
<h2 id="discovery-zen-ping-unicast-hosts中的hostname-ping不通"><a href="#discovery-zen-ping-unicast-hosts中的hostname-ping不通" class="headerlink" title="discovery.zen.ping.unicast.hosts中的hostname ping不通"></a>discovery.zen.ping.unicast.hosts中的hostname ping不通</h2><p>日志</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">discovery.zen.ping.unicast] [es1] failed to send ping to [&#123;#zen_unicast_3#&#125;&#123;193.168.201.117&#125;&#123;es3/193.168.201.117:9300&#125;]</div><div class="line">SendRequestTransportException[internal:discovery/zen/unicast]]; </div><div class="line">nested: NodeNotConnectedException[[][es3/<span class="number">193.168</span>.201.117:<span class="number">9300</span>] Node not connected];</div><div class="line">at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:<span class="number">340</span>)</div><div class="line">[action.admin.cluster.health] [es1] no known master node, scheduling a retry</div></pre></td></tr></table></figure>
<p>解决：hostname忘记设置了，(╯□╰)</p>
]]></content>
      
        <categories>
            
            <category> 后端技术 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Elasticsearch </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Elasticsearch学习笔记]]></title>
      <url>http://geosmart.github.io/2016/07/22/Elasticsearch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>Elasticsearch是一个基于Apache Lucene(TM)的开源搜索引擎。<br>Lucene非常复杂，你需要深入了解检索的相关知识来理解它是如何工作的。Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。<br>不过，Elasticsearch不仅仅是Lucene和全文搜索，我们还能这样去描述它：</p>
<ul>
<li>分布式的实时文件存储，每个字段都被索引并可被搜索</li>
<li>分布式的实时分析搜索引擎</li>
<li>可以扩展到上百台服务器，处理PB级结构化或非结构化数据<br>而且，所有的这些功能被集成到一个服务里面，你的应用可以通过简单的RESTful API、各种语言的客户端甚至命令行与之交互。</li>
</ul>
<p>在Elasticsearch中，文档归属于一种类型(type),而这些类型存在于索引(index)中，类比传统关系型数据库：</p>
<p>  Relational DB -&gt; Databases -&gt; Tables -&gt; Rows -&gt; Columns<br>  Elasticsearch -&gt; Indices   -&gt; Types  -&gt; Documents -&gt; Fields</p>
<p>Elasticsearch集群可以包含多个索引(indices)（数据库），每一个索引可以包含多个类型(types)（表），每一个类型包含多个文档(documents)（行），然后每个文档包含多个字段(Fields)（列）。</p>
<hr>
<a id="more"></a> 
<h1 id="Document-文档"><a href="#Document-文档" class="headerlink" title="Document 文档"></a>Document 文档</h1><p>程序中大多的实体或对象能够被序列化为包含键值对的JSON对象，键(key)是字段(field)或属性(property)的名字，值(value)，可以是字符串、数字、布尔类型、另一个对象、值数组或者其他特殊类型，比如表示日期的字符串或者表示地理位置的对象。</p>
<p>通常，我们可以认为对象(object)和文档(document)是等价相通的。但他们还是有所差别：</p>
<ul>
<li>对象(Object)是一个JSON结构体——类似于哈希、hashmap、字典或者关联数组；</li>
<li>对象(Object)中还可能包含其他对象(Object)。 </li>
<li>Elasticsearch中，文档(document)这个术语有着特殊含义，它特指最顶层结构或者根对象(root object)序列化成的JSON数据（以唯一ID标识并存储于Elasticsearch中）。</li>
</ul>
<h2 id="文档元数据"><a href="#文档元数据" class="headerlink" title="文档元数据"></a>文档元数据</h2><p>一个文档不只有数据。它还包含了元数据(metadata)——关于文档的信息。三个必须的元数据节点是： </p>
<table>
<thead>
<tr>
<th style="text-align:left">节点</th>
<th style="text-align:left">说明              </th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">_index</td>
<td style="text-align:left">文档存储的地方</td>
</tr>
<tr>
<td style="text-align:left">_type</td>
<td style="text-align:left">文档代表的对象的类</td>
</tr>
<tr>
<td style="text-align:left">_id</td>
<td style="text-align:left">文档的唯一标识</td>
</tr>
</tbody>
</table>
<h3 id="index"><a href="#index" class="headerlink" title="_index"></a>_index</h3><p>索引(index)类似于关系型数据库里的“数据库”——它是我们存储和索引关联数据的地方。</p>
<blockquote>
<p>事实上，我们的数据被存储和索引在分片(shards)中，索引只是一个把一个或多个分片分组在一起的逻辑空间。<br>然而，这只是一些内部细节——我们的程序完全不用关心分片。<br>我们唯一需要做的仅仅是选择一个索引名。这个名字必须是全部小写，不能以下划线开头，不能包含逗号。</p>
</blockquote>
<h3 id="type"><a href="#type" class="headerlink" title="_type"></a>_type</h3><p>在应用中，我们使用对象表示一些“事物”，例如一个用户、一篇博客、一个评论，或者一封邮件。每个对象都属于一个类(class)，这个类定义了属性或与对象关联的数据。user类的对象可能包含姓名、性别、年龄和Email地址。</p>
<p>在Elasticsearch中，我们使用相同类型(type)的文档表示相同的“事物”，因为他们的数据结构也是相同的。</p>
<ul>
<li>每个类型(type)都有自己的映射(mapping)或者结构定义，就像传统数据库表中的列一样。</li>
<li>所有类型下的文档被存储在同一个索引下，但是类型的映射(mapping)会告诉Elasticsearch不同的文档如何被索引。</li>
<li>_type的名字可以是大写或小写，不能包含下划线或逗号。我们将使用blog做为类型名。</li>
</ul>
<h3 id="id"><a href="#id" class="headerlink" title="_id"></a>_id</h3><p>id仅仅是一个字符串，它与_index和_type组合时，就可以在Elasticsearch中唯一标识一个文档。当创建一个文档，你可以自定义_id，也可以让Elasticsearch帮你自动生成。</p>
<h1 id="Index-索引"><a href="#Index-索引" class="headerlink" title="Index 索引"></a>Index 索引</h1><p>文档通过index API被索引——使数据可以被存储和搜索。<br>但是首先需要决定文档所在。文档通过其_index、_type、_id唯一确定。</p>
<h1 id="Elasticsearch-CRUD"><a href="#Elasticsearch-CRUD" class="headerlink" title="Elasticsearch CRUD"></a>Elasticsearch CRUD</h1><h2 id="检索"><a href="#检索" class="headerlink" title="检索"></a>检索</h2><p>request：<code>GET /{_index}/{_type}/{_id}?pretty</code>，如<code>/website/blog/123?pretty</code>；<br>response：<br><figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">  <span class="attr">"_index"</span> :   <span class="string">"website"</span>,</div><div class="line">  <span class="attr">"_type"</span> :    <span class="string">"blog"</span>,</div><div class="line">  <span class="attr">"_id"</span> :      <span class="string">"123"</span>,</div><div class="line">  <span class="attr">"_version"</span> : <span class="number">1</span>,</div><div class="line">  <span class="attr">"found"</span> :    <span class="literal">true</span>,</div><div class="line">  <span class="attr">"_source"</span> :  &#123;</div><div class="line">      <span class="attr">"title"</span>: <span class="string">"My first blog entry"</span>,</div><div class="line">      <span class="attr">"text"</span>:  <span class="string">"Just trying this out..."</span>,</div><div class="line">      <span class="attr">"date"</span>:  <span class="string">"2014/01/01"</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="pretty"><a href="#pretty" class="headerlink" title="pretty"></a>pretty</h3><blockquote>
<p>在任意的查询字符串中增加pretty参数，类似于上面的例子。会让Elasticsearch美化输出(pretty-print)JSON响应以便更加容易阅读。_source字段不会被美化，它的样子与我们输入的一致。</p>
</blockquote>
<h3 id="检索部分文档"><a href="#检索部分文档" class="headerlink" title="检索部分文档"></a>检索部分文档</h3><p>通常，GET请求将返回文档的全部，存储在_source参数中。</p>
<ul>
<li>请求个别字段可以使用_source参数。多个字段可以使用逗号分隔，如<code>GET /website/blog/123?_source=title,text</code>；</li>
<li>只想得到_source字段而不要其他的元数据，你可以这样请求：<code>GET /website/blog/123/_source</code>；</li>
</ul>
<h3 id="检查文档是否存在"><a href="#检查文档是否存在" class="headerlink" title="检查文档是否存在"></a>检查文档是否存在</h3><p>如果你想做的只是检查文档是否存在——你对内容完全不感兴趣——使用HEAD方法来代替GET。HEAD请求不会返回响应体，只有HTTP头：</p>
<ul>
<li>存在返回<code>200 OK</code>状态：</li>
<li>不存在返回<code>404 Not Found</code>：</li>
</ul>
<h3 id="mget批量查询"><a href="#mget批量查询" class="headerlink" title="mget批量查询"></a>mget批量查询</h3><p>从Elasticsearch中检索多个文档，相对于逐条get检索，更快的方式是在一个请求中使用multi-get或者mget API。</p>
<h2 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h2><p>文档在Elasticsearch中是不可变的——我们不能修改他们。如果需要更新已存在的文档，可以使用index API 重建索引(reindex) 或者替换掉它。<br>在内部，Elasticsearch已经标记旧文档为删除并添加了一个完整的新文档。旧版本文档不会立即消失，但你也不能去访问它。<br>Elasticsearch会在你继续索引更多数据时清理被删除的文档。</p>
<h2 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h2><p>当索引一个文档，如何确定是完全创建了一个新的还是覆盖了一个已经存在的呢？<br>请记住<code>_index、_type、_id</code>三者唯一确定一个文档。</p>
<h3 id="Elasticsearch自动生成唯一-id"><a href="#Elasticsearch自动生成唯一-id" class="headerlink" title="Elasticsearch自动生成唯一_id"></a>Elasticsearch自动生成唯一_id</h3><p>所以要想保证文档是新加入的，最简单的方式是使用POST方法让Elasticsearch自动生成唯一_id：<br><code>POST /website/blog/</code> </p>
<h3 id="自定义的-id"><a href="#自定义的-id" class="headerlink" title="自定义的_id"></a>自定义的_id</h3><p>如果使用自定义的_id，必须告诉Elasticsearch应该在<code>_index、_type、_id</code>三者都不同时才接受请求。有两种实现方式</p>
<ol>
<li>使用op_type查询参数：<code>PUT /website/blog/123?op_type=create</code>；</li>
<li>在URL后加/_create做为端点：<code>PUT /website/blog/123/_create</code>；</li>
</ol>
<p>响应结果</p>
<ul>
<li>如果请求成功的创建了一个新文档，Elasticsearch将返回正常的元数据且响应状态码是<code>201 Created</code>；</li>
<li>如果包含相同的_index、_type和_id的文档已经存在，Elasticsearch将返回<code>409 Conflict</code>响应状态码；</li>
</ul>
<h2 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h2><p>使用DELETE方法：<code>DELETE /website/blog/123</code>；</p>
<ul>
<li>如果文档被找到，Elasticsearch将返回200 OK状态码和以下响应体。注意_version数字已经增加了。 </li>
<li>如果文档未找到，我们将得到一个404 Not Found状态码， </li>
</ul>
<blockquote>
<p><em>. 尽管文档不存在——“found”的值是false——_version依旧增加了。这是内部记录的一部分，它确保在多节点间不同操作可以有正确的顺序。
</em>. 除一个文档也不会立即从磁盘上移除，它只是被标记成已删除。Elasticsearch将会在你之后添加更多索引的时候才会在后台进行删除内容的清理。</p>
</blockquote>
<h2 id="批量操作"><a href="#批量操作" class="headerlink" title="批量操作"></a>批量操作</h2><p>就像mget允许一次性检索多个文档一样，<br><code>bulk API</code>允许我们使用单一请求来实现多个文档的<code>create、index、update或delete</code>‘；这对索引类似于日志活动这样的数据流非常有用，它们可以以成百上千的数据为一个批次按序进行索引。<br>bulk请求体如下，它有一点不同寻常：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&#123; action: &#123; metadata &#125;&#125;\n</div><div class="line">&#123; request body        &#125;\n</div><div class="line">&#123; action: &#123; metadata &#125;&#125;\n</div><div class="line">&#123; request body        &#125;\n</div></pre></td></tr></table></figure>
<p>这种格式类似于用”\n”符号连接起来的一行一行的JSON文档流(stream)。两个重要的点需要注意：</p>
<ul>
<li>每行必须以”\n”符号结尾，包括最后一行。这些都是作为每行有效的分离而做的标记。</li>
<li>每一行的数据不能包含未被转义的换行符，它们会干扰分析——这意味着JSON不能被美化打印。</li>
</ul>
<p><a href="http://es.xiaoleilu.com/040_Distributed_CRUD/35_Bulk_format.html">为什么bulk API需要带换行符的奇怪格式，而不是像mget API一样使用JSON数组？</a><br>在分布式环境下，Elasticsearch则从网络缓冲区中一行一行的直接读取数据。它使用换行符识别和解析action/metadata行，以决定哪些分片来处理这个请求。这利于任务分解，可以减少JSON序列化RAM消耗，从而降低JVM GC时间；</p>
<h3 id="行为-action"><a href="#行为-action" class="headerlink" title="行为(action)"></a>行为(action)</h3><p>action/metadata这一行定义了文档行为(what action)发生在哪个文档(which document)之上。</p>
<p>行为(action)必须是以下几种：</p>
<table>
<thead>
<tr>
<th style="text-align:left">行为</th>
<th style="text-align:left">解释</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">create</td>
<td style="text-align:left">当文档不存在时创建之。</td>
</tr>
<tr>
<td style="text-align:left">index</td>
<td style="text-align:left">创建新文档或替换已有文档。</td>
</tr>
<tr>
<td style="text-align:left">update</td>
<td style="text-align:left">局部更新文档。</td>
</tr>
<tr>
<td style="text-align:left">delete</td>
<td style="text-align:left">删除一个文档。</td>
</tr>
</tbody>
</table>
<p>在索引、创建、更新或删除时必须指定文档的<code>_index、_type、_id</code>这些元数据(metadata)。</p>
<h3 id="请求体-request-body"><a href="#请求体-request-body" class="headerlink" title="请求体(request body)"></a>请求体(request body)</h3><p>请求体由文档的_source组成——文档所包含的一些字段以及其值，即提供文档用来检索。</p>
<ul>
<li>update操作需要请求体，请求体的组成应该与update API（doc, upsert, script等等）一致。</li>
<li>delete操作不需要请求体(request body)。</li>
</ul>
<h3 id="响应结果"><a href="#响应结果" class="headerlink" title="响应结果"></a>响应结果</h3><p>每个子请求都被独立的执行，所以一个子请求的错误并不影响其它请求。<br>如果任何一个请求失败，顶层的error标记将被设置为true，然后错误的细节将在相应的请求中被报告：</p>
<h3 id="请求最佳大小（sweetspot）"><a href="#请求最佳大小（sweetspot）" class="headerlink" title="请求最佳大小（sweetspot）"></a>请求最佳大小（sweetspot）</h3><p>整个批量请求需要被加载到接受我们请求节点的内存里，所以请求越大，给其它请求可用的内存就越小。<br>有一个最佳的bulk请求大小。超过这个大小，性能不再提升而且可能降低。<br>最佳大小，当然并不是一个固定的数字。它完全取决于硬件、文档的大小和复杂度以及索引和搜索的负载。  </p>
<p>如何找到最佳点(sweetspot)：</p>
<ul>
<li>试着批量索引标准的文档，随着大小的增长，当性能开始降低，说明每个批次的大小太大了。</li>
<li>开始的数量可以在1000~5000个文档之间，如果文档非常大，可以使用较小的批次。</li>
<li>通常着眼于请求批次的物理大小是非常有用的。一千个1kB的文档和一千个1MB的文档大不相同。一个好的批次最好保持在5-15MB大小间。</li>
</ul>
<h1 id="Shard和Replica"><a href="#Shard和Replica" class="headerlink" title="Shard和Replica"></a>Shard和Replica</h1><h2 id="shard分片"><a href="#shard分片" class="headerlink" title="shard分片"></a>shard分片</h2><p>每个Index（对应Database）包含多个Shard，默认是5个，分散在不同的Node上，但不会存在两个相同的Shard存在一个Node上，这样就没有备份的意义了。Shard是一个最小的Lucene索引单元。<br>当插入document的时候，Elasticsearch通过对docid进行hash来确定其放在哪个shard上面，然后在shard上面进行索引存储。<br>shard代表索引分片，es可以把一个完整的索引分成多个分片，这样的好处是可以把一个大的索引拆分成多个，分布到不同的节点上。构成分布式搜索。分片的数量只能在索引创建前指定，并且索引创建后不能更改。</p>
<h2 id="replica副本"><a href="#replica副本" class="headerlink" title="replica副本"></a>replica副本</h2><p>replicas就是备份，Elasticsearch采用的是Push Replication模式，当你往 master主分片上面索引一个文档，该分片会复制该文档(document)到剩下的所有 replica副本分片中，这些分片也会索引这个文档。<br>es可以设置多个索引的副本，副本的作用一是提高系统的容错性，当个某个节点某个分片损坏或丢失时可以从副本中恢复。二是提高es的查询效率，es会自动对搜索请求进行负载均衡。</p>
<h1 id="gateway"><a href="#gateway" class="headerlink" title="gateway"></a>gateway</h1><p>代表es索引的持久化存储方式，es默认是先把索引存放到内存中，当内存满了时再持久化到硬盘。当这个es集群关闭再 重新启动时就会从gateway中读取索引数据。es支持多种类型的gateway，有本地文件系统（默认），分布式文件系统，Hadoop的HDFS和 amazon的s3云存储服务。</p>
<h1 id="discovery-zen"><a href="#discovery-zen" class="headerlink" title="discovery.zen"></a>discovery.zen</h1><p>代表es的自动发现节点机制，es是一个基于p2p的系统，它先通过广播寻找存在的节点，再通过多播协议来进行节点之间的通信，同时也支持点对点的交互。</p>
<h1 id="Transport"><a href="#Transport" class="headerlink" title="Transport"></a>Transport</h1><p>代表es内部节点或集群与客户端的交互方式，默认内部是使用tcp协议进行交互，同时它支持http协议（json格式）、thrift、servlet、memcached、zeroMQ等的传输协议（通过插件方式集成）。</p>
<h1 id="analyzer"><a href="#analyzer" class="headerlink" title="analyzer"></a>analyzer</h1><p>分布式搜索elasticsearch中文分词集成：elasticsearch官方只提供smartcn这个中文分词插件，效果不是很好，好在国内有medcl大神写的两个中文分词插件，一个是<a href="https://github.com/medcl/elasticsearch-analysis-ik">IKAnalyzer分词插件</a>的，一个是<a href="https://github.com/medcl/elasticsearch-analysis-mmseg">mmseg</a>的</p>
<h2 id="IKAnalyzer分词安装"><a href="#IKAnalyzer分词安装" class="headerlink" title="IKAnalyzer分词安装"></a>IKAnalyzer分词安装</h2><p>下载elasticsearch-analysis-ik源码并打包<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/medcl/elasticsearch-analysis-ik</div><div class="line">cd elasticsearch-analysis-ik</div><div class="line">mvn clean</div><div class="line">mvn compile</div><div class="line">mvn package</div></pre></td></tr></table></figure></p>
<p>拷贝和解压release下的文件: #{project_path}/elasticsearch-analysis-ik/target/releases/elasticsearch-analysis-ik-*.zip 到你的 elasticsearch 插件目录, 如: plugins/ik 重启elasticsearch </p>
<h2 id="IKAnalyzer测试中文分词"><a href="#IKAnalyzer测试中文分词" class="headerlink" title="IKAnalyzer测试中文分词"></a>IKAnalyzer测试中文分词</h2><p>IKAnalyzer分词测试：<a href="http://es1.es.com:9200/mycompany/_analyze?analyzer=ik&amp;pretty=true&amp;text=中华人民共和国国歌">http://es1.es.com:9200/mycompany/_analyze?analyzer=ik&amp;pretty=true&amp;text=中华人民共和国国歌</a></p>
<h2 id="对指定field建全文索引"><a href="#对指定field建全文索引" class="headerlink" title="对指定field建全文索引"></a>对指定field建全文索引</h2><ul>
<li>对index=cloudx_web_v3,type=T_EVENT_LOG的name字段以IKAnalyzer建全文索引<br>curl -XPUT <a href="http://es1.es.com:9200/cloudx_web_v3/T_EVENT_LOG/_mapping?pretty">http://es1.es.com:9200/cloudx_web_v3/T_EVENT_LOG/_mapping?pretty</a> -d ‘{“T_EVENT_LOG”:{“properties”:{“name”:{“type”:”string”,”analyzer”:”ik”,”search_analyzer”:”ik”}}}}’</li>
<li>测试索引：curl -XPOST <a href="http://es1.es.com:9200/cloudx_web_v3/_search?pretty">http://es1.es.com:9200/cloudx_web_v3/_search?pretty</a>  -d ‘{“query”:{“match”:{“name”:{“query”:”规则 专用”,”operator”:”and”}}}}’ </li>
</ul>
<h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><h3 id="field-must-be-set-when-search-analyzer-is-set"><a href="#field-must-be-set-when-search-analyzer-is-set" class="headerlink" title="field must be set when search_analyzer is set"></a>field must be set when search_analyzer is set</h3><ul>
<li>请求参数：<br>curl -XPUT <a href="http://es1.es.com:9200/cloudx_web_v3/T_EVENT_LOG/_mapping?pretty">http://es1.es.com:9200/cloudx_web_v3/T_EVENT_LOG/_mapping?pretty</a> -d ‘{“T_EVENT_LOG”:{“properties”:{“name”:{“type”:”string”,”indexAnalyzer”:”ik”,”searchAnalyzer”:”ik”}}}}’</li>
<li><p>问题日志：<br>{“error”:{“root_cause”:[{“type”:”mapper_parsing_exception”,”reason”:”analyzer on field [name] must be set when search_analyzer is set”}],”type”:”mapper_parsing_exception”,”reason”:”analyzer on field [name] must be set when search_analyzer is set”},”status”:400}</p>
</li>
<li><p>问题解决：参考旧版本教程的坑，V2.3.4的参数改了，应为<br>curl -XPUT <a href="http://es1.es.com:9200/cloudx_web_v3/T_EVENT_LOG/_mapping?pretty">http://es1.es.com:9200/cloudx_web_v3/T_EVENT_LOG/_mapping?pretty</a> -d ‘{“T_EVENT_LOG”:{“properties”:{“name”:{“type”:”string”,”analyzer”:”ik”,”search_analyzer”:”ik”}}}}’</p>
</li>
</ul>
<h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><h2 id="如何合理设置shard和replica"><a href="#如何合理设置shard和replica" class="headerlink" title="如何合理设置shard和replica"></a>如何合理设置shard和replica</h2><p><a href="http://www.cnblogs.com/richaaaard/p/5231905.html">ElasticSearch性能调优-Shard数</a></p>
<h3 id="shard数"><a href="#shard数" class="headerlink" title="shard数"></a>shard数</h3><ul>
<li><p>shard数==node数时<br>此时性能最佳，但是由于ElasticSearch的不可变性（Immutable）的限制，系统无法对Shard进行重新拆分分配，除非重新索引这个文件集合，而重建索引开销巨大,所以，为了支持未来可能的水平扩展，一般会为集群分配比node数更多的shard数，也就是说每个节点会有多个Shard。</p>
</li>
<li><p>shard数==node数*2<br>shard过多就会引入另外一系列的性能问题，如对于任意一次完整的搜索，ElasticSearch会分别对每个shard进行查询，最后进行汇总。当节点数和shard数是一对一的时候，所有的查询可以并行运行。但是，对于具有多个shard的节点，如果磁盘是15000RPM或SSD，可能会相对较快，但是这也会存在等待响应的问题，所以通常不推荐一个节点超过2个shard。</p>
</li>
</ul>
<h3 id="replica数"><a href="#replica数" class="headerlink" title="replica数"></a>replica数</h3><p>Replica也是Shard，与shard不同的是，replica只会参与读操作，同时也能提高集群的可用性。<br>对于Replica来说，它的主要作用就是提高集群错误恢复的能力，所以replica的数目与shard的数目以及node的数目相关，<br>与shard不同的是，replica的数目可以在集群建立之后变更，且代价较小，所以相比shard的数目而言，没有那么重要。<br>3 node, 3 shard, 1 replica (each)，2个node宕机，服务仍然正常运行。</p>
<h2 id="如何防止elasticsearch的脑裂问题"><a href="#如何防止elasticsearch的脑裂问题" class="headerlink" title="如何防止elasticsearch的脑裂问题"></a><a href="https://segmentfault.com/a/1190000004504225">如何防止elasticsearch的脑裂问题</a></h2><blockquote>
<p>如果刚开始使用elasticsearch，建议配置一个3节点集群。这样你可以设置minimum_master_nodes为2，减少了脑裂的可能性，但仍然保持了高可用的优点：你可以承受一个节点失效但集群还是正常运行的。<br>但如果已经运行了一个两节点elasticsearch集群怎么办？可以选择为了保持高可用而忍受脑裂的可能性，或者选择为了防止脑裂而选择高可用性。为了避免这种妥协，最好的选择是给集群添加一个节点。这听起来很极端，但并不是。<br>对于每一个elasticsearch节点你可以设置node.data参数来选择这个节点是否需要保存数据。缺省值是“true”，意思是默认每个elasticsearch节点同时也会作为一个数据节点。<br>在一个两节点集群，你可以添加一个新节点并把node.data参数设置为“false”。这样这个节点不会保存任何分片，但它仍然可以被选为主（默认行为）。因为这个节点是一个无数据节点，所以它可以放在一台便宜服务器上。<br>现在你就有了一个三节点的集群，可以安全的把minimum_master_nodes设置为2，避免脑裂而且仍然可以丢失一个节点并且不会丢失数据。</p>
<p>If discovery.zen.master_election.filter_client is true </p>
<ol>
<li>pings from client nodes (nodes where node.client is true, or both node.data and node.master are false) are ignored during master election; the default value is true.   </li>
<li>pings from non-master-eligible data nodes (nodes where node.data is true and node.master is false) are ignored during master election; the default value is false.   </li>
<li>Pings from master-eligible nodes are always observed during master election.  </li>
</ol>
<p>Nodes can be excluded from becoming a master by setting node.master to false.<br>Note, once a node is a client node (node.client set to true), it will not be allowed to become a master (node.master is automatically set to false).</p>
</blockquote>
<p>master和data同时配置会产生一些神奇的效果：</p>
<ol>
<li>当master为false，而data为true时，会对该节点产生严重负荷；</li>
<li>当master为true，而data为false时，该节点作为一个协调者； </li>
<li>当master为false，data也为false时，该节点就变成了一个负载均衡器。 </li>
</ol>
<h2 id="如何给Elasticsearch设置合适的Heap内存"><a href="#如何给Elasticsearch设置合适的Heap内存" class="headerlink" title="如何给Elasticsearch设置合适的Heap内存"></a><a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html">如何给Elasticsearch设置合适的Heap内存</a></h2><p>设置Elastic Heap内存（for Elasticsearch faster GCs）：<code>export ES_HEAP_SIZE=3g</code>，<br>建议分配可用内存的50%给ElasticSearch（如<code>aggregating on analyzed string fields</code>比较少的话，可以设置更小，以留下足够的空闲内存给lucene），<br>注意Lucene的segments是不可变的，为提高聚合和倒排索引的性能，lucene需要占用系统内存作为缓存</p>
<h2 id="如何删除document中的重复数据？"><a href="#如何删除document中的重复数据？" class="headerlink" title="如何删除document中的重复数据？"></a>如何删除document中的重复数据？</h2><p><a href="https://qbox.io/blog/minimizing-document-duplication-in-elasticsearch">minimizing-document-duplication-in-elasticsearch</a><br><a href="http://es1.es.com:9200/cloudx_web_v3/T_EVENT_LOG/_search?pretty=true">http://es1.es.com:9200/cloudx_web_v3/T_EVENT_LOG/_search?pretty=true</a> -d <code>{json}</code><br><figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    <span class="attr">"aggs"</span>: &#123;</div><div class="line">        <span class="attr">"duplicateCount"</span>: &#123;</div><div class="line">            <span class="attr">"terms"</span>: &#123;</div><div class="line">                <span class="attr">"field"</span>: <span class="string">"name"</span>,</div><div class="line">                <span class="attr">"min_doc_count"</span>: <span class="number">2</span></div><div class="line">            &#125;,</div><div class="line">            <span class="attr">"aggs"</span>: &#123;</div><div class="line">                <span class="attr">"duplicateDocuments"</span>: &#123;</div><div class="line">                    <span class="attr">"top_hits"</span>: &#123;&#125;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h1 id="ES参考资料"><a href="#ES参考资料" class="headerlink" title="ES参考资料"></a>ES参考资料</h1><ul>
<li><a href="http://www.cnblogs.com/richaaaard/category/783901.html">Richaaaard的Elasticsearch系列教程</a></li>
<li><a href="https://github.com/garyelephant/blog/blob/master/elasticsearch_optimization_checklist.md">ES调优参数列表</a></li>
</ul>
]]></content>
      
        <categories>
            
            <category> 后端技术 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Elasticsearch </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[日志分析ELK]]></title>
      <url>http://geosmart.github.io/2016/07/21/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90ELK/</url>
      <content type="html"><![CDATA[<p><a href="http://jolestar.com/elasticsearch-architecture/">Elasticsearch 架构以及源码概览</a></p>
<p>开源实时日志分析 ELK 平台由 <code>ElasticSearch 、Logstash 和 Kiabana</code> 三个开源工具组成。<br><a href="https://www.elastic.co/products">官方网站</a></p>
<ul>
<li>Elasticsearch 是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制， restful 风格接口，多数据源，自动搜索负载等。</li>
<li>Logstash 是一个完全开源的工具，他可以对你的日志进行收集、分析，并将其存储供以后使用（如，搜索）。</li>
<li>kibana 也是一个开源和免费的工具，他 Kibana 可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助您汇总、分析和搜索重要数据日志。</li>
</ul>
<h1 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h1><p>Docker…</p>
]]></content>
      
        <categories>
            
            <category> 后端技术 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Elasticsearch </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Neo4j索引笔记之SchemaIndex和LegacyIndex]]></title>
      <url>http://geosmart.github.io/2016/05/01/Neo4j%E7%B4%A2%E5%BC%95%E7%AC%94%E8%AE%B0%E4%B9%8BSchemaIndex%E5%92%8CLegacyIndex/</url>
      <content type="html"><![CDATA[<p>neo4j包含schema indexes 和 legacy indexes两种类型，两者理念不同且不可互换或兼容，实际应用中应明确检索需求后采用合适的索引。</p>
<hr>
<a id="more"></a>
<h1 id="schema-index-vs-legacy-index"><a href="#schema-index-vs-legacy-index" class="headerlink" title="schema index vs legacy index"></a>schema index vs legacy index</h1><p>参考<a href="http://nigelsmall.com/neo4j/index-confusion">neo4j index-confusion</a></p>
<ul>
<li>schema index和legacy index 都是基于lucene实现；</li>
<li>如果你正在使用Neo4j 2.0或者更高版本并且不需要支持2.0版本之前legacy index的代码，那么请只使用schema index同时避免legacy index；</li>
<li>如果你不得不使用Neo4j的早期版本，并且无法升级，无论如何你都只有一种索引可以选择（legacy index）；</li>
<li>如果你需要全文检索的索引，不管是什么版本，都将使用legacy index。</li>
</ul>
<h1 id="schema-index（schema-based-indexes）"><a href="#schema-index（schema-based-indexes）" class="headerlink" title="schema index（schema based indexes）"></a>schema index（schema based indexes）</h1><p><code>Neo4j is a schema-optional graph database. You can use Neo4j without any schema. Optionally you can introduce it in order to gain performance or modeling benefits.    This allows a way of working where the schema does not get in your way until you are at a stage where you want to reap the benefits of having one.</code></p>
<ul>
<li>在Neo4j 2.0版本之前，Legacy index被称作indexes。这个索引是在graph外部通过Lucene实现，允许“节点”和“关系”以键值对的形式被检索。从Neo4j 提供的REST接口来看，被称作<code>index</code>的变量通常是指Legacy indexes；</li>
<li>Legacy index能够提供全文本检索的能力。这个功能并没有在schema index中被提供，这也是Neo4j 2.0* 版本保留legacy indexes的原因之一。</li>
</ul>
<h2 id="新建索引"><a href="#新建索引" class="headerlink" title="新建索引"></a>新建索引</h2><p>create index on  :Node(property)，会对指定label property的所有node新建index ，index新建成功后，当graph更新时index会自动更新，index默认存储在根目录的/schema/index/lucene目录；<br>如：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># 新建索引</div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">INDEX</span> <span class="keyword">ON</span> :AddressNode( preAddressNodeGUIDs)</div><div class="line"># 删除索引</div><div class="line"><span class="keyword">DROP</span> <span class="keyword">INDEX</span> <span class="keyword">ON</span> :AddressNode(_id)</div></pre></td></tr></table></figure></p>
<h2 id="存储方式"><a href="#存储方式" class="headerlink" title="存储方式"></a>存储方式</h2><p>schema index存储方式为复合索引（Compound Index），除了段信息文件，锁文件，以及删除的文件外，其他的一系列索引文件压缩一个后缀名为cfs的文件，即所有的索引文件会被存储成一个单例的Directory，<br>此方式有助于减少索引文件数量，减少同时打开的文件数量，从而获取更高的效率。比如说，查询频繁，而不经常更新的需求，就很适合这种索引格式。</p>
<h1 id="legacy-index"><a href="#legacy-index" class="headerlink" title="legacy index"></a>legacy index</h1><p><a href="http://neo4j.com/docs/stable/indexing-create-advanced.html">Neo4j Legacy Index配置参数</a></p>
<table>
<thead>
<tr>
<th style="text-align:left">参数</th>
<th style="text-align:left">值</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">type</td>
<td style="text-align:left">exact, fulltext</td>
<td style="text-align:center">exact采用Lucene keyword analyzer是默认配置. fulltext采用white-space tokenizer in its analyzer.</td>
</tr>
<tr>
<td style="text-align:left">to_lower_case</td>
<td style="text-align:left">true, false</td>
<td style="text-align:center">type=fulltext时生效，在新建索引和查询时会自动进行字母的大小写转换，默认为小写</td>
</tr>
<tr>
<td style="text-align:left">analyzer</td>
<td style="text-align:left">Analyzer类全名</td>
<td style="text-align:center">自定义Lucene Analyzer，注意：to_lower_case配置会默认将查询参数转换为小写.如果自定义analyzer索引写入的字母为大写，查询结果将会不匹配</td>
</tr>
</tbody>
</table>
<h2 id="新建索引-1"><a href="#新建索引-1" class="headerlink" title="新建索引"></a>新建索引</h2><p>分exact和fulltext两类，两者可结合使用，可新建relationship索引，默认存储在根目录的index/lucene目录；<br>fulltext索引新建方式参考笔记<a href="http://geosmart.github.io/2016/04/21/Neo4j中实现自定义中文全文索引">Neo4j中实现自定义中文全文索引</a></p>
<ul>
<li>注意：使用legacy index查询往往需要一个start node；</li>
</ul>
<h2 id="存储方式-1"><a href="#存储方式-1" class="headerlink" title="存储方式"></a>存储方式</h2><p>legacy index采用非复合索引，更灵活，可以单独的访问某几个索引文件</p>
<h1 id="Neo4j联合索引"><a href="#Neo4j联合索引" class="headerlink" title="Neo4j联合索引"></a>Neo4j联合索引</h1><p>参考：<a href="https://dzone.com/articles/indexing-neo4j-overview">https://dzone.com/articles/indexing-neo4j-overview</a><br>Neo4j不支持联合索引，可采用拼接字段实现</p>
<p>Neo4j 3.0开始支持联合索引，但需要升级至JDK8<br><a href="https://github.com/neo4j/neo4j/issues/6841">https://github.com/neo4j/neo4j/issues/6841</a></p>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Neo4j </tag>
            
            <tag> Lucene </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Lucene学习笔记]]></title>
      <url>http://geosmart.github.io/2016/04/29/Lucene%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>Neo4j图数据库的索引采用的是Lucene全文索引，特别是LegacyIndex部分，需要深入了解Lucene进行索引定制，之前以IK分词在Solr中建索引和检索浅尝辄止，对Lucene也是停留在概念层。<br>Solr对Lucene商业封装后的易用性很强，提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展并对查询性能进行了优化，并且提供了一个完善的功能管理界面。Solr的封装屏蔽了许多技术细节，但是对于开发人员来说，最好还是自下而上循序渐进比较好。<br>lucene（全文检索引擎工具包）&gt;solr（企业级搜索应用服务器）&gt;nutch（分布式检索引擎）和打Boss一样，得一个个来。</p>
<hr>
<a id="more"></a>
<h1 id="Apache-Lucene简介"><a href="#Apache-Lucene简介" class="headerlink" title="Apache Lucene简介"></a>Apache Lucene简介</h1><p>The Apache LuceneTM project develops open-source search software, including:</p>
<ul>
<li>Lucene Core, our flagship sub-project, provides Java-based indexing and search technology, as well as spellchecking, hit highlighting and advanced analysis/tokenization capabilities.</li>
<li>SolrTM  is a high performance search server built using Lucene Core, with XML/HTTP and JSON/Python/Ruby APIs, hit highlighting, faceted search, caching, replication, and a web admin interface.</li>
<li>PyLucene is a Python port of the Core project.</li>
</ul>
<h1 id="Lucene-Core简介"><a href="#Lucene-Core简介" class="headerlink" title="Lucene Core简介"></a>Lucene Core简介</h1><p>Apache LuceneTM is a high-performance, full-featured text search engine library written entirely in Java. It is a technology suitable for nearly any application that requires full-text search, especially cross-platform.</p>
<h1 id="Lucene-Features"><a href="#Lucene-Features" class="headerlink" title="Lucene Features"></a>Lucene Features</h1><h2 id="可扩展、高性能索引"><a href="#可扩展、高性能索引" class="headerlink" title="可扩展、高性能索引"></a>可扩展、高性能索引</h2><ul>
<li>over 150GB/hour on modern hardware</li>
<li>small RAM requirements – only 1MB heap</li>
<li>incremental indexing as fast as batch indexing</li>
<li>index size roughly 20-30% the size of text indexed</li>
</ul>
<h2 id="强大、精准、高效的检索算法"><a href="#强大、精准、高效的检索算法" class="headerlink" title="强大、精准、高效的检索算法"></a>强大、精准、高效的检索算法</h2><ul>
<li>ranked searching – best results returned first</li>
<li>many powerful query types: phrase queries, wildcard queries, proximity queries, range queries and more</li>
<li>fielded searching (e.g. title, author, contents)</li>
<li>sorting by any field</li>
<li>multiple-index searching with merged results</li>
<li>allows simultaneous update and searching</li>
<li>flexible faceting, highlighting, joins and result grouping</li>
<li>fast, memory-efficient and typo-tolerant suggesters</li>
<li>pluggable ranking models, including the Vector Space Model and Okapi BM25</li>
<li>configurable storage engine (codecs)</li>
</ul>
<h2 id="跨平台的解决方案"><a href="#跨平台的解决方案" class="headerlink" title="跨平台的解决方案"></a>跨平台的解决方案</h2><ul>
<li>Available as Open Source software under the Apache License which lets you use Lucene in both commercial and Open Source programs</li>
<li>100%-pure Java</li>
<li>Implementations in other programming languages available that are index-compatible</li>
</ul>
<h1 id="Lucene的总体架构"><a href="#Lucene的总体架构" class="headerlink" title="Lucene的总体架构"></a>Lucene的总体架构</h1><p><a href="http://www.cnblogs.com/forfuture1978/archive/2009/12/14/1623596.html">http://www.cnblogs.com/forfuture1978/archive/2009/12/14/1623596.html</a></p>
<h1 id="Lucene索引结构"><a href="#Lucene索引结构" class="headerlink" title="Lucene索引结构"></a>Lucene索引结构</h1><p>Lucene的索引结构是有层次结构的，主要分以下几个层次：</p>
<h2 id="索引-Index"><a href="#索引-Index" class="headerlink" title="索引(Index)"></a>索引(Index)</h2><p>在Lucene中一个索引是放在一个文件夹中的，同一文件夹中的所有的文件构成一个Lucene索引。</p>
<h2 id="段-Segment"><a href="#段-Segment" class="headerlink" title="段(Segment)"></a>段(Segment)</h2><p>一个索引可以包含多个段，段与段之间是独立的，添加新文档可以生成新的段，不同的段可以合并。<br>具有相同前缀文件的属同一个段，segments.gen和segments_5是段的元数据文件，也即它们保存了段的属性信息。</p>
<h2 id="文档-Document"><a href="#文档-Document" class="headerlink" title="文档(Document)"></a>文档(Document)</h2><p><code>A document is a sequence of fields.</code><br>文档是我们建索引的基本单位，不同的文档是保存在不同的段中的，一个段可以包含多篇文档。<br>新添加的文档是单独保存在一个新生成的段中，随着段的合并，不同的文档合并到同一个段中。</p>
<h2 id="域-Field"><a href="#域-Field" class="headerlink" title="域(Field)"></a>域(Field)</h2><p><code>A field is a named sequence of terms.</code><br>一篇文档包含不同类型的信息，可以分开索引，比如标题，时间，正文，作者等，都可以保存在不同的域里（不同域的索引方式可以不同）。</p>
<h3 id="Field类型"><a href="#Field类型" class="headerlink" title="Field类型"></a>Field类型</h3><ul>
<li>field的text以文本形式存储在index中，field倒排后即为index，也可配置为只存储不建index；<br>Field.Store.* field存储选项通过倒排序索引来控制文本是否可以搜索；</li>
<li>field的text看分词为term后建立index，或者field的text直接以原始文本作为term存储为index；大多数field是分词后建立索引的，但有时候指定一些identifier field只存储原始文本是很有用的；<br>Field.Index.*  field索引选项确定是否要存储域的真实值；<h2 id="词元-Term"><a href="#词元-Term" class="headerlink" title="词元(Term)"></a>词元(Term)</h2><code>A term is a string.</code><br>词元是索引的最小单位，是经过词法分析和语言处理后的字符串。<br>在不同field中的相同字符串是不同的term，因此term表示一对字符串，第一个用以命名field，第二个用以命名field中的text；<br>文档是Lucene搜索和索引的原子单位，文档为包含一个或者多个域的容器，而域则是依次包含“真正的”被搜索的内容，域值通过分词技术处理，得到多个词元。</li>
</ul>
<h1 id="索引可视化工具"><a href="#索引可视化工具" class="headerlink" title="索引可视化工具"></a>索引可视化工具</h1><p><a href="https://github.com/DmitryKey/luke">Luke</a></p>
<h1 id="倒排-反向索引（Inverted-Indexing）"><a href="#倒排-反向索引（Inverted-Indexing）" class="headerlink" title="倒排/反向索引（Inverted Indexing）"></a>倒排/反向索引（<a href="https://zh.wikipedia.org/wiki/倒排索引">Inverted Indexing</a>）</h1><p>定义：存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射<br>为了使得基于term的检索更高效，index中存储了term的统计数据；lucene的索引在索引家族中被称为倒排/反向索引，这是因为它能列出所有包含某个term的document，而这与根据document列出terms的自然联系是倒置的</p>
<h2 id="Lucene索引中的正向信息"><a href="#Lucene索引中的正向信息" class="headerlink" title="Lucene索引中的正向信息"></a>Lucene索引中的正向信息</h2><p>正向信息按层次保存了从index一直到term的包含关系：<code>索引(Index) –&gt; 段(segment) –&gt; 文档(Document) –&gt; 域(Field) –&gt; 词(Term)</code><br>也即此索引包含了那些段，每个段包含了那些文档，每个文档包含了那些域，每个域包含了那些词。既然是层次结构，则每个层次都保存了本层次的信息以及下一层次的元信息，也即属性信息。<br>包含正向信息的文件有：</p>
<ul>
<li>segments_N保存了此索引包含多少个段，每个段包含多少篇文档。</li>
<li>XXX.fnm保存了此段包含了多少个域，每个域的名称及索引方式。</li>
<li>XXX.fdx，XXX.fdt保存了此段包含的所有文档，每篇文档包含了多少域，每个域保存了那些信息。</li>
<li>XXX.tvx，XXX.tvd，XXX.tvf保存了此段包含多少文档，每篇文档包含了多少域，每个域包含了多少词，每个词的字符串，位置等信息。</li>
</ul>
<p>示例：如一本介绍中国地理的书，应该首先介绍中国地理的概况，以及中国包含多少个省，每个省介绍本省的基本概况及包含多少个市，每个市介绍本市的基本概况及包含多少个县，每个县具体介绍每个县的具体情况。</p>
<h2 id="Lucene索引中的反向信息"><a href="#Lucene索引中的反向信息" class="headerlink" title="Lucene索引中的反向信息"></a>Lucene索引中的反向信息</h2><p>反向信息保存了词典到倒排表的映射：<code>词(Term) –&gt; 文档(Document)</code><br>包含反向信息的文件有：</p>
<ul>
<li>XXX.tis，XXX.tii保存了词典(Term Dictionary)，也即此段包含的所有的词按字典顺序的排序。</li>
<li>XXX.frq保存了倒排表，也即包含每个词的文档ID列表。</li>
<li>XXX.prx保存了倒排表中每个词在包含此词的文档中的位置。</li>
</ul>
<h2 id="倒排索引的应用"><a href="#倒排索引的应用" class="headerlink" title="倒排索引的应用"></a>倒排索引的应用</h2><ul>
<li>反向索引数据结构是典型的搜索引擎检索算法重要的部分。</li>
<li>一个搜索引擎执行的目标就是优化查询的速度：找到某个单词在文档中出现的地方。以前，正向索引开发出来用来存储每个文档的单词的列表，接着掉头来开发了一种反向索引。 正向索引的查询往往满足每个文档有序频繁的全文查询和每个单词在校验文档中的验证这样的查询。</li>
<li>实际上，时间、内存、处理器等等资源的限制，技术上正向索引是不能实现的。</li>
<li>为了替代正向索引的每个文档的单词列表，能列出每个查询的单词所有所在文档的列表的反向索引数据结构开发了出来。</li>
<li>随着反向索引的创建，如今的查询能通过立即的单词标示迅速获取结果（经过随机存储）。随机存储也通常被认为快于顺序存储。</li>
</ul>
<h1 id="Lucene索引文件的基本类型"><a href="#Lucene索引文件的基本类型" class="headerlink" title="Lucene索引文件的基本类型"></a>Lucene索引文件的基本类型</h1><p>Lucene索引文件中，用一下基本类型来保存信息：  </p>
<ul>
<li>Byte：是最基本的类型，长8位(bit)。</li>
<li>UInt32：由4个Byte组成。</li>
<li>UInt64：由8个Byte组成。</li>
<li>VInt：变长的整数类型，它可能包含多个Byte，对于每个Byte的8位，其中后7位表示数值，最高1位表示是否还有另一个Byte，0表示没有，1表示有。<br>越前面的Byte表示数值的低位，越后面的Byte表示数值的高位。<br>例如130化为二进制为 1000, 0010，总共需要8位，一个Byte表示不了，因而需要两个Byte来表示，第一个Byte表示后7位，并且在最高位置1来表示后面还有一个Byte，所以为(1) 0000010，第二个Byte表示第8位，并且最高位置0来表示后面没有其他的Byte了，所以为(0) 0000001。</li>
<li>Chars：是UTF-8编码的一系列Byte。</li>
<li>String：一个字符串首先是一个VInt来表示此字符串包含的字符的个数，接着便是UTF-8编码的字符序列Chars。</li>
</ul>
<h1 id="Lucene索引存储的基本规则"><a href="#Lucene索引存储的基本规则" class="headerlink" title="Lucene索引存储的基本规则"></a>Lucene索引存储的基本规则</h1><p>Lucene为了使的信息的存储占用的空间更小，访问速度更快，采取了一些特殊的技巧.</p>
<h2 id="前缀后缀规则-Prefix-Suffix"><a href="#前缀后缀规则-Prefix-Suffix" class="headerlink" title="前缀后缀规则(Prefix+Suffix)"></a>前缀后缀规则(Prefix+Suffix)</h2><p>Lucene在反向索引中，要保存词典(Term Dictionary)的信息，所有的词(Term)在词典中是按照字典顺序进行排列的，然而词典中包含了文档中的几乎所有的词，并且有的词还是非常的长的，这样索引文件会非常的大，所谓前缀后缀规则，即当某个词和前一个词有共同的前缀的时候，后面的词仅仅保存前缀在词中的偏移(offset)，以及除前缀以外的字符串(称为后缀)。</p>
<h2 id="差值规则-Delta"><a href="#差值规则-Delta" class="headerlink" title="差值规则(Delta)"></a>差值规则(Delta)</h2><p>在Lucene的反向索引中，需要保存很多整型数字的信息，比如文档ID号，比如词(Term)在文档中的位置等等。<br>整型数字是以VInt的格式存储的。随着数值的增大，每个数字占用的Byte的个数也逐渐的增多。所谓差值规则(Delta)就是先后保存两个整数的时候，后面的整数仅仅保存和前面整数的差即可。</p>
<h2 id="或然跟随规则-A-B"><a href="#或然跟随规则-A-B" class="headerlink" title="或然跟随规则(A, B?)"></a>或然跟随规则(A, B?)</h2><p>Lucene的索引结构中存在这样的情况，某个值A后面可能存在某个值B，也可能不存在，需要一个标志来表示后面是否跟随着B。<br>一般的情况下，在A后面放置一个Byte，为0则后面不存在B，为1则后面存在B，或者0则后面存在B，1则后面不存在B。  </p>
<h2 id="跳跃表规则-Skip-list"><a href="#跳跃表规则-Skip-list" class="headerlink" title="跳跃表规则(Skip list)"></a>跳跃表规则(Skip list)</h2><p>为了提高查找的性能，Lucene在很多地方采取的跳跃表的数据结构。<br>跳跃表(Skip List)是如图的一种数据结构，有以下几个基本特征：</p>
<ul>
<li>元素是按顺序排列的，在Lucene中，或是按字典顺序排列，或是按从小到大顺序排列。</li>
<li>跳跃是有间隔的(Interval)，也即每次跳跃的元素数，间隔是事先配置好的，如图跳跃表的间隔为3。</li>
<li>跳跃表是由层次的(level)，每一层的每隔指定间隔的元素构成上一层，如图跳跃表共有2层。</li>
</ul>
<h1 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h1><p>TF-IDF（term frequency–inverse document frequency）是一种用于信息检索与数据挖掘的常用加权技术。</p>
<h2 id="Lucene词元权重计算"><a href="#Lucene词元权重计算" class="headerlink" title="Lucene词元权重计算"></a>Lucene词元权重计算</h2><ul>
<li>Term Frequency（tf）：此term在文档中出现的次数，tf越大则该词元越重要。</li>
<li>Document Frequency（df）：有多少文档包含此term，df越大该词元越不重要。<br>计算夹角的余弦值，夹角越小，余弦值越大，分值越大，从而相关性越大。</li>
</ul>
<h1 id="Lucene检索"><a href="#Lucene检索" class="headerlink" title="Lucene检索"></a>Lucene检索</h1><h2 id="TokenStream"><a href="#TokenStream" class="headerlink" title="TokenStream"></a>TokenStream</h2><p>TokenStream extends AttributeSource implements Closeable:<br>incrementToken,end,reset,close</p>
<h2 id="Tokenizer"><a href="#Tokenizer" class="headerlink" title="Tokenizer"></a>Tokenizer</h2><p>Tokenizers perform the task of breaking a string into separate tokens.<br>Tokenizer直接继承至TokenStream,其输入input是一个reader</p>
<h2 id="TokenFilter"><a href="#TokenFilter" class="headerlink" title="TokenFilter"></a>TokenFilter</h2><p>Token filters act on each token that is generated by a tokenizer and apply some set of operations that alter or normalize them.<br>TokenFilter也直接继承TokenStream,但input是一个TokenStream。</p>
<h2 id="TokenStreamComponents"><a href="#TokenStreamComponents" class="headerlink" title="TokenStreamComponents"></a>TokenStreamComponents</h2><p>TokenStreamComponents其实是将tokenizer和tokenfilter包装起来的(也可以只是tokenizer,两个成员叫source和sink),可以setReader,getTokenStream方法返回sink。</p>
<h2 id="Analyzer"><a href="#Analyzer" class="headerlink" title="Analyzer"></a>Analyzer</h2><p><a href="http://www.citrine.io/blog/2015/2/14/building-a-custom-analyzer-in-lucene">如何自定义Analyzer</a><br>Analyzer就是一个TokenStreamComponents的容器，因此需要确定ReuseStrategy,重写createComponents(fieldName,reader)方法,使用时调用tokenStream(fieldName,reader)方法获取TokenStream就可以了。</p>
<h1 id="Lucene常用组件"><a href="#Lucene常用组件" class="headerlink" title="Lucene常用组件"></a>Lucene常用组件</h1><ul>
<li>lucene-core</li>
<li>lucene-analyzers-common</li>
<li>lucene-analyzers</li>
<li>lucene-queryparser</li>
<li>lucene-codecs</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Lucene </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Neo4j中实现自定义中文全文索引]]></title>
      <url>http://geosmart.github.io/2016/04/21/Neo4j%E4%B8%AD%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%AE%9A%E4%B9%89%E4%B8%AD%E6%96%87%E5%85%A8%E6%96%87%E7%B4%A2%E5%BC%95/</url>
      <content type="html"><![CDATA[<p>数据库检索效率时，一般首要优化途径是从索引入手，然后根据需求再考虑更复杂的负载均衡、读写分离和分布式水平/垂直分库/表等手段；<br>索引通过信息冗余来提高检索效率，其以空间换时间并会降低数据写入的效率；因此对索引字段的选择非常重要。</p>
<ul>
<li>Neo4j可对指定Label的Node Create Index，当新增/更新符合条件的Node属性时，Index会自动更新。Neo4j Index默认采用Lucene实现（可定制，如Spatial Index自定义实现的RTree索引），但默认新建的索引只支持精确匹配（get），模糊查询（query）的话需要以全文索引，控制Lucene后台的分词行为。  </li>
<li>Neo4j全文索引默认的分词器是针对西方语种的，如默认的exact查询采用的是lucene KeywordAnalyzer（关键词分词器）,fulltext查询采用的是 white-space tokenizer（空格分词器），大小写什么的对中文没啥意义；所以针对中文分词需要挂一个中文分词器，如IK Analyzer,Ansj，至于类似梁厂长家的基于深度学习的分词系统pullword，那就更厉害啦。   </li>
</ul>
<p>本文以常用的IK Analyzer分词器为例，介绍如何在Neo4j中对字段新建全文索引实现模糊查询。</p>
<hr>
<a id="more"></a>
<h1 id="IKAnalyzer分词器"><a href="#IKAnalyzer分词器" class="headerlink" title="IKAnalyzer分词器"></a>IKAnalyzer分词器</h1><p><a href="https://github.com/wks/ik-analyzer">IKAnalyzer</a>是一个开源的，基于java语言开发的轻量级的中文分词工具包。<br>IKAnalyzer3.0特性:</p>
<ul>
<li>采用了特有的“正向迭代最细粒度切分算法“，支持细粒度和最大词长两种切分模式；具有83万字/秒（1600KB/S）的高速处理能力。</li>
<li>采用了多子处理器分析模式，支持：英文字母、数字、中文词汇等分词处理，兼容韩文、日文字符优化的词典存储，更小的内存占用。支持用户词典扩展定义</li>
<li>针对Lucene全文检索优化的查询分析器IKQueryParser(作者吐血推荐)；引入简单搜索表达式，采用歧义分析算法优化查询关键字的搜索排列组合，能极大的提高Lucene检索的命中率。<br>IK Analyser目前还没有maven库，还得自己手动下载install到本地库，下次空了自己在github做一个maven私有库，上传这些maven central库里面没有的工具包。</li>
</ul>
<h1 id="IKAnalyzer自定义用户词典"><a href="#IKAnalyzer自定义用户词典" class="headerlink" title="IKAnalyzer自定义用户词典"></a>IKAnalyzer自定义用户词典</h1><ul>
<li>词典文件<br>自定义词典后缀名为.dic的词典文件，必须使用无BOM的UTF-8编码保存的文件。  </li>
<li>词典配置<br>词典和IKAnalyzer.cfg.xml配置文件的路径问题，IKAnalyzer.cfg.xml必须在src根目录下。词典可以任意放，但是在IKAnalyzer.cfg.xml里要配置对。如下这种配置，ext.dic和stopword.dic应当在同一目录下。<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</div><div class="line"><span class="meta">&lt;!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd"&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span>  </div><div class="line"><span class="tag">&lt;<span class="name">comment</span>&gt;</span>IK Analyzer 扩展配置<span class="tag">&lt;/<span class="name">comment</span>&gt;</span></div><div class="line"></div><div class="line"><span class="comment">&lt;!--用户可以在这里配置自己的扩展字典 --&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span>=<span class="string">"ext_dict"</span>&gt;</span>/ext.dic;<span class="tag">&lt;/<span class="name">entry</span>&gt;</span></div><div class="line"></div><div class="line"><span class="comment">&lt;!--用户可以在这里配置自己的扩展停止词字典--&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span>=<span class="string">"ext_stopwords"</span>&gt;</span>/stopword.dic<span class="tag">&lt;/<span class="name">entry</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></div></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="Neo4j全文索引构建"><a href="#Neo4j全文索引构建" class="headerlink" title="Neo4j全文索引构建"></a>Neo4j全文索引构建</h1><p>指定IKAnalyzer作为luncene分词的analyzer，并对所有Node的指定属性新建全文索引<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">createAddressNodeFullTextIndex</span> <span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">try</span> (Transaction tx = graphDBService.beginTx()) &#123;</div><div class="line">      IndexManager index = graphDBService.index();</div><div class="line">      Index&lt;Node&gt; addressNodeFullTextIndex =</div><div class="line">            index.forNodes( <span class="string">"addressNodeFullTextIndex"</span>, MapUtil.stringMap(IndexManager.PROVIDER, <span class="string">"lucene"</span>, <span class="string">"analyzer"</span>, IKAnalyzer.class.getName()));</div><div class="line"></div><div class="line">      ResourceIterator&lt;Node&gt; nodes = graphDBService.findNodes(DynamicLabel.label( <span class="string">"AddressNode"</span>));</div><div class="line">      <span class="keyword">while</span> (nodes.hasNext()) &#123;</div><div class="line">          Node node = nodes.next();</div><div class="line">          <span class="comment">//对text字段新建全文索引</span></div><div class="line">          Object text = node.getProperty( <span class="string">"text"</span>, <span class="keyword">null</span>);</div><div class="line">          addressNodeFullTextIndex.add(node, <span class="string">"text"</span>, text);</div><div class="line">      &#125;</div><div class="line">      tx.success();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h1 id="Neo4j全文索引测试"><a href="#Neo4j全文索引测试" class="headerlink" title="Neo4j全文索引测试"></a>Neo4j全文索引测试</h1><p>对关键词（如’有限公司’），多关键词模糊查询（如’苏州 教育 公司’）默认都能检索，且检索结果按关联度已排好序。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> uadb.tr.neodao.test;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.junit.Test;</div><div class="line"><span class="keyword">import</span> org.junit.runner.RunWith;</div><div class="line"><span class="keyword">import</span> org.neo4j.graphdb.GraphDatabaseService;</div><div class="line"><span class="keyword">import</span> org.neo4j.graphdb.Node;</div><div class="line"><span class="keyword">import</span> org.neo4j.graphdb.Transaction;</div><div class="line"><span class="keyword">import</span> org.neo4j.graphdb.index.Index;</div><div class="line"><span class="keyword">import</span> org.neo4j.graphdb.index.IndexHits;</div><div class="line"><span class="keyword">import</span> org.neo4j.graphdb.index.IndexManager;</div><div class="line"><span class="keyword">import</span> org.neo4j.helpers.collection.MapUtil;</div><div class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</div><div class="line"><span class="keyword">import</span> org.springframework.test.context.ContextConfiguration;</div><div class="line"><span class="keyword">import</span> org.springframework.test.context.junit4.SpringJUnit4ClassRunner;</div><div class="line"><span class="keyword">import</span> org.wltea.analyzer.lucene.IKAnalyzer;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.lt.uadb.tr.entity.adtree.AddressNode;</div><div class="line"><span class="keyword">import</span> com.lt.util.serialize.JsonUtil;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * AddressNodeNeoDaoTest</span></div><div class="line"><span class="comment"> *</span></div><div class="line"><span class="comment"> * <span class="doctag">@author</span> geosmart</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="meta">@RunWith</span>(SpringJUnit4ClassRunner. <span class="class"><span class="keyword">class</span>)</span></div><div class="line"><span class="class">@<span class="title">ContextConfiguration</span>(<span class="title">locations</span> </span>= &#123; <span class="string">"classpath:app.neo4j.cfg.xml"</span> &#125;)</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AddressNodeNeoDaoTest</span> </span>&#123;</div><div class="line">      <span class="meta">@Autowired</span></div><div class="line">      GraphDatabaseService graphDBService;</div><div class="line"></div><div class="line">      <span class="meta">@Test</span></div><div class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test_selectAddressNodeByFullTextIndex</span><span class="params">()</span> </span>&#123;</div><div class="line">             <span class="keyword">try</span> (Transaction tx = graphDBService.beginTx()) &#123;</div><div class="line">                  IndexManager index = graphDBService.index();</div><div class="line">                  Index&lt;Node&gt; addressNodeFullTextIndex = index.forNodes(<span class="string">"addressNodeFullTextIndex"</span> ,</div><div class="line">                              MapUtil. stringMap(IndexManager.PROVIDER, <span class="string">"lucene"</span>, <span class="string">"analyzer"</span> , IKAnalyzer.class.getName()));</div><div class="line">                  IndexHits&lt;Node&gt; foundNodes = addressNodeFullTextIndex.query(<span class="string">"text"</span> , <span class="string">"苏州 教育 公司"</span> );</div><div class="line">                   <span class="keyword">for</span> (Node node : foundNodes) &#123;</div><div class="line">                        AddressNode entity = JsonUtil.ConvertMap2POJO(node.getAllProperties(), AddressNode. <span class="class"><span class="keyword">class</span>, <span class="title">false</span>, <span class="title">true</span>)</span>;</div><div class="line">                        System. out.println(entity.getAll地址实全称());</div><div class="line">                  &#125;</div><div class="line">                  tx.success();</div><div class="line">            &#125;</div><div class="line">      &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h1 id="CyperQL中使用自定义全文索引查询"><a href="#CyperQL中使用自定义全文索引查询" class="headerlink" title="CyperQL中使用自定义全文索引查询"></a>CyperQL中使用自定义全文索引查询</h1><h2 id="正则查询"><a href="#正则查询" class="headerlink" title="正则查询"></a>正则查询</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">profile  </div><div class="line">match (a:AddressNode&#123;ruleabbr:'TOW',text:'唯亭镇'&#125;)&lt;-[r:BELONGTO]-(b:AddressNode&#123;ruleabbr:'STR'&#125;)</div><div class="line">where b.text=~ '金陵.*'</div><div class="line">return a,b</div></pre></td></tr></table></figure>
<h2 id="全文索引查询"><a href="#全文索引查询" class="headerlink" title="全文索引查询"></a>全文索引查询</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">profile</div><div class="line"><span class="keyword">START</span> b=node:addressNodeFullTextIndex(<span class="string">"text:金陵*"</span>)</div><div class="line"><span class="keyword">match</span> (a:AddressNode&#123;ruleabbr:<span class="string">'TOW'</span>,<span class="built_in">text</span>:<span class="string">'唯亭镇'</span>&#125;)&lt;-[r:BELONGTO]-(b:AddressNode)</div><div class="line"><span class="keyword">where</span> b.ruleabbr=<span class="string">'STR'</span></div><div class="line"><span class="keyword">return</span> a,b</div></pre></td></tr></table></figure>
<h1 id="LegacyIndex中建立联合exact和fulltext索引"><a href="#LegacyIndex中建立联合exact和fulltext索引" class="headerlink" title="LegacyIndex中建立联合exact和fulltext索引"></a>LegacyIndex中建立联合exact和fulltext索引</h1><p>对label为AddressNode的节点，根据节点属性ruleabbr的分类addressnode_fulltext_index（省-&gt;市-&gt;区县-&gt;乡镇街道-&gt;街路巷/物业小区）/addressnode_exact_index(门牌号-&gt;楼幢号-&gt;单元号-&gt;层号-&gt;户室号)，对属性text分别建不同类型的索引<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">profile</div><div class="line"><span class="keyword">START</span> a=node:addressnode_fulltext_index(<span class="string">"text:商业街"</span>),b=node:addressnode_exact_index(<span class="string">"text:二期19"</span>)</div><div class="line"><span class="keyword">match</span> (a:AddressNode&#123;ruleabbr:<span class="string">'STR'</span>&#125;)-[r:BELONGTO]-(b:AddressNode&#123;ruleabbr:<span class="string">'TAB'</span>&#125;)</div><div class="line"><span class="keyword">return</span> a,b <span class="keyword">limit</span> <span class="number">10</span></div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Neo4j </tag>
            
            <tag> Lucene </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Neo4j空间索引学习笔记]]></title>
      <url>http://geosmart.github.io/2016/04/03/Neo4j%E7%A9%BA%E9%97%B4%E7%B4%A2%E5%BC%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>Neo4j采用Neo4j Spatial插件实现空间索引，Neo4j Spatial可使用API或Cypher执行空间查询操作，另作为插件可部署于GeoServer与uDig；与Oracle/MySQL Spatial Extention/MongoDB 2dSphere等空间模块相比，这种结合关系与空间的分析更值得尝试！</p>
<hr>
<a id="more"></a>
<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><p><a href="http://neo4j-contrib.github.io/spatial/">neo4j spatial github官网</a><br><a href="http://www.lyonwj.com/">lyonwj博客</a></p>
<h1 id="Neo4j-Spatial简介"><a href="#Neo4j-Spatial简介" class="headerlink" title="Neo4j Spatial简介"></a>Neo4j Spatial简介</h1><p>Neo4j Spatial is a library of utilities for Neo4j that faciliates the enabling of spatial operations on data.</p>
<ul>
<li>Utilities for importing from ESRI Shapefile as well as Open Street Map files</li>
<li>Support for all the common geometry types</li>
<li>An RTree index for fast searches on geometries</li>
<li>Support for topology operations during the search (contains, within, intersects, covers, disjoint, etc.)</li>
<li>The possibility to enable spatial operations on any graph of data, regardless of the way the spatial data is stored, as long as an adapter is provided to map from the graph to the geometries.</li>
<li>Ability to split a single layer or dataset into multiple sub-layers or views with pre-configured filters</li>
</ul>
<h1 id="neo4j-spatial-安装"><a href="#neo4j-spatial-安装" class="headerlink" title="neo4j spatial 安装"></a>neo4j spatial 安装</h1><ol>
<li>在<a href="https://github.com/neo4j-contrib/m2/tree/master/releases/org/neo4j/neo4j-spatial">neo4j spatial github maven库</a>下载最新服务端Neo4j Spatial Server插件，下载后解压到neo4j plugin目录；</li>
<li>验证安装状态：以<a href="http://localhost:7474/db/data/ext/SpatialPlugin验证是否成功安装，将返回以下几类graphdb的操作">http://localhost:7474/db/data/ext/SpatialPlugin验证是否成功安装，将返回以下几类graphdb的操作</a><ul>
<li>addSimplePointLayer,addEditableLayer,addCQLDynamicLayer,addGeometryWKTToLayer</li>
<li>addNodeToLayer,addNodesToLayer,updateGeometryFromWKT</li>
<li>getLayer,findClosestGeometries, findGeometriesWithinDistance,findGeometriesInBBox</li>
</ul>
</li>
<li>索引新建<ul>
<li>Create a Spatial index</li>
<li>Create nodes with lat/lon data as properties</li>
<li>Add these nodes to the Spatial index</li>
</ul>
</li>
<li>RTree关系可视化<br><img src="RTreeRelationship.png" alt="RTree索引"><br>Neo4j Spatial REST服务可参考<a href="http://neo4j-contrib.github.io/spatial/">Neo4j Spatial v0.12-neo4j-2.0.0-SNAPSHOT文档</a></li>
</ol>
<h1 id="neo4j-spatial应用"><a href="#neo4j-spatial应用" class="headerlink" title="neo4j spatial应用"></a>neo4j spatial应用</h1><p>The technology industry and open source groups are building <strong>Spatial tools (“where” analysis) and Graph tools (relationship analysis)</strong> so that businesses can improve their insight on patterns, trends, and (perhaps most importantly) outliers in the networks.</p>
<ul>
<li><a href="http://www.lyonwj.com/using-neo4j-spatial-and-leaflet-js-with-mapbox">using-neo4j-spatial-and-leaflet-js-with-mapbox</a></li>
<li><a href="http://neo4j.com/blog/neo4j-spatial-part1-finding-things-close-to-other-things/">neo4j-spatial-part1-finding-things-close-to-other-thing</a></li>
<li><a href="http://www.lyonwj.com/mapping-the-worlds-airports-with-neo4j-spatial-and-openflights-part-1">Mapping the World’s Airports With Neo4j Spatial and Openflights</a></li>
<li><a href="http://neo4j.com/blog/geospatial-indexing-us-congress-neo4j/">Geospatial Indexing US Congressional Districts with Neo4j-spatial</a></li>
<li><a href="http://neo4j.com/news/webinar-recommend-restaurants-intro-neo4j-spatial/">Webinar: Recommend Restaurants Near Me: Introduction to Neo4j Spatial</a></li>
<li><a href="http://neo4j.com/blog/outliers-opportunities-graph-spatial/">Finding Valuable Outliers and Opportunities Using Graph and Spatial</a></li>
<li><a href="http://legis-graph.github.io/legis-graph-spatial/">legis-graph-spatial</a></li>
</ul>
<h1 id="Java构建Neo4j-空间索引"><a href="#Java构建Neo4j-空间索引" class="headerlink" title="Java构建Neo4j 空间索引"></a>Java构建Neo4j 空间索引</h1><p><a href="https://structr.org/blog/distance-queries-with-neo4j-spatial">参考distance-queries-with-neo4j-spatial</a><br><a href="https://gist.github.com/geosmart/0559745a69875e9f8876aeecda10f86b">gist代码示例：Neo4j Emberded 嵌入式SpringBean配置</a><br><a href="https://gist.github.com/geosmart/19e6e4cb0c953e1b63e9afe48425de8f">gist代码示例：Java实现Neo4j Spatial新建索引和空间查询测试用例</a>  </p>
<h1 id="关于withinDistance查询结果排序问题"><a href="#关于withinDistance查询结果排序问题" class="headerlink" title="关于withinDistance查询结果排序问题"></a>关于withinDistance查询结果排序问题</h1><ul>
<li><p>球面距离计算采用OrthodromicDistance算法<br><a href="http://www.movable-type.co.uk/scripts/latlong-db.html">OrthodromicDistance算法</a>：<code>d = acos( sin(lat1)*sin(lat2) + cos(lat1)*cos(lat2)*cos(lon2-lon1) ) * R</code>，<br>Neo4j-Spatial中的实现：<code>org.neo4j.gis.spatial.pipes.processing.OrthodromicDistance</code></p>
</li>
<li><p>返回结果默认以命中目标坐标与查询中心点坐标的距离进行排序<br>参考Neo4j Spatial 源码测试用例中的：<a href="https://github.com/neo4j-contrib/spatial/blob/ca7bb0f6db16bf1b012a4365bc17ca2881816106/src/test/java/org/neo4j/gis/spatial/TestSimplePointLayer.java">TestSimplePointLayer</a>中的checkPointOrder，<br>查询示例：<code>List&lt;GeoPipeFlow&gt; res = GeoPipeline. startNearestNeighborLatLonSearch( layer, start, distance).sort(&quot;OrthodromicDistance&quot;).toList();</code></p>
</li>
</ul>
<h1 id="neo4j-spatial-query-示例"><a href="#neo4j-spatial-query-示例" class="headerlink" title="neo4j spatial query 示例"></a>neo4j spatial query 示例</h1><h2 id="withinDistance缓存区查询"><a href="#withinDistance缓存区查询" class="headerlink" title="withinDistance缓存区查询"></a>withinDistance缓存区查询</h2><p>查询点120.678966,31.300864周边0.1km范围内的Node<br>格式：<code>START n = node:&lt;layer&gt;(&quot;withinDistance:[&lt;y&gt;, &lt;x&gt;, &lt;max distance in km&gt;]&quot;)</code>  </p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">start</span> n = node:geom(<span class="string">'withinDistance:[31.331937,120.638154,0.1]'</span>) <span class="keyword">return</span> n <span class="keyword">limit</span> <span class="number">10</span></div></pre></td></tr></table></figure>
<h2 id="bbox矩形查询"><a href="#bbox矩形查询" class="headerlink" title="bbox矩形查询"></a>bbox矩形查询</h2><p>查询由点1(120.678966,31.300864)与点2(120.978966,31.330864)构成的BBox矩形范围内的Node<br>格式：<code>START n = node:&lt;layer&gt;(&quot;bbox:[&lt;min x&gt;, &lt;max x&gt;, &lt;min y&gt;, &lt;max y&gt;]&quot;)</code>  </p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">start</span> n = node:geom(<span class="string">'bbox:[120.678966,120.978966,31.300864,31.330864]'</span>) <span class="keyword">return</span> n <span class="keyword">limit</span> <span class="number">10</span></div></pre></td></tr></table></figure>
<h2 id="withinWKTGeometry查询"><a href="#withinWKTGeometry查询" class="headerlink" title="withinWKTGeometry查询"></a>withinWKTGeometry查询</h2><p>查询由点1(120.678966,31.300864)与点2(120.978966,31.330864)构成的Polygon多边形范围内的Node<br>格式：<code>START n = node:&lt;layer&gt;(&quot;withinWKTGeometry:POLYGON((&lt;x1&gt; &lt;y1&gt;, ..., &lt;xN&gt; &lt;yN&gt;, &lt;x1&gt; &lt;y1&gt;))&quot;)</code>  </p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">start</span> n = node:geoindex(<span class="string">'withinWKTGeometry:POLYGON ((120.678966 31.300864, 120.678966 31.330864, 120.978966 31.330864, 120.978966 31.300864, 120.678966 31.300864))'</span>)  <span class="keyword">return</span> n <span class="keyword">limit</span> <span class="number">10</span></div></pre></td></tr></table></figure>
<h2 id="空间索引和关系遍历联合查询"><a href="#空间索引和关系遍历联合查询" class="headerlink" title="空间索引和关系遍历联合查询"></a>空间索引和关系遍历联合查询</h2><p>联合geom索引图层和match进行查询</p>
<ul>
<li>查询指定范围&amp;&amp;指定path路径中的节点</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">start</span> n = node:geom(<span class="string">'withinDistance:[31.331937,120.638154,0.1]'</span>)</div><div class="line"><span class="keyword">match</span> <span class="keyword">path</span>=(:DIS&#123;<span class="built_in">text</span>:<span class="string">'工业园区'</span>&#125;)-[:BELONGTO ]-(:POI&#123;<span class="built_in">text</span>:<span class="string">'拙政别墅'</span>&#125;)</div><div class="line"><span class="keyword">where</span> n <span class="keyword">in</span> nodes(<span class="keyword">path</span>)</div><div class="line"><span class="keyword">return</span> n,<span class="keyword">path</span></div></pre></td></tr></table></figure>
<p>优化后</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">profile <span class="keyword">start</span> n = node:geom(<span class="string">'withinDistance:[31.331937,120.638154,0.1]'</span>)</div><div class="line"><span class="keyword">match</span> <span class="keyword">path</span>=(:DIS&#123;<span class="built_in">text</span>:<span class="string">'工业园区'</span>&#125;)&lt;-[:BELONGTO ]-(n)</div><div class="line"><span class="keyword">return</span> <span class="keyword">path</span></div></pre></td></tr></table></figure>
<p>查询结果可视化效果图<br><img src="spatialQuery.png" alt="空间索引和关系遍历联合查询"></p>
<ul>
<li>联合查询：withinWKTGeometry空间过滤与match属性过滤</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">profile <span class="keyword">start</span> n = node:geoindex(<span class="string">'withinWKTGeometry:POLYGON ((120.678966 31.300864, 120.678966 31.330864, 120.978966 31.330864, 120.978966 31.300864, 120.678966 31.300864))'</span>)</div><div class="line"><span class="keyword">match</span> (n)</div><div class="line"><span class="keyword">where</span> (n.ruleabbr <span class="keyword">in</span> [<span class="string">'POI'</span>,<span class="string">'STR'</span>]) <span class="keyword">and</span> n.spapriority=<span class="number">1</span></div><div class="line"><span class="keyword">and</span> <span class="keyword">ANY</span>(adtext <span class="keyword">IN</span> n.adtext <span class="keyword">WHERE</span> adtext =~ <span class="string">'.*公司.*'</span> )</div><div class="line"><span class="keyword">return</span> n <span class="keyword">limit</span> <span class="number">10</span></div></pre></td></tr></table></figure>
<ul>
<li>CypherQL必须先执行空间索引，再执行Relation过滤，这样每个空间围内的Node都要进行Relationship过滤，效率较低；  </li>
<li>若能先执行Match再执行空间过滤，可提高SpatialIndex命中率</li>
<li>若无分页需求，可临时采用NativeAPI进行Match过滤，再以SpatialIndex withinDiatance过滤。  </li>
<li>若需要分页的话skip limit必须在CypherQL中实现，但是空间索引与关系遍历并行的CQL怎么写？暂时无解！</li>
</ul>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><h2 id="建空间索引内存溢出问题"><a href="#建空间索引内存溢出问题" class="headerlink" title="建空间索引内存溢出问题"></a>建空间索引内存溢出问题</h2><p>neo4j transaction优化方案：每n条手动提交事物  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"> <span class="comment">// 获取所有地址节类型，针对不同地址节分别构建R树索引</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">createAddressNodeIndex_spatial</span><span class="params">(Set&lt; String&gt; addressNodes)</span> </span>&#123;</div><div class="line">true<span class="keyword">final</span> <span class="keyword">long</span> commitInterval = <span class="number">10000</span>;</div><div class="line">trueTransaction tx = graphDBService.beginTx();</div><div class="line">true<span class="keyword">try</span> &#123;</div><div class="line">truetrue<span class="keyword">long</span> i = <span class="number">0L</span>;</div><div class="line">truetrue<span class="keyword">long</span> startTime = System.currentTimeMillis();</div><div class="line">truetrue<span class="keyword">for</span> (String addressNodeLabel : addressNodes) &#123;</div><div class="line">truetruetrueIndex&lt; Node&gt; index = getSpatialIndex(UADBLabel.valueOf(addressNodeLabel));</div><div class="line">truetruetrueResourceIterator&lt; Node&gt; nodes = graphDBService.findNodes(createAddresseNodeLable(addressNodeLabel));</div><div class="line"></div><div class="line">truetruetrue<span class="keyword">while</span> (nodes.hasNext()) &#123;</div><div class="line">truetruetruetrueNode node = nodes.next();</div><div class="line">truetruetruetrue<span class="keyword">if</span> (node.getProperty(<span class="string">"lon"</span>, <span class="keyword">null</span>) != <span class="keyword">null</span> &amp;&amp; node.getProperty(<span class="string">"lat"</span>, <span class="keyword">null</span>) != <span class="keyword">null</span>) &#123;</div><div class="line">truetruetruetruetrueindex.add(node, <span class="string">""</span>, <span class="string">""</span>);</div><div class="line">truetruetruetruetruei++;</div><div class="line">truetruetruetrue&#125;</div><div class="line">truetruetruetrue<span class="comment">// 处理内存溢出</span></div><div class="line">truetruetruetrue<span class="keyword">if</span> (i % commitInterval == <span class="number">0</span>) &#123;</div><div class="line">truetruetruetruetruetx.success();</div><div class="line">truetruetruetruetruetx.close();</div><div class="line">truetruetruetruetruelog.info(<span class="string">"indexing (&#123;&#125; nodes added) ... time in seconds:&#123;&#125;"</span>, i,</div><div class="line">truetruetruetruetruetruetrueDateUtil.convertMillis2DateStr(System.currentTimeMillis() - startTime));</div><div class="line">truetruetruetruetruetx = graphDBService.beginTx();</div><div class="line">truetruetruetrue&#125;</div><div class="line">truetruetrue&#125;</div><div class="line">truetrue&#125;</div><div class="line">truetruetx.success();</div><div class="line">true&#125; <span class="keyword">finally</span> &#123;</div><div class="line">truetruetx.close();</div><div class="line">true&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>建空间索引速度还是偏慢，35万左右的数据量建索引花了将近1.5小时。</p>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Neo4j </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Neo4j常用CypherQL语句]]></title>
      <url>http://geosmart.github.io/2016/03/30/Neo4j%E5%B8%B8%E7%94%A8CypherQL%E8%AF%AD%E5%8F%A5/</url>
      <content type="html"><![CDATA[<p>记录常用Cypher语句</p>
<hr>
<a id="more"></a>
<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a href="http://neo4j.com/docs/stable/cypher-query-lang.html">cypher-query-lang</a><br><a href="http://neo4j.com/docs/stable/cypher-refcard/">cypher-refcard </a></p>
<h1 id="create-Node"><a href="#create-Node" class="headerlink" title="create Node"></a>create Node</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> (root:<span class="keyword">User</span> &#123; <span class="keyword">type</span>:<span class="string">'admin'</span>, <span class="keyword">name</span>: <span class="string">'root'</span>&#125;)</div><div class="line"><span class="keyword">CREATE</span> (u1:<span class="keyword">User</span> &#123; <span class="keyword">type</span>:<span class="string">'guest'</span>, <span class="keyword">name</span> : <span class="string">'user1'</span>&#125;)</div><div class="line"><span class="keyword">CREATE</span> (u2:<span class="keyword">User</span> &#123; <span class="keyword">type</span>:<span class="string">'guest'</span>, <span class="keyword">name</span>: <span class="string">'user2'</span>&#125;)</div><div class="line"><span class="keyword">CREATE</span> (u3:<span class="keyword">User</span> &#123; <span class="keyword">type</span>:<span class="string">'guest'</span>, <span class="keyword">name</span>: <span class="string">'user3'</span>&#125;)</div><div class="line"><span class="keyword">CREATE</span> (u4:<span class="keyword">User</span> &#123; <span class="keyword">type</span>:<span class="string">'guest'</span>, <span class="keyword">name</span>: <span class="string">'user4'</span>&#125;)</div></pre></td></tr></table></figure>
<h1 id="Create-RelationShip"><a href="#Create-RelationShip" class="headerlink" title="Create RelationShip"></a>Create RelationShip</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">MATCH (root&#123;type:'admin' &#125;),(guest&#123;type:'guest'&#125;)</div><div class="line"><span class="keyword">CREATE</span>  (root)-[r:knows]-&gt;(guest)</div><div class="line"><span class="keyword">RETURN</span> r</div></pre></td></tr></table></figure>
<h1 id="Create-Unique-RelationShip"><a href="#Create-Unique-RelationShip" class="headerlink" title="Create  Unique RelationShip"></a>Create  Unique RelationShip</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">MATCH (root&#123;type:'admin' &#125;)</div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">UNIQUE</span> (root)-[r:knows]-(u5:<span class="keyword">User</span>&#123;<span class="keyword">name</span>:<span class="string">'user5'</span>&#125;)</div><div class="line"><span class="keyword">RETURN</span>  u5</div></pre></td></tr></table></figure>
<h1 id="match-Node"><a href="#match-Node" class="headerlink" title="match Node"></a>match Node</h1><ul>
<li><p>match by property</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">MATCH (root &#123; name : 'root' &#125;)</div><div class="line">return root</div></pre></td></tr></table></figure>
</li>
<li><p>match by ID identifier</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">MATCH (s)</div><div class="line">WHERE ID(s) = 65110</div><div class="line">RETURN s</div></pre></td></tr></table></figure>
</li>
<li><p>complex query</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">MATCH (d:District &#123;state: &#123;state&#125;, district: &#123;district&#125;&#125;)</div><div class="line">MATCH (d)&lt;-[:REPRESENTS]-(l:Legislator)</div><div class="line">MATCH (l)-[:SERVES_ON]-&gt;(c:Committee)</div><div class="line">MATCH (c)&lt;-[:REFERRED_TO]-(b:Bill)</div><div class="line">MATCH (b)-[:DEALS_WITH]-&gt;(s:Subject)</div><div class="line">WITH l.govtrackID AS govtrackID, l.lastName AS lastName, l.firstName AS firstName, l.currentParty AS party, s.title AS subject, count(*) AS strength, collect(DISTINCT c.name) AS committees ORDER BY strength DESC LIMIT 10</div><div class="line">WITH &#123;lastName: lastName, firstName: firstName, govtrackID: govtrackID, party: party, committees: committees&#125; AS legislator, collect(&#123;subject: subject, strength: strength&#125;) AS subjects</div><div class="line">RETURN &#123;legislator: legislator, subjects: subjects&#125; AS r</div></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="match-relationNode"><a href="#match-relationNode" class="headerlink" title="match relationNode"></a>match relationNode</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">MATCH (root&#123; type:'admin' &#125;)--&gt;(user)</div><div class="line">RETURN user</div></pre></td></tr></table></figure>
<h1 id="match-Node-and-relationNode"><a href="#match-Node-and-relationNode" class="headerlink" title="match Node and relationNode"></a>match Node and relationNode</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">MATCH (root &#123; type:'admin' &#125;)-[r]-(user)</div><div class="line">RETURN r</div></pre></td></tr></table></figure>
<h1 id="match-collection"><a href="#match-collection" class="headerlink" title="match collection"></a>match collection</h1><h2 id="collection-contain-string"><a href="#collection-contain-string" class="headerlink" title="collection contain string"></a>collection contain string</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">match (an)</div><div class="line">where all (x IN ['709908DCF9D24734BA8FEF8A831F1BA4'] where x in an.preAddressNodeGUIDs)</div><div class="line">return count(an)</div></pre></td></tr></table></figure>
<h2 id="collection-equal"><a href="#collection-equal" class="headerlink" title="collection equal"></a>collection equal</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">match (an&#123;preAddressNodeGUIDs:['709908DCF9D24734BA8FEF8A831F1BA4 ']&#125;)</div><div class="line">return count(an)</div></pre></td></tr></table></figure>
<h1 id="delete-relationship"><a href="#delete-relationship" class="headerlink" title="delete relationship"></a>delete relationship</h1><h2 id="delete-a-node-with-its-relationships"><a href="#delete-a-node-with-its-relationships" class="headerlink" title="delete a node with its relationships"></a>delete a node with its relationships</h2><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">MATCH (n &#123; name:'Andres' &#125;)DETACH DELETE n</div></pre></td></tr></table></figure>
<h2 id="delete-all-relationships"><a href="#delete-all-relationships" class="headerlink" title="delete all relationships"></a>delete all relationships</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Match (:AddressNode)-[r:parent]-&gt;(:AddressNode)</div><div class="line"><span class="keyword">delete</span> r</div></pre></td></tr></table></figure>
<h1 id="start"><a href="#start" class="headerlink" title="start"></a>start</h1><p>The START clause should only be used when accessing legacy indexes <a href="http://neo4j.com/docs/stable/indexing.html">Legacy Indexing</a>.<br>In all other cases, use MATCH instead (see Section 11.1, “Match”).<br>In Cypher, every query describes a pattern, and in that pattern one can have multiple starting points.<br>A starting point is a relationship or a node where a pattern is anchored. Using START you can only introduce starting points by legacy index seeks.<br>Note that trying to use a legacy index that doesn’t exist will generate an error.</p>
<h1 id="index"><a href="#index" class="headerlink" title="index"></a>index</h1><h2 id="create-index"><a href="#create-index" class="headerlink" title="create index"></a>create index</h2><p>CREATE INDEX ON :PRO( preAddressNodeGUIDs)</p>
<h2 id="drop-index"><a href="#drop-index" class="headerlink" title="drop index"></a>drop index</h2><p>DROP INDEX ON :PRO( preAddressNodeGUIDs)</p>
<h2 id="Neo4j联合索引"><a href="#Neo4j联合索引" class="headerlink" title="Neo4j联合索引"></a>Neo4j联合索引</h2><p>Neo4j2.3.x不支持联合索引，可采用拼接字段实现，<a href="https://dzone.com/articles/indexing-neo4j-overview">参考indexing-neo4j-overview</a>；<br>Neo4j 3.0开始支持联合索引，但需要升级至JDK8，<a href="https://github.com/neo4j/neo4j/issues/6841">参考github neo4j Issue</a><br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">profile</div><div class="line">MATCH (p:AddressNode &#123;text:"拙政别墅"&#125;)</div><div class="line">WITH p</div><div class="line">MATCH (o:AddressNode&#123; ruleabbr:"POI"&#125;)</div><div class="line">WHERE id(p) = id(o)</div><div class="line">RETURN p</div></pre></td></tr></table></figure></p>
<p><img src="Neo4j联合索引测试1.png" alt="Neo4j联合索引测试1"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">profile</div><div class="line">MATCH (p:AddressNode &#123;ruleabbr:"POI",text:"拙政别墅"&#125;)</div><div class="line">RETURN p</div></pre></td></tr></table></figure>
<p><img src="Neo4j联合索引测试2.png" alt="Neo4j联合索引测试2"><br>暂测试，疑neo4j由于采用lucene全文索引的缘故，在2个字段各有索引，但无联合索引的情况下，索引倒排会提高检索命中率。</p>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Neo4j </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MongoDB与Neo4j数据同步]]></title>
      <url>http://geosmart.github.io/2016/03/23/MongoDB%E4%B8%8ENeo4j%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/</url>
      <content type="html"><![CDATA[<p>采用mongo-connector及Neo4j Doc Manager将MongoDB中数据导入Neo4j（嵌套结构形成关系）</p>
<hr>
<a id="more"></a>
<p><a href="http://neo4j.com/developer/mongodb/#_neo4j_doc_manager">参考文档</a><br><a href="https://github.com/neo4j-contrib/neo4j_doc_manager">neo4j_doc_manager项目地址</a></p>
<h1 id="MongoDB启用副本"><a href="#MongoDB启用副本" class="headerlink" title="MongoDB启用副本"></a>MongoDB启用副本</h1><h2 id="Windows安装MongoDB服务-bat脚本"><a href="#Windows安装MongoDB服务-bat脚本" class="headerlink" title="Windows安装MongoDB服务 bat脚本"></a>Windows安装MongoDB服务 bat脚本</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">@<span class="built_in">echo</span> off</div><div class="line">title  卸载MongoDB</div><div class="line">sc delete MongoDB</div><div class="line">cmd /k</div></pre></td></tr></table></figure>
<h2 id="Windows卸载MongoDB服务-bat脚本"><a href="#Windows卸载MongoDB服务-bat脚本" class="headerlink" title="Windows卸载MongoDB服务 bat脚本"></a>Windows卸载MongoDB服务 bat脚本</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">@<span class="built_in">echo</span> off</div><div class="line">title 安装MongoDB</div><div class="line">D:\mongodb\bin\mongod --logpath <span class="string">"D:\mongodb\log\mongo.log"</span> --logappend --dbpath <span class="string">"D:\mongodb\data"</span> --directoryperdb --replSet myDevReplSet --serviceName <span class="string">"MongoDB"</span> --serviceDisplayName <span class="string">"MongoDB"</span>  --install</div><div class="line">cmd /k</div></pre></td></tr></table></figure>
<h2 id="初始化MongoDB-Replica-set"><a href="#初始化MongoDB-Replica-set" class="headerlink" title="初始化MongoDB Replica set"></a>初始化MongoDB Replica set</h2><p>进入mongo shell执行<code>rs.initiate()</code></p>
<h1 id="安装Neo4j-Doc-Manager"><a href="#安装Neo4j-Doc-Manager" class="headerlink" title="安装Neo4j Doc Manager"></a>安装Neo4j Doc Manager</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 新增python环境neo4j.venv</span></div><div class="line">virtualenv  --no-site-packages neo4j.venv</div><div class="line"><span class="comment">#  进入neo4j.venv</span></div><div class="line">workon neo4j.venv</div><div class="line"><span class="comment">#  安装neo4j-doc-manager   --pre</span></div><div class="line">pip install -i  http://pypi.douban.com/simple  neo4j-doc-manager --trusted-host pypi.douban.com</div></pre></td></tr></table></figure>
<h1 id="启动mongo-connector"><a href="#启动mongo-connector" class="headerlink" title="启动mongo-connector"></a>启动mongo-connector</h1><p>进入Python环境：<code>workon neo4j.venv</code><br>运行neo4j_doc_manager：<code>mongo-connector -m 192.168.1.188:27017 -t http://127.0.0.1:7474/db/data -d neo4j_doc_manager</code><br>同步指定Databse.Collection：<code>mongo-connector -m 127.0.0.1:27017 -n uadb_suzhou_gyyq.AddressNode -t http://127.0.0.1:7474/db/data -d neo4j_doc_manager</code><br>neo4j_doc_manager运行后，当MongoDB插入数据时，mongodb Document将会实时转换为图结构存储到Neo4j，文档Key会转换为Node,值对象作为Node的属性值。</p>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="No-handlers-could-be-found-for-logger-“mongo-connector-util”"><a href="#No-handlers-could-be-found-for-logger-“mongo-connector-util”" class="headerlink" title="No handlers could be found for logger “mongo_connector.util”"></a>No handlers could be found for logger “mongo_connector.util”</h2><p>实际错误：py2neo.database.status.Unauthorized: <a href="http://127.0.0.1:7474/db/manage/server/jmx/domain/org.neo4j">http://127.0.0.1:7474/db/manage/server/jmx/domain/org.neo4j</a><br>解决方案：</p>
<ol>
<li>停用 authorization<br>考虑到性能和测试便捷可停用Neo4j安全授权机制。<br>在<code>neo4j-server.properties</code>中设置<code>dbms.security.auth_enabled=false</code></li>
<li>设置NEO4J_AUTH环境变量<br>若生产环境已启用授权，设置NEO4J_AUTH环境变量<code>export NEO4J_AUTH=user:password</code></li>
</ol>
<h2 id="AttributeError-‘Graph’-object-has-no-attribute-‘cypher’"><a href="#AttributeError-‘Graph’-object-has-no-attribute-‘cypher’" class="headerlink" title="AttributeError: ‘Graph’ object has no attribute ‘cypher’"></a>AttributeError: ‘Graph’ object has no attribute ‘cypher’</h2><p>解决方案：<a href="https://github.com/neo4j-contrib/neo4j_doc_manager/issues/59">neo4j_doc_manager github issue</a><br>参考官网文档，安装时附加–pre参数，然而运行dev版有问题，老实安装stable版本即可</p>
<h2 id="OplogThread-Last-entry-no-longer-in-oplog-cannot-recove"><a href="#OplogThread-Last-entry-no-longer-in-oplog-cannot-recove" class="headerlink" title="OplogThread: Last entry no longer in oplog cannot recove"></a>OplogThread: Last entry no longer in oplog cannot recove</h2><p>修改mongo-connector配置参数后报错<br>解决：删除日志文件（mongo-connector.log）所在根目录的<code>oplog.timestamp</code>文件，上次异常终止mongo-connector写入了xxx，导致无法正常运行</p>
<h2 id="如何提高同步速度"><a href="#如何提高同步速度" class="headerlink" title="如何提高同步速度"></a>如何提高同步速度</h2><p><a href="https://github.com/mongodb-labs/mongo-connector/wiki/FAQ#how-do-i-increase-the-speed-of-mongo-connector">how-do-i-increase-the-speed-of-mongo-connector</a><br><a href="https://github.com/mongodb-labs/mongo-connector/wiki/Configuration-Options">mongo-connector Configuration-Options</a></p>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MongoDB </tag>
            
            <tag> Neo4j </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MySQL常用函数（UDF）]]></title>
      <url>http://geosmart.github.io/2016/03/18/MySQL%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%EF%BC%88UDF%EF%BC%89/</url>
      <content type="html"><![CDATA[<p>数据分析/特定业务逻辑MySQL内置的Function无法满足需求，只能祭出UDF。</p>
<hr>
<a id="more"></a>
<h1 id="字符串分割-split-string"><a href="#字符串分割-split-string" class="headerlink" title="字符串分割(split_string)"></a>字符串分割(split_string)</h1><ul>
<li>函数定义</li>
<li>CREATE DEFINER = ‘ugcdb’@’%’<br>FUNCTION ugcdb.split_string(<br>x VARCHAR(255),<br>delim VARCHAR(12),<br>pos INT<br>)<br>RETURNS varchar(255) CHARSET utf8<br>RETURN REPLACE(SUBSTRING(SUBSTRING_INDEX(x, delim, pos),<br>   LENGTH(SUBSTRING_INDEX(x, delim, pos -1)) + 1),<br>   delim, ‘’)</li>
<li>函数调用</li>
<li><code>update tableName set 门牌号= SPLIT_STR(门牌号,&#39;号&#39;,1) ;</code></li>
</ul>
<h1 id="获取行号-get-rownum"><a href="#获取行号-get-rownum" class="headerlink" title="获取行号(get_rownum)"></a>获取行号(get_rownum)</h1><p><a href="http://stackoverflow.com/questions/15891993/create-a-view-with-column-num-rows-mysql">参考create-a-view-with-column-num-rows-mysql</a></p>
<ul>
<li>函数定义</li>
<li>CREATE DEFINER=<code>geocodingdb</code>@<code>%</code> FUNCTION <code>geocodingdb</code>.<code>get_rownum</code>() RETURNS int(11)<br>BEGIN<br>  SET @temp_rowNumber := IFNULL(@temp_rowNumber,0)+1;<br>  return @temp_rowNumber;<br>END</li>
<li>函数调用</li>
<li>SET @temp_rowNumber=0;<br>select fieldA , get_rownum() AS rownum from tableName;</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[JVM学习笔记（三）垃圾收集器与内存分配策略]]></title>
      <url>http://geosmart.github.io/2016/03/09/JVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E4%B8%8E%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/</url>
      <content type="html"><![CDATA[<p>Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的“高墙”，墙外面的人想进去，墙里面的人想出来。</p>
<hr>
<a id="more"></a>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>垃圾收集（Garbage Collection，GC）需要完成的三件事情：</p>
<ol>
<li>哪些内存需要回收？<br>-[] 内存区域-回收条件</li>
<li>什么时候回收？<br>-[] 多线程/安全点</li>
<li>如何回收？<br>-[] 回收算法</li>
</ol>
<p>当要排查各种内存溢出、内存泄漏问题时，当垃圾收集称为系统达到更高并发量的瓶颈时，我们就需要对这些”自动化”的技术实施必要的监控和调节。</p>
<ol>
<li><code>程序计数器、虚拟机栈、本地方法栈</code>3个区域随线程而生，随线程而灭；每一个栈帧中分配多少内存基本上在类结构确定下来的时候就已知。因此这几个区域的内存分配和回收都具有确定性，不需过多考虑回收问题，方法结束或者线程结束时，内存自然就随之回收了。</li>
<li><code>Java堆和方法区</code>则不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样，只有在程序处于运行期间才知道会创建哪些对象，这部分内存的分配和回收都是<code>动态</code>的，垃圾收集器所关注的是这部分内存！</li>
</ol>
<h1 id="对象已死吗？"><a href="#对象已死吗？" class="headerlink" title="对象已死吗？"></a>对象已死吗？</h1><p>垃圾回收器在对堆进行回收前，首要确定的事情就是这些对象之间哪些还<code>存活</code>着，哪些已经<code>死去</code>？</p>
<h2 id="引用计数算法"><a href="#引用计数算法" class="headerlink" title="引用计数算法"></a>引用计数算法</h2><ul>
<li>定义：引用计数算法（<code>Reference Counting</code>）:给对象添加一个引用计数器，每当一个地方引用它时，计数器值就+1；当引用失效时，计数器值就-1；任何时刻计数器为0的对象就是不可能被再使用的；</li>
<li>优点：实现简单，判定效率高；微软的COM技术、Python中都使用了Reference Couting算法进行内存管理；</li>
<li>缺点：由于其很难解决对象之间相互循环引用的问题，主流Java虚拟机里面都没有选用Refrence Couting算法来管理内存；</li>
</ul>
<h2 id="可达性分析算法"><a href="#可达性分析算法" class="headerlink" title="可达性分析算法"></a>可达性分析算法</h2><ul>
<li>定义：可达性分析（<code>Reachability Analysis</code>）判断对象存活的基本思路：通过一系列的称为GC Roots的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain）,当一个对象到GC Roots没有任何引用链相连（即GC Roots到这个对象不可达）时，则证明此对象是不可用的；<br><img src="可达性分析算法.png" alt="可达性分析算法"></li>
<li>Java语言中，可作为GC Roots对象包括：</li>
</ul>
<ol>
<li>虚拟机栈（栈帧中的本地变量表）中引用的对象；</li>
<li>方法区中类静态属性引用的对象；</li>
<li>方法区中产量引用的对象；</li>
<li>本地方法栈中JNI（即一般的Native方法）引用的对象</li>
</ol>
<h2 id="再谈引用"><a href="#再谈引用" class="headerlink" title="再谈引用"></a>再谈引用</h2><p>JDk1.2之后，Java对引用概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用4种，4种强度一次逐渐减弱。</p>
<ol>
<li>强引用（<code>Strong Reference</code>）是指在程序代码之中普遍存在的，类似<code>Object obj=new Object()</code>这类的引用，只要强引用存在，对象就不会发生GC；</li>
<li>软引用（<code>Soft Reference</code>）是用来描述一些还有用但并非必须的对象。对于软引用关联着的对象，在系统将要发生OOM异常之前，将会把这些对象列进回收范围之中进行第二次回收，如果这次回收后还没有足够的内存，才会抛出OOM异常。</li>
<li>弱引用（<code>Weak Reference</code>）是用来描述非必须对象的，强度比软引用更弱，被弱引用关联的对象只能生存到下一次GC发生之前。当垃圾回收器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。</li>
<li>虚引用（<code>Phantom Reference</code>）也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。</li>
</ol>
<h2 id="回收方法区"><a href="#回收方法区" class="headerlink" title="回收方法区"></a>回收方法区</h2><ul>
<li>在方法区中进行垃圾收集的性价比一般比较低；而在Heap中，尤其是在新生代，常规应用进行一次垃圾收集一般回收70%~95%的空间，而永久代的垃圾收集效率远低于此；</li>
<li>永久代的垃圾收集主要回收两部分内容：废弃常量和无用的类；</li>
<li>回收废弃常量与回收Java堆中的对象类似；</li>
<li>判定一个类是否是无用的类条件相对苛刻：<ul>
<li>该类所有实例都已被回收，即Java堆中不存在该类的任何实例；</li>
<li>加载该类的<code>ClassLoader</code>已经被回收；</li>
<li>该类对应的<code>java.lang.Class</code>对象没有在任何地方被引用，无法在任何地方通过反射访问该方法。</li>
</ul>
</li>
</ul>
<p>在大量使用反射、动态代理、CGLib等ByteCode框架、动态生成JSP以及OSGi这类自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。</p>
<h1 id="垃圾收集算法"><a href="#垃圾收集算法" class="headerlink" title="垃圾收集算法"></a>垃圾收集算法</h1><p>只介绍内存回收的方法论（算法思想及发展过程），不讨论具体算法实现。</p>
<h2 id="标记-清除算法（Mak-Sweep）"><a href="#标记-清除算法（Mak-Sweep）" class="headerlink" title="标记-清除算法（Mak-Sweep）"></a>标记-清除算法（Mak-Sweep）</h2><ul>
<li>定义：MS算法分标记和清除两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。<br><img src="标记-清除算法示意图.png" alt="标记-清除算法示意图"></li>
<li>两点不足：<ul>
<li>效率问题，标记和清除两个过程的效率都不高；</li>
<li>空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多后导致以后程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前出发一次垃圾收集动作；</li>
</ul>
</li>
</ul>
<h2 id="复制算法（Coping）"><a href="#复制算法（Coping）" class="headerlink" title="复制算法（Coping）"></a>复制算法（Coping）</h2><ul>
<li>定义：Coping算法将可用内存按容量划分为大小相等的两块，每次使用其中一块。当这一块的内存用完了，就将还存活的对象复制到另一块上面，然后再把已使用的内存清理掉。<br><img src="复制算法示意图.png" alt="复制算法示意图"></li>
<li>优点：每次对整个半区进行回收，内存分配时不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效；</li>
<li>不足：提高效率的代价是将内存缩小到原来的一半；<br>现代商业虚拟机都采用这种收集算法来回收新生代，但新生代中的对象一般98%是<code>朝生夕死</code>，无需按照1:1比例来划分内存空间，而是将内存分为1块较大的Eden（伊甸园）空间和2块较小的Survivor（幸存者）空间，每次使用Eden和其中1块Survivor。</li>
<li>回收时，将Eden和Survivor中还存活的对象一次性复制到另外一个Survivor空间中，最后清理掉Eden和刚才用过的Survivor空间。</li>
<li>HotSpot VM默认Eden和Survivor的比例是8:1:1，即只浪费10%的内存。</li>
<li>98%的对象可回收只是一般场景下的数据，无法保证每次回收都只有不多于10%的对象存活，所以当Survivor空间不足时，需要依赖其他内存（老年代）进行<code>分配担保（Handle Promotion）</code>，让对象进入老年代。</li>
</ul>
<h2 id="标记-整理算法（Mark-Compact）"><a href="#标记-整理算法（Mark-Compact）" class="headerlink" title="标记-整理算法（Mark-Compact）"></a>标记-整理算法（Mark-Compact）</h2><ul>
<li>出场背景：复制算法在对象存活率较高时复制操作较多，效率会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以对应被使用内存中的所有对象都100%存活的极端情况，所以老年代一般不直接选用这种算法。</li>
<li>定义：根据老年代的特点，提出标记-整理（Mark-Compact）算法，标记过程仍然与<code>标记-清除</code>算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理调用端边界以外的内存。<br><img src="标记-整理算法.png" alt="标记-整理算法"></li>
<li>内存碎片整理<br><img src="内存碎片整理.png" alt="内存碎片整理"></li>
<li>标记-清除算法 vs 标记-整理算法<br><img src="mark_sweep_vs_mark_compact.png" alt="mark_sweep_vs_mark_compact"></li>
</ul>
<h2 id="分代收集算法"><a href="#分代收集算法" class="headerlink" title="分代收集算法"></a>分代收集算法</h2><p>当前商业虚拟机的垃圾收集都采用<code>分代收集</code>(Generational Collection)算法，根据对象存活周期的不同将内存分为几块。</p>
<ul>
<li>一般把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法；</li>
<li>新生代每次垃圾回收时都发现有大批对象死去,只有<code>少量对象存活</code>，故采用<code>复制</code>算法，以少量对象复制的成本即可完成收集；</li>
<li>老年代中因为<code>对象存活率高</code>、没有额外空间对其进行分配担保，必须采用<code>标记-清理</code>或<code>标记-整理</code>算法来进行回收。</li>
</ul>
<h1 id="HotSpot的算法实现"><a href="#HotSpot的算法实现" class="headerlink" title="HotSpot的算法实现"></a>HotSpot的算法实现</h1><p>HotSpot虚拟机上实现对象存活判断算法和垃圾收集算法时，必须对算法的执行效率有严格的考量，才能保证虚拟机高效运行。</p>
<h2 id="枚举根基点（GC-Roots）"><a href="#枚举根基点（GC-Roots）" class="headerlink" title="枚举根基点（GC Roots）"></a>枚举根基点（GC Roots）</h2><ul>
<li>可作为GC Roots的节点主要在全局性的引用（如常量或静态变量）与执行上下文（如栈帧中的本地变量表）中；</li>
<li>可达性分析对执行时间的敏感体还现在GC停顿上，因为这项分析工作必须在一个能确保一致性的快照中进行（即对象引用关系在某个时间点冻结），这点是导致GC必须停顿所有Java执行线程<code>（Stop The World）</code>的一个重要原因，即使号称不会发生停顿的CMS收集器中，GC Roots也是必须要停顿的。</li>
<li><code>准确式内存管理</code>（Exact Memory Management）,即虚拟机可以知道内存中某个位置的数据具体是什么类型。</li>
<li>HotSpot VM采用<code>OopMap</code>(oop,Ordinary Object Pointer,普通对象指针)数据结构，在类加载完成的时候，将对象内什么偏移量上是什么类型的数据计算出来，在<code>JIT(Just-In-Time Compiler)</code>编译过程中，也会在特定的位置（Safepoint）记录下栈和寄存器中哪些位置是引用。</li>
</ul>
<h2 id="安全点（Safepoint）"><a href="#安全点（Safepoint）" class="headerlink" title="安全点（Safepoint）"></a>安全点（Safepoint）</h2><ul>
<li>关于OopMap</li>
</ul>
<ol>
<li>在OopMap的协助下，HotSpot可以快速且准确地完成GC Roots枚举，但是可能会导致引用关系变化；</li>
<li>OopMap内容变化的指令非常多，如果为每一条指令都生成对应的OopMap，将会需要大量的额外空间，这样GC的空间成本将会变得很高。</li>
</ol>
<ul>
<li>安全点定义<br>HotSpot没有为每条指令都生成OopMap，只是在特定的位置记录了这些信息，这些位置称为安全点(Sapfepoint)，即程序执行时并非在所有地方都能停顿下来开始GC，只有在到达安全点时才能暂停。</li>
<li>安全点的选定</li>
</ul>
<ol>
<li>安全点的选定既不能太少以至于让GC等待时间太长，也不能过于频繁以至于过分增大运行时的负荷。</li>
<li>安全点的选定基本上是以程序<code>是否具有让程序长时间执行的特性</code>为标准选定的，<code>长时间执行</code>的最明显特性就是指令序列复用，如方法调用、循环跳转、异常跳转等，所以具有这些功能的指令才会产生Safepoint。</li>
</ol>
<ul>
<li>如何在GC发生时让所有线程（这里不包括执行JNI调用的线程）都跑到最近的安全点上再停顿下来，有两张方案可供选择：</li>
</ul>
<ol>
<li><code>抢先式中断</code>（Preemptive Suspension）：不需要线程的执行代码主动去配合，在GC发生时，首先把所有线程全部中断，如果发现有线程中断的地方不在安全点上，就恢复线程，让它跑到安全点。<br>现在几乎没有虚拟机实现采用抢先式中断来暂停线程从而响应GC事件。</li>
<li><code>主动式中断</code>（Voluntary Suspension）：当GC需要中断线程的时候，不直接对线程进行操作，仅仅简单的设置一个标志，各个线程执行时主动去轮询这个标志，发现中断标志为真时就自己中断挂起（VM将内存页设置为不可读，线程会产生自陷异常，在预先注册异常处理器中<code>暂停线程</code>实现等待），轮询标志的地方和安全点是重合的。</li>
</ol>
<h2 id="安全区域（Safe-Region）"><a href="#安全区域（Safe-Region）" class="headerlink" title="安全区域（Safe Region）"></a>安全区域（Safe Region）</h2><ul>
<li>安全区域产生背景<br>Safepoint机制保证了程序执行时，在不太长时间内就会遇到可进入GC的Safepoint；但是当程序不执行（没有CPU分配时间）的时候（如线程出于Sleep状态或者Block状态），这时线程无法响应JVM的中断请求，走到安全的地方中断挂起，JVM也不可能等待线程重新分配CPU时间。对于这种情况，就需要安全区域（Safe Region）来解决。</li>
<li>安全区域定义<br>安全区域是指在一段代码片中，引用关系不会发生变化。在这个区域中的任意地方开始GC都是安全的。可以将Safe Region看作被扩展了的Safepoint。</li>
<li>工作原理<br>执行函数在进入安全区域时设置ready flag。在它离开安全区域以前，它先检查GC是否完成了枚举（或者收集），并且不再需要执行函数呆在阻塞状态。如果是真，它就向前执行，离开安全区域； 否则，它就像安全点一样阻塞他自己。</li>
</ul>
<h1 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h1><p>介绍垃圾收集器之前，需要明确一点，就是在新生代采用的停止复制算法中，“停 止（Stop-the-world）”的意义是在回收内存时，需要暂停其他所 有线程的执行。这个是很低效的，现在的各种新生代收集器越来越优化这一点，但仍然只是将停止的时间变短，并未彻底取消停止。</p>
<h2 id="Serial收集器"><a href="#Serial收集器" class="headerlink" title="Serial收集器"></a>Serial收集器</h2><ul>
<li>新生代收集器，使用停止复制算法，使用一个线程进行GC，串行，其它工作线程暂停。</li>
<li>使用-XX:+UseSerialGC可以使用Serial+Serial Old模式运行进行内存回收（这也是虚拟机在Client模式下运行的默认值）</li>
</ul>
<h2 id="ParNew收集器（Parallel-New）"><a href="#ParNew收集器（Parallel-New）" class="headerlink" title="ParNew收集器（Parallel New）"></a>ParNew收集器（Parallel New）</h2><ul>
<li>新生代收集器，使用停止复制算法，Serial收集器的多线程版，用多个线程进行GC，并行，其它工作线程暂停，关注缩短垃圾收集时间。</li>
<li>使用-XX:+UseParNewGC开关来控制使用ParNew+Serial Old收集器组合收集内存；使用-XX:ParallelGCThreads来设置执行内存回收的线程数。</li>
</ul>
<h2 id="Parallel-Scavenge收集器"><a href="#Parallel-Scavenge收集器" class="headerlink" title="Parallel Scavenge收集器"></a>Parallel Scavenge收集器</h2><ul>
<li><p>新生代收集器，使用停止复制算法，关注CPU吞吐量，即运行用户代码的时间/总时间，<br>比如：JVM运行100分钟，其中运行用户代码99分钟，垃圾收集1分钟，则吞吐量是99%，</p>
</li>
<li><p>这种收集器能最高效率的利用CPU，适合运行后台运算（关注缩短垃圾收集时间的收集器，如CMS，等待时间很少，所以适 合用户交互，提高用户体验）。</p>
</li>
<li>使用-XX:+UseParallelGC开关控制使用Parallel Scavenge+Serial Old收集器组合回收垃圾（这也是在Server模式下的默认值）；</li>
<li>使用-XX:GCTimeRatio来设置用户执行时间占总时间的比例，默认99，即1%的时间用来进行垃圾回收。</li>
<li>使用-XX:MaxGCPauseMillis设置GC的最大停顿时间（这个参数只对Parallel Scavenge有效），</li>
<li>用开关参数-XX:+UseAdaptiveSizePolicy可以进行动态控制，如自动调整Eden/Survivor比例，老年代对象年龄，新生代大小等，这个参数在ParNew下没有。</li>
</ul>
<h2 id="Serial-Old收集器"><a href="#Serial-Old收集器" class="headerlink" title="Serial Old收集器"></a>Serial Old收集器</h2><ul>
<li>老年代收集器，单线程收集器，串行，</li>
<li>使用标记整理（整理的方法是Sweep（清理）和Compact（压缩），清理是将废弃的对象干掉，只留幸存的对象，压缩是将移动对象，将空间填满保证内存分为2块，一块全是对象，一块空闲）算法，</li>
<li>使用单线程进行GC，其它工作线程暂停（注意，在老年代中进行标记整理算法清理，也需要暂停其它线程），</li>
<li>在JDK1.5之前，Serial Old收集器与ParallelScavenge搭配使用。</li>
</ul>
<h2 id="Parallel-Old收集器"><a href="#Parallel-Old收集器" class="headerlink" title="Parallel Old收集器"></a>Parallel Old收集器</h2><ul>
<li>老年代收集器，多线程，并行，多线程机制与Parallel Scavenge差不错，</li>
<li>使用标记整理（与Serial Old不同，这里的整理是Summary（汇总）和Compact（压缩），汇总的意思就是将幸存的对象复制到预先准备好的区域，而不是像Sweep（清理）那样清理废弃的对象）算法，</li>
<li>在Parallel Old执行时，仍然需要暂停其它线程。</li>
<li>Parallel Old在多核计算中很有用。</li>
<li>Parallel Old出现后（JDK 1.6），与Parallel Scavenge配合有很好的效果，充分体现Parallel Scavenge收集器吞吐量优先的效果。</li>
<li>使用-XX:+UseParallelOldGC开关控制使用Parallel Scavenge +Parallel Old组合收集器进行收集。</li>
</ul>
<h2 id="CMS收集器（Concurrent-Mark-Sweep）"><a href="#CMS收集器（Concurrent-Mark-Sweep）" class="headerlink" title="CMS收集器（Concurrent Mark Sweep）"></a>CMS收集器（Concurrent Mark Sweep）</h2><ul>
<li>老年代收集器，致力于获取最短回收停顿时间（即缩短垃圾回收的时间），使用标记清除算法，多线程，优点是并发收集（用户线程可以和GC线程同时工作），停顿小。</li>
<li>使用-XX:+UseConcMarkSweepGC进行ParNew+CMS+Serial Old进行内存回收，</li>
<li>优先使用ParNew+CMS，当用户线程内存不足时，采用备用方案Serial Old收集。</li>
<li>CMS收集的执行过程是：初始标记(CMS-initial-mark) -&gt; 并发标记(CMS-concurrent-mark) –&gt;预清理(CMS-concurrent-preclean)–&gt;可控预清理(CMS-concurrent-abortable-preclean)-&gt; 重新标记(CMS-remark) -&gt; 并发清除(CMS-concurrent-sweep) -&gt;并发重设状态等待下次CMS的触发(CMS-concurrent-reset)</li>
<li>在CMS清理过程中，只有初始标记和重新标记需要短暂停顿，并发标记和并发清除都不需要暂停用户线程，因此效率很高，很适合高交互的场合。</li>
<li>CMS也有缺点，它需要消耗额外的CPU和内存资源，在CPU和内存资源紧张，CPU较少时，会加重系统负担（CMS默认启动线程数为(CPU数量+3)/4）。</li>
<li>在并发收集过程中，用户线程仍然在运行，仍然产生内存垃圾，所以可能产生“浮动垃圾”，本次无法清理，只能下一次Full GC才清理，因此在GC期间，需要预留足够的内存给用户线程使用。</li>
<li>使用CMS的收集器并不是老年代满了才触发Full GC，而是在使用了一大半（默认68%，即2/3，使用-XX:CMSInitiatingOccupancyFraction来设置）的时候就要进行Full GC，如果用户线程消耗内存不是特别大，可以适当调高-XX:CMSInitiatingOccupancyFraction以降低GC次数，提高性能，如果预留的用户线程内存不够，则会触发Concurrent Mode Failure，此时，将触发备用方案：使用Serial Old 收集器进行收集，但这样停顿时间就长了，因此-XX:CMSInitiatingOccupancyFraction不宜设的过大。</li>
<li>CMS采用的是标记清除算法，会导致内存碎片的产生，可以使用-XX：+UseCMSCompactAtFullCollection来设置是否在Full GC之后进行碎片整理，用-XX：CMSFullGCsBeforeCompaction来设置在执行多少次不压缩的Full GC之后，来一次带压缩的Full GC。</li>
</ul>
<h2 id="G1收集器（Garbage-First）"><a href="#G1收集器（Garbage-First）" class="headerlink" title="G1收集器（Garbage-First）"></a>G1收集器（Garbage-First）</h2><p>面向服务器端应用的垃圾收集器，计划未来替代CMS收集器。</p>
<h2 id="理解GC日志"><a href="#理解GC日志" class="headerlink" title="理解GC日志"></a>理解GC日志</h2><h2 id="垃圾收集器参数总结"><a href="#垃圾收集器参数总结" class="headerlink" title="垃圾收集器参数总结"></a>垃圾收集器参数总结</h2><h1 id="内存分配与回收策略"><a href="#内存分配与回收策略" class="headerlink" title="内存分配与回收策略"></a>内存分配与回收策略</h1><h2 id="对象优先在Eden分配"><a href="#对象优先在Eden分配" class="headerlink" title="对象优先在Eden分配"></a>对象优先在Eden分配</h2><h2 id="大对象直接进入老年代"><a href="#大对象直接进入老年代" class="headerlink" title="大对象直接进入老年代"></a>大对象直接进入老年代</h2><h2 id="长期存活的对象将进入老年代"><a href="#长期存活的对象将进入老年代" class="headerlink" title="长期存活的对象将进入老年代"></a>长期存活的对象将进入老年代</h2><h2 id="动态对象年龄判定"><a href="#动态对象年龄判定" class="headerlink" title="动态对象年龄判定"></a>动态对象年龄判定</h2><h2 id="空间分配担保"><a href="#空间分配担保" class="headerlink" title="空间分配担保"></a>空间分配担保</h2>]]></content>
      
        <categories>
            
            <category> 读书笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> JVM </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MySQL存储过程学习笔记]]></title>
      <url>http://geosmart.github.io/2016/03/08/MySQL%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>团队一直有小伙伴顶着数据库相关的工作，ETL数据整合分析事情多了，研发开发工作相应减少，终于有机会也来写写存储过程了。<br>以SP进行SQL业务逻辑封装，执行性能能大大提高，在注意合理拆分SP、SQL书写简洁规范和注释到位的情况下，也能做到易于维护。<br>特别是对于海量数据分析追求时效性的业务，效率第一，就算逻辑复杂不易维护也得认。如Hibernate VS Mybatis，产品 VS 项目，现实世界丰富多彩，存在即合理。</p>
<hr>
<a id="more"></a>
<p>MySQL从V5.0开始支持存储过程，V5.0~V5.7版本之间自带的function有所差别，查资料的时候注意过滤，本文以<code>MySQL5.5.4</code>作为测试环境。</p>
<h1 id="关于MySQL存储过程"><a href="#关于MySQL存储过程" class="headerlink" title="关于MySQL存储过程"></a>关于MySQL存储过程</h1><p>MySQL 存储过程(Stored Procedure) 是通过给定的语法格式编写自定义的数据库API, 包含一系列sql语句的集合, 完成一个复杂的功能.</p>
<ul>
<li><a href="http://dev.mysql.com/doc/refman/5.5/en/stored-programs-views.html">MySQL5.5官方文档 存储过程</a></li>
<li>调试工具：dbForge Studio for MySQL Professional Edition<br><img src="DbForgeStudio调试MySQL存储过程.png" alt="DbForgeStudio调试MySQL存储过程"></li>
</ul>
<h1 id="变量定义"><a href="#变量定义" class="headerlink" title="变量定义"></a>变量定义</h1><p>mysql存储过程中，定义变量有两种方式：</p>
<h2 id="会话变量"><a href="#会话变量" class="headerlink" title="会话变量"></a>会话变量</h2><p>使用set或select直接赋值，变量名以 @ 开头，可以在一个会话的任何地方声明，作用域是整个会话，称为会话变量。<br>如:<code>set @var=1;</code></p>
<h2 id="存储过程变量"><a href="#存储过程变量" class="headerlink" title="存储过程变量"></a>存储过程变量</h2><p>以 DECLARE 关键字声明的变量，只能在存储过程中使用，称为存储过程变量，主要用在存储过程中，或者是给存储传参数中。<br>如：<code>DECLARE var1  INT DEFAULT 0;</code></p>
<h2 id="两者的区别"><a href="#两者的区别" class="headerlink" title="两者的区别"></a>两者的区别</h2><ul>
<li>在调用存储过程时，以DECLARE声明的变量都会被初始化为 NULL。</li>
<li>会话变量（即@开头的变量）则不会被再初始化，在一个会话内，只须初始化一次，之后在会话内都是对上一次计算的结果，就相当于在是这个会话内的全局变量。</li>
<li>在存储过程中，使用动态语句，预处理时，动态内容必须赋给一个会话变量。</li>
</ul>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ul>
<li>变量命名需与表字段不一致；</li>
</ul>
<h1 id="输出日志信息"><a href="#输出日志信息" class="headerlink" title="输出日志信息"></a>输出日志信息</h1><p>SELECT concat(‘Comment:’,’—Comment—‘);</p>
<h1 id="临时表"><a href="#临时表" class="headerlink" title="临时表"></a>临时表</h1><p><a href="http://www.nowamagic.net/librarys/veda/detail/1317">参考-MySQL临时表的简单用法</a><br><a href="http://dev.mysql.com/doc/refman/5.5/en/internal-temporary-tables.html">参考-internal-temporary-tables</a><br>临时表将在你连接MySQL期间存在。当连接断开时，MySQL将自动删除表并释放所用的空间。当然也可以在仍然连接的时候删除表并释放空间。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">-- 新建</span></div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">TEMPORARY</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> sp_output_tmp <span class="keyword">ENGINE</span> = <span class="keyword">MEMORY</span> SELECT... from... where... ;</div><div class="line"><span class="comment">-- 删除</span></div><div class="line"><span class="keyword">DROP</span> <span class="keyword">TEMPORARY</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">EXISTS</span> sp_output_tmp;</div></pre></td></tr></table></figure></p>
<h1 id="游标嵌套循环（nested-cursor-loop）"><a href="#游标嵌套循环（nested-cursor-loop）" class="headerlink" title="游标嵌套循环（nested cursor loop）"></a>游标嵌套循环（nested cursor loop）</h1><p><a href="http://stackoverflow.com/questions/6099500/multiple-cursors-in-nested-loops-in-mysql/6099837#6099837">参考/multiple-cursors-in-nested-loops-in-mysql</a></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">BEGIN</span></div><div class="line">  <span class="keyword">DECLARE</span> done1 <span class="built_in">int</span> <span class="keyword">default</span> <span class="literal">false</span>;  </div><div class="line">  <span class="comment">-- 批量更新计数器</span></div><div class="line">  <span class="keyword">DECLARE</span> cachSize_matchedAddress <span class="built_in">int</span> <span class="keyword">DEFAULT</span> <span class="number">0</span>;</div><div class="line"></div><div class="line">  <span class="comment">-- 定义Cursor1</span></div><div class="line">  <span class="keyword">DECLARE</span> cursor_bizId <span class="keyword">CURSOR</span> <span class="keyword">FOR</span> <span class="keyword">select</span> *  <span class="keyword">from</span> table1;</div><div class="line">  <span class="keyword">DECLARE</span> CONTINUE <span class="keyword">HANDLER</span> <span class="keyword">FOR</span> <span class="keyword">NOT</span> <span class="keyword">FOUND</span> <span class="keyword">SET</span> done1 = <span class="literal">TRUE</span>;  </div><div class="line"></div><div class="line">  <span class="comment">-- 打开Cursor1</span></div><div class="line">  OPEN cursor_bizId;</div><div class="line">  <span class="comment">-- 循环获取业务ID  </span></div><div class="line">  loop_getBizId:LOOP</div><div class="line">     FETCH cursor_bizId INTO bizId;</div><div class="line">      IF done1 THEN</div><div class="line">        LEAVE loop_getBizId;</div><div class="line">        # 关闭Cursor1</div><div class="line">        CLOSE cursor_bizId;</div><div class="line">      <span class="keyword">END</span> <span class="keyword">IF</span>;</div><div class="line">    <span class="comment">-- TODO Cursor1相关业务逻辑</span></div><div class="line"></div><div class="line">    <span class="comment">-- 根据业务ID获取业务数据</span></div><div class="line">    block_matchedAddress:<span class="keyword">BEGIN</span></div><div class="line">        <span class="keyword">DECLARE</span> done2 <span class="built_in">int</span> <span class="keyword">default</span> <span class="literal">false</span>;</div><div class="line">        <span class="comment">-- 定义Cursor2</span></div><div class="line">        <span class="keyword">DECLARE</span> cursor_matchedAddress <span class="keyword">CURSOR</span> <span class="keyword">FOR</span> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> temp_matchedAddress;</div><div class="line">        <span class="keyword">DECLARE</span> continue <span class="keyword">handler</span> <span class="keyword">for</span> <span class="keyword">not</span> <span class="keyword">found</span> <span class="keyword">set</span> done2 = <span class="literal">true</span>;  </div><div class="line"></div><div class="line">        OPEN cursor_matchedAddress;  </div><div class="line">        <span class="comment">-- 循环获取业务数据</span></div><div class="line">        loop_getMatchedAddress:LOOP   </div><div class="line">            FETCH cursor_matchedAddress INTO _rownum, _matchID, _matchedType, _matchedAddress, _x, _y;</div><div class="line">            IF done2 THEN</div><div class="line">               LEAVE loop_getMatchedAddress;</div><div class="line">               <span class="comment">-- 关闭Cursor2</span></div><div class="line">               CLOSE cursor_matchedAddress;</div><div class="line">            <span class="keyword">END</span> <span class="keyword">IF</span>;</div><div class="line">            <span class="comment">-- TODO Cursor2相关业务逻辑</span></div><div class="line"></div><div class="line">        <span class="keyword">END</span> <span class="keyword">LOOP</span> loop_getMatchedAddress;</div><div class="line">      <span class="keyword">END</span> block_matchedAddress;</div><div class="line"></div><div class="line">  <span class="keyword">END</span> <span class="keyword">LOOP</span> loop_getBizId;</div><div class="line"><span class="keyword">END</span></div></pre></td></tr></table></figure>
<h1 id="动态sql"><a href="#动态sql" class="headerlink" title="动态sql"></a>动态sql</h1><p>PREPARE命令：<code>PREPARE stmt_name FROM preparable_stmt</code><br>The PREPARE statement prepares a SQL statement and assigns it a name, stmt_name, by which to refer to the statement later. The prepared statement is executed with EXECUTE and released with DEALLOCATE PREPARE. For examples, see Section 13.5, “SQL Syntax for Prepared Statements”.  </p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SET</span> @<span class="keyword">sql</span> = <span class="string">"select *  from table"</span>;</div><div class="line"><span class="keyword">PREPARE</span> stmt <span class="keyword">from</span> @<span class="keyword">sql</span> ;</div><div class="line"><span class="keyword">EXECUTE</span> stmt;</div><div class="line"><span class="keyword">DEALLOCATE</span> <span class="keyword">PREPARE</span> stmt;</div></pre></td></tr></table></figure>
<p>注意：<strong>The text must represent a single statement, not multiple statements.</strong></p>
<h1 id="批量更新"><a href="#批量更新" class="headerlink" title="批量更新"></a>批量更新</h1><p>在sp中类似<code>insert into (column1) values (value1)</code>这样循环单条insert执行速度太慢，<br>可采用<code>temporary table</code>将数据先插入临时表；设置一个计数器，当临时表达到limit记录数时，关联更新目标表并重置临时表以释放资源。</p>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="Json序列化函数JSON-Array不存在问题"><a href="#Json序列化函数JSON-Array不存在问题" class="headerlink" title="Json序列化函数JSON_Array不存在问题"></a>Json序列化函数JSON_Array不存在问题</h2><p>问题描述：JSON_Array does not existed<br>解决：我用的V5.5，不支持,V5.7.8才支持;</p>
<blockquote>
<p>As of MySQL 5.7.8, MySQL supports a native JSON data type that enables efficient access to data in JSON (JavaScript Object Notation) documents. The JSON data type provides these advantages over storing JSON-format strings in a string column:</p>
</blockquote>
<h2 id="嵌套Cusor问题"><a href="#嵌套Cusor问题" class="headerlink" title="嵌套Cusor问题"></a>嵌套Cusor问题</h2><p>问题描述：子Cursor fetch的values总是父Cursor的第一个值，见<a href="https://gist.github.com/geosmart/c3d7f4eb0d9ad53751d7">gist存储过程记录</a><br>解决：View的问题，换成temporary table解决，见<a href="https://gist.github.com/geosmart/9020fdc1cad9fb0ab36e">gist-batchUpdateMatchedAddress.sql</a></p>
<h2 id="游标动态sql问题"><a href="#游标动态sql问题" class="headerlink" title="游标动态sql问题"></a>游标动态sql问题</h2><p>问题描述：动态设置的条件与静态条件相比，少返回1条记录<br>原因：游标中查询条件不支持动态条件。<br><a href="http://dev.mysql.com/doc/refman/5.6/en/sql-syntax-prepared-statements.html">参考sql-syntax-prepared-statements</a></p>
<blockquote>
<p>SQL syntax for prepared statements can be used within stored procedures, but not in stored functions or triggers. However, a cursor cannot be used for a dynamic statement that is prepared and executed with PREPARE and EXECUTE. The statement for a cursor is checked at cursor creation time, so the statement cannot be dynamic.</p>
</blockquote>
<p>解决：<a href="http://stackoverflow.com/questions/7685588/dynamic-cursor-in-stored-procedure">参考dynamic-cursor-in-stored-procedure</a></p>
<ul>
<li>A cursor will only accept a select statement, so if the SQL really needs to be dynamic make the declare cursor part of the statement you are executing.</li>
<li>以View视图或Temporary Table临时表形式间接实现</li>
</ul>
<h2 id="新建视图时select中不能带有动态参数"><a href="#新建视图时select中不能带有动态参数" class="headerlink" title="新建视图时select中不能带有动态参数"></a>新建视图时select中不能带有动态参数</h2><p>原因： Within a stored program, the SELECT statement cannot refer to program parameters or local variables.<br>解决：View嵌套子查询，参考<a href="http://stackoverflow.com/questions/8428641/views-select-contains-a-subquery-in-the-from-clause">View’s SELECT contains a subquery in the FROM clause</a><br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">create</span> <span class="keyword">view</span> view_clients_credit_usage <span class="keyword">as</span></div><div class="line">    <span class="keyword">select</span> client_id, <span class="keyword">sum</span>(credits_used) <span class="keyword">as</span> credits_used</div><div class="line">    <span class="keyword">from</span> credit_usage</div><div class="line">    <span class="keyword">group</span> <span class="keyword">by</span> client_id;</div><div class="line"></div><div class="line"><span class="keyword">create</span> <span class="keyword">view</span> view_credit_status <span class="keyword">as</span></div><div class="line">    <span class="keyword">select</span></div><div class="line">        credit_orders.client_id,</div><div class="line">        <span class="keyword">sum</span>(credit_orders.number_of_credits) <span class="keyword">as</span> purchased,</div><div class="line">        <span class="keyword">ifnull</span>(t1.credits_used,<span class="number">0</span>) <span class="keyword">as</span> used</div><div class="line">    <span class="keyword">from</span> credit_orders</div><div class="line">    <span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">join</span> view_clients_credit_usage <span class="keyword">as</span> t1 <span class="keyword">on</span> t1.client_id = credit_orders.client_id</div><div class="line">    <span class="keyword">where</span> credit_orders.payment_status=<span class="string">'Paid'</span></div><div class="line">    <span class="keyword">group</span> <span class="keyword">by</span> credit_orders.client_id);</div></pre></td></tr></table></figure></p>
<p>　</p>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> Stored Procedure </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[JVM学习笔记（二）Java内存区域与内存溢出异常]]></title>
      <url>http://geosmart.github.io/2016/03/07/JVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89Java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E4%B8%8E%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%BC%82%E5%B8%B8/</url>
      <content type="html"><![CDATA[<p>《深入理解Java虚拟机 JVM高级特性与最佳实践》 第二章 Java内存区域与内存溢出异常</p>
<hr>
<a id="more"></a>
<h1 id="运行时的数据区域"><a href="#运行时的数据区域" class="headerlink" title="运行时的数据区域"></a>运行时的数据区域</h1><p><img src="Java虚拟机运行时数据区.jpg" alt="Java虚拟机运行时数据区"></p>
<h2 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h2><ul>
<li>程序计数器（Program Counter Register）是一块比较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器；</li>
<li>PCR为线程私有内存；</li>
<li>是唯一一个在Java虚拟机规范中没有规定任何OOM情况的区域；</li>
</ul>
<h2 id="Java虚拟机栈"><a href="#Java虚拟机栈" class="headerlink" title="Java虚拟机栈"></a>Java虚拟机栈</h2><p><img src="JavaStacks.jpg" alt="Java虚拟机栈"></p>
<ul>
<li>Java虚拟机栈（Java Virtual Machine Stacks）描述的是Java方法执行的内存模型：每个方法在在执行的同时都会创建一个栈帧（Stack Frame）用于存储<code>局部变量表、操作数栈、动态链接、方法接口</code>等信息。每个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈出栈的过程。</li>
<li>Java虚拟机栈也是线程私有，它的生命周期与线程相同。</li>
<li>Java内存区常分为堆内存（Heap）和栈内存（Stack）；</li>
<li>OOM情况：（1）线程请求的栈深度&gt;虚拟机所运行的最大深度；（2）虚拟机动态扩展时无法申请到足够的内存</li>
</ul>
<h2 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h2><p><img src="Java本地方法栈.png" alt="Java本地方法栈"> 本地方法栈（Native Method Stack）与虚拟机所发挥的作用非常相似的，他们之间的区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚拟机所使用的Native方法服务。</p>
<ul>
<li>HotSpot虚拟机把本地方法栈和虚拟机栈合二为一；</li>
<li>此区域会抛StackOverflowError 和 OutofMemoryError异常</li>
</ul>
<h2 id="Java堆"><a href="#Java堆" class="headerlink" title="Java堆"></a>Java堆</h2><p><img src="JavaHeap.gif" alt="Java堆"> Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块，Java Heap是所有线程共享的一块内存区域，在VM启动时创建。</p>
<ul>
<li><code>所有的对象实例以及数组都要在堆上分配</code>（不绝对：栈上分配、标量替换优化技术）；</li>
<li>Java堆是垃圾收集器管理的主要区域，也可称做GC堆（Garbage Collected Heap）</li>
<li>从内存回收的角度，现代收集器基本都采用分代收集算法，Java Heap可细分为新生代和老年代，再细致可分为Eden空间、From Survivor空间、To Survivor空间等–&gt;更好回收内存。</li>
<li>从内存分配的角度，线程共享的Java堆中可能分出多个线程私有的分配缓存区（TLAB：Thread Local Allocation Buffer）–&gt;更快分配内存。</li>
<li>Java堆出于逻辑连续的内存空间中，物理上可不连续，如磁盘空间一样；</li>
<li>Java堆在实现上可时，可以实现成固定大小的，也可以按照可扩展实现（-Xmx和-Xms控制）；</li>
<li>OOM情况：堆中没有内存完成实例分配，堆也无法再扩展时</li>
</ul>
<h2 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h2><p>方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储<code>已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码</code>等数据。</p>
<ul>
<li>也称为永久代（Permanent Generation）但随着Java8的到来，已放弃永久代改为采用Native Memory来实现方法区的规划。</li>
<li>此区域回收目标主要是针对常量池的回收和对类型的卸载。</li>
</ul>
<h2 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h2><p><img src="Java虚拟机运行时数据区拓扑关系.png" alt="Java虚拟机运行时数据区拓扑关系"> 运行时常量池（Runtime Constants Pool）是方法区的一部分</p>
<ul>
<li>Class文件中除了有<code>类的版本、字段、方法、接口</code>等描述的信息外，还有一项信息是常量池（Constant Pool Table）,用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。</li>
</ul>
<h2 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h2><p>直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域。</p>
<ul>
<li>能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。</li>
<li>直接内存的分配不会受到Java堆大小的限制，但会收到本机总内存（RAM以及SWAP/分页文件）大小以及处理器寻址空间的限制。</li>
<li>设置Xmx等参数信息时注意不能忽略直接内存，不然会引起OOM。</li>
</ul>
<h1 id="HotSpot虚拟机"><a href="#HotSpot虚拟机" class="headerlink" title="HotSpot虚拟机"></a>HotSpot虚拟机</h1><h2 id="对象的创建"><a href="#对象的创建" class="headerlink" title="对象的创建"></a>对象的创建</h2><p>为新生对象分配内存的分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾回收器是否带有压缩整理功能决定。</p>
<ul>
<li>指针碰撞（Bump the Pointer）分配方式：Serial、ParNew等带有Compact过程的收集器</li>
<li>空闲列表（Free List）分配方式：类CMS这种基于Mark-Sweep算法的收集器</li>
<li>对分配内存空间的动作进行同步处理—VM采用CAS配上失败重试的方式保证更新操作的原子性；</li>
<li>本地线程分配缓冲（Thread Local Allocation Buffer,TLAB）：把内存分配动作按线程划分在不同空间中进行，即每个线程在Java堆中预先分配一小块内存，虚拟机是否启用TLAB，可由-XX:+/-UseTLAB参数设定；</li>
</ul>
<h2 id="对象的内存布局"><a href="#对象的内存布局" class="headerlink" title="对象的内存布局"></a>对象的内存布局</h2><p><img src="对象内存布局1.jpg" alt="对象的内存布局1"> 对象在内存中存储的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）、和对齐填充（Padding）;</p>
<ul>
<li>对象头包含2部分信息</li>
<li><p><img src="对象内存布局2.png" alt="对象的内存布局2"></p>
<ul>
<li>Mark Word,存储对象自身的运行时数据（如哈希码、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳）；由于对象头与对象自身定义的数据存储大小无关，考虑到VM的空间效率，Mark Word被设计成非固定的数据结构以便在极小的空间内存储尽量多的信息，他会根据对象的状态复用自己的存储空间。</li>
<li>类型指针，即对象指向它的类元数据的指针，VM通过这个指针来确定这个对象是哪个类的实例。</li>
</ul>
</li>
<li><p>实例数据是对象真正存储的有效信息，也似乎程序代码中定义的各种类型的字段内容。</p>
</li>
<li>对齐填充，并不必然存在，没有特别含义，仅仅起占位符的作用，8byte对齐。</li>
</ul>
<h2 id="对象的访问定位"><a href="#对象的访问定位" class="headerlink" title="对象的访问定位"></a>对象的访问定位</h2><p>Java程序需要通过栈上的reference数据来操作堆上的具体对象，对象访问方法取决于VM实现而定，目前主流访问方式有使用句柄和直接指针2种：</p>
<h3 id="句柄访问"><a href="#句柄访问" class="headerlink" title="句柄访问"></a>句柄访问</h3><p>Java堆中划分出一块内存作为句柄池，reference中存储对象的句柄地址，句柄中包含对象实例数据与类型数据各自的具体地址信息； <img src="句柄访问对象.jpg" alt="句柄访问对象"></p>
<h3 id="直接指针访问"><a href="#直接指针访问" class="headerlink" title="直接指针访问"></a>直接指针访问</h3><p>Java堆对象的布局中必须考虑如何放置访问类型数据的相关信息，reference中存储对象地址； <img src="直接指针访问对象.jpg" alt="直接指针访问对象"></p>
<h3 id="两种访问方式各有优势"><a href="#两种访问方式各有优势" class="headerlink" title="两种访问方式各有优势"></a>两种访问方式各有优势</h3><ul>
<li>使用句柄访问最大的好处是reference中存储的是稳定的句柄地址，在对象被移动（GC时移动对象是很普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要修改；</li>
<li>使用直接指针访问方式的最大好处是速度更快，它节省了一次指针定位的时间开销，由于对象访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本；</li>
<li>HotSpot虚拟机采用指针访问方式进行对象访问，从整个软件开发范围看，各种语言和框架使用句柄来访问的情况也非常常见。</li>
</ul>
<h2 id="实战OOM异常"><a href="#实战OOM异常" class="headerlink" title="实战OOM异常"></a>实战OOM异常</h2><h3 id="Java堆溢出"><a href="#Java堆溢出" class="headerlink" title="Java堆溢出"></a>Java堆溢出</h3><p>Java堆用于存储对象实例，只要不断创建对象，并保证GC Roots到对象之间有可达路径来避免回收机制清除这些对象，那么当对象数量到达最大堆的容量限制后就会产生OOM。</p>
<h4 id="控制参数"><a href="#控制参数" class="headerlink" title="控制参数"></a>控制参数</h4><ul>
<li>-Xms：堆最小值</li>
<li>-Xmx：堆最大值</li>
<li>-XX:+HeapDumpOnOutOfMemoryError：让虚拟机在出现OOM异常时Dump出当前内存堆转储快照以便事后进行分析</li>
</ul>
<h4 id="异常信息"><a href="#异常信息" class="headerlink" title="异常信息"></a>异常信息</h4><p><code>Java.lang.OutOfMemory</code> + <code>Java Heap Space</code></p>
<h4 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h4><p>以内存映像分析工具（Eclipse Memory Analyzer）对Dump出来的堆转储快照进行分析，重点是确认内存中的对象是否是必要的，即判断是内存泄漏（Memory Leak）还是内存溢出（Memory Overflow）</p>
<ul>
<li>如果是内存泄漏：通过工具查看泄漏对象到GC Roots的引用链，掌握泄漏对象的类型信息及引用链的信息后可较准确的定位代码位置；</li>
<li>如果是内存溢出：可通过检查VM的堆参数（-Xmx和-Xms），与机器物理内存对比看是否可以调大；从代码检查是否存在某些对象生命周期过长，持有状态时间过长的情况，尝试减少程序运行期的内存消耗  </li>
</ul>
<h3 id="虚拟机栈和本地方法栈溢出"><a href="#虚拟机栈和本地方法栈溢出" class="headerlink" title="虚拟机栈和本地方法栈溢出"></a>虚拟机栈和本地方法栈溢出</h3><h4 id="控制参数-1"><a href="#控制参数-1" class="headerlink" title="控制参数"></a>控制参数</h4><p>HotSpot虚拟机不区分虚拟机栈和本地方法栈，</p>
<ul>
<li>-Xoss（设置本地方法栈大小）：参数设置无效;</li>
<li>-Xss（栈容量）;</li>
</ul>
<h4 id="异常信息-1"><a href="#异常信息-1" class="headerlink" title="异常信息"></a>异常信息</h4><p>关于虚拟机栈和本地方法栈，在Java虚拟机规范中描述了两种异常：</p>
<ul>
<li>如果线程请求的栈深度 &gt; 虚拟机所允许的最大深度，抛出<code>StackOverFlowError</code>异常</li>
<li>如果虚拟机在扩展栈时无法申请到足够的内存空间，抛出<code>OutOfMemoryError</code>异常  </li>
</ul>
<h4 id="解决办法-1"><a href="#解决办法-1" class="headerlink" title="解决办法"></a>解决办法</h4><p>操作系统分配给每个进程的内存是有限制的，如32位Windwos限制为2G。虚拟机提供了参数来控制Java堆和方法区这两部分内存的最大值， <code>虚拟机栈和本地方法栈可瓜分的剩余内存=2G（操作系统限制）-Xmx（最大堆容量）-MaxPermSize（最大方法区容量）-虚拟机进程本身耗费内存</code>；程序计数器消耗内存很小，可以忽略。</p>
<ul>
<li>每个线程分配到的栈容量越大，可以建立的线程数就越少，建立线程时候就越容易耗尽剩余内存。</li>
<li>按虚拟机默认参数，栈深度在大多数情况下达到1000~2000完全没问题，对于正常方法调用（包括递归），这个深度应该完全够用；但如果是建立过多线程导致内存溢出，在不能<strong>减少线程数或者更换X64位虚拟机</strong>的情况下，就只能通过<strong>减少最大堆和减少栈容量</strong>来换取更多的线程</li>
</ul>
<h3 id="方法区和运行时常量区溢出"><a href="#方法区和运行时常量区溢出" class="headerlink" title="方法区和运行时常量区溢出"></a>方法区和运行时常量区溢出</h3><p>运行时常量池是方法区的一部分，因此这两个区域的溢出可放在一起进行。</p>
<h4 id="控制参数-2"><a href="#控制参数-2" class="headerlink" title="控制参数"></a>控制参数</h4><ul>
<li>-XX:PermSize（方法区最小容量）</li>
<li>-XX:MaxPermSize （方法区最大容量）</li>
</ul>
<h4 id="异常信息-2"><a href="#异常信息-2" class="headerlink" title="异常信息"></a>异常信息</h4><p><code>OutOfMemoryError</code> 后面跟随<code>PermGen space</code> 说明运行时常量池属于方法区（HotSpot虚拟机中的永久代）的一部分</p>
<h3 id="本机直接内存溢出"><a href="#本机直接内存溢出" class="headerlink" title="本机直接内存溢出"></a>本机直接内存溢出</h3><h4 id="控制参数-3"><a href="#控制参数-3" class="headerlink" title="控制参数"></a>控制参数</h4><p>DirectMemory容量可通过<code>-XX:MaxDirectMemorySize</code>指定，不指定默认与-Xmx(Java堆最大值)一样。</p>
<h4 id="异常信息-3"><a href="#异常信息-3" class="headerlink" title="异常信息"></a>异常信息</h4><p>由DirectMemory导致的内存溢出，一个明显的特征是在Heap Dump文件中不会看见明显的异常； 如果发现OOM之后Dump文件很小，而程序又直接或简介使用了NIO，可以考虑是不是这方面的原因。</p>
]]></content>
      
        <categories>
            
            <category> 读书笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> JVM </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HDFS使用笔记]]></title>
      <url>http://geosmart.github.io/2016/03/03/HDFS%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>Hadoop框架中最核心的设计就是：MapReduce和HDFS。MapReduce的思想是分而治之（任务的分解与结果的汇总）。HDFS是Hadoop分布式文件系统（Hadoop Distributed File System）的缩写，为分布式计算存储提供了底层支持。</p>
<hr>
<a id="more"></a>
<p><img src="https://hadoop.apache.org/docs/r1.2.1/images/hdfsarchitecture.gif" alt="HDFS架构图"></p>
<h1 id="HDFS的基本概念"><a href="#HDFS的基本概念" class="headerlink" title="HDFS的基本概念"></a>HDFS的基本概念</h1><h2 id="数据块-block"><a href="#数据块-block" class="headerlink" title="数据块(block)"></a>数据块(block)</h2><p>HDFS默认的最基本的存储单位是64M的数据块。和普通文件系统相同的是，HDFS中的文件是被分成64M一块的数据块存储的。不同于普通文件系统的是，HDFS中，如果一个文件小于一个数据块的大小，并不占用整个数据块存储空间。</p>
<h2 id="元数据节点-Namenode"><a href="#元数据节点-Namenode" class="headerlink" title="元数据节点(Namenode)"></a>元数据节点(Namenode)</h2><p>元数据节点用来管理文件系统的命名空间。其将所有的文件和文件夹的元数据保存在一个文件系统树中。这些信息也会在硬盘上保存成以下文件：命名空间镜像(namespace image)及修改日志(edit log)其还保存了一个文件包括哪些数据块，分布在哪些数据节点上。然而这些信息并不存储在硬盘上，而是在系统启动的时候从数据节点收集而成的。</p>
<h2 id="数据节点-datanode"><a href="#数据节点-datanode" class="headerlink" title="数据节点(datanode)"></a>数据节点(datanode)</h2><p>数据节点是文件系统中真正存储数据的地方。客户端(client)或者元数据信息(namenode)可以向数据节点请求写入或者读出数据块。其周期性的向元数据节点回报其存储的数据块信息。</p>
<h2 id="从元数据节点-secondary-namenode"><a href="#从元数据节点-secondary-namenode" class="headerlink" title="从元数据节点(secondary namenode)"></a>从元数据节点(secondary namenode)</h2><p>从元数据节点并不是元数据节点出现问题时候的备用节点，它和元数据节点负责不同的事情。其主要功能就是周期性将元数据节点的命名空间镜像文件和修改日志合并，以防日志文件过大。合并过后的命名空间镜像文件也在从元数据节点保存了一份，以防元数据节点失败的时候，可以恢复。</p>
<h1 id="HDFS读文件原理"><a href="#HDFS读文件原理" class="headerlink" title="HDFS读文件原理"></a>HDFS读文件原理</h1><p>//TODO</p>
<h1 id="HDFS写文件原理"><a href="#HDFS写文件原理" class="headerlink" title="HDFS写文件原理"></a>HDFS写文件原理</h1><p>//TODO</p>
<h1 id="HDFS文件操作"><a href="#HDFS文件操作" class="headerlink" title="HDFS文件操作"></a>HDFS文件操作</h1><h2 id="上传本地文件到hdfs"><a href="#上传本地文件到hdfs" class="headerlink" title="上传本地文件到hdfs"></a>上传本地文件到hdfs</h2><p><a href="http://www.linuxidc.com/Linux/2013-05/83867.htm">使用Java实现在HDFS中创建文件夹</a><br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="string">hdfs</span> <span class="string">dfs</span> <span class="bullet">-rm</span>  <span class="string">/user/uadb/etl/geocoding</span></div><div class="line"><span class="string">hdfs</span> <span class="string">dfs</span> <span class="bullet">-rm</span>  <span class="string">/user/uadb/etl/geocoding</span></div><div class="line"><span class="string">hdfs</span> <span class="string">dfs</span> <span class="bullet">-put</span>  <span class="string">/user/uadb/etl/geocoding</span>  <span class="string">/user/uadb/etl/</span></div></pre></td></tr></table></figure></p>
<h2 id="删除hdfs文件"><a href="#删除hdfs文件" class="headerlink" title="删除hdfs文件"></a>删除hdfs文件</h2><ul>
<li>rm命令：<code>-rm [-f] [-r|-R] [-skipTrash] &lt;src&gt; ...]</code><br>删除hdfs文件夹内所有文件：<code>hdfs dfs  -rm -R  /user/hive/warehouse/geocodingdb.db/addressnodesgroupbyskeleton/*</code></li>
</ul>
<h2 id="删除hdfs文件夹"><a href="#删除hdfs文件夹" class="headerlink" title="删除hdfs文件夹"></a>删除hdfs文件夹</h2><ul>
<li>rmdir命令：<code>[-rmdir [--ignore-fail-on-non-empty] &lt;dir&gt; ...]</code>，不能删除非空文件夹<br>hdfs dfs  -rmdir   /user/hive/warehouse/geocodingdb.db/addressnodesgroupbyskeleton</li>
</ul>
<h1 id="HDFS相关"><a href="#HDFS相关" class="headerlink" title="HDFS相关"></a>HDFS相关</h1><h2 id="为什么HDFS不适合大量小文件"><a href="#为什么HDFS不适合大量小文件" class="headerlink" title="为什么HDFS不适合大量小文件"></a>为什么HDFS不适合大量小文件</h2><p>1）在HDFS中，namenode将文件系统中的元数据存储在内存中，因此，HDFS所能存储的文件数量会受到namenode内存的限制。一般来说，每个文件、目录、数据块的存储信息大约占150个字节，根据当前namenode的内存空间的配置，就可以计算出大约能容纳多少个文件了。<br>2）有一种误解就是，之所以HDFS不适合大量小文件，是因为即使很小的文件也会占用一个块的存储空间。这是错误的，HDFS与其它文件系统不同，小于一个块大小的文件，不会占用一个块的空间。</p>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Python开发常见问题]]></title>
      <url>http://geosmart.github.io/2016/02/24/Python%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</url>
      <content type="html"><![CDATA[<p>记录Python开发过程中的遇到的问题</p>
<hr>
<a id="more"></a>
<h1 id="ImportError-No-module-named-MySQLdb"><a href="#ImportError-No-module-named-MySQLdb" class="headerlink" title="ImportError: No module named MySQLdb"></a>ImportError: No module named MySQLdb</h1><p>You can find binary installers here (Python 2.6-3.2), here (2.7) or here (2.6). Note that you don’t have to use 64bit Python on Windows x64. You can just as well use a 32bit build of Python, for which there are more pre-built 3rd party packages around.</p>
<h1 id="TypeError-‘-Callable’-object-is-not-callable"><a href="#TypeError-‘-Callable’-object-is-not-callable" class="headerlink" title="TypeError: ‘_Callable’ object is not callable"></a>TypeError: ‘_Callable’ object is not callable</h1><p>That error occurs when you try to call, with (), an object that is not callable.<br>A callable object can be a function or a class (that implements <strong>call</strong> method). According toPython Docs:<br>解决：在init构造函数删除初始化对象的代码</p>
<h1 id="TypeError-getPointByBounds-takes-exactly-4-arguments-5-given"><a href="#TypeError-getPointByBounds-takes-exactly-4-arguments-5-given" class="headerlink" title="TypeError: getPointByBounds() takes exactly 4 arguments (5 given)"></a>TypeError: getPointByBounds() takes exactly 4 arguments (5 given)</h1><p><code>def getPointByBounds(lng0, lat0, lng1, lat1, step=0.001) :</code>应该为<br><code>def getPointByBounds(self,lng0, lat0, lng1, lat1, step=0.001) :</code>第一个参数为self</p>
<h2 id="apply-async最后一个process调用的函数被中止"><a href="#apply-async最后一个process调用的函数被中止" class="headerlink" title="apply_async最后一个process调用的函数被中止"></a>apply_async最后一个process调用的函数被中止</h2><p>暂未发现原因</p>
<h2 id="hangs-on-‘scanning-files-to-index’-background-task"><a href="#hangs-on-‘scanning-files-to-index’-background-task" class="headerlink" title="hangs on ‘scanning files to index’ background task"></a>hangs on ‘scanning files to index’ background task</h2><p>go to the “File” on the left top, then select “invalidate caches/restart…”, and press “invalidate and restart”.</p>
<h2 id="pycharm添加已有virtualEnv"><a href="#pycharm添加已有virtualEnv" class="headerlink" title="pycharm添加已有virtualEnv"></a>pycharm添加已有virtualEnv</h2><p>如通过virtualEnvWarpper创建的env，默认在pycharm中无法选择已有virtualEnv，只能新建，可通过add local手动完成虚拟环境导入<br><code>File&gt;setting&gt;Project Interpreter&gt;add local&gt;选择virtualEnv\Scripts\python.exe</code></p>
<h2 id="pycharm5源代码管理之svn配置"><a href="#pycharm5源代码管理之svn配置" class="headerlink" title="pycharm5源代码管理之svn配置"></a>pycharm5源代码管理之svn配置</h2><p><a href="http://netcologne.dl.sourceforge.net/project/win32svn/1.8.14/Setup-Subversion-1.8.14.msi">svn1.8下载地址</a></p>
<ul>
<li>svn安装：注意安装路径不能带空格：</li>
<li>pycharm配置svn：在version contro&gt;svn&gt;command line client设置为C:\Dev\SVN\bin\svn.exe</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 脚本工具 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Python </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Sqoop使用笔记]]></title>
      <url>http://geosmart.github.io/2016/02/24/Sqoop%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>Sqoop是Apache顶级项目，主要用来在Hadoop和关系数据库中传递数据。通过sqoop，可以方便的将数据从关系数据库导入到HDFS，或将数据从HDFS导出到关系数据库。</p>
<hr>
<a id="more"></a>
<h1 id="关于Sqoop"><a href="#关于Sqoop" class="headerlink" title="关于Sqoop"></a>关于Sqoop</h1><p><a href="http://sqoop.apache.org/">官网</a><br>Sqoop架构整合了Hive、Hbase和Oozie，通过map-reduce任务来传输数据，从而提供并发特性和容错。<br>Sqoop主要通过JDBC和关系数据库进行交互。理论上支持JDBC的database都可以使用sqoop和hdfs进行数据交互。但只有一小部分经过sqoop官方测试，如：HSQLDB（1.8.0+），MySQL（5.0+），Oracle（10.2.0+），PostgreSQL（8.3+ ）；<br>MySQL和PostgreSQL支持direct；较老的版本有可能也被支持，但未经过测试。出于性能考虑，sqoop提供不同于JDBC的快速存取数据的机制，可以通过–direct使用。</p>
<h1 id="Sqoop与MySQL数据交换"><a href="#Sqoop与MySQL数据交换" class="headerlink" title="Sqoop与MySQL数据交换"></a>Sqoop与MySQL数据交换</h1><p>版本：sqoop-1.4.5-cdh5.4.0<br><a href="http://archive.cloudera.com/cdh5/cdh/5/sqoop-1.4.5-cdh5.4.0/SqoopUserGuide.html">sqoop-1.4.5-cdh5.4.0官方文档</a><br><a href="http://archive.cloudera.com/cdh5/cdh/5/sqoop-1.4.5-cdh5.4.0/SqoopUserGuide.html#_example_invocations">数据导入示例</a></p>
<h2 id="mysql-drive导入sqoop"><a href="#mysql-drive导入sqoop" class="headerlink" title="mysql drive导入sqoop"></a>mysql drive导入sqoop</h2><p>cp  /tmp/mysql-connector-java-5.1.36-bin.jar  /opt/cloudera/parcels/CDH-5.4.7-1.cdh5.4.7.p0.3/lib/sqoop/lib<br>cp  /opt/cloudera/parcels/CDH-5.4.7-1.cdh5.4.7.p0.3/lib/sqoop/lib/mysql-connector-java-5.1.36-bin.jar   /opt/cloudera/parcels/CDH-5.4.7-1.cdh5.4.7.p0.3/lib/hadoop/lib/<br>备注：官方文档是要导入到sqoop2目录，但copy到sqoop2目录无效，sqoop目录生效</p>
<h2 id="MySQL表导入HDFS然后导入Hive"><a href="#MySQL表导入HDFS然后导入Hive" class="headerlink" title="MySQL表导入HDFS然后导入Hive"></a>MySQL表导入HDFS然后导入Hive</h2><ul>
<li>切换到hdfs用户执行：<code>su hdfs</code></li>
<li><p>将MySQL数据库geocodingdb的MatchingAddress表导入HDFS用户目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">sqoop import --connect jdbc:mysql://192.168.1.161:3306/geocodingdb   \</div><div class="line">--driver com.mysql.jdbc.Driver   \</div><div class="line">--username geocodingdb --password geocodingdb  \</div><div class="line">--table MatchingAddress       \</div><div class="line">--fields-terminated-by '\t'  --lines-terminated-by '\n' --optionally-enclosed-by '\"'</div><div class="line">--direct</div></pre></td></tr></table></figure>
</li>
<li><p>附加<code>--direct</code>参数快速完成MySQL数据导入/导出操作<br>与selects和inserts操作相比，MySQL Direct Connector可以用mysqldump and mysqlimport工具对MySQL数据进行更快的导入和导出操作</p>
</li>
<li><p>hive新建表结构并导入数据</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">EXISTS</span> geocodingdb.MatchingAddress;</div><div class="line"></div><div class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> geocodingdb.MatchingAddress (source_address_id <span class="keyword">string</span>,source_address <span class="keyword">string</span> ,head_splitted_address <span class="keyword">string</span>,splitted_skeleton_addressnode <span class="keyword">string</span>,skeleton_addressnode <span class="keyword">string</span>,skeleton_addressnode_type <span class="keyword">string</span>,tail_address <span class="keyword">string</span>,tail_splitted_address <span class="keyword">string</span>)</div><div class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span>  <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>  <span class="keyword">stored</span> <span class="keyword">as</span> textfile;</div><div class="line"></div><div class="line"><span class="keyword">load</span> <span class="keyword">data</span> inpath <span class="string">'/user/hdfs/MatchingAddress/*'</span>  <span class="keyword">into</span> <span class="keyword">table</span> geocodingdb.MatchingAddress;</div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="MySQL表直接导入Hive"><a href="#MySQL表直接导入Hive" class="headerlink" title="MySQL表直接导入Hive"></a>MySQL表直接导入Hive</h2><ul>
<li><p>MySQL表授权</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'geocodingdb'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'geocodingdb'</span> <span class="keyword">with</span> <span class="keyword">grant</span> <span class="keyword">option</span>;</div><div class="line"><span class="keyword">FLUSH</span> <span class="keyword">PRIVILEGES</span>;</div></pre></td></tr></table></figure>
</li>
<li><p>hive-import命令<br>注意导入MySQL表结构字段顺序需与Hive表结构字段顺序一致</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="string">sqoop</span> <span class="string">import</span> <span class="bullet">--connect</span> <span class="attr">jdbc:mysql://192.168.1.161:3306/geocodingdb</span>   <span class="string">\</span></div><div class="line"><span class="bullet">-</span><span class="bullet">-driver</span> <span class="string">com.mysql.jdbc.Driver</span>   <span class="string">\</span></div><div class="line"><span class="bullet">-</span><span class="bullet">-username</span> <span class="string">geocodingdb</span> <span class="bullet">--password</span> <span class="string">geocodingdb</span>  <span class="string">\</span></div><div class="line"><span class="bullet">-</span><span class="bullet">-table</span> <span class="string">MatchingAddress</span>       <span class="string">\</span></div><div class="line"><span class="bullet">-</span><span class="bullet">-fields-terminated-by</span> <span class="string">'\t'</span>  <span class="bullet">--lines-terminated-by</span> <span class="string">'\n'</span> <span class="bullet">--optionally-enclosed-by</span> <span class="string">'\"'</span>     <span class="string">\</span></div><div class="line"><span class="bullet">-</span><span class="bullet">-direct</span></div></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="Hive表导出到MySQL"><a href="#Hive表导出到MySQL" class="headerlink" title="Hive表导出到MySQL"></a>Hive表导出到MySQL</h1><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="string">sqoop</span> <span class="string">export</span> <span class="bullet">--direct</span> <span class="bullet">--connect</span> <span class="attr">jdbc:mysql://192.168.1.161:3306/geocodingdb</span> <span class="bullet">--driver</span> <span class="string">com.mysql.jdbc.Driver</span>   <span class="string">\</span></div><div class="line"><span class="bullet">-</span><span class="bullet">-username</span> <span class="string">geocodingdb</span> <span class="bullet">--password</span> <span class="string">geocodingdb</span>  <span class="string">\</span></div><div class="line"><span class="bullet">-</span><span class="bullet">-table</span> <span class="string">MatchedAddressGroupbySkeleton</span> <span class="string">\</span></div><div class="line"><span class="bullet">-</span><span class="bullet">-export-dir</span> <span class="string">/user/hive/warehouse/geocodingdb.db/matchedaddressgroupbyskeleton</span>  <span class="string">\</span></div><div class="line"><span class="bullet">-</span><span class="bullet">-input-fields-terminated-by</span> <span class="string">"\t"</span>   <span class="string">\</span></div><div class="line"><span class="bullet">-</span><span class="bullet">-input-null-string</span> <span class="string">"\\\\N"</span> <span class="bullet">--input-null-non-string</span> <span class="string">"\\\\N"</span></div></pre></td></tr></table></figure>
<h1 id="Sqoop-MySQL-常用命令"><a href="#Sqoop-MySQL-常用命令" class="headerlink" title="Sqoop(MySQL)常用命令"></a>Sqoop(MySQL)常用命令</h1><h2 id="指定列"><a href="#指定列" class="headerlink" title="指定列"></a>指定列</h2><p>sqoop import –connect jdbc:mysql://db.foo.com/corp –table EMPLOYEES \<br>–columns “employee_id,first_name,last_name,job_title”</p>
<h2 id="使用8个线程"><a href="#使用8个线程" class="headerlink" title="使用8个线程"></a>使用8个线程</h2><p>sqoop import –connect jdbc:mysql://db.foo.com/corp –table EMPLOYEES \<br>-m 8</p>
<h2 id="快速模式"><a href="#快速模式" class="headerlink" title="快速模式"></a>快速模式</h2><p>sqoop import –connect jdbc:mysql://db.foo.com/corp –table EMPLOYEES \<br>–direct</p>
<h2 id="使用sequencefile作为存储方式"><a href="#使用sequencefile作为存储方式" class="headerlink" title="使用sequencefile作为存储方式"></a>使用sequencefile作为存储方式</h2><p>sqoop import –connect jdbc:mysql://db.foo.com/corp –table EMPLOYEES \<br>–class-name com.foocorp.Employee –as-sequencefile</p>
<h2 id="分隔符"><a href="#分隔符" class="headerlink" title="分隔符"></a>分隔符</h2><p>sqoop import –connect jdbc:mysql://db.foo.com/corp –table EMPLOYEES \<br>–fields-terminated-by ‘\t’ –lines-terminated-by ‘\n’ \<br>–optionally-enclosed-by ‘\”‘</p>
<h2 id="导入到hive"><a href="#导入到hive" class="headerlink" title="导入到hive"></a>导入到hive</h2><p>sqoop import –connect jdbc:mysql://db.foo.com/corp –table EMPLOYEES \<br>–hive-import</p>
<h2 id="条件过滤"><a href="#条件过滤" class="headerlink" title="条件过滤"></a>条件过滤</h2><p>sqoop import –connect jdbc:mysql://db.foo.com/corp –table EMPLOYEES \<br>–where “start_date &gt; ‘2010-01-01’”</p>
<h2 id="用dept-id作为分个字段"><a href="#用dept-id作为分个字段" class="headerlink" title="用dept_id作为分个字段"></a>用dept_id作为分个字段</h2><p>sqoop import –connect jdbc:mysql://db.foo.com/corp –table EMPLOYEES \<br>–split-by dept_id</p>
<h2 id="追加导入"><a href="#追加导入" class="headerlink" title="追加导入"></a>追加导入</h2><p>sqoop import –connect jdbc:mysql://db.foo.com/somedb –table sometable \<br>–where “id &gt; 100000” –target-dir /incremental_dataset –append</p>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="sqoop-export-–direct导出mysqlimport错误"><a href="#sqoop-export-–direct导出mysqlimport错误" class="headerlink" title="sqoop export –direct导出mysqlimport错误"></a>sqoop export –direct导出mysqlimport错误</h2><p>错误描述：Cannot run program “mysqlimport”: error=2, No such file or directory<br>解决办法：附加<code>--driver com.mysql.jdbc.Driver</code>参数</p>
<h2 id="sqoop-export-–direct导出mapreduce程序错误"><a href="#sqoop-export-–direct导出mapreduce程序错误" class="headerlink" title="sqoop export –direct导出mapreduce程序错误"></a>sqoop export –direct导出mapreduce程序错误</h2><p>错误描述1：Caused by: java.lang.RuntimeException: Can’t parse input data: ‘长浜    STR    18119    B316D057CE523018E0430A23A2C13018’<br>解决办法：附加<code>--input-fields-terminated-by &quot;\t&quot;</code>参数</p>
<p>错误描述2：com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException: Duplicate entry ‘1614’ for key ‘PRIMARY’<br>解决办法：附加<code>--input-null-string &quot;\\\\N&quot; --input-null-non-string &quot;\\\\N&quot;</code>如果遇到空值就插入null</p>
<h2 id="Sqoop-导入-Hive-导致发生-Null-Pointer-Exception-NPE"><a href="#Sqoop-导入-Hive-导致发生-Null-Pointer-Exception-NPE" class="headerlink" title="Sqoop 导入 Hive 导致发生 Null Pointer Exception (NPE)"></a>Sqoop 导入 Hive 导致发生 Null Pointer Exception (NPE)</h2><p>解决办法：首先通过 Sqoop 将数据导入 HDFS，然后将其从 HDFS 导入 Hive。</p>
<h2 id="MySQL导入Hive表报错"><a href="#MySQL导入Hive表报错" class="headerlink" title="MySQL导入Hive表报错"></a>MySQL导入Hive表报错</h2><p>Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ‘쀀’ )’ at line 1<br>解决：hive表编码问题；导入时不附加–hcatalog-table，手动新建表，然后导入数据</p>
<h1 id="Sqoop导入MySQL大表内存溢出问题"><a href="#Sqoop导入MySQL大表内存溢出问题" class="headerlink" title="Sqoop导入MySQL大表内存溢出问题"></a>Sqoop导入MySQL大表内存溢出问题</h1><p><a href="https://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html">SqoopUserGuide</a><br>抛出异常java.lang.OutOfMemoryError：GC overhead limit exceeded导致服务起不来</p>
<p>参考：<a href="http://www.hadooptechs.com/sqoop/handling-database-fetch-size-in-sqoop">http://www.hadooptechs.com/sqoop/handling-database-fetch-size-in-sqoop</a></p>
<p>修改yarn的nodemanager xmx还是sqoop 的xmx</p>
<h1 id="分页查询写入"><a href="#分页查询写入" class="headerlink" title="分页查询写入"></a>分页查询写入</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">sqoop import --connect jdbc:mysql://192.168.1.161:3306/geocodingdb  --username geocodingdb --password geocodingdb  \</div><div class="line">--query <span class="string">'select * from  MatchingAddress  WHERE $CONDITIONS  limit 0,100000'</span>  \</div><div class="line">--split-by  guid  \</div><div class="line">--fields-terminated-by <span class="string">'\t'</span>  --lines-terminated-by <span class="string">'\n'</span> --optionally-enclosed-by <span class="string">'\"'</span>  \</div><div class="line">--target-dir /user/hive/warehouse/geocodingdb.db/matchingaddress  \</div><div class="line">--append</div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">sqoop import --connect jdbc:mysql://192.168.1.161:3306/geocodingdb  --username geocodingdb --password geocodingdb  \</div><div class="line">--query <span class="string">'select * from  MatchingAddress  WHERE $CONDITIONS'</span>  \</div><div class="line">--split-by  guid  \</div><div class="line">--fields-terminated-by <span class="string">'\t'</span>  --lines-terminated-by <span class="string">'\n'</span> --optionally-enclosed-by <span class="string">'\"'</span>  \</div><div class="line">--target-dir /user/hive/warehouse/geocodingdb.db/matchingaddress  \</div><div class="line">--append</div></pre></td></tr></table></figure>
<p>sqoop import –connect jdbc:mysql://192.168.1.161:3306/geocodingdb?user=geocodingdb&amp;password=geocodingdb&amp;dontTrackOpenResources=true&amp;defaultFetchSize=10000&amp;useCursorFetch=true  –query ‘select * from MatchingAddress  WHERE $CONDITIONS’ –split-by  guid \<br>–fields-terminated-by ‘\t’  –lines-terminated-by ‘\n’ –optionally-enclosed-by ‘\”‘  \<br>–target-dir /user/hive/warehouse/geocodingdb.db/matchingaddress  \<br>–append</p>
<p>sqoop import –connect jdbc:mysql://192.168.1.161:3306/geocodingdb  \<br>–driver com.mysql.jdbc.Driver  \<br>–username geocodingdb –password geocodingdb  \<br>–direct  \<br>–table MatchingAddress1  \<br>–fields-terminated-by ‘\t’  –lines-terminated-by ‘\n’ –optionally-enclosed-by ‘\”‘  \<br>–target-dir /user/hive/warehouse/geocodingdb.db/matchingaddress  \<br>–append</p>
<p>sqoop import –connect jdbc:mysql://192.168.1.161:3306/geocodingdb  \<br>–driver com.mysql.jdbc.Driver  \<br>–username geocodingdb –password geocodingdb  \<br>–direct  \<br>–table MatchingAddress2  \<br>–fields-terminated-by ‘\t’  –lines-terminated-by ‘\n’ –optionally-enclosed-by ‘\”‘  \<br>–target-dir /user/hive/warehouse/geocodingdb.db/matchingaddress  \<br>–append</p>
<p>sqoop import –connect jdbc:mysql://192.168.1.161:3306/geocodingdb  \<br>–driver com.mysql.jdbc.Driver  \<br>–username geocodingdb –password geocodingdb  \<br>–direct  \<br>–table MatchingAddress3  \<br>–fields-terminated-by ‘\t’  –lines-terminated-by ‘\n’ –optionally-enclosed-by ‘\”‘  \<br>–target-dir /user/hive/warehouse/geocodingdb.db/matchingaddress  \<br>–append</p>
<p>sqoop import –connect jdbc:mysql://192.168.1.161:3306/geocodingdb  \<br>–driver com.mysql.jdbc.Driver  \<br>–username geocodingdb –password geocodingdb  \<br>–direct  \<br>–table MatchingAddress4  \<br>–fields-terminated-by ‘\t’  –lines-terminated-by ‘\n’ –optionally-enclosed-by ‘\”‘  \<br>–target-dir /user/hive/warehouse/geocodingdb.db/matchingaddress  \<br>–append</p>
<p>sqoop import –connect jdbc:mysql://192.168.1.161:3306/geocodingdb  \<br>–driver com.mysql.jdbc.Driver  \<br>–username geocodingdb –password geocodingdb  \<br>–direct  \<br>–table MatchingAddress5  \<br>–fields-terminated-by ‘\t’  –lines-terminated-by ‘\n’ –optionally-enclosed-by ‘\”‘  \<br>–target-dir /user/hive/warehouse/geocodingdb.db/matchingaddress  \<br>–append</p>
<p>Stack trace: ExitCodeException exitCode=255:</p>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hadoop </tag>
            
            <tag> Hive </tag>
            
            <tag> Sqoop </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[《深入理解Java虚拟机》读书笔记]]></title>
      <url>http://geosmart.github.io/2016/02/22/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>2016上半年花点时间深入了解JVM，读《《深入理解Java虚拟机 JVM高级特性与最佳实践》，整理遇到过的内存泄漏，性能优化问题</p>
<hr>
<a id="more"></a>
<h1 id="第一章-走近Java"><a href="#第一章-走近Java" class="headerlink" title="第一章 走近Java"></a>第一章 走近Java</h1><h2 id="Java技术体系"><a href="#Java技术体系" class="headerlink" title="Java技术体系"></a>Java技术体系</h2><p><img src="JDK技术组成.png" alt="JDK"></p>
<ul>
<li>Java程序设计语言、Java虚拟机、Java API类库三部分统称为JDK(Java Development Kit) ,JDK是Java程序开发的最小环境</li>
<li>Java API类库中的Java SE API子集和Java虚拟机两部分统称为JRE(Java Runtime Environment)，JRE是支持Java程序运行的标准环境</li>
<li>按照Java技术关注的重点业务领域来划分，Java技术体系可分为4个平台<ul>
<li>Java Card：支持Applets(Java小程序)运行在小内存设备（如智能卡）上的平台；</li>
<li>Java ME(Micro Edition)：支持Java运行在移动终端上的平台；（今有Android SDK）</li>
<li>Java SE(Standard Edition)：支持面向桌面级应用的Java平台；</li>
<li>Java EE(Enterprise Edition)：支持使用多层架构的企业级应用(如ERP、CRM应用)的Java平台；</li>
</ul>
</li>
</ul>
<h2 id="Java发展史"><a href="#Java发展史" class="headerlink" title="Java发展史"></a>Java发展史</h2><h2 id="Java虚拟机发展史"><a href="#Java虚拟机发展史" class="headerlink" title="Java虚拟机发展史"></a>Java虚拟机发展史</h2><ul>
<li>Sun Classic/Extract VM</li>
<li>Sun HotSpot VM</li>
<li>Sun Mobile-Embedded VM/Meta-Circular VM</li>
<li>Bea Jrockit/IDM J9 VM</li>
<li>Azul VM/BEA Liquid VM</li>
<li>Apache Harmony/Google Android Dalvik VM</li>
<li>Microsoft JVM…</li>
</ul>
<h2 id="Java技术的未来展望"><a href="#Java技术的未来展望" class="headerlink" title="Java技术的未来展望"></a>Java技术的未来展望</h2><ul>
<li>模块化（Jigsaw）</li>
<li>混合语言：多语言混合编程，通过特定领域发语言去解决特定领域的问题</li>
<li>多核并行（concurrent.forkjoin；Lambada；函数式编程）</li>
<li>丰富语法（Coin子项目）</li>
<li>64位虚拟机（计算机终究完全过渡到64位的时代）</li>
</ul>
<h2 id="JDK编译实战"><a href="#JDK编译实战" class="headerlink" title="JDK编译实战"></a>JDK编译实战</h2><p><a href="https://jdk7.java.net/source.html">OpenJDK7下载</a><br>Building the source code for the OpenJDK requires a certain degree of technical expertise.</p>
<h1 id="第二章-Java内存区域与内存溢出异常"><a href="#第二章-Java内存区域与内存溢出异常" class="headerlink" title="第二章 Java内存区域与内存溢出异常"></a>第二章 Java内存区域与内存溢出异常</h1><h2 id="运行时的数据区域"><a href="#运行时的数据区域" class="headerlink" title="运行时的数据区域"></a>运行时的数据区域</h2><p><img src="Java虚拟机运行时数据区.jpg" alt="Java虚拟机运行时数据区"></p>
<h3 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h3><ul>
<li>程序计数器（Program Counter Register）是一块比较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器；</li>
<li>PCR为线程私有内存；</li>
<li>是唯一一个在Java虚拟机规范中没有规定任何OOM情况的区域；</li>
</ul>
<h3 id="Java虚拟机栈"><a href="#Java虚拟机栈" class="headerlink" title="Java虚拟机栈"></a>Java虚拟机栈</h3><p><img src="JavaStacks.jpg" alt="Java虚拟机栈"></p>
<ul>
<li>Java虚拟机栈（Java Virtual Machine Stacks）描述的是Java方法执行的内存模型：每个方法在在执行的同时都会创建一个栈帧（Stack Frame）用于存储 局部变量表、操作数栈、动态链接、方法接口 等信息。每个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈出栈的过程。</li>
<li>Java虚拟机栈也是线程私有，它的生命周期与线程相同。</li>
<li>Java内存区常分为 堆内存（Heap）和栈内存（Stack）；</li>
<li>OOM情况：（1）线程请求的栈深度&gt;虚拟机所运行的最大深度；（2）虚拟机动态扩展时无法申请到足够的内存</li>
</ul>
<h3 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h3><p><img src="Java本地方法栈.png" alt="Java本地方法栈"><br>本地方法栈（Native Method Stack）与虚拟机所发挥的作用非常相似的，他们之间的区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚拟机所使用的Native方法服务。</p>
<ul>
<li>HotSpot虚拟机把本地方法栈和虚拟机栈合二为一；</li>
<li>此区域会抛StackOverflowError 和 OutofMemoryError异常</li>
</ul>
<h3 id="Java堆"><a href="#Java堆" class="headerlink" title="Java堆"></a>Java堆</h3><p><img src="JavaHeap.gif" alt="Java堆"><br>Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块，Java Heap是所有线程共享的一块内存区域，在VM启动时创建。</p>
<ul>
<li>所有的对象实例以及数组都要在堆上分配（不绝对：栈上分配、标量替换优化技术）；</li>
<li>Java堆是垃圾收集器管理的主要区域，也可称做GC堆（Garbage Collected Heap）</li>
<li>从内存回收的角度，现代收集器基本都采用分代收集算法，Java Heap可细分为新生代和老年代，再细致可氛围Eden空间、From Survivor空间、To Survivor空间等–&gt;更好回收内存。</li>
<li>从内存分配的角度，线程共享的Java堆中可能分出多个线程私有的分配缓存区（TLAB：Thread Local Allocation Buffer）–&gt;更快分配内存。</li>
<li>Java堆出于逻辑连续的内存空间中，物理上可不连续，如磁盘空间一样；</li>
<li>Java堆在实现上可时，可以实现成固定大小的，也可以按照可扩展实现（-Xmx和-Xms控制）；</li>
<li>OOM情况：堆中没有内存完成实例分配，堆也无法再扩展时</li>
</ul>
<h3 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h3><ul>
<li>Non-Heap：在Java虚拟机规范中，将方法区作为堆的一个逻辑部分来对待，但事实上，方法区并不是堆（Non-Heap）；</li>
<li>永久代：JavaGC的分代收集机制分为3个代：年青代，老年代，永久代，将方法区定义为“永久代”，这是因为，对于之前的HotSpot Java虚拟机的实现方式中，将分代收集的思想扩展到了方法区，并将方法区设计成了永久代。不过，除HotSpot之外的多数虚拟机，并不将方法区当做永久代，随着Java8的到来，已放弃永久代改为采用Native Memory来实现方法区的规划。</li>
<li>线程共享区域：方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，</li>
<li>方法区用于存储已经被虚拟机加载的类信息（即加载类时需要加载的信息，包括版本、field、方法、接口等信息）、final常量、静态变量、编译器即时编译后的代码等数据。</li>
<li>方法区在物理上也不需要是连续的，可以选择固定大小或可扩展大小，并且方法区比堆还多了一个限制：可以选择是否执行垃圾收集。</li>
<li>一般的，方法区上执行的垃圾收集是很少的，这也是方法区被称为永久代的原因之一（HotSpot），但这也不代表着在方法区上完全没有垃圾收集，<code>此区域回收目标主要是针对常量池的回收和对类型的卸载</code>。 </li>
</ul>
<h3 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h3><p><img src="Java虚拟机运行时数据区拓扑关系.png" alt="Java虚拟机运行时数据区拓扑关系"><br>运行时常量池（Runtime Constants Pool）是方法区的一部分</p>
<ul>
<li>Class文件中除了有类的版本、字段、方法、接口等描述的信息外，还有一项信息是常量池（Constant Pool Table）,用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。</li>
</ul>
<h3 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h3><p>直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域。</p>
<ul>
<li>能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。</li>
<li>直接内存的分配不会受到Java堆大小的限制，但会收到本机总内存（RAM以及SWAP/分页文件）大小以及处理器寻址空间的限制。</li>
<li>设置Xmx等参数信息时注意不能忽略直接内存，不然会引起OOM。</li>
</ul>
<h2 id="HotSpot虚拟机"><a href="#HotSpot虚拟机" class="headerlink" title="HotSpot虚拟机"></a>HotSpot虚拟机</h2>]]></content>
      
        <categories>
            
            <category> 读书笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[JVM学习笔记（一）走近Java]]></title>
      <url>http://geosmart.github.io/2016/02/22/JVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E8%B5%B0%E8%BF%91Java/</url>
      <content type="html"><![CDATA[<p>2016上半年花点时间深入了解JVM，读《《深入理解Java虚拟机 JVM高级特性与最佳实践》，整理遇到过的内存泄漏，性能优化问题</p>
<hr>
<a id="more"></a>
<h1 id="第一章-走近Java"><a href="#第一章-走近Java" class="headerlink" title="第一章 走近Java"></a>第一章 走近Java</h1><h2 id="Java技术体系"><a href="#Java技术体系" class="headerlink" title="Java技术体系"></a>Java技术体系</h2><p><img src="JDK技术组成.png" alt="JDK"></p>
<ul>
<li>Java程序设计语言、Java虚拟机、Java API类库三部分统称为JDK(Java Development Kit) ,JDK是Java程序开发的最小环境</li>
<li>Java API类库中的Java SE API子集和Java虚拟机两部分统称为JRE(Java Runtime Environment)，JRE是支持Java程序运行的标准环境</li>
<li><p>按照Java技术关注的重点业务领域来划分，Java技术体系可分为4个平台</p>
<ul>
<li>Java Card：支持Applets(Java小程序)运行在小内存设备（如智能卡）上的平台；</li>
<li>Java ME(Micro Edition)：支持Java运行在移动终端上的平台；（今有Android SDK）</li>
<li>Java SE(Standard Edition)：支持面向桌面级应用的Java平台；</li>
<li>Java EE(Enterprise Edition)：支持使用多层架构的企业级应用(如ERP、CRM应用)的Java平台；</li>
</ul>
</li>
</ul>
<h2 id="Java发展史"><a href="#Java发展史" class="headerlink" title="Java发展史"></a>Java发展史</h2><h2 id="Java虚拟机发展史"><a href="#Java虚拟机发展史" class="headerlink" title="Java虚拟机发展史"></a>Java虚拟机发展史</h2><ul>
<li>Sun Classic/Extract VM</li>
<li>Sun HotSpot VM</li>
<li>Sun Mobile-Embedded VM/Meta-Circular VM</li>
<li>Bea Jrockit/IDM J9 VM</li>
<li>Azul VM/BEA Liquid VM</li>
<li>Apache Harmony/Google Android Dalvik VM</li>
<li>Microsoft JVM…</li>
</ul>
<h2 id="Java技术的未来展望"><a href="#Java技术的未来展望" class="headerlink" title="Java技术的未来展望"></a>Java技术的未来展望</h2><ul>
<li>模块化（Jigsaw）</li>
<li>混合语言：多语言混合编程，通过特定领域发语言去解决特定领域的问题</li>
<li>多核并行（concurrent.forkjoin；Lambada；函数式编程）</li>
<li>丰富语法（Coin子项目）</li>
<li>64位虚拟机（计算机终究完全过渡到64位的时代）</li>
</ul>
<h2 id="JDK编译实战"><a href="#JDK编译实战" class="headerlink" title="JDK编译实战"></a>JDK编译实战</h2><p><a href="https://jdk7.java.net/source.html">OpenJDK7下载</a> Building the source code for the OpenJDK requires a certain degree of technical expertise.</p>
]]></content>
      
        <categories>
            
            <category> 读书笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> JVM </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MyEclipse常用插件]]></title>
      <url>http://geosmart.github.io/2016/01/27/MyEclipse%E5%B8%B8%E7%94%A8%E6%8F%92%E4%BB%B6/</url>
      <content type="html"><![CDATA[<p>记录以J2EE开发采用MyEclipse IDE的常用插件</p>
<hr>
<a id="more"></a>
<p><img src="Eclipse版本.png" alt="Eclipse内核版本"></p>
<h1 id="SVN"><a href="#SVN" class="headerlink" title="SVN"></a>SVN</h1><p><a href="http://subclipse.tigris.org/update_1.12.x/">svn update site URL</a><br><a href="http://subclipse.tigris.org/servlets/ProjectDocumentList?folderID=2240">svn offline package</a></p>
<h1 id="FatJar"><a href="#FatJar" class="headerlink" title="FatJar"></a>FatJar</h1><p><a href="http://kurucz-grafika.de/fatjar">FatJar update site URL</a></p>
<h1 id="Freemarker-Editor"><a href="#Freemarker-Editor" class="headerlink" title="Freemarker Editor"></a>Freemarker Editor</h1><p><a href="http://download.jboss.org/jbosstools/updates/development/kepler/">Freemarker Editor update site URL</a><br>安装时选择Jboss IDE即可</p>
<h1 id="Drools插件"><a href="#Drools插件" class="headerlink" title="Drools插件"></a>Drools插件</h1><p><a href="http://download.jboss.org/drools/release/5.5.0.Final/org.drools.updatesite/">drools 5.5.0 update site URL</a></p>
<h1 id="OneJar"><a href="#OneJar" class="headerlink" title="OneJar"></a>OneJar</h1><p><a href="http://one-jar.sourceforge.net/">OneJar官网</a></p>
<h2 id="maven配置onejar打包"><a href="#maven配置onejar打包" class="headerlink" title="maven配置onejar打包"></a>maven配置onejar打包</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="comment">&lt;!-- Make this jar executable --&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">plugin</span> &gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">groupId</span> &gt;</span>org.apache.maven.plugins <span class="tag">&lt;/<span class="name">groupId</span> &gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">artifactId</span> &gt;</span>maven-jar-plugin <span class="tag">&lt;/<span class="name">artifactId</span> &gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">configuration</span> &gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">archive</span> &gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">manifest</span> &gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">mainClass</span> &gt;</span>gto.amo.mapper.app.form.Main <span class="tag">&lt;/<span class="name">mainClass</span> &gt;</span></div><div class="line">      <span class="tag">&lt;/<span class="name">manifest</span> &gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">archive</span> &gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">configuration</span> &gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">plugin</span> &gt;</span></div><div class="line">  <span class="comment">&lt;!-- Includes the runtime dependencies --&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">plugin</span> &gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">groupId</span> &gt;</span>com.jolira <span class="tag">&lt;/<span class="name">groupId</span> &gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">artifactId</span> &gt;</span>onejar-maven-plugin <span class="tag">&lt;/<span class="name">artifactId</span> &gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">version</span> &gt;</span>1.4.4 <span class="tag">&lt;/<span class="name">version</span> &gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">executions</span> &gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">execution</span> &gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">configuration</span> &gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">attachToBuild</span> &gt;</span>true <span class="tag">&lt;/<span class="name">attachToBuild</span> &gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">classifier</span> &gt;</span>onejar <span class="tag">&lt;/<span class="name">classifier</span> &gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">configuration</span> &gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">goals</span> &gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">goal</span> &gt;</span>one-jar <span class="tag">&lt;/<span class="name">goal</span> &gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">goals</span> &gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">execution</span> &gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">executions</span> &gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">plugin</span> &gt;</span></div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> IDE </category>
            
        </categories>
        
        
        <tags>
            
            <tag> J2EE </tag>
            
            <tag> Eclipse </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Ne04j单机版和集群版部署]]></title>
      <url>http://geosmart.github.io/2016/01/25/Ne04j%E5%8D%95%E6%9C%BA%E7%89%88%E5%92%8C%E9%9B%86%E7%BE%A4%E7%89%88%E9%83%A8%E7%BD%B2/</url>
      <content type="html"><![CDATA[<p>Neo4j HA(Neo4j High Availability)，高可用性主要指其包含容错机制和可进行水平扩展，即Neo4j Cluster</p>
<hr>
<a id="more"></a>
<h1 id="部署Ne04j单机版-windows"><a href="#部署Ne04j单机版-windows" class="headerlink" title="部署Ne04j单机版(windows)"></a>部署Ne04j单机版(windows)</h1><h2 id="java-se-8安装"><a href="#java-se-8安装" class="headerlink" title="java se 8安装"></a>java se 8安装</h2><p><a href="http://download.oracle.com/otn-pub/java/jdk/8u71-b15/jdk-8u71-windows-x64.exe?AuthParam=1453700621_44741e28a0fd105dbfea10bad65c95b3">java8下载</a><br>安装java se8后，并临时设置环境变量：<code>set JAVA_HOME=E:\Software\jdk8x64\jre1.8</code>（避免与本机java7冲突）</p>
<h2 id="下载Neo4j-3-0-0"><a href="#下载Neo4j-3-0-0" class="headerlink" title="下载Neo4j-3.0.0"></a>下载Neo4j-3.0.0</h2><p><a href="http://neo4j.com/artifact.php?name=neo4j-enterprise-3.0.0-M02-windows.zip">neo4j-enterprise-3.0.0-M02-windows</a></p>
<h2 id="下载Neo4j-2-3-2"><a href="#下载Neo4j-2-3-2" class="headerlink" title="下载Neo4j-2.3.2"></a>下载Neo4j-2.3.2</h2><p><a href="http://neo4j.com/artifact.php?name=neo4j-community-2.3.2-windows.zip">neo4j-enterprise-2.3.2-windows</a><br>设置NEO4J_HOME，</p>
<h2 id="Neo4j-Browser"><a href="#Neo4j-Browser" class="headerlink" title="Neo4j Browser"></a>Neo4j Browser</h2><ul>
<li>运行bin\Neo4j.bat，如<code>cd F:\Dev\neo4j-enterprise-3.0.0-M02\bin &amp;&amp; Neo4j.bat</code></li>
<li>在浏览器打开Neo4j的在线REPL，即<a href="http://localhost:7474/">Neo4j Browser</a>,在命令行输入Cypher query语句进行查询</li>
<li>在浏览器打开<a href="http://localhost:7474/webadmin/#/info/">Neo4j Guide</a>了解Neo4j</li>
<li>老版本的在线入口：<a href="http://localhost:7474/webadmin/#/index/">neo4j webAdmin</a></li>
</ul>
<h2 id="在Windows-PowerShell运行Neo4j"><a href="#在Windows-PowerShell运行Neo4j" class="headerlink" title="在Windows PowerShell运行Neo4j"></a>在Windows PowerShell运行Neo4j</h2><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 权限配置</span></div><div class="line"><span class="string">Set-ExecutionPolicy</span> <span class="bullet">-ExecutionPolicy</span> <span class="string">RemoteSigned</span></div><div class="line"><span class="comment"># 导入Neo4j模块</span></div><div class="line"><span class="string">Import-Module</span> <span class="attr">C:\Neo4j\bin\Neo4j-Management.psd1</span></div><div class="line"><span class="comment"># 查询Neo4j命令</span></div><div class="line"><span class="string">Get-Command</span> <span class="bullet">-Module</span> <span class="string">Neo4j-Management</span></div><div class="line"><span class="comment"># 安装Neo4j服务</span></div><div class="line"><span class="string">Install-Neo4jServer</span></div><div class="line"><span class="comment"># 查询NEO4J_HOME路径</span></div><div class="line"><span class="string">Get-Neo4jServer</span> <span class="attr">C:\Neo4j</span></div><div class="line"><span class="comment"># 启动Neo4j服务</span></div><div class="line"><span class="string">Start-Neo4jServer</span></div><div class="line"><span class="comment"># 关闭Neo4j服务</span></div><div class="line"><span class="string">Stop-Neo4jServer</span></div><div class="line"><span class="comment"># 重启Neo4j服务</span></div><div class="line"><span class="string">Restart-Neo4jServer</span></div></pre></td></tr></table></figure>
<h2 id="Neo4j-Browser常用脚本"><a href="#Neo4j-Browser常用脚本" class="headerlink" title="Neo4j Browser常用脚本"></a>Neo4j Browser常用脚本</h2><p>:help 帮助<br>shift+enter 多行书写<br>ctrl+enter 执行<br>:clear 清空执行结果<br>:play 打开入门教程</p>
<h1 id="部署Neo4j集群-Linux"><a href="#部署Neo4j集群-Linux" class="headerlink" title="部署Neo4j集群(Linux)"></a>部署Neo4j集群(Linux)</h1><p><a href="http://neo4j.com/docs/3.0.0-M02/">neo4j manual doc</a></p>
<ul>
<li>TODO<br>Neo4j HA has been designed to make the transition from single machine to multi machine operation simple, by not having to change the already existing application.<br>Consider an existing application with Neo4j embedded and running on a single machine. To deploy such an application in a multi machine setup the only required change is to switch the creation of the GraphDatabaseService from GraphDatabaseFactory to HighlyAvailableGraphDatabaseFactory. Since both implement the same interface, no additional changes are required.</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Neo4j </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Neo4j图数据库学习笔记]]></title>
      <url>http://geosmart.github.io/2016/01/25/Neo4j%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>Explore the World of Graphs – From Query Efficiency to Business Performance</p>
<hr>
<a id="more"></a>
<h1 id="关于图形数据库"><a href="#关于图形数据库" class="headerlink" title="关于图形数据库"></a>关于图形数据库</h1><p>图形数据库是一种非关系型数据库，它应用图形理论存储实体之间的关系信息。最常见的一个例子，就是社会网络中人与人之间的关系。</p>
<ul>
<li>当前有流行图形数据库：Neo4j、FlockDB、AllegroGraph、GraphDB、InfiniteGraph、OrientDB、InfoGrid和HypergraphDB等等，<br>另有自称比MongoDB和Neo4j性能更佳的多模型数据库ArangoDB,见<a href="https://github.com/weinberger/nosql-tests">nosql-tests</a></li>
<li>关系型数据库用于存储“关系型”数据的效果并不好，其查询复杂、缓慢、超出预期，而图形数据库的独特设计恰恰弥补了这个缺陷。  </li>
</ul>
<h1 id="Neo4j简介"><a href="#Neo4j简介" class="headerlink" title="Neo4j简介"></a>Neo4j简介</h1><p><a href="http://neo4j.com/docs/3.0.0-M02/">官方Manual</a><br><a href="http://www.infoq.com/articles/full-stack-web-development-using-neo4j">参考full-stack-web-development-using-neo4j</a><br><a href="http://neo4j.com/">Neo4j</a>是一个用Java实现、完全兼容ACID的图形数据库。数据以一种针对图形网络进行过优化的格式保存在磁盘上。Neo4j的内核是一种极快的图形引擎，具有数据库产品期望的所有特性，如恢复、两阶段提交、符合XA等。自2003年起，Neo4j就已经被作为24/7的产品使用。<br>Neo4j是目前主流的一个图数据库，相比传统的关系型数据库，它可以快速的进行基于人际社交网络类的查询查询和检索;它同时提供了cypher语言来方便进行图数据库的操作和查询，该查询语言类似SQL语言。<br>Neo4j的数据并非保存在表或集合中，而是保存为节点以及节点之间的关系。在Neo4j中，节点以及关系都能够包含保存值的属性，此外：</p>
<ul>
<li>可以为节点设置零或多个标签（例如Author或Book）</li>
<li>每个关系都对应一种类型（例如WROTE或FRIEND_OF）</li>
<li>关系总是从一个节点指向另一个节点（但可以在不考虑指向性的情况下进行查询）</li>
</ul>
<h1 id="为什么要选择Neo4j？"><a href="#为什么要选择Neo4j？" class="headerlink" title="为什么要选择Neo4j？"></a>为什么要选择Neo4j？</h1><p>在考虑为web应用选择某个数据库时，我们需要考虑对它有哪些方面的期望，其中最重要的一些条件包括：</p>
<ul>
<li>它是否易于使用？</li>
<li>它是否允许你方便地回应对需求的变更？</li>
<li>它是否支持高性能查询？</li>
<li>是否能够方便地对其进行数据建模？</li>
<li>它是否支持事务？</li>
<li>它是否支持大规模应用？</li>
<li>它是否足够有趣（很遗憾的是对于数据库的这方面要求经常被忽略）？</li>
</ul>
<p>从这以下几个方面来说，Neo4j是一个合适的选择。Neo4j……</p>
<ul>
<li>自带一套易于学习的查询语言（名为Cypher）</li>
<li>不使用schema，因此可以满足你的任何形式的需求</li>
<li>与关系型数据库相比，对于高度关联的数据（图形数据）的查询快速要快上许多</li>
<li>它的实体与关系结构非常自然地切合人类的直观感受</li>
<li>支持兼容ACID的事务操作</li>
<li>提供了一个高可用性模型，以支持大规模数据量的查询，支持备份、数据局部性以及冗余</li>
<li>提供了一个可视化的查询控制台，你不会对它感到厌倦的</li>
</ul>
<h1 id="什么时候不应使用Neo4j？"><a href="#什么时候不应使用Neo4j？" class="headerlink" title="什么时候不应使用Neo4j？"></a>什么时候不应使用Neo4j？</h1><p>作为一个图形NoSQL数据库，Neo4j提供了大量的功能，但没有什么解决方案是完美的。在以下这些用例中，Neo4j就不是非常适合的选择：</p>
<ul>
<li>记录大量基于事件的数据（例如日志条目或传感器数据）</li>
<li>对大规模分布式数据进行处理，类似于Hadoop</li>
<li>二进制数据存储</li>
<li>适合于保存在关系型数据库中的结构化数据</li>
</ul>
<p>虽然Neo4j也能够处理“大数据”，但它毕竟不是Hadoop、HBase或Cassandra，通常来说不会在Neo4j数据库中直接处理海量数据（以PB为单位）的分析。但如果你乐于提供关于某个实体及其相邻数据关系（比如你可以提供一个web页面或某个API返回其结果），那么它是一种良好的选择。无论是简单的CRUD访问，或是复杂的、深度嵌套的资源视图都能够胜任。</p>
<p>虽然关系型数据库对于保存结构化数据来说依然是最佳的选择，但NoSQL数据库更适合于管理半结构化数据、非结构化数据以及图形数据。如果数据模型中包括大量的关联数据，并且希望使用一种直观的、有趣的并且快速的数据库进行开发，那么可以考虑尝试Neo4j。</p>
<h1 id="Neo4j图模型"><a href="#Neo4j图模型" class="headerlink" title="Neo4j图模型"></a>Neo4j图模型</h1><p>Neo4J中的图形模型要点：Nodes与Relationships可以被赋予Properties(key-value); Nodes可按label分组；Relationships可赋予direction和type并最终构成数据形态；Neo4j可存储10亿级别的数据量<br>Neo4J使用以下索引机制：一个超级参考节点通过一条特殊类别的边线“REFERENCE”与所有节点相连。这实际上允许创建多个索引，借以通过不同的边线类别对其加以区分。Neo4J还提供了一些特殊功能，如列出特定节点的相邻诸节点或是两节点间长度最短的诸类路径等。注意要使用上述各类“遍历”功能，Neo4J要求指定路径中经过的边线类别。</p>
<h1 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h1><p>enterprise和community公共特性<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Property Graph Model</div><div class="line">Native Graph Processing &amp; Storage</div><div class="line">ACID</div><div class="line">Cypher – Graph Query Language</div><div class="line">Language Drivers most popular languages</div><div class="line">REST API</div><div class="line">High-Performance Native API</div><div class="line">HTTPS (via Plug-in)</div></pre></td></tr></table></figure></p>
<p>enterprise性能扩展特性<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">Enterprise Lock Manager</div><div class="line">Cache Sharding</div><div class="line">Clustered Replication</div><div class="line">Cypher Query Tracing</div><div class="line">Property Existence Constraints</div><div class="line">Hot Backups</div><div class="line">Advanced Monitoring</div></pre></td></tr></table></figure></p>
<h1 id="嵌入式使用"><a href="#嵌入式使用" class="headerlink" title="嵌入式使用"></a>嵌入式使用</h1><p>可不必将Neo4J作为软件加以安装。可在项目中导入JAR文件来建立嵌入式图形数据库，该操作将在硬盘上建立对应的目录，类似sqlite。</p>
<h1 id="High-Availability"><a href="#High-Availability" class="headerlink" title="High Availability"></a>High Availability</h1><p>Neo4j HA(Neo4j High Availability)，高可用性主要指其包含容错机制和可进行水平扩展，即Neo4j Cluster</p>
<h1 id="Neo4j相关技术选型"><a href="#Neo4j相关技术选型" class="headerlink" title="Neo4j相关技术选型"></a>Neo4j相关技术选型</h1><p>所有主流的编程语言都通过HTTP_API的方式支持Neo4j，或者采用基本的HTTP类库，或是通过某些原生的类库提供更高层的抽象。此外，由于Neo4j是以Java语言编写的，因此所有包含JVM接口的语言都能够充分利用Neo4j中的高性能API。</p>
<p>Neo4j本身也提供了一个“技术栈”，它允许你选择不同的访问方式，包括简单访问乃至原生性能等等。它提供的特性包括：</p>
<ul>
<li>通过一个HTTP API执行Cypher查询，并获取JSON格式的结果</li>
<li>一种“非托管扩展”机制，允许你为Neo4j数据库编写自己的终结点</li>
<li>通过一个高层Java API指定节点与关系的遍历</li>
<li>通过一个低层的批量加载API处理海量初始数据的获取</li>
<li>通过一个核心Java API直接访问节点与关系，以获得最大的性能</li>
</ul>
<h2 id="Jcypher"><a href="#Jcypher" class="headerlink" title="Jcypher"></a>Jcypher</h2><ol>
<li>集成Remote、Emberded和InMemmory三种Neo4j数据库访问形式，在程序测试和Neo4j Browserz间切换很方便；</li>
<li>无需在POJO中手动标注实现OGM，会自动将对象嵌套关系转换为Graph Relationship，可更专注与业务逻辑；</li>
</ol>
<h2 id="NativeAPI"><a href="#NativeAPI" class="headerlink" title="NativeAPI"></a>NativeAPI</h2><p>Neo4j官方原生API，需手动进行事物管理，实现较为繁琐；</p>
<h2 id="Spring-Data-for-Neo4j"><a href="#Spring-Data-for-Neo4j" class="headerlink" title="Spring Data for Neo4j"></a>Spring Data for Neo4j</h2><p><a href="http://docs.spring.io/spring-data/data-neo4j/docs/4.0.0.RELEASE/api/">doc-api</a><br><a href="http://docs.spring.io/spring-data/data-neo4j/docs/4.0.0.RELEASE/reference/html/">The Spring Data Neo4j Guide Book</a><br><a href="https://github.com/geosmart/me.demo.neo4j/tree/master/neo4j.springdata">demo.neo4j.springdata</a></p>
<ul>
<li>spring-data-neo4j<br>Spring Data Neo4j</li>
<li>spring-data-neo4j-rest<br>pring Data Neo4j Wrapper for the Neo4j REST API, provides a Graph Database proxy for the remote invocation</li>
<li>spring-data-neo4j-aspects<br>Advanced Mapping support for Spring Data Neo4j</li>
</ul>
<h1 id="Cypher"><a href="#Cypher" class="headerlink" title="Cypher"></a>Cypher</h1><p>Cypher(Neo4j’s graph query language)，类似SQL<br>Cypher为ASCII风格的语法，它在括号内表示节点名称，并用箭头表示一个节点指向另一个节点的关系。Cypher通过这种方式允许你匹配某个指定的子图形模式。</p>
<h2 id="Create"><a href="#Create" class="headerlink" title="Create"></a>Create</h2><p>Create(Create Nodes and Relationships)<br><img src="query_template_create.png" alt="create模版"><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">CREATE (ee:Person &#123; name: "Emil", from: "Sweden", klout: 99 &#125;)</div><div class="line"><span class="meta">#</span><span class="bash"> () parenthesis to indicate a node</span></div><div class="line"><span class="meta">#</span><span class="bash"> ee:Person a variable <span class="string">'ee'</span> and label <span class="string">'Person'</span> <span class="keyword">for</span> the new node</span></div><div class="line"><span class="meta">#</span><span class="bash"> &#123;&#125; brackets to add properties to the node</span></div><div class="line"></div><div class="line">CREATE多个Nodes和Relationships</div><div class="line">MATCH (ee:Person) where ee.name = "Emil"</div><div class="line">CREATE (js:Person &#123; name: "Johan", from: "Sweden", learn: "surfing" &#125;),</div><div class="line">(ir:Person &#123; name: "Ian", from: "England", title: "author" &#125;),</div><div class="line">(rvb:Person &#123; name: "Rik", from: "Belgium", pet: "Orval" &#125;),</div><div class="line">(ally:Person &#123; name: "Allison", from: "California", hobby: "surfing" &#125;),</div><div class="line">(ee)-[:KNOWS &#123;since: 2001&#125;]-&gt;(js),(ee)-[:KNOWS &#123;rating: 5&#125;]-&gt;(ir),</div><div class="line">(js)-[:KNOWS]-&gt;(ir),(js)-[:KNOWS]-&gt;(rvb),</div><div class="line">(ir)-[:KNOWS]-&gt;(js),(ir)-[:KNOWS]-&gt;(ally),</div><div class="line">(rvb)-[:KNOWS]-&gt;(ally)</div></pre></td></tr></table></figure></p>
<p><img src="sns.png" alt="sns graph"></p>
<h2 id="MATCH"><a href="#MATCH" class="headerlink" title="MATCH"></a>MATCH</h2><p>MATCH(Finding nodes)<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">MATCH (ee:Person) WHERE ee.name = "Emil" RETURN ee;</div><div class="line"># (ee:Person) a single node pattern with label 'Person' which will assign matches to the variable 'ee'</div><div class="line"># WHERE clause to constrain the results</div><div class="line"># ee.name = "Emil" compares name property to the value "Emil"</div><div class="line"># RETURN clause used to request particular results</div></pre></td></tr></table></figure></p>
<h2 id="Pattern-matching"><a href="#Pattern-matching" class="headerlink" title="Pattern matching"></a>Pattern matching</h2><p>Pattern matching(Describe what to find in the graph)<br><img src="query_template_find.png" alt="Finding模版"></p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># find Emil's friends:</div><div class="line">MATCH (ee:Person)-[:KNOWS]-(friends) WHERE ee.name = "Emil" RETURN ee, friends</div><div class="line"># MATCHclause to describe the pattern from known Nodes to found Nodes</div><div class="line"># (ee)starts the pattern with a Person (qualified by WHERE)</div><div class="line"># -[:KNOWS]-matches "KNOWS" relationships (in either direction)</div><div class="line"># (friends)will be bound to Emil's friends</div></pre></td></tr></table></figure>
<h2 id="Recommend"><a href="#Recommend" class="headerlink" title="Recommend"></a>Recommend</h2><p>Pattern matching can be used to make recommendations，这个赞，天然的可以进行推荐，如六度分割（Six Degrees of Kevin Bacon），即Bacon Path最短路径问题<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># Johan is learning to surf, so he may want to find a new friend who already does:</div><div class="line">MATCH (js:Person)-[:KNOWS]-()-[:KNOWS]-(surfer) WHERE js.name = "Johan" AND surfer.hobby = "surfing" RETURN DISTINCT surfer</div><div class="line"># ()empty parenthesis to ignore these nodes</div><div class="line"># DISTINCTbecause more than one path will match the pattern</div><div class="line"># surferwill contain Allison, a friend of a friend who surfs</div></pre></td></tr></table></figure></p>
<h2 id="Analyze"><a href="#Analyze" class="headerlink" title="Analyze"></a>Analyze</h2><p>可视化查询计划理解Cypher查询如何工作（EXPLAIN/PROFILE）<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">PROFILE MATCH (js:Person)-[:KNOWS]-()-[:KNOWS]-(surfer)</div><div class="line">WHERE js.name = "Johan" AND surfer.hobby = "surfing"</div><div class="line">RETURN DISTINCT surfer</div></pre></td></tr></table></figure></p>
<h1 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h1><p><a href="http://neo4j.com/developer/guide-data-visualization/">visualization</a></p>
<h1 id="Neo4j可用性测试"><a href="#Neo4j可用性测试" class="headerlink" title="Neo4j可用性测试"></a>Neo4j可用性测试</h1><p><a href="http://neo4j.com/developer/in-production/">Neo4j in Production</a><br>读写性能测试</p>
<h1 id="Neo4j性能优化配置"><a href="#Neo4j性能优化配置" class="headerlink" title="Neo4j性能优化配置"></a>Neo4j性能优化配置</h1><p><a href="http://neo4j.com/docs/3.0.0-M02/configuration-introduction.html">neo4j-configuration-introduction</a>  </p>
<ul>
<li>确认JVM没有在GC垃圾回收上耗费太多时间,以确保有足够的heap避免heavy/peak引起GC-trashing时，GC-trashing时性能会下降两个数量级</li>
<li>JVM以-server参数启动，并设置一个合理的heap size，太大的heap也会损害性能，所以需要尝试不同的heap size</li>
<li>用并发的GC垃圾回收器，在大多数情况下<code>-XX:+UseG1GC</code>是最佳实践</li>
<li>给Neo4j page cache 设置大量的内存，在一个专用服务器上，需要平衡4大部分内存分配：操作系统、Neo4j JVM、Neo4j page cache和Neo4j Lucene全文索引用到的paging memory  <ul>
<li>服务器操作系统一般需要1到2GB的内存，服务器物理内存越大，操作系统需要分配的内存越大；  </li>
<li>由于Neo4j JVM和内存回收器的head-room消耗，需要足够大的heap   memory用来进行事物状态和查询处理；因为工作负载非常依赖heap memory，所以配置heap memory从1G到32G都很常见；  </li>
<li>Neo4j page cache 最好有足够的内存来保持整个数据集在内存中，也就是说page cache应该足够大，以适应所有的neostore.<em> 文件（不是neostore.transaction.db.</em> 文件）；  </li>
<li>配置足够的操作系统page cache以适应索引的内容和schema目录,因为如果索引不能装入内存,它将会影响索引查找性能；</li>
</ul>
</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Neo4j </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Python并行编程笔记]]></title>
      <url>http://geosmart.github.io/2016/01/23/Python%E5%B9%B6%E8%A1%8C%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>大数据时代，并发/并行是不变的话题，以并行计算来提高程序运行效率，可充分利用硬件资源（CPU，内存，磁盘/网络IO）。Python作为脚本语言，解释器简洁轻量，软件研发后无需编译且更新部署方便，对于实现一些类似爬取的工具十分友好。</p>
<hr>
<a id="more"></a>
<h1 id="关于多进程问题"><a href="#关于多进程问题" class="headerlink" title="关于多进程问题"></a>关于多进程问题</h1><p><a href="http://blog.tankywoo.com/2015/09/06/cant-pickle-instancemethod.html">http://blog.tankywoo.com/2015/09/06/cant-pickle-instancemethod.html</a><br>如果你的代码是CPU密集型，多个线程的代码很有可能是线性执行的。所以这种情况下多线程是鸡肋，效率可能还不如单线程因为有context switch,<br>如果你的代码是IO密集型，多线程可以明显提高效率。例如制作爬虫（我就不明白为什么Python总和爬虫联系在一起…不过也只想起来这个例子…），绝大多数时间爬虫是在等待socket返回数据。这个时候C代码里是有release GIL的，最终结果是某个线程等待IO的时候其他线程可以继续执行。</p>
<h1 id="python线程"><a href="#python线程" class="headerlink" title="python线程"></a>python线程</h1><h2 id="python协程"><a href="#python协程" class="headerlink" title="python协程"></a>python协程</h2><p>协程，又称微线程，纤程。英文名Coroutine。<br>最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。<br>第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。<br>因为协程是一个线程执行，那怎么利用多核CPU呢？最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。<br>Python对协程的支持还非常有限，用在generator中的yield可以一定程度上实现协程。虽然支持不完全，但已经可以发挥相当大的威力了。</p>
<h2 id="threading"><a href="#threading" class="headerlink" title="threading"></a>threading</h2><h2 id="生产者-消费者模型"><a href="#生产者-消费者模型" class="headerlink" title="生产者-消费者模型"></a>生产者-消费者模型</h2><h1 id="python多线程"><a href="#python多线程" class="headerlink" title="python多线程"></a>python多线程</h1><h2 id="monkey-patch"><a href="#monkey-patch" class="headerlink" title="monkey.patch"></a>monkey.patch</h2><p>monkey patch指的是在运行时动态替换,一般是在startup的时候.<br>用过gevent就会知道,会在最开头的地方gevent.monkey.patch_all();把标准库中的thread/socket等给替换掉.这样我们在后面使用socket的时候可以跟平常一样使用,无需修改任何代码,但是它变成非阻塞的了.<br>之前做的一个游戏服务器,很多地方用的import json,后来发现ujson比自带json快了N倍,于是问题来了,难道几十个文件要一个个把import json改成import ujson as json吗?<br>其实只需要在进程startup的地方monkey patch就行了.是影响整个进程空间的.<br>同一进程空间中一个module只会被运行一次.</p>
<h2 id="gevent"><a href="#gevent" class="headerlink" title="gevent"></a>gevent</h2><p>gevent 并发实现：<br>from gevent import monkey; monkey.patch_socket()</p>
<h1 id="python多进程"><a href="#python多进程" class="headerlink" title="python多进程"></a>python多进程</h1><h2 id="multiprocessing"><a href="#multiprocessing" class="headerlink" title="multiprocessing"></a>multiprocessing</h2><p>One can create a pool of processes which will carry out tasks submitted to it with the Pool class.<br>参考：<a href="http://www.davidmoodie.com/python-multiprocessing-fbalbumdownloader/">http://www.davidmoodie.com/python-multiprocessing-fbalbumdownloader/</a></p>
<p>注意：multiprocessing与gevent同时使用时，如果运行了gevent.monkey.patch_thread()或patch_all(),pool进程池将无效</p>
]]></content>
      
        <categories>
            
            <category> 脚本工具 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Python </tag>
            
            <tag> 并行 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[搭建Python工程化开发框架]]></title>
      <url>http://geosmart.github.io/2016/01/20/%E6%90%AD%E5%BB%BAPython%E5%B7%A5%E7%A8%8B%E5%8C%96%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/</url>
      <content type="html"><![CDATA[<p>2016的元月以python作为开端。<br>采用python进行网络数据聚合抽取，需调研并搭建python工程化开发框架，几番迭代，一个适用于数据采集的开发环境搭建完成：</p>
<ul>
<li>开发环境：python2.7.10 32位/pycharm5</li>
<li>项目构建：virtualenv/virtualenvWrapper 虚拟运行环境；pip 依赖项管理；pyBuilder项目构建，其中pyBuilder以disutils用于项目打包</li>
<li>项目文档：mkdocs/sphinx；参考<a href="http://docs.python-guide.org/en/latest/writing/documentation/">python-guide-writing</a></li>
<li>Web框架：Tornado/web,py（非阻塞式web服务器，精简）；django（文档功能齐全，但生态封闭）</li>
<li>单元测试：unittest/coverage(测试覆盖率统计)</li>
<li>并行框架：gevent(多线程)+monkey patch(运行时动态替换模块)，multiprocessing(多进程)</li>
<li>爬虫框架：scrapy/selenium</li>
<li>接口设计： zope.interface</li>
<li>编码风格：<a href="http://zh-google-styleguide.readthedocs.org/en/latest/google-python-styleguide/contents/">google-python-styleguide</a></li>
</ul>
<hr>
<a id="more"></a>
<p>pip install -i  <a href="http://pypi.douban.com/simple">http://pypi.douban.com/simple</a>  Shapely –trusted-host pypi.douban.com</p>
<h1 id="pip源配置"><a href="#pip源配置" class="headerlink" title="pip源配置"></a>pip源配置</h1><h2 id="临时换源"><a href="#临时换源" class="headerlink" title="临时换源"></a>临时换源</h2><p>临时换源只在某一条命令中生效，只要在命令中加上”-i“，指定使用的源即可<code>pip install scrapy -i url</code>，<br>如安装pandas：<code>pip install -i  http://pypi.douban.com/simple  pandas --trusted-host pypi.douban.com</code></p>
<h2 id="永久换源"><a href="#永久换源" class="headerlink" title="永久换源"></a>永久换源</h2><p>要是想永久更改pip源，在pip的配置文件（~/.pip/pip.conf）中增加<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[global]</div><div class="line">index-url=http://pypi.douban.com/simple</div></pre></td></tr></table></figure></p>
<h2 id="一些国内的pip源"><a href="#一些国内的pip源" class="headerlink" title="一些国内的pip源"></a>一些国内的pip源</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">http://mirrors.aliyun.com/pypi/simple/ # 阿里云</div><div class="line">http://pypi.douban.com/simple  #豆瓣</div><div class="line">http://pypi.hustunique.com/simple  #华中理工大学</div><div class="line">http://pypi.sdutlinux.org/simple  #山东理工大学</div><div class="line">http://pypi.mirrors.ustc.edu.cn/simple  #中国科学技术大学</div></pre></td></tr></table></figure>
<h1 id="打包部署问题"><a href="#打包部署问题" class="headerlink" title="打包部署问题"></a>打包部署问题</h1><p><a href="http://zengrong.net/post/2169.htm">python打包部署历史</a><br>distutils&gt;setuptools/easyinstall(<em>.egg)&gt;pip/wheel(</em>.whl)</p>
<h2 id="pip"><a href="#pip" class="headerlink" title="pip"></a>pip</h2><p>导出dependency:<code>pip freeze &gt; requirements.txt</code><br>安装dependency:<code>pip install -r requirements.txt</code></p>
<h2 id="whl"><a href="#whl" class="headerlink" title="whl"></a>whl</h2><p>二进制文件whl</p>
<h2 id="如何cmd中运行开发的-py程序模块"><a href="#如何cmd中运行开发的-py程序模块" class="headerlink" title="如何cmd中运行开发的*.py程序模块"></a>如何cmd中运行开发的*.py程序模块</h2><p>新增workspace.path文件到virtualenv目录（如<code>E:\PythonWorkspace\ugc\ugc_venv\Lib\site-packages</code>）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">E:\PythonWorkspace\ugc\ugc.aggregator</div><div class="line">E:\PythonWorkspace\ugc\ugc.aggregator\src\main\python</div></pre></td></tr></table></figure></p>
<p>注意path文件中的模块目录必须有<strong>init</strong>.py文件</p>
<h1 id="virtualenv"><a href="#virtualenv" class="headerlink" title="virtualenv"></a>virtualenv</h1><p>习惯了J2EE下的maven开发，对于python默认的module都安装到site-packages下的混乱不能理解，好在原来有virtualenv，它比maven本地repositoy库更具有独立性，当然冗余module是代价,好在python intepreter足够小巧。<br>virtualenv可以用来创建隔离的python环境 ，但新建出来的virtualenv都依赖本机安装的python底层dll等库。</p>
<ul>
<li>安装：<code>pip install virtualenv</code></li>
<li>新建virtualEnv：<code>virtualenv --no-site-packages venv</code></li>
<li>进入venvShel：<code>E:\PythonWorkspace\ugc\ugc_venv\Scripts\activate</code></li>
</ul>
<h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><ul>
<li>问题描述：执行<code>pip install MySQL-python</code>报错： <code>fatal error C1083: Cannot open include file: &#39;config-win.h&#39;: No such file or directory</code>或者报错<code>No module named MySQLdb</code><br>解决方案：从<code>C:\Python27\Lib\site-packages</code>复制mysql相关的文件到虚拟环境的site-packages目录</li>
</ul>
<h1 id="virtualenvwrapper"><a href="#virtualenvwrapper" class="headerlink" title="virtualenvwrapper"></a>virtualenvwrapper</h1><p>virtualenv创建的环境都是零散的，而且还要执行cd，执行source 来激活环境。 如此繁琐十分影响工作效率，于是有了virtualenvwrapper。vw可以进行环境的管理，把创建的环境记录下来，并进行管理。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ul>
<li>linux：<code>pip install  virtualenvwrapper</code>  </li>
<li>windows：<code>pip install virtualenvwrapper-win</code>  </li>
</ul>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><ul>
<li>安装完毕过后在环境变量里面新建一个WORKON_HOME字段存储虚拟python环境,WORKON_HOME：<code>E:\PythonWorkspace\venv</code></li>
<li>环境变量立即生效：cmd中运行<code>set WORKON_HOME=E:\PythonWorkspace\venv</code></li>
</ul>
<h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><p>virtualenvwrapper运行bat默认安装在<code>C:\Python27\Scripts\*.bat</code></p>
<ul>
<li>创建虚拟环境:<code>mkvirtualenv VirtualenvName</code></li>
<li>列出所有虚拟环境:<code>Lsvirtualenv</code></li>
<li>移除虚拟环境:<code>rmvirtualenv VirtualenvName</code></li>
<li>切换到VirtualenvName环境:<code>workon VirtualenvName</code></li>
<li>退出当前虚拟环境:<code>deactivate</code></li>
</ul>
<h2 id="问题记录-1"><a href="#问题记录-1" class="headerlink" title="问题记录"></a>问题记录</h2><ul>
<li><p>问题描述：执行virtualenv报错：<code>SyntaxError: Non-ASCII character &#39;\x90&#39; in file C:\Python27\Scripts\virtualenv.exe on line 1, but no encoding declared;</code><br>解决方案：卸载virtualenv<code>pip uninstall virtualenv</code>；卸载virtualenvwarpper<code>pip uninstall virtualenvwarpper-win</code>；重新安装virtualenvwarpper<code>pip install virtualenvwarpper-win</code>,要是还不行那就重装python！</p>
</li>
<li><p>问题描述：  File “E:\PythonWorkspace\venv\ugc.venv\Scripts\pip.exe”, line 1 SyntaxError: Non-ASCII character ‘\x90’ in file E:\PythonWorkspace\venv\ugc.venv\Scripts\pip.exe on line 1, but no encoding declared;<br>解决方案：原因是pip安装python包会加载我的用户目录，我的用户目录恰好是中文的，ascii不能编码。解决办法是：<br>python目录 Python27\Lib\site-packages 建一个文件sitecustomize.py,python会自动运行这个文件。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line">sys.setdefaultencoding(<span class="string">'gb2312'</span>)</div></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="pybuilder"><a href="#pybuilder" class="headerlink" title="pybuilder"></a>pybuilder</h1><p><a href="http://pybuilder.github.io/">pybuilder官网</a><br>经常在java/c#/javascript之间切着敲代码，今年又多了python这个数据分析神器，习惯了Maven约定俗成的构建环境，为了实现单元测试打包一体化的高效，于是决定采用pybuidler进行工程构建</p>
<h2 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h2><p>在venv环境安装：<code>pip install pybuilder</code></p>
<h2 id="pybuilder项目目录结构"><a href="#pybuilder项目目录结构" class="headerlink" title="pybuilder项目目录结构"></a>pybuilder项目目录结构</h2><p><code>src/main/python</code>：源码<br><code>src/main/scripts</code>：可执行脚本<br><code>src/main/unittest</code>：单元测试</p>
<h2 id="常用命令-1"><a href="#常用命令-1" class="headerlink" title="常用命令"></a>常用命令</h2><ul>
<li>进入venvShell：<code>workon ugc.venv</code></li>
<li>执行默认build文件：<code>pyb_.exe</code> (参考官方文档执行pyb报错，暂未找到办法)</li>
<li>执行默认build文件，并打印unittest错误详情：<code>pyb_.exe -v</code></li>
<li>新增测试项目：<code>pyb_.exe  --start-project</code></li>
<li>发布：<code>pyb_.exe install_dependencies publish</code></li>
</ul>
<h2 id="问题记录-2"><a href="#问题记录-2" class="headerlink" title="问题记录"></a>问题记录</h2><ul>
<li>单元测试执行错误：<code>BUILD FAILED - &#39;module&#39; object has no attribute &#39;FileUtil_test</code></li>
</ul>
]]></content>
      
        <categories>
            
            <category> 脚本工具 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Python </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MongoDB集群学习笔记]]></title>
      <url>http://geosmart.github.io/2015/12/29/MongoDB%E9%9B%86%E7%BE%A4%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>考虑部署实施的复杂度，一直没上MongoDB集群，但现在海量数据一来，单机性能就扛不住了，本文记录MongoDB集群的基础知识。</p>
<hr>
<a id="more"></a>
<p>Mongodb 有三种集群方式的搭建： Replica Set ，Sharding 和 Master-Slaver</p>
<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><ol>
<li>Chunck（块）：一个区间的数据称为一个数据块,是一个逻辑概念，物理存储并不连续，默认64M,可通过启动时附加’–chunkSize N’参数设置块大小</li>
<li>Vertical Scaling（垂直扩展）：CPU/RAM/IO等硬件层扩展，有云端部署和硬件扩展的瓶颈</li>
<li>Sharding（水平分片）：逻辑上是一个数据库，但物理存储上分开独立存储</li>
<li>Balancing（平衡）：当存在多个可用的分片，且块的数量足够多，mongodb的balancer（平衡器）会把数据迁移到其他分片上</li>
<li>mongos：mongos是用户和群集间的交互点，其职责是隐藏分片内部的复杂性并向用户提供一个简洁的单服务器接口，mongos会将所有用户请求转发到恰当的分片上。</li>
<li>config server（配置服务器）：配置服务器包含了有关集群的最完整可靠的信息以供所有人（分片、mongos进程和系统管理员）访问。</li>
</ol>
<h1 id="集群的构造"><a href="#集群的构造" class="headerlink" title="集群的构造"></a>集群的构造</h1><p>一个MongoDB集群基本由3类进程组成： shards（存储数据）, mongos(路由器）、 config servers（配置服务器）</p>
<h2 id="Shard-Server"><a href="#Shard-Server" class="headerlink" title="Shard Server"></a>Shard Server</h2><p>即存储实际数据的分片每个Shard 可以是一个mongod实例也可以是一组mongod实例构成的Replica Set。为了实现每个Shard内部的auto-failover，MongoDB官方建议每个Shard为一组Replica Set。</p>
<h2 id="Config-Server"><a href="#Config-Server" class="headerlink" title="Config Server"></a>Config Server</h2><p>为了将一个特定的collection 存储在多个shard 中需要为该collection指定一个shard key例如{age: 1} shard key 可以决定该条记录属于哪个chunk。Config Servers 就是用来存储所有shard 节点的配置信息、每个chunk 的shard key 范围、chunk 在各shard 的分布情况、该集群中所有DB 和collection 的sharding 配置信息。</p>
<h2 id="Route-Process"><a href="#Route-Process" class="headerlink" title="Route Process"></a>Route Process</h2><p>路由客户端由此接入，然后询问Config Servers 需要到哪个Shard 上查询或保存记录再连接相应的Shard 进行操作，最后将结果返回给客户端。客户端只需要将原本发给mongod的查询或更新请求原封不动地发给Routing Process而不必关心所操作的记录存储在哪个Shard 上。</p>
<h1 id="Replica-Set（复制）"><a href="#Replica-Set（复制）" class="headerlink" title="Replica Set（复制）"></a>Replica Set（复制）</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>复制是在多台服务器之间同步数据的过程。</p>
<h2 id="容灾性"><a href="#容灾性" class="headerlink" title="容灾性"></a>容灾性</h2><p>由于在不同的数据库服务器上拥有多个数据镜像，复制可以有效的防止由于单台服务器故障而导致的数据丢失。复制还能够帮助我们从硬件故障或是服务中断中恢复数据。我们也可以通过增加复制节点来将其用于灾难恢复、报表或是备份。</p>
<h2 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h2><p>在某些情况中，我们可以通过复制的方式来提高读的性能。客户端可以将读与写请求分别发送到不同的服务器上。我们还能够通过在其他数据中心建立分布式复制节点的方式来做异地冗灾，以进一步提高可用性。</p>
<h1 id="Sharding（分片）"><a href="#Sharding（分片）" class="headerlink" title="Sharding（分片）"></a>Sharding（分片）</h1><p><a href="https://docs.mongodb.org/manual/faq/sharding/">shard官方QA</a></p>
<h2 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h2><p>sharding（分片）是使用多个机器存储数据的方法,MongoDB使用分片以支持巨大的数据存储量与对数据操作.<br>为了解决这些问题,有两个基本的方法: 纵向扩展 和 分片 .<br>分片的目的：高数据量和吞吐量的数据库应用会对单机的性能造成较大压力,大的查询量会将单机的CPU耗尽,大的数据量对单机的存储压力较大,最终会耗尽系统的内存而将压力转移到磁盘IO上.</p>
<p>一个分片可由多台服务器组成（每台服务器都有一份分片数据的Replica set副本）<br>根据片键（key）分片[a,b)，MongoDB会在不同分片区间移动数据子集<br><a href="http://www.server110.com/mongodb/201403/7201.html">MongoDB集群（分片）安装与配置方法图解</a></p>
<h2 id="shard-key-片键"><a href="#shard-key-片键" class="headerlink" title="shard key(片键)"></a>shard key(片键)</h2><p>shard key大小不能超过512 bytes.<br>分片后shard key不可改变，除非重建collection</p>
<h3 id="小基数片键"><a href="#小基数片键" class="headerlink" title="小基数片键"></a>小基数片键</h3><p>小基数片键：片键值数量有限<br>适用的键：应使用组合片键(一个片键包含2个字段），请确保第二个字段有足够的值供MongoDB用来进行分割</p>
<h3 id="升序片键"><a href="#升序片键" class="headerlink" title="升序片键"></a>升序片键</h3><p>适用于任何升序排列的键值，而并不必须是时间戳，包括日期、自增主键。<br>只要键值趋于无穷大，就会面临单一且不可分散的热点问题</p>
<h3 id="随机片键"><a href="#随机片键" class="headerlink" title="随机片键"></a>随机片键</h3><p>初衷是为了避免热点，会选择一个随机值的字段来分片。<br>数据量变大后会给RAM增加压力，且会引发大量的磁盘IO</p>
<h3 id="好片键"><a href="#好片键" class="headerlink" title="好片键"></a>好片键</h3><p>具有良好的数据局部性（data locality）特征，但又不会太局部而导致热点出现。<br>准升序键+搜索键<code>｛coarselyAscending:1，search:1｝</code>，coarselyAscending用来控制数据局部化，search字段则是数据上常用的一个检索字段。<br>coarselyAscending键的每个值最好能对应几十到几百个数据块，如月份（2015-12）<br>search键则应当是应用程序通常都会依据其进行查询的字段，如用户信息、文件名称、或GUID等</p>
<h1 id="Master-Slaver（主从）"><a href="#Master-Slaver（主从）" class="headerlink" title="Master-Slaver（主从）"></a>Master-Slaver（主从）</h1><p>对于Mongodb来说，并不推荐使用Master-Slave架构，因为Master-Slave其中Master宕机后不能自动恢复，推荐使用Replica Set，除非Replica的节点数超过50，才需要使用Master-Slave架构，正常情况是不可能用那么多节点的。<br>主从架构一般用于备份或者做读写分离。由两种角色构成：</p>
<h2 id="主-Master"><a href="#主-Master" class="headerlink" title="主(Master)"></a>主(Master)</h2><p>可读可写，当数据有修改的时候，会将oplog同步到所有连接的salve上去。</p>
<h2 id="从-Slave"><a href="#从-Slave" class="headerlink" title="从(Slave)"></a>从(Slave)</h2><p>只读不可写，自动从Master同步数据。</p>
<h1 id="mongodb集群监控"><a href="#mongodb集群监控" class="headerlink" title="mongodb集群监控"></a>mongodb集群监控</h1><p>在线：Mongodb Cloud Manager<br>离线：MongoDB Management Service(MMS)<br><img src="automation.png" alt="how automation agent work"><br><img src="monitoring.png" alt="how monitoring agent work"><br><img src="backup.png" alt="how bakcup agent work"></p>
<h1 id="mongodb-gui-tools"><a href="#mongodb-gui-tools" class="headerlink" title="mongodb gui tools"></a>mongodb gui tools</h1><p><code>MongoVUE1.6.9</code> 在<code>Mongodb3.2.0</code>版本不可用了，不得不寻找替代品<br><a href="https://docs.mongodb.org/ecosystem/tools/administration-interfaces">官方推荐工具列表</a></p>
<p>亲测觉得不错的GUI工具</p>
<ul>
<li><a href="http://3t.io/mongochef/">3T MongoChef</a> 提供64位</li>
<li><a href="http://mongobooster.com/">mongobooster</a></li>
</ul>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MongoDB </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MongoDB3离线部署]]></title>
      <url>http://geosmart.github.io/2015/12/28/MongoDB3%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2/</url>
      <content type="html"><![CDATA[<p>基于Ops Manager的MongoDB 3.2集群离线部署笔记</p>
<hr>
<a id="more"></a>
<h1 id="MongoDB3带来的改变"><a href="#MongoDB3带来的改变" class="headerlink" title="MongoDB3带来的改变"></a>MongoDB3带来的改变</h1><p>MongoDB 3.0新版重点主要在效能的提升以及可扩展性，这些改变来自于储存层（Storage Layer）的强化，<br>MongoDB 2.8版本开始引入支持Latch-free、Non-blocking算法的WiredTiger储存引擎，因此可以开始使用新硬件才有的功能，比如大量的高速缓存（On-chip Cache）和多执行架构。<br>MongoDB 3.0 还提供了企业Ops Manager管理工具，用来管理大规模的 MongoDB 架构。</p>
<h2 id="个人测试"><a href="#个人测试" class="headerlink" title="个人测试"></a>个人测试</h2><ol>
<li>数据恢复（mongorestore）支持并行导入了，性能有所提升；</li>
<li>数据存储变成了*.wt后缀的，待确认具体更新；</li>
</ol>
<p>MongoDB的管理服务（MMS）是用于监控和备份MongoDB的基础设施服务。其中监控的服务是免费的，备份的服务是需要收费的。</p>
<h1 id="Ops-Manager"><a href="#Ops-Manager" class="headerlink" title="Ops Manager"></a>Ops Manager</h1><p><code>The Best Way to Run MongoDB: Ops Manager</code><br><a href="https://www.mongodb.com/products/ops-manager">Ops Manager官网</a></p>
<p>Ops Manager能做什么？</p>
<blockquote>
<p>Deployment. Any topology, at any scale<br>Management. Deploy new clusters. Manage, monitor, and back up existing ones<br>Upgrades. In minutes, with no downtime<br>Scaling. Add capacity, without taking the application offline<br>Point-in-time, Scheduled Backups. Restore to any point in time, because disasters aren’t predictable<br>Performance Alerts. Monitor 100+ system metrics and get custom alerts before the system degrades<br>Add Query Optimization. Identify slow-running queries, get index suggestions, automate index builds</p>
</blockquote>
<h1 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h1><h2 id="服务器准备"><a href="#服务器准备" class="headerlink" title="服务器准备"></a>服务器准备</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#mms应用服务器</span></div><div class="line">192.168.1.80</div><div class="line"></div><div class="line"><span class="comment">#mms监控数据服务器，Monitor Agent部署</span></div><div class="line">192.168.1.51</div><div class="line"></div><div class="line">192.168.1.52：shard</div><div class="line">192.168.1.54：config server</div><div class="line">192.168.1.58：mongos</div></pre></td></tr></table></figure>
<h2 id="域名解析配置"><a href="#域名解析配置" class="headerlink" title="域名解析配置"></a>域名解析配置</h2><h3 id="HostName配置-FQDN配置"><a href="#HostName配置-FQDN配置" class="headerlink" title="HostName配置/FQDN配置"></a>HostName配置/FQDN配置</h3><p>FQDN是Fully Qualified Domain Name的缩写, 含义是完整的域名. 例如, 一台机器主机名(hostname)是www, 域后缀(domain)是example.com, 那么该主机的FQDN应该是www.example.com.<br>注意：hosts配置不当，后面server和agent间通讯会存在问题，参考host配置如下：</p>
<ul>
<li>server/agent配置(master)</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># vim /etc/hosts</span></div><div class="line"></div><div class="line"><span class="comment"># localhost</span></div><div class="line">127.0.0.1 localhost.localdomain localhost</div><div class="line"></div><div class="line"><span class="comment">#mongodb ops manager server</span></div><div class="line">192.168.1.80   opsserver.lt.com opsserver</div><div class="line"></div><div class="line"><span class="comment">#mongodb ops monitor agent</span></div><div class="line">192.168.1.51   opsagent1.lt.com opsagent1</div><div class="line">192.168.1.52   opsagent2.lt.com opsagent2</div><div class="line">192.168.1.53   opsagent3.lt.com opsagent3</div><div class="line">192.168.1.54   opsagent4.lt.com opsagent4</div><div class="line">192.168.1.58   opsagent8.lt.com opsagent8</div></pre></td></tr></table></figure>
<h3 id="network配置"><a href="#network配置" class="headerlink" title="network配置"></a>network配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># vim /etc/sysconfig/network</span></div><div class="line">NETWORKING=yes</div><div class="line">HOSTNAME=opsserver</div><div class="line">NTPSERVERARGS=iburst</div></pre></td></tr></table></figure>
<h2 id="安装Ops-Manager-Application-Database"><a href="#安装Ops-Manager-Application-Database" class="headerlink" title="安装Ops Manager Application Database"></a>安装Ops Manager Application Database</h2><p>可选：Backup Database</p>
<p>设置最大文件打开数<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#vim /etc/rc.local</span></div><div class="line"><span class="built_in">ulimit</span> -n 65536</div></pre></td></tr></table></figure></p>
<p>##　安装Ops Manager集群监控</p>
<h3 id="关于Ops-Manager"><a href="#关于Ops-Manager" class="headerlink" title="关于Ops Manager"></a>关于Ops Manager</h3><p><a href="https://www.mongodb.com/presentations/webinar-introducing-ops-manager">视频教程</a><br><a href="http://www.slideshare.net/mongodb/ops-manager-webinar-mar-5-2015">视频教程</a></p>
<p><a href="https://docs.opsmanager.mongodb.com/master/application/">介绍文档</a><br>MongoDB Ops Manager is a service for managing, monitoring and backing up a MongoDB infrastructure. Ops Manager provides the services described here.<br><img src="https://docs.opsmanager.mongodb.com/master/_images/opsmanager-network-diagram-fullsize.png" alt="组成部分"></p>
<p><img src="https://docs.opsmanager.mongodb.com/master/_images/opsmanager-large.png" alt="Production Install with a Highly Available Ops Manager Application and Multiple Backup Databases¶"></p>
<p>备注：目前Ops Manager只能完成从无到有的集群部署，sharding集群的shard key等配置需在xshell中手动配置</p>
<h3 id="centos6安装Ops-Manager"><a href="#centos6安装Ops-Manager" class="headerlink" title="centos6安装Ops Manager"></a>centos6安装Ops Manager</h3><p><a href="https://docs.opsmanager.mongodb.com/current/tutorial/install-on-prem-with-rpm-packages/">RPM安装参考教程</a><br><a href="http://www.ttlsa.com/mms/follow-me-to-use-mongodb-mms-services/">中文配置教程</a></p>
<ol>
<li>配置ops manager application data数据服务器（192.168.1.51），安装mongodb并启动服务<br>从其他机器复制mongodb：<code>scp -r root@192.168.1.52:/usr/local/mongodb /usr/local</code></li>
<li>安装ops manager server<ul>
<li>复制到<code>mongodb-mms-2.0.0.327-1.x86_64.rpm</code>到<code>/mnt</code></li>
<li>执行<code>sudo rpm -ivh  /mnt/mongodb-mms-2.0.0.327-1.x86_64.rpm</code>，mms将默认安装到<code>/opt/mongodb/mms/</code></li>
<li>配置/opt/mongodb/mms/conf/conf-mms.properties,设置mongo.mongoUri等参数</li>
<li>启动服务<code>sudo service mongodb-mms start</code></li>
<li>设置mongodb-mms为开机自启动：chkconfig  mongodb-mms  on</li>
<li>登录http://<host>:8080/注册用户</li>
</ul>
</li>
<li>agent节点分别配置安装automation agent  </li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#以下具体参数参考http://192.168.1.80:8080/settings/agents/中的Automation选项卡的操作步骤</span></div><div class="line"></div><div class="line"><span class="comment">#Download the agent</span></div><div class="line">curl -OL http://192.168.1.80:8080/download/agent/automation/mongodb-mms-automation-agent-manager-2.5.11.1484-1.x86_64.rpm</div><div class="line"><span class="comment">#and install the package.</span></div><div class="line">sudo rpm -U mongodb-mms-automation-agent-manager-2.5.11.1484-1.x86_64.rpm</div><div class="line"></div><div class="line"><span class="comment">#Open the config file</span></div><div class="line">sudo vi /etc/mongodb-mms/automation-agent.config</div><div class="line"><span class="comment">#配置唯一 API key, Group ID, and Ops Manager Base URL</span></div><div class="line">mmsGroupId=568486a424ac2c591d35e00c</div><div class="line">mmsApiKey=e4db7d0b6757a704271d04e25748ac41</div><div class="line">mmsBaseUrl=http://192.168.1.80:8080</div><div class="line"></div><div class="line"><span class="comment">#Prepare a directory in which to store your MongoDB data. This directory must be owned by the mongod user. Any directory is fine, but the default is /data. This directory can be created with a command similar to below.</span></div><div class="line">sudo mkdir /data</div><div class="line">sudo chown mongod:mongod /data</div><div class="line"></div><div class="line"><span class="comment">#Start the agent.</span></div><div class="line">sudo service mongodb-mms-automation-agent start</div><div class="line"></div><div class="line"><span class="comment">#设置mongodb-mms-automation-agent为开机自启动</span></div><div class="line">chkconfig  mongodb-mms-automation-agent on</div></pre></td></tr></table></figure>
<p>其他shard节点可从monitor节点复制automation-agent配置文件：<code>scp root@192.168.1.51:/etc/mongodb-mms/automation-agent.config /etc/mongodb-mms/automation-agent.config</code><br>重启automation-agent服务：<code>sudo service mongodb-mms-automation-agent restart</code></p>
<ol>
<li>在web控制台Deployment中选1台性能较好的服务器配置monitoring agent（如在ops manager application data数据服务器）</li>
<li>zai Deployment模块Add New Cluster,配置mongos,config server和shards</li>
<li>集群测试<br>服务器主机名regex过滤:(opsagent2|opsagent4|opsagent8)<br>集群服务器配置:mongos:1/mongod:3/config server:1<br>端口配置，shards(27000-28000),mongos(27017)config server(27019)<br>分片数配置<br>配置完成确认执行后，ops会按顺序自动安装部署shard&gt;config server&gt;mongos，再也不用kb手动去安装了！<br>mongodb安装的默认位置：/var/lib/mongodb-mms-automation</li>
</ol>
<h3 id="windows-server安装Ops-Manager"><a href="#windows-server安装Ops-Manager" class="headerlink" title="windows server安装Ops Manager"></a>windows server安装Ops Manager</h3><p><a href="https://docs.opsmanager.mongodb.com/current/tutorial/install-on-prem-windows/">参考教程</a></p>
<ol>
<li>安装mongodb</li>
<li>安装Install Ops Manager</li>
<li>配置<code>C:\MMSData\Server\Config\conf-mms.properties</code>（默认路径）中的<code>mongo.mongoUri</code>等连接配置属性</li>
<li>在windows服务列表启动服务<code>MongoDB Ops Manager HTTP Service</code></li>
<li>登录http://<host>:8080/注册用户，admin/1qaz@WSX</li>
</ol>
<h3 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h3><ol>
<li>No MongoDB versions have been made available for use in your deployment. Visit the Version Manager to enable MongoDB versions.<br>重新配置，将version manager参数设置为internet而非local</li>
<li>There are a mix of Agents that are installed manually and managed by your Automation Agents. This configuration is not supported.<br>You will not be able to add new hosts to monitoring or create new automated hosts while in this state. The Agents that should be removed are indicated on the table above.<br>After stopping an Agent it can take up to 5 minutes to take effect.</li>
<li>添加集群报错： Unable to create member 2 of myShard_0. Unable to find enough servers. Requested port range was 27000 to 27000. Excluding port ranges 27019 to 27019, 27017 to 27017. Please ensure all agents are running.<br>shard server port设置在27000-28000范围内，不能设置为27000</li>
<li>mongos服务无法启动<br>错误日志：<code>not master or secondary; cannot currently read from this replSet member ns,config.settings query,config.shards query</code><br>解决方案：pkill mongod 强制关闭mongo进程，删除/data目录内的shard数据(不能删automation的数据)，重新添加集群</li>
<li>shard集群分片测试，目前数据量小，数据存储表现为replica set，待测试分片效果！</li>
</ol>
<h1 id="MongoDB离线部署配置"><a href="#MongoDB离线部署配置" class="headerlink" title="MongoDB离线部署配置"></a>MongoDB离线部署配置</h1><p><a href="https://docs.opsmanager.mongodb.com/v2.0/tutorial/configure-local-mode/">Configure Local Mode if Servers Have No Internet Access</a></p>
<h2 id="设置为Local"><a href="#设置为Local" class="headerlink" title="设置为Local"></a>设置为Local</h2><p>在Ops Manager控制台，单击右上角Admin，General&gt;Ops Manager Config&gt; Miscellaneous&gt;设置Version Manifest Source 为Local<br>设置 Versions Directory存储MongoDB binaries，默认<code>/opt/mongodb/mms/mongodb-releases</code></p>
<h2 id="下载MongoDB离线Binaries"><a href="#下载MongoDB离线Binaries" class="headerlink" title="下载MongoDB离线Binaries"></a>下载MongoDB离线Binaries</h2><p>cd /opt/mongodb/mms/mongodb-releases<br>curl -OL <a href="http://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel62-3.2.0.tgz">http://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel62-3.2.0.tgz</a></p>
<h2 id="设置Versions-Directory目录权限"><a href="#设置Versions-Directory目录权限" class="headerlink" title="设置Versions Directory目录权限"></a>设置Versions Directory目录权限</h2><ol>
<li>查看目录权限：<code>ls -l /opt/mongodb/mms/mongodb-releases</code></li>
<li>设置mongodb-mms用户对Versions Directory中文件有读写权限：<code>sudo chown -R  mongodb-mms:mongodb-mms /opt/mongodb/mms/mongodb-releases</code></li>
</ol>
<h2 id="编辑conf-mms-properties"><a href="#编辑conf-mms-properties" class="headerlink" title="编辑conf-mms.properties"></a>编辑conf-mms.properties</h2><p>在conf-mms.propertie最后新增两行<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#vim /opt/mongodb/mms/conf/conf-mms.properties</span></div><div class="line">automation.versions.source=<span class="built_in">local</span></div><div class="line">automation.versions.directory=/opt/mongodb/mms/mongodb-releases/</div></pre></td></tr></table></figure></p>
<h2 id="重启服务"><a href="#重启服务" class="headerlink" title="重启服务"></a>重启服务</h2><p><code>sudo service mongodb-mms restart</code></p>
<h2 id="部署截图"><a href="#部署截图" class="headerlink" title="部署截图"></a>部署截图</h2><p><img src="01_deployment.png" alt="deployment"><br><img src="02_statis_chart.png" alt="statis_chart"><br><img src="03_statis_table.png" alt="statis_table"></p>
<h2 id="Version-Manager配置MongoDB版本"><a href="#Version-Manager配置MongoDB版本" class="headerlink" title="Version Manager配置MongoDB版本"></a>Version Manager配置MongoDB版本</h2><p>在Ops Manager控制台，Deployment&gt;Version Manager&gt;选择离线的mongodb版本&gt;Review &amp; Deploy&gt;Confirm &amp; Deploy.</p>
<h1 id="MongoDB-数据备份与恢复"><a href="#MongoDB-数据备份与恢复" class="headerlink" title="MongoDB 数据备份与恢复"></a>MongoDB 数据备份与恢复</h1><p><a href="https://docs.mongodb.org/manual/tutorial/backup-small-sharded-cluster-with-mongodump/">backup-small-sharded-cluster-with-mongodump</a><br>在mongodb primary节点执行mongorestore<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /var/lib/mongodb-mms-automation/mongodb-linux-x86_64-3.2.0/bin</div><div class="line">mongorestore -drop  -d uadb  /mnt/dump/dump/uadb_dump/uadb</div><div class="line">mongorestore -drop  -d uadb_attachment  /mnt/dump/dump/uadb_attachment_dump/uadb_attachment</div></pre></td></tr></table></figure></p>
<h1 id="Route-Server配置chunk-size"><a href="#Route-Server配置chunk-size" class="headerlink" title="Route Server配置chunk size"></a>Route Server配置chunk size</h1><p><a href="https://docs.mongodb.org/manual/tutorial/modify-chunk-size-in-sharded-cluster/">参考文档：modify-chunk-size-in-sharded-cluster</a></p>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ol>
<li>Automatic splitting only occurs on insert or update.</li>
<li>If you lower the chunk size, it may take time for all chunks to split to the new size.</li>
<li>Splits cannot be undone.</li>
<li>If you increase the chunk size, existing chunks grow only through insertion or updates until they reach the new size.</li>
<li>The allowed range of the chunk size is between 1 and 1024 megabytes, inclusive.</li>
</ol>
<h2 id="修改步骤"><a href="#修改步骤" class="headerlink" title="修改步骤"></a>修改步骤</h2><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#连接Route Server(mongos shell)</span></div><div class="line"><span class="string">/var/lib/mongodb-mms-automation/mongodb-linux-x86_64-3.2.0/bin/mongo</span> <span class="string">opsagent2.lt.com:27017</span>  </div><div class="line"> <span class="comment">#切换到config数据库</span></div><div class="line"> <span class="string">use</span> <span class="string">config</span></div><div class="line"> <span class="comment">#修改chunk size</span></div><div class="line"> <span class="string">db.settings.save(</span> <span class="string">&#123;</span> <span class="attr">_id:"chunksize",</span> <span class="attr">value:</span> <span class="string">&lt;sizeInMB&gt;</span> <span class="string">&#125;</span> <span class="string">)</span></div><div class="line"> <span class="string">如</span> <span class="string">db.settings.save(</span> <span class="string">&#123;</span> <span class="attr">_id:"chunksize",</span> <span class="attr">value:</span> <span class="number">64</span> <span class="string">&#125;</span> <span class="string">)</span></div></pre></td></tr></table></figure>
<h1 id="数据库启用分片：enableSharding"><a href="#数据库启用分片：enableSharding" class="headerlink" title="数据库启用分片：enableSharding"></a>数据库启用分片：enableSharding</h1><p><a href="https://docs.mongodb.org/manual/tutorial/deploy-shard-cluster/">参考文档：deploy-shard-cluster</a><br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#连接以mingo连接route server（mongo shell）</span></div><div class="line"><span class="string">mongo</span> <span class="bullet">--host</span> <span class="string">&lt;hostname</span> <span class="string">of</span> <span class="string">machine</span> <span class="string">running</span> <span class="string">mongos&gt;</span> <span class="bullet">--port</span> <span class="string">&lt;port</span> <span class="string">mongos</span> <span class="string">listens</span> <span class="string">on&gt;</span></div><div class="line"><span class="string">如/var/lib/mongodb-mms-automation/mongodb-linux-x86_64-3.2.0/bin/mongo</span> <span class="bullet">--host</span> <span class="string">opsagent2.lt.com</span> <span class="bullet">--port</span> <span class="number">27017</span></div><div class="line"><span class="comment">#启用分片</span></div><div class="line"><span class="string">sh.enableSharding("&lt;database&gt;")</span> <span class="string">或者</span> <span class="string">db.runCommand(</span> <span class="string">&#123;</span> <span class="attr">enableSharding:</span> <span class="string">&lt;database&gt;</span> <span class="string">&#125;</span> <span class="string">)</span></div><div class="line"><span class="string">如</span></div><div class="line"><span class="string">sh.enableSharding("uadb")</span></div><div class="line"><span class="string">sh.enableSharding("uadb_attachment")</span></div><div class="line"><span class="string">或</span></div><div class="line"><span class="string">use</span> <span class="string">admin</span></div><div class="line"><span class="string">db.runCommand(</span> <span class="string">&#123;</span> <span class="attr">enableSharding:</span> <span class="string">"uadb"</span><span class="string">&#125;</span> <span class="string">);</span></div><div class="line"><span class="string">db.runCommand(</span> <span class="string">&#123;</span> <span class="attr">enableSharding:</span> <span class="string">"uadb_attachment"</span><span class="string">&#125;</span> <span class="string">);</span></div><div class="line"><span class="comment"># collection分片</span></div><div class="line"><span class="string">sh.shardCollection("&lt;database&gt;.&lt;collection&gt;",</span> <span class="string">shard-key-pattern)</span></div><div class="line"><span class="string">如</span> <span class="string">sh.shardCollection("uadb.AddressNode",</span> <span class="string">&#123;</span> <span class="string">"_id"</span><span class="string">:</span> <span class="number">1</span><span class="string">,</span> <span class="string">"ruleabbr"</span><span class="string">:</span> <span class="number">1</span> <span class="string">&#125;</span> <span class="string">)</span></div><div class="line"><span class="comment">#查看是否成功启用分片</span></div><div class="line"><span class="string">use</span> <span class="string">uadb;</span></div><div class="line"><span class="string">db.AddressNode.stats();</span></div></pre></td></tr></table></figure></p>
<h1 id="shard集群测试"><a href="#shard集群测试" class="headerlink" title="shard集群测试"></a>shard集群测试</h1><p><a href="http://janephp.blog.51cto.com/4439680/1330656">Sharding 分片分片测试</a><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#mongo连接admin库</span></div><div class="line">/var/lib/mongodb-mms-automation/mongodb-linux-x86_64-3.2.0/bin/mongo admin --host opsagent2.lt.com --port 27017</div><div class="line"></div><div class="line"><span class="comment">#设置分片存储数据库</span></div><div class="line">sh.enableSharding(<span class="string">"test"</span>)</div><div class="line">sh.shardCollection(<span class="string">'test.users'</span>, &#123; <span class="string">"_id"</span>: 1&#125; )</div><div class="line"></div><div class="line"><span class="comment">#插入测试数据</span></div><div class="line">use <span class="built_in">test</span></div><div class="line"><span class="keyword">for</span>(var i=1;i&lt;50000;i++) db.users.insert(&#123;age:i,name:<span class="string">'geosmart'</span>,address:<span class="string">'anhui_chuzhou'</span>,country:<span class="string">'china'</span>&#125;)</div><div class="line"><span class="comment">#查询分片状态</span></div><div class="line">db.users.stats();</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MongoDB </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MongoDB权限配置]]></title>
      <url>http://geosmart.github.io/2015/12/28/MongoDB%E6%9D%83%E9%99%90%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<hr>
<a id="more"></a>
<h1 id="在未开启auth模式下新建sa用户"><a href="#在未开启auth模式下新建sa用户" class="headerlink" title="在未开启auth模式下新建sa用户"></a>在未开启auth模式下新建sa用户</h1><p>//进入admin数据库<br>mongo admin<br>//新建sa超级用户<br><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">db.createUser(</div><div class="line">   &#123;</div><div class="line">     user: <span class="string">"sa"</span>,</div><div class="line">     pwd: <span class="string">"1qaz2wsx"</span>,</div><div class="line">     roles:</div><div class="line">       [</div><div class="line">         &#123; <span class="attr">db</span>: <span class="string">"uadb"</span>, <span class="attr">role</span>: <span class="string">"readWrite"</span> &#125;,</div><div class="line"> &#123; <span class="attr">db</span>: <span class="string">"uadb"</span>, <span class="attr">role</span>: <span class="string">"dbAdmin"</span> &#125;,</div><div class="line"> &#123; <span class="attr">db</span>: <span class="string">"uadb"</span>, <span class="attr">role</span>: <span class="string">"userAdmin"</span> &#125;,</div><div class="line"> &#123; <span class="attr">db</span>: <span class="string">"uadb"</span>, <span class="attr">role</span>: <span class="string">"dbOwner"</span> &#125;,    </div><div class="line"> &#123; <span class="attr">db</span>: <span class="string">"uadb_attachment"</span>, <span class="attr">role</span>: <span class="string">"readWrite"</span> &#125;,</div><div class="line"> &#123; <span class="attr">db</span>: <span class="string">"uadb_attachment"</span>, <span class="attr">role</span>: <span class="string">"dbAdmin"</span> &#125;,</div><div class="line"> &#123; <span class="attr">db</span>: <span class="string">"uadb_attachment"</span>, <span class="attr">role</span>: <span class="string">"userAdmin"</span> &#125;,</div><div class="line"> &#123; <span class="attr">db</span>: <span class="string">"uadb_attachment"</span>, <span class="attr">role</span>: <span class="string">"dbOwner"</span> &#125;,     </div><div class="line"> &#123; <span class="attr">db</span>: <span class="string">"admin"</span>, <span class="attr">role</span>: <span class="string">"readWrite"</span> &#125;,</div><div class="line"> &#123; <span class="attr">db</span>: <span class="string">"admin"</span>, <span class="attr">role</span>: <span class="string">"dbAdmin"</span> &#125;,</div><div class="line"> &#123; <span class="attr">db</span>: <span class="string">"admin"</span>, <span class="attr">role</span>: <span class="string">"userAdmin"</span> &#125;,</div><div class="line"> &#123; <span class="attr">db</span>: <span class="string">"admin"</span>, <span class="attr">role</span>: <span class="string">"dbOwner"</span> &#125;,</div><div class="line"> &#123; <span class="attr">db</span>: <span class="string">"admin"</span>, <span class="attr">role</span>: <span class="string">"root"</span> &#125;</div><div class="line">       ]</div><div class="line">   &#125;</div><div class="line">)</div></pre></td></tr></table></figure></p>
<p>//sa用户授权测试<br>db.auth(“sa”,”1qaz2wsx”)</p>
<h1 id="启用MongoDB权限控制"><a href="#启用MongoDB权限控制" class="headerlink" title="启用MongoDB权限控制"></a>启用MongoDB权限控制</h1><p>Windows<br>卸载现有MongoDB服务<br>C:\WINDOWS\system32&gt;sc delete “MongoDB”</p>
<p>启动服务<br>按照MongoDB服务（设置权限控制）：E:\mongodb\bin\mongod –logpath “E:\mongodb\log\mongo.log” –logappend –dbpath “E:\mongodb\data” –directoryperdb   –auth  –serviceName “MongoDB” –serviceDisplayName “MongoDB” –install</p>
<p>Linux<br>启动服务<br>/mnt/data/mongodb/bin/mongod –dbpath /mnt/data/mongodb/data –logpath /mnt/data/mongodb/log/mongodb.log  –auth</p>
<h1 id="开启auth后新建用户"><a href="#开启auth后新建用户" class="headerlink" title="开启auth后新建用户"></a>开启auth后新建用户</h1><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//以admin登陆获取权限</span></div><div class="line">use admin</div><div class="line"><span class="comment">//sa用户授权</span></div><div class="line">db.auth(<span class="string">"sa"</span>,<span class="string">"1qaz2wsx"</span>)</div><div class="line"><span class="comment">//切换到uadb库新建用户uadb</span></div><div class="line">use uadb</div><div class="line">db.auth(<span class="string">"uadb"</span>,<span class="string">"1c63129ae9db9c60c3e8aa94d3e00495"</span>)</div><div class="line">db.dropUser(<span class="string">"uadb"</span>);</div><div class="line">db.createUser( &#123;<span class="attr">user</span>: <span class="string">"uadb"</span>, <span class="attr">pwd</span>: <span class="string">"1c63129ae9db9c60c3e8aa94d3e00495"</span>, <span class="attr">roles</span>: [   <span class="string">"readWrite"</span> , <span class="string">"dbAdmin"</span> ] &#125;)</div><div class="line"></div><div class="line"><span class="comment">//切换到uadb库新建用户uadb_attachment</span></div><div class="line">use uadb_attachment</div><div class="line">db.dropUser(<span class="string">"uadb_attachment"</span>);</div><div class="line">db.createUser( &#123;<span class="attr">user</span>: <span class="string">"uadb_attachment"</span>, <span class="attr">pwd</span>: <span class="string">"1c63129ae9db9c60c3e8aa94d3e00495"</span>, <span class="attr">roles</span>: [   <span class="string">"readWrite"</span> , <span class="string">"dbAdmin"</span> ] &#125;)</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MongoDB </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MongoDB空间分析]]></title>
      <url>http://geosmart.github.io/2015/12/28/MongoDB%E7%A9%BA%E9%97%B4%E5%88%86%E6%9E%90/</url>
      <content type="html"><![CDATA[<p>用MongoDB与其他NoSQL数据库之间一个大的差别就是她的空间数据存储，2dsphere空间索引（WGS84），用于通用的空间分析（如缓冲区）会很方便。</p>
<hr>
<a id="more"></a>  
<h1 id="新建空间索引"><a href="#新建空间索引" class="headerlink" title="新建空间索引"></a>新建空间索引</h1><p>连接到数据库：<code>/mnt/data/mongodb/bin/mongo uadb</code><br>新建空间索引：<code>db.AddressNode.ensureIndex( { 空间位置 : &quot;2dsphere&quot; });</code><br>新建空间联合索引：<code>db.AddressNode.ensureIndex( { 空间位置 : &quot;2dsphere&quot;, 规范地址节简称: 1  });</code></p>
<h1 id="几何查询"><a href="#几何查询" class="headerlink" title="几何查询"></a>几何查询</h1><p>MongoDB查询关键词：<a href="http://docs.mongodb.org/manual/reference/operator/query-geospatial/">http://docs.mongodb.org/manual/reference/operator/query-geospatial/</a></p>
<h2 id="geoWithin多边形范围查询"><a href="#geoWithin多边形范围查询" class="headerlink" title="geoWithin多边形范围查询"></a>geoWithin多边形范围查询</h2><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">空间位置: &#123;</div><div class="line">        $geoWithin: &#123;</div><div class="line">            $geometry: &#123;</div><div class="line">                 <span class="string">"type"</span>:<span class="string">"Polygon"</span>,</div><div class="line">                 <span class="string">"coordinates"</span>:[[</div><div class="line">                    [<span class="number">110</span>,<span class="number">30</span>],</div><div class="line">                    [<span class="number">110</span>, <span class="number">60</span>],</div><div class="line">                    [<span class="number">120</span>, <span class="number">60</span>],</div><div class="line">                    [<span class="number">120</span>, <span class="number">30</span>],</div><div class="line">                    [<span class="number">110</span>,<span class="number">30</span>]</div><div class="line">                    ]]</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">&#123;</div><div class="line">空间位置:&#123;</div><div class="line">  $geoWithin:&#123;</div><div class="line">  $geometry: &#123;<span class="attr">type</span>:<span class="string">'Polygon'</span>,<span class="attr">coordinates</span>:[[[<span class="number">110</span>,<span class="number">30</span>],[<span class="number">110</span>, <span class="number">60</span>],[<span class="number">120</span>, <span class="number">60</span>],[<span class="number">120</span>, <span class="number">30</span>],[<span class="number">110</span>,<span class="number">30</span>]]]&#125;&#125;&#125;,</div><div class="line">  规范地址节简称:&#123;<span class="attr">$in</span>:[<span class="string">"DIS"</span>,<span class="string">"POI"</span>]</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="geoWithin圆范围查询（距离单位：弧度）"><a href="#geoWithin圆范围查询（距离单位：弧度）" class="headerlink" title="geoWithin圆范围查询（距离单位：弧度）"></a>geoWithin圆范围查询（距离单位：弧度）</h2><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">空间位置:&#123;</div><div class="line">        $geoWithin: &#123;</div><div class="line">            $centerSphere: [[<span class="number">119.22426261</span>, <span class="number">31.61467114</span>],<span class="number">0.0025</span>]</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line">联合索引查询</div><div class="line">&#123;</div><div class="line">空间位置:&#123;</div><div class="line">        $geoWithin: &#123;</div><div class="line">            $centerSphere: [[<span class="number">119.22426261</span>, <span class="number">31.61467114</span>],<span class="number">0.0025</span>]</div><div class="line">        &#125;</div><div class="line">    &#125;,</div><div class="line">     <span class="string">"规范地址节简称"</span>:<span class="string">"POI"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="矩形范围查询"><a href="#矩形范围查询" class="headerlink" title="矩形范围查询"></a>矩形范围查询</h2><p>$box，针对2d索引，不能针对GeoJson数据进行查询</p>
<h2 id="nearSphere缓冲区范围查询（距离单位：米）"><a href="#nearSphere缓冲区范围查询（距离单位：米）" class="headerlink" title="nearSphere缓冲区范围查询（距离单位：米）"></a>nearSphere缓冲区范围查询（距离单位：米）</h2><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">空间位置: &#123;</div><div class="line">        $nearSphere: &#123;</div><div class="line">            $geometry: &#123;</div><div class="line">                 <span class="string">"type"</span>:<span class="string">"Point"</span>,</div><div class="line">                 <span class="string">"coordinates"</span>:[<span class="number">119.22426261</span>, <span class="number">31.61467114</span>]</div><div class="line">            &#125;,</div><div class="line">          $maxDistance : <span class="number">5000</span></div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="intersect相交查询"><a href="#intersect相交查询" class="headerlink" title="intersect相交查询"></a>intersect相交查询</h2><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">空间位置: &#123;</div><div class="line">        $geoIntersects: &#123;</div><div class="line">            $geometry: &#123;</div><div class="line">                 <span class="string">"type"</span>:<span class="string">"Polygon"</span>,</div><div class="line">                 <span class="string">"coordinates"</span>:[[</div><div class="line">                    [<span class="number">110</span>,<span class="number">30</span>],</div><div class="line">                    [<span class="number">110</span>, <span class="number">60</span>],</div><div class="line">                    [<span class="number">120</span>, <span class="number">60</span>],</div><div class="line">                    [<span class="number">120</span>, <span class="number">30</span>],</div><div class="line">                    [<span class="number">110</span>,<span class="number">30</span>]</div><div class="line">                    ]]</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>图解 MongoDB 地理位置索引的实现原理： <a href="http://blog.nosqlfan.com/html/1811.html">http://blog.nosqlfan.com/html/1811.html</a><br>结合MongoDB开发LBS应用：<a href="http://www.infoq.com/cn/articles/depth-study-of-Symfony2">http://www.infoq.com/cn/articles/depth-study-of-Symfony2</a><br><a href="http://docs.mongodb.org/manual/applications/geospatial-indexes/">http://docs.mongodb.org/manual/applications/geospatial-indexes/</a></p>
<h2 id="MongoDB地理位置索引"><a href="#MongoDB地理位置索引" class="headerlink" title="MongoDB地理位置索引"></a>MongoDB地理位置索引</h2><p>MongoDB地理位置索引常用的有两种</p>
<pre><code>* 2d 平面坐标索引，适用于基于平面的坐标计算。也支持球面距离计算，不过官方推荐使用2dsphere索引。
* 2dsphere 几何球体索引，适用于球面几何运算
* 2d空间索引也支持Polygon+属性查询，但在组合索引/查询中为串行过程（低效），而2dsphere空间索引支持高效的组合索引/查询（即真正的GIS查询）
</code></pre><p>查询方式分三种情况：</p>
<pre><code>1. Inclusion。范围查询，如百度地图“视野内搜索”。
2. Inetersection。交集查询。不常用。
3. Proximity。周边查询，如“附近500内的餐厅”。
</code></pre><p>MongoDB查询地理位置默认有3种距离单位：</p>
<pre><code>* 米(meters)
* 平面单位(flat units，可以理解为经纬度的“一度”)
* 弧度(radians)。
</code></pre><p>通过GeoJSON格式查询，单位默认是米，通过其它方式则比较混乱<br>geoWithin的查询范围：经/纬度范围之和不能大于180<br><figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"> double[][] geometry = GeoUtil. createRectangle(<span class="number">-20</span>, <span class="number">90</span>, <span class="number">160</span>, <span class="number">-90</span>);</div><div class="line">&#123;空间位置: &#123;<span class="attr">$geoWithin</span>: &#123;<span class="attr">$geometry</span>: &#123;<span class="attr">type</span>:<span class="string">'Polygon'</span>,<span class="attr">coordinates</span>:[[[<span class="number">-20.0</span>,<span class="number">90.0</span>],[<span class="number">-20.0</span>,<span class="number">-90.0</span>],[<span class="number">160.0</span>,<span class="number">-90.0</span>],[<span class="number">160.0</span>,<span class="number">90.0</span>],[<span class="number">-20.0</span>,<span class="number">90.0</span>]]]&#125;&#125;&#125;,规范地址节简称:<span class="string">'POI'</span>,空间优先级:<span class="number">1</span>&#125;</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MongoDB </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MongoDB常用脚本]]></title>
      <url>http://geosmart.github.io/2015/12/28/MongoDB%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC/</url>
      <content type="html"><![CDATA[<p>记录一些工作过程中常用的MongoDB脚本。</p>
<hr>
<a id="more"></a>
<h1 id="数据库连接与关闭"><a href="#数据库连接与关闭" class="headerlink" title="数据库连接与关闭"></a>数据库连接与关闭</h1><h2 id="数据库连接"><a href="#数据库连接" class="headerlink" title="数据库连接"></a>数据库连接</h2><p>mongo uadb</p>
<h2 id="切换数据库"><a href="#切换数据库" class="headerlink" title="切换数据库"></a>切换数据库</h2><p>use uadb</p>
<h2 id="强制关闭mongodb进程"><a href="#强制关闭mongodb进程" class="headerlink" title="强制关闭mongodb进程"></a>强制关闭mongodb进程</h2><p>pkill mongod</p>
<h1 id="查询语句"><a href="#查询语句" class="headerlink" title="查询语句"></a>查询语句</h1><p>模糊查询<br>查询条件中包含like时，格式为：<code>{&quot;地址节全称&quot;:new RegExp(&quot;.*花园&quot;)}</code></p>
<h1 id="操作关键词"><a href="#操作关键词" class="headerlink" title="操作关键词"></a>操作关键词</h1><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="string">&gt;,</span> <span class="string">&gt;=,</span> <span class="string">&lt;,</span> <span class="string">&lt;=,</span> <span class="string">!=,</span> <span class="string">=</span></div><div class="line"><span class="string">$gt,</span> <span class="string">$gte,</span> <span class="string">$lt,</span> <span class="string">$lte,$ne,</span></div><div class="line"><span class="string">And，OR，In，NotIn</span></div><div class="line"><span class="string">无关键字,</span> <span class="string">$or,</span> <span class="string">$in，$nin</span></div></pre></td></tr></table></figure>
<h1 id="更新语句"><a href="#更新语句" class="headerlink" title="更新语句"></a>更新语句</h1><p>MongoDB更新字段名，如将AddressNode的adalias字段改为adtext：<code>db.AddressNode.update({}, {$rename:{&quot;adalias&quot;:&quot;adtext&quot;}}, false, true);</code></p>
<h1 id="数据备份恢复"><a href="#数据备份恢复" class="headerlink" title="数据备份恢复"></a>数据备份恢复</h1><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#数据备份</span></div><div class="line"><span class="string">mongodump</span> <span class="bullet">-d</span> <span class="string">uadb</span>  <span class="bullet">-u</span> <span class="string">uadb</span> <span class="bullet">-p</span> <span class="string">psd</span>  <span class="bullet">-o</span>  <span class="string">/usr/local/mongodb/dump</span></div><div class="line"><span class="comment">#数据还原</span></div><div class="line"><span class="string">mongorestore</span> <span class="bullet">-drop</span>  <span class="bullet">-d</span> <span class="string">uadb</span>   <span class="bullet">-u</span> <span class="string">uadb</span> <span class="bullet">-p</span> <span class="string">psd</span>  <span class="string">/usr/local/mongodb/dump/uadb</span></div><div class="line"><span class="string">```</span>  </div><div class="line"></div><div class="line"><span class="comment"># 删除数据库</span></div><div class="line"><span class="string">db.dropDatabase();</span></div><div class="line"></div><div class="line"><span class="comment"># maxConns并发连接数设置</span></div><div class="line"><span class="string">备注：V3.0版本以上参数为maxIncomingConnections，默认65536，详见</span></div><div class="line"><span class="string">[V3.2官方configuration-options文档](https://docs.mongodb.org/v3.2/reference/configuration-options/)</span></div><div class="line"><span class="comment">## 查询并发数</span></div><div class="line"><span class="string">db.serverStatus().connections</span></div><div class="line"><span class="comment">## ulimit 设置可以打开最大文件描述符的数量。</span></div><div class="line"><span class="string">查看最大文件打开数：ulimite</span> <span class="bullet">-n</span></div><div class="line"><span class="string">临时生效：`ulimit</span> <span class="bullet">-n</span> <span class="number">32768</span><span class="string">`</span></div><div class="line"><span class="string">永久生效：`vim</span> <span class="string">/etc/rc.local`</span> <span class="string">新增`ulimit</span> <span class="bullet">-n</span> <span class="number">32768</span><span class="string">`</span></div><div class="line"></div><div class="line"><span class="comment">## 重启mongodb服务，带上--maxConns参数</span></div><div class="line"><span class="string">`/usr/local/mongodb/bin/mongod</span> <span class="bullet">--dbpath</span> <span class="string">/usr/local/mongodb/data</span> <span class="bullet">--logpath</span> <span class="string">/usr/local/mongodb/log/mongodb.log</span> <span class="bullet">--maxConns=20000</span>  <span class="bullet">--fork</span> <span class="bullet">--smallfiles`</span></div><div class="line"></div><div class="line"><span class="comment"># MongoDB全局变量设置</span></div><div class="line"><span class="string">```yaml</span></div><div class="line"><span class="comment"># vim /etc/profile</span></div><div class="line"><span class="string">export</span> <span class="string">MONGODB_HOME=/usr/local/mongodb</span></div><div class="line"><span class="string">export</span> <span class="string">PATH=$MONGODB_HOME/bin:$PATH</span></div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MongoDB </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[CentOS配置本地Yum源]]></title>
      <url>http://geosmart.github.io/2015/12/07/CentOS%E9%85%8D%E7%BD%AE%E6%9C%AC%E5%9C%B0Yum%E6%BA%90/</url>
      <content type="html"><![CDATA[<p>现场环境没有网络，有些软件安装简直太痛苦，和maven的依赖链一样，最终耗时耗力不一定能安装好，此时制作本地yum只读光盘就是一个好主意，此文主要介绍如何配置本地yum。</p>
<hr>
<a id="more"></a>
<h1 id="建立本地源目录"><a href="#建立本地源目录" class="headerlink" title="建立本地源目录"></a>建立本地源目录</h1><p><code>mkdir   /mnt/cdrom</code></p>
<h1 id="挂载CentOS光盘"><a href="#挂载CentOS光盘" class="headerlink" title="挂载CentOS光盘"></a>挂载CentOS光盘</h1><p><code>mount   /dev/cdrom    /mnt/cdrom</code></p>
<h1 id="备份repo"><a href="#备份repo" class="headerlink" title="备份repo"></a>备份repo</h1><p>进入/etc/yum.repos.d目录，可以看到四个文件分别为CentOS-Base.repo、 CentOS-Media.repo 、CentOS-Vault.repo、CentOS-Vault.repo.repo,将其中三个改名或者移走留下CentOS-Media.repo<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /etc/yum.repos.d</div><div class="line">mv  CentOS-Base.repo     CentOS-Base.repo.bak</div><div class="line">mv  CentOS-Vault.repo     CentOS-Vault.repo.bak</div><div class="line">mv  CentOS-Vault.repo     CentOS-Vault.repo.bak</div><div class="line">cp  CentOS-Media.repo     CentOS-Vault.Media.bak</div></pre></td></tr></table></figure></p>
<h1 id="编辑CentOS-Media-repo"><a href="#编辑CentOS-Media-repo" class="headerlink" title="编辑CentOS-Media.repo"></a>编辑CentOS-Media.repo</h1><p>编辑CentOS-Media.repo：<code>vi  CentOS-Media.repo</code><br>将以下内容<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[c6-media]</div><div class="line">name=CentOS-<span class="variable">$releasever</span> - Media</div><div class="line">baseurl=file:///media/CentOS/</div><div class="line">        file:///media/cdrom/</div><div class="line">        file:///media/cdrecorder/</div><div class="line">gpgcheck=1</div><div class="line">enabled=0</div><div class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-6</div></pre></td></tr></table></figure></p>
<p>修改为<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[c6-media]</div><div class="line">name=CentOS-<span class="variable">$releasever</span> - Media</div><div class="line">baseurl=file:///mnt/cdrom/  <span class="comment">#这里为本地源路径</span></div><div class="line">        file:///media/cdrom/</div><div class="line">        file:///media/cdrecorder/</div><div class="line">gpgcheck=1</div><div class="line">enabled=1    <span class="comment">##开启本地源</span></div><div class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-6</div></pre></td></tr></table></figure></p>
<p>修改好保存并退出</p>
<h1 id="清yum缓存"><a href="#清yum缓存" class="headerlink" title="清yum缓存"></a>清yum缓存</h1><p><code>yum   clean</code>   </p>
<h1 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h1><p>如需要将yum源改为网络，还原<code>/etc/yum.repos.d</code>目录下的四个文件即可！</p>
]]></content>
      
        <categories>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> yum </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Samba安装配置笔记]]></title>
      <url>http://geosmart.github.io/2015/12/07/Samba%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>一个局域网的项目，需要在Linux上进行文件共享，最终选型samba，即通过jcifs实现java读写共享文件。</p>
<hr>
<a id="more"></a>
<h1 id="关于SMB"><a href="#关于SMB" class="headerlink" title="关于SMB"></a>关于SMB</h1><p>SMB（Server Message Block）:通信协议是微软（Microsoft）和英特尔(Intel)在1987年制定的协议，主要是作为Microsoft网络的通讯协议。SMB 是在会话层（session layer）和表示层（presentation layer）以及小部分应用层（application layer）的协议。SMB使用了NetBIOS的应用程序接口 （Application Program Interface，简称API）。另外，它是一个开放性的协议，允许了协议扩展——使得它变得更大而且复杂；大约有65个最上层的作业，而每个作业都超过120个函数，甚至Windows NT也没有全部支持到，最近微软又把 SMB 改名为 CIFS（Common Internet ile System），并且加入了许多新的特色。　　<br>SMB协议是基于TCP－NETBIOS下的，一般端口使用为139，445</p>
<h1 id="关于CIFS"><a href="#关于CIFS" class="headerlink" title="关于CIFS"></a>关于CIFS</h1><p>CIFS(Common Internet File System)：通用Internet文件系统在windows主机之间进行网络文件共享是通过使用微软公司自己的CIFS服务实现的。CIFS 是一个新提出的协议，它使程序可以访问远程Internet计算机上的文件并要求此计算机的服务。CIFS 使用客户/服务器模式。客户程序请求远在服务器上的服务器程序为它提供服务。服务器获得请求并返回响应。<br>CIFS是公共的或开放的SMB协议版本，并由Microsoft使用。SMB协议现在是局域网上用于服务器文件访问和打印的协议。<br>象SMB协议一样，CIFS在高层运行，而不象TCP/IP协议那样运行在底层。CIFS可以看做是应用程序协议如文件传输协议和超文本传输协议的一个实现。</p>
<h1 id="关于JCIFS"><a href="#关于JCIFS" class="headerlink" title="关于JCIFS"></a>关于JCIFS</h1><p>JCIFS是CIFS 在JAVA中的一个实现，是samba组织负责维护开发的一个开源项目，专注于使用java语言对cifs协议的设计和实现。他们将jcifs设计成为一个完整的，丰富的，具有可扩展能力且线程安全的客户端库。这一库可以应用于各种java虚拟机访问遵循CIFS/SMB网络传输协议的网络资源。类似于java.io.File的接口形式，在多线程的工作方式下被证明是有效而容易使用的。</p>
<h1 id="关于Samba"><a href="#关于Samba" class="headerlink" title="关于Samba"></a>关于Samba</h1><p>Samba，是种用来让UNIX系列的操作系统与微软Windows操作系统的SMB/CIFS（Server Message Block/Common Internet File System）网络协议做链接的自由软件。第三版不仅可访问及分享SMB的文件夹及打印机，本身还可以集成入Windows Server的域，扮演为域控制站（Domain Controller）以及加入Active Directory成员。简而言之，此软件在Windows与UNIX系列OS之间搭起一座桥梁，让两者的资源可互通有无。</p>
<h1 id="CentOS下yum安装配置Samba"><a href="#CentOS下yum安装配置Samba" class="headerlink" title="CentOS下yum安装配置Samba"></a>CentOS下yum安装配置Samba</h1><h2 id="新建用户samba"><a href="#新建用户samba" class="headerlink" title="新建用户samba"></a>新建用户samba</h2><p>useradd  samba</p>
<h2 id="设置samba用户密码"><a href="#设置samba用户密码" class="headerlink" title="设置samba用户密码"></a>设置samba用户密码</h2><p>passwd samba</p>
<h2 id="将samba加入到Samba用户数据库"><a href="#将samba加入到Samba用户数据库" class="headerlink" title="将samba加入到Samba用户数据库"></a>将samba加入到Samba用户数据库</h2><p><code>smbpasswd -a samba</code> windows访问samba共享目录时需要输入此用户名和密码</p>
<h2 id="设置目录访问权限"><a href="#设置目录访问权限" class="headerlink" title="设置目录访问权限"></a>设置目录访问权限</h2><p>chown -R   samba:samba /uadb/exchange/import<br>chown -R   samba:samba /uadb/exchange/export<br>chown -R  samba:samba /uadb/exchange/export_backup</p>
<h2 id="编辑smb-conf配置文件"><a href="#编辑smb-conf配置文件" class="headerlink" title="编辑smb.conf配置文件"></a>编辑smb.conf配置文件</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#vim/etc/samba/smb.conf</span></div><div class="line">[global]</div><div class="line"></div><div class="line">workgroup = WORKGROUP</div><div class="line">netbios name = sambaServer</div><div class="line">server string = Linux Samba Server TestServer</div><div class="line">security = user</div><div class="line"></div><div class="line">[import]</div><div class="line">path = /uadb/exchange/import</div><div class="line">writeable = yes</div><div class="line">browseable = yes</div><div class="line">guest ok = yes</div><div class="line"></div><div class="line">[<span class="built_in">export</span>]</div><div class="line">path = /uadb/exchange/<span class="built_in">export</span></div><div class="line">writeable = yes</div><div class="line">browseable = yes</div><div class="line">guest ok = yes</div></pre></td></tr></table></figure>
<h2 id="设置samba服务开机启动"><a href="#设置samba服务开机启动" class="headerlink" title="设置samba服务开机启动"></a>设置samba服务开机启动</h2><p><code>chkconfig smb on</code></p>
<h2 id="重启服samba服务"><a href="#重启服samba服务" class="headerlink" title="重启服samba服务"></a>重启服samba服务</h2><p><code>service smb  restart</code></p>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="连接路径问题"><a href="#连接路径问题" class="headerlink" title="连接路径问题"></a>连接路径问题</h2><ul>
<li>问题描述：cifs.smb.SmbException: The network name cannot be found.</li>
<li>问题定位：不能用绝对路径来访问，需要用samba的配置的共享文件夹名称来访问</li>
<li>解决方案：正确：<code>smb://samba:samba@192.168.1.80/import</code>；错误：<code>smb://samba:samba@192.168.1.80/uadb/exchange/import</code>  </li>
</ul>
<h1 id="Samba读写示例"><a href="#Samba读写示例" class="headerlink" title="Samba读写示例"></a>Samba读写示例</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line">/</div><div class="line"> * jcifs的开发方法类似java的文件操作功能，它的资源url定位：smb:<span class="comment">//&#123;user&#125;:&#123;password&#125;@&#123;host&#125;/&#123;path&#125;，</span></div><div class="line"> * smb为协议名，user和password分别为共享文件机子的登陆名和密码，@后面是要访问的资源的主机名或IP地址。最后是资源的共享文件夹名称和共享资源名。</div><div class="line"> * 例如smb:<span class="comment">//administrator:122122@192.168.0.22/test/response.txt。</span></div><div class="line"> *  </div><div class="line"> * SmbFile file = newSmbFile(<span class="string">"smb://guest:1234@192.168.3.56/share/a.txt"</span>);</div><div class="line"> *</div><div class="line">/</div><div class="line"><span class="meta">@Test</span></div><div class="line">true<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFile</span><span class="params">()</span> </span>&#123;</div><div class="line">truetrue<span class="keyword">try</span> &#123;</div><div class="line">truetruetrue<span class="comment">// 局域网共享文件，读文件</span></div><div class="line">truetruetrueSmbFile smbFile = <span class="keyword">new</span> SmbFile(<span class="string">"smb://samba:samba@192.168.1.80/import/test.db"</span>);</div><div class="line">truetruetrue<span class="comment">// 通过 smbFile.isDirectory();isFile()可以判断smbFile是文件还是文件夹</span></div><div class="line">truetruetrue<span class="keyword">int</span> length = smbFile.getContentLength();</div><div class="line">truetruetrue<span class="keyword">byte</span> buffer[] = <span class="keyword">new</span> <span class="keyword">byte</span>[length];</div><div class="line">truetruetrueSmbFileInputStream in = <span class="keyword">new</span> SmbFileInputStream(smbFile);</div><div class="line">truetruetrue<span class="keyword">while</span> ((in.read(buffer)) != -<span class="number">1</span>) &#123;</div><div class="line">truetruetruetrueSystem.out.write(buffer);</div><div class="line">truetruetruetrueSystem.out.println(<span class="string">"\n"</span> + buffer.length);</div><div class="line">truetruetrue&#125;</div><div class="line">truetruetruein.close();</div><div class="line">truetruetruesmbFile.delete();</div><div class="line"></div><div class="line">truetrue&#125; <span class="keyword">catch</span> (SmbAuthException e) &#123;</div><div class="line">truetruetruee.printStackTrace();</div><div class="line">truetrue&#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">truetruetruee.printStackTrace();</div><div class="line">truetrue&#125;</div><div class="line">true&#125;</div><div class="line"></div><div class="line">true<span class="meta">@Test</span></div><div class="line">true<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">wariteFile</span><span class="params">()</span> </span>&#123;</div><div class="line">truetrue<span class="keyword">try</span> &#123;</div><div class="line">truetruetrueSmbFile smbFileOut = <span class="keyword">new</span> SmbFile(<span class="string">"smb://samba:samba@192.168.1.80/import/test2.db"</span>);</div><div class="line">truetruetrue<span class="keyword">if</span> (!smbFileOut.exists())</div><div class="line">truetruetruetruesmbFileOut.createNewFile();</div><div class="line">truetruetrueSmbFileOutputStream out = <span class="keyword">new</span> SmbFileOutputStream(smbFileOut);</div><div class="line">truetruetrueout.write(<span class="string">"abcdefw"</span>.getBytes());</div><div class="line">truetruetrueout.close();</div><div class="line">truetruetruesmbFileOut.delete();</div><div class="line">truetrue&#125; <span class="keyword">catch</span> (SmbAuthException e) &#123;</div><div class="line">truetruetruee.printStackTrace();</div><div class="line">truetrue&#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">truetruetruee.printStackTrace();</div><div class="line">truetrue&#125;</div><div class="line">true&#125;</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> Samba </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hive学习笔记]]></title>
      <url>http://geosmart.github.io/2015/12/06/Hive%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>最近处理一个ETL的项目，技术选型是CDH的Hadoop方案，理所当然离不了Hive数据仓库，记录下Hive学习路上的点滴。</p>
<hr>
<a id="more"></a>
<h1 id="Hive简介"><a href="#Hive简介" class="headerlink" title="Hive简介"></a>Hive简介</h1><p>Apache Hive是一个建立在Hadoop架构之上的数据仓库。它能够提供数据的精炼，查询和分析。<br>Hive是建立在 Hadoop 上的数据仓库基础构架。它提供了一系列的工具，可以用来进行数据提取转化加载（ETL）。<br>Hive定义了简单的类 SQL 查询语言，称为 HQL，它允许熟悉 SQL 的用户查询数据。同时，这个语言也允许熟悉 MapReduce 开发者的开发自定义的 mapper 和 reducer 来处理内建的 mapper 和 reducer 无法完成的复杂的分析工作。</p>
<h1 id="Hive-Maven库"><a href="#Hive-Maven库" class="headerlink" title="Hive Maven库"></a>Hive Maven库</h1><p><a href="http://maven.outofmemory.cn/org.apache.hive/hive-exec/1.1.0/">Hive1.1.0离线包</a></p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://cwiki.apache.org/confluence/display/Hive/Home">Hive 官方Wiki</a></p>
<h1 id="hive-Maven库"><a href="#hive-Maven库" class="headerlink" title="hive Maven库"></a>hive Maven库</h1><p>有时候中央库的没法下载，但是spring.io提供的CDH的可以。<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">&lt;!-- cdh  repository--&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">repository</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">id</span>&gt;</span>cdh-5.3.0<span class="tag">&lt;/<span class="name">id</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://repo.spring.io/libs-release-remote/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">repository</span>&gt;</span></div><div class="line"></div><div class="line"><span class="comment">&lt;!-- hive jdbc --&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hive.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div></pre></td></tr></table></figure></p>
<h1 id="Hive-With-Hbase"><a href="#Hive-With-Hbase" class="headerlink" title="Hive With Hbase"></a>Hive With Hbase</h1><h1 id="Hive存储Hbase数据-测试语句"><a href="#Hive存储Hbase数据-测试语句" class="headerlink" title="Hive存储Hbase数据 测试语句"></a>Hive存储Hbase数据 测试语句</h1><h2 id="参考资料-1"><a href="#参考资料-1" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="http://zh.hortonworks.com/blog/hbase-via-hive-part-1/">hbase-via-hive1</a><br><a href="http://www.n10k.com/blog/hbase-via-hive-pt2/">hbase-via-hive2</a></p>
<h2 id="示例SQL"><a href="#示例SQL" class="headerlink" title="示例SQL"></a>示例SQL</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span>  <span class="keyword">User</span> (userId <span class="keyword">STRING</span>, address <span class="keyword">STRING</span>,<span class="keyword">name</span> <span class="keyword">STRING</span> ,photo <span class="keyword">STRING</span> ,psd <span class="keyword">STRING</span>)</div><div class="line"><span class="keyword">STORED</span> <span class="keyword">BY</span> <span class="string">'org.apache.hadoop.hive.hbase.HBaseStorageHandler'</span></div><div class="line"><span class="keyword">WITH</span> SERDEPROPERTIES (<span class="string">'hbase.columns.mapping'</span> = <span class="string">':key,f:data'</span>)</div><div class="line">TBLPROPERTIES (<span class="string">'hbase.table.name'</span> = <span class="string">'User'</span>);</div></pre></td></tr></table></figure>
<h1 id="hive-新建表"><a href="#hive-新建表" class="headerlink" title="hive 新建表"></a>hive 新建表</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> Geocoding_Address (</div><div class="line"><span class="keyword">SID</span> <span class="keyword">String</span>,SAddress <span class="keyword">String</span></div><div class="line">)</div><div class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span></div><div class="line"><span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\t'</span></div><div class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> TEXTFILE;</div><div class="line"><span class="comment">--PARTITIONED BY(STR STRING)</span></div></pre></td></tr></table></figure>
<h2 id="hive新增partion"><a href="#hive新增partion" class="headerlink" title="hive新增partion"></a>hive新增partion</h2><p>alter table alter2 add partition (insertdate=’2008-01-01’) location ‘2008/01/01’;</p>
<h1 id="Hive数据导入"><a href="#Hive数据导入" class="headerlink" title="Hive数据导入"></a>Hive数据导入</h1><h2 id="导入hdfs数据到hive表"><a href="#导入hdfs数据到hive表" class="headerlink" title="导入hdfs数据到hive表"></a>导入hdfs数据到hive表</h2><p><code>load data inpath &#39;/user/uadb/test.txt&#39; into table test ;</code></p>
<h2 id="导入本地文件到hive表"><a href="#导入本地文件到hive表" class="headerlink" title="导入本地文件到hive表"></a>导入本地文件到hive表</h2><p><code>load data local inpath &#39;/home/uadb/test.txt&#39; into table test ;</code></p>
<h1 id="Hive自定义函数"><a href="#Hive自定义函数" class="headerlink" title="Hive自定义函数"></a>Hive自定义函数</h1><ul>
<li><p>UDF:一进一出（ 输入一行输出一行 On-to-one maping ）</p>
<blockquote>
<p>transformation of one row value into another one, which can be added with UDFs (User Defined Function);</p>
</blockquote>
</li>
<li><p>UDAF:多进一出（ 输入多行输出一行 Many-to-one maping ）</p>
<blockquote>
<p>transformation of multiple row values into one, which can be added with UDAFs (User Defined Aggregate Functions);</p>
</blockquote>
</li>
<li><p>UDTF:一进多出（ 输入一行输出多行 On-to-many maping ）</p>
<blockquote>
<p>transformation of one row value into many, which can be added with UDTFs (User Defined Table Functions).</p>
</blockquote>
</li>
</ul>
<h2 id="查看UDF依赖的jar包"><a href="#查看UDF依赖的jar包" class="headerlink" title="查看UDF依赖的jar包"></a>查看UDF依赖的jar包</h2><p>查看自定义函数依赖的jar包：<code>list jars</code>;</p>
<h2 id="hue导入-删除jar"><a href="#hue导入-删除jar" class="headerlink" title="hue导入/删除jar"></a>hue导入/删除jar</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">add  jar /user/hive/test/test.jar;</div><div class="line"><span class="keyword">delete</span> jar /<span class="keyword">user</span>/hive/<span class="keyword">test</span>/test.jar;</div></pre></td></tr></table></figure>
<h2 id="新建临时UDF函数"><a href="#新建临时UDF函数" class="headerlink" title="新建临时UDF函数"></a>新建临时UDF函数</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">create</span> <span class="keyword">temporary</span> <span class="keyword">function</span>  testUDF  <span class="keyword">as</span> <span class="string">"com.lt.uadb.match.udf.SkeletonAddressNodeMapUDF"</span>;</div><div class="line"><span class="keyword">select</span> a.skeleton_addressnode,testUDF(a.skeleton_addressnode,<span class="string">'一'</span>)   <span class="keyword">from</span> matchingAddress <span class="keyword">as</span> a</div></pre></td></tr></table></figure>
<h2 id="Hive-UUID"><a href="#Hive-UUID" class="headerlink" title="Hive  UUID"></a>Hive  UUID</h2><p>select reflect(“java.util.UUID”, “randomUUID”) from table</p>
<h2 id="UDF程序打包"><a href="#UDF程序打包" class="headerlink" title="UDF程序打包"></a>UDF程序打包</h2><p>UDF程序打包有两张方式：</p>
<ol>
<li>以类fatjar工具将UDF和依赖打成一个jar包，但是打包部署耗时；</li>
<li>将jar包分为稳定和经常更新的两类；通过执行add和delete动态添加依赖</li>
</ol>
<h2 id="CM中设置Hive自动加载UDTF依赖JAR"><a href="#CM中设置Hive自动加载UDTF依赖JAR" class="headerlink" title="CM中设置Hive自动加载UDTF依赖JAR"></a>CM中设置Hive自动加载UDTF依赖JAR</h2><p><a href="http://blog.csdn.net/xiao_jun_0820/article/details/38302451">参考cloudera mamager中配置hive加载自定义的jar包</a></p>
<ol>
<li>进入Hive配置页</li>
<li>在高级选型中设置<code>Hive 辅助 JAR 目录</code>：<code>/etc/hive/udtflib</code></li>
<li>设置Gateway Default Group（hive-env.sh 的 Gateway 客户端环境高级配置代码段（安全阀））：<code>HIVE_AUX_JARS_PATH=/etc/hive/udtflib</code></li>
<li>重启集群，CM会自动将Hive辅助JAR目录中的jar包分发到Hive客户端</li>
</ol>
<h2 id="UDF日志查看"><a href="#UDF日志查看" class="headerlink" title="UDF日志查看"></a>UDF日志查看</h2><p>除了开发环境的Junit单元测试外，生产环境的日志查看非常重要，</p>
<ol>
<li>通过在hue -jobbrowser中查看syslog；</li>
<li>通过在YARN的ResourceManager UI中查看Mapreduce打印的详细日志，日志会打印syso的内容；</li>
</ol>
<h1 id="Hive-JDBC"><a href="#Hive-JDBC" class="headerlink" title="Hive JDBC"></a>Hive JDBC</h1><p>HiveServer和HiveServer2都有两种模式，分别为嵌入式和单机服务器模式，</p>
<ol>
<li>嵌入式URI为”jdbc:hive://“或者”jdbc:hive2://“；</li>
<li>单机服务器模式的URI为”jdbc:hive://host:port/dbname”或者”jdbc:hive2://host:port/dbname”；</li>
<li>HiveServer使用的JDBC驱动类为org.apache.hadoop.hive.jdbc.HiveDriver，HiveServer2使用的驱动类为org.apache.hive.jdbc.HiveDriver；</li>
</ol>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="tmp-hive-on-HDFS-should-be-writable"><a href="#tmp-hive-on-HDFS-should-be-writable" class="headerlink" title="/tmp/hive on HDFS should be writable"></a>/tmp/hive on HDFS should be writable</h2><p>问题日志：Exception in thread “main” java.lang.RuntimeException: java.lang.RuntimeException: The root scratch dir: /tmp/hive on HDFS should be writable. Current permissions are: rwx-wx–x<br>解决方法：</p>
<ol>
<li>更新权限hdfs目录权限：<code>hadoop fs -chmod 777 /tmp/hive</code></li>
<li>hdfs执行：<code>hadoop fs -rm -r /tmp/hive;</code></li>
<li>local执行：<code>rm -rf /tmp/hive</code></li>
</ol>
<h2 id="hive-query-can’t-generate-result-set-via-jdbc"><a href="#hive-query-can’t-generate-result-set-via-jdbc" class="headerlink" title="hive query can’t generate result set via jdbc"></a>hive query can’t generate result set via jdbc</h2><p>解决：Use stmt.execute() for a query that makes a new table. of executeQuery. The executeQuery() is now only for select queries (DML) while execute is probably for DDL (data definition).</p>
<ul>
<li>DDL（Data Definition Language 数据定义语言）用于操作对象和对象的属性，这种对象包括数据库本身，以及数据库对象，像：表、视图等等，DDL对这些对象和属性的管理和定义具体表现在Create、Drop和Alter上；  </li>
<li>DML（Data Manipulation Language 数据操控语言）用于操作数据库对象中包含的数据，也就是说操作的单位是记录；  </li>
</ul>
<h2 id="Hive-Jdbc调用UDTF问题"><a href="#Hive-Jdbc调用UDTF问题" class="headerlink" title="Hive Jdbc调用UDTF问题"></a>Hive Jdbc调用UDTF问题</h2><ul>
<li>问题描述：在Java中以Hive的JDBC接口调用UDTF语句，逐行执行到create temporary function就会报错，但在Hue中（客户端连接）能正常执行</li>
<li><p>问题日志</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">org.apache.hive.service.cli.HiveSQLException: Error <span class="keyword">while</span> processing statement: FAILED: Execution Error, <span class="keyword">return</span> code <span class="number">1</span> from org.apache.hadoop.hive.ql.exec.FunctionTask</div><div class="line">    at org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:<span class="number">315</span>)</div></pre></td></tr></table></figure>
</li>
<li><p>解决方案：</p>
</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> Hadoop </tag>
            
            <tag> Hive </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MyEclipse安装MapReduceTools插件]]></title>
      <url>http://geosmart.github.io/2015/11/20/MyEclipse%E5%AE%89%E8%A3%85MapReduceTools%E6%8F%92%E4%BB%B6/</url>
      <content type="html"><![CDATA[<p>Windwos10开发环境测试MapReduce程序，需自行编译hadoop2x-eclipse-plugin，生成MyEclipse2014的MapReduceTolls插件，可结合MRUnit进行单元测试。</p>
<hr>
<a id="more"></a>
<p><a href="http://my.oschina.net/muou/blog/408543">参考中文教程</a><br>具体配置步骤如下：</p>
<h2 id="安装MyEclipse2014"><a href="#安装MyEclipse2014" class="headerlink" title="安装MyEclipse2014"></a>安装MyEclipse2014</h2><p>Myeclipse安装位置：C:\Dev\myeclipse（路径无中文字段/空格）</p>
<h2 id="下载Hadoop-lib"><a href="#下载Hadoop-lib" class="headerlink" title="下载Hadoop lib"></a>下载Hadoop lib</h2><p>下载hadoop-2.6.0.tar.gz并解压到目录（路径无中文字段/空格）<br><a href="http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.6.0/hadoop-2.6.0.tar.gz">hadoop-2.6.0.tar.gz下载地址</a><br>解压后置于F:\Dev\hadoop\hadoop-2.6.0</p>
<h2 id="配置Ant"><a href="#配置Ant" class="headerlink" title="配置Ant"></a>配置Ant</h2><p><a href="http://archive.apache.org/dist/ant/binaries/apache-ant-1.9.0-bin.zip">ant-1.9.0下载地址</a><br>配置环境变量</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="string">ANT_HOME=F:\Dev\apache-ant-1.9.0</span></div><div class="line"><span class="string">PATH</span> <span class="string">后追加</span> <span class="string">;%ANT_HOME%\bin</span></div></pre></td></tr></table></figure>
<p>检验Ant配置：<code>ant -version</code></p>
<h2 id="编译hadoop-eclipse-plugin插件"><a href="#编译hadoop-eclipse-plugin插件" class="headerlink" title="编译hadoop-eclipse-plugin插件"></a>编译hadoop-eclipse-plugin插件</h2><p><a href="https://github.com/winghc/hadoop2x-eclipse-plugin">hadoop-eclipse-plugin下载地址</a><br>解压后置于F:\Dev\hadoop\hadoop2x-eclipse-plugin-master<br>打开cmd执行以下脚本编译hadoop-eclipse-plugin插件</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="string">cd</span> <span class="attr">F:\Dev\hadoop\hadoop2x-eclipse-plugin-master\src\contrib\eclipse-plugin</span></div><div class="line"><span class="string">ant</span> <span class="string">jar</span> <span class="bullet">-Dversion=2.6.0</span> <span class="bullet">-Declipse.home=C:\Dev\myeclipse</span> <span class="bullet">-Dhadoop.home=F:\Dev\hadoop\hadoop-2.6.0</span></div></pre></td></tr></table></figure>
<p>执行成功后生成的jar位置：<br><code>F:\Dev\hadoop\hadoop2x-eclipse-plugin-master\build\contrib\eclipse-plugin\hadoop-eclipse-plugin-2.6.0.jar</code></p>
<h2 id="配置hadoop-eclipse-plugin-2-6-0-jar"><a href="#配置hadoop-eclipse-plugin-2-6-0-jar" class="headerlink" title="配置hadoop-eclipse-plugin-2.6.0.jar"></a>配置hadoop-eclipse-plugin-2.6.0.jar</h2><ol>
<li>将<code>hadoop-eclipse-plugin-2.6.0.jar</code>剪切到<code>C:\Dev\myeclipse\dropins</code>目录；</li>
<li>重启Myeclipse即完成MyEclipse2014的MapReduceTolls插件；</li>
<li>可在Window&gt;Show View&gt;MapReduce Tools打开插件视图。</li>
</ol>
<h2 id="配置hadoop-location"><a href="#配置hadoop-location" class="headerlink" title="配置hadoop location"></a>配置hadoop location</h2><p>Location name ：随便取个名字 比如 hadoop2.6.0<br>Map/Reduce（V2） Master ：根据hdfs-site.xml中配置dfs.datanode.ipc.address的值填写，50020<br>DFS Master： Name Node的IP和端口，根据core-site.xml中配置fs.defaultFS的值填写，8020</p>
<p>CDH配置文件位置：/etc/hadoop/conf.cloudera.yarn</p>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> Hadoop </tag>
            
            <tag> MapReduce </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[CDH使用问题记录]]></title>
      <url>http://geosmart.github.io/2015/10/27/CDH%E4%BD%BF%E7%94%A8%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/</url>
      <content type="html"><![CDATA[<h1 id="如何制作CDH-Agent-虚拟机模板"><a href="#如何制作CDH-Agent-虚拟机模板" class="headerlink" title="如何制作CDH Agent 虚拟机模板"></a>如何制作CDH Agent 虚拟机模板</h1><ul>
<li>问题描述：CDH Manager安装配置好一台Agent机器A（VM虚拟机）后，如果以A复制出B，在集群中B与A会冲突，每次Host Inspector只能检测到一个</li>
<li>问题定位：判断为SCM库中HOSTS表的HOST_IDENTIFIER字段冲突导致</li>
<li>解决思路：ClouderaManager是根据什么自动生成HOST_IDENTIFIER的？ 如何复制VM虚拟机才能不冲突？</li>
<li>问题解决：由于在复制cm-5.4.7到agent之前启动了cloudera-scm-agent，在/opt/cm-5.4.7/lib/cloudera-scm-agent中生成response.avro和uuid两个文件，cloudera的HOST_IDENTIFIER读取的就是uuid文件的文本，停止agent&gt;删除response.avro和uuid&gt;启动agent，问题解决</li>
</ul>
<h1 id="Cloudera-Manager无法删除某项服务"><a href="#Cloudera-Manager无法删除某项服务" class="headerlink" title="Cloudera Manager无法删除某项服务"></a>Cloudera Manager无法删除某项服务</h1><p>删除依赖关系或在命令中查看正在执行的（卡死）的命令，中止即可</p>
<h1 id="Key-Value-Store-Indexer服务总是异常终止"><a href="#Key-Value-Store-Indexer服务总是异常终止" class="headerlink" title="Key-Value Store Indexer服务总是异常终止"></a>Key-Value Store Indexer服务总是异常终止</h1><ul>
<li>问题描述：重新构建的Solr Collection和Index，数据写入少量没问题，程序批量写入时（&gt;250条）服务就自动终止   </li>
<li>问题定位：Java OOM虚拟机内存溢出问题</li>
<li>解决方式：hbase-indexer github-issues：<a href="https://github.com/NGDATA/hbase-indexer/issues/66">Lily Hbase Indexers always auto exit</a>，<br>通过向hbase-indexer官方github提交issue寻求帮助，确认是OOM问题！<ul>
<li>运行<code>hbase-indexer server</code>在单个hbase-server服务器调试运行（不在cloudera管理下运行），不会发生OOM</li>
<li>CM集中修改参数<em>Lily HBase Indexer的Java堆栈大小</em>，默认设置的是131M，改为1GB后重新启动服务，往Hbase写入数据时，SOlr索引生成正常，Hbase-Indexer未自动退出。</li>
</ul>
</li>
</ul>
<p>其他参考资料：<a href="https://github.com/NGDATA/hbase-indexer/blob/master/hbase-indexer-morphlines/src/main/java/com/ngdata/hbaseindexer/morphline/LocalMorphlineResultToSolrMapper.java">LocalMorphlineResultToSolrMapper源码</a></p>
<h1 id="创建-Hive-Metastore-数据库表失败"><a href="#创建-Hive-Metastore-数据库表失败" class="headerlink" title="创建 Hive Metastore 数据库表失败"></a>创建 Hive Metastore 数据库表失败</h1><p>问题日志：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">++ exec /opt/cloudera/parcels/CDH-<span class="number">5.4</span>.7-<span class="number">1</span>.cdh5.4.7.p0.3/lib/hadoop/bin/hadoop jar /opt/cloudera/parcels/CDH-<span class="number">5.4</span>.7-<span class="number">1</span>.cdh5.4.7.p0.3/lib/hive/lib/hive-cli-<span class="number">1.1</span>.0-cdh5.4.7.jar org.apache.hive.beeline.HiveSchemaTool -verbose -dbType mysql -initSchema</div><div class="line">org.apache.hadoop.hive.metastore.HiveMetaException: Failed to load driver</div><div class="line">org.apache.hadoop.hive.metastore.HiveMetaException: Failed to load driver</div><div class="line">trueat org.apache.hive.beeline.HiveSchemaHelper.getConnectionToMetastore(HiveSchemaHelper.java:<span class="number">79</span>)</div><div class="line">trueat org.apache.hive.beeline.HiveSchemaTool.getConnectionToMetastore(HiveSchemaTool.java:<span class="number">113</span>)</div><div class="line">trueat org.apache.hive.beeline.HiveSchemaTool.testConnectionToMetastore(HiveSchemaTool.java:<span class="number">159</span>)</div><div class="line">trueat org.apache.hive.beeline.HiveSchemaTool.doInit(HiveSchemaTool.java:<span class="number">257</span>)</div><div class="line">trueat org.apache.hive.beeline.HiveSchemaTool.doInit(HiveSchemaTool.java:<span class="number">243</span>)</div><div class="line">trueat org.apache.hive.beeline.HiveSchemaTool.main(HiveSchemaTool.java:<span class="number">473</span>)</div><div class="line">trueat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</div><div class="line">trueat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">57</span>)</div><div class="line">trueat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</div><div class="line">trueat java.lang.reflect.Method.invoke(Method.java:<span class="number">606</span>)</div><div class="line">trueat org.apache.hadoop.util.RunJar.run(RunJar.java:<span class="number">221</span>)</div><div class="line">trueat org.apache.hadoop.util.RunJar.main(RunJar.java:<span class="number">136</span>)</div><div class="line">Caused by: java.lang.ClassNotFoundException: com.mysql.jdbc.Driver</div><div class="line">trueat java.net.URLClassLoader$<span class="number">1</span>.run(URLClassLoader.java:<span class="number">366</span>)</div><div class="line">trueat java.net.URLClassLoader$<span class="number">1</span>.run(URLClassLoader.java:<span class="number">355</span>)</div><div class="line">trueat java.security.AccessController.doPrivileged(Native Method)</div><div class="line">trueat java.net.URLClassLoader.findClass(URLClassLoader.java:<span class="number">354</span>)</div><div class="line">trueat java.lang.ClassLoader.loadClass(ClassLoader.java:<span class="number">425</span>)</div><div class="line">trueat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:<span class="number">308</span>)</div><div class="line">trueat java.lang.ClassLoader.loadClass(ClassLoader.java:<span class="number">358</span>)</div><div class="line">trueat java.lang.Class.forName0(Native Method)</div><div class="line">trueat java.lang.Class.forName(Class.java:<span class="number">195</span>)</div><div class="line">trueat org.apache.hive.beeline.HiveSchemaHelper.getConnectionToMetastore(HiveSchemaHelper.java:<span class="number">70</span>)</div><div class="line">true... <span class="number">11</span> more</div><div class="line">true*** schemaTool failed ***</div></pre></td></tr></table></figure>
<h1 id="CDH5使用端口"><a href="#CDH5使用端口" class="headerlink" title="CDH5使用端口"></a>CDH5使用端口</h1><p><a href="http://www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/cdh_ig_ports_cdh5.html"> CDH 5 组件使用的端口</a></p>
<h1 id="Hbase运行中止问题"><a href="#Hbase运行中止问题" class="headerlink" title="Hbase运行中止问题"></a>Hbase运行中止问题</h1><ul>
<li>错误日志</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//cat /var/log/hbase/hbase-cmf-hbase-REGIONSERVER-slave3.lt.com.log.out</span></div><div class="line"></div><div class="line">Error syncing, request close of wal</div><div class="line">java.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: <span class="string">"slave3.lt.com/192.168.1.103"</span>; destination host is: <span class="string">"server1.lt.com"</span>:<span class="number">8020</span>;  </div><div class="line">trueat com.sun.proxy.$Proxy20.updateBlockForPipeline(Unknown Source)</div><div class="line">Caused by: java.io.IOException: Connection reset by peer</div></pre></td></tr></table></figure>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="string">Unable</span> <span class="string">to</span> <span class="string">reconnect</span> <span class="string">to</span> <span class="string">ZooKeeper</span> <span class="string">service,</span> <span class="string">session</span> <span class="number">0x1508e4d86eb8047</span> <span class="string">has</span> <span class="string">expired,</span> <span class="string">closing</span> <span class="string">socket</span> <span class="string">connection</span></div></pre></td></tr></table></figure>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="string">Client</span> <span class="string">session</span> <span class="string">timed</span> <span class="string">out,</span> <span class="string">have</span> <span class="string">not</span> <span class="string">heard</span> <span class="string">from</span> <span class="string">server</span> <span class="string">in</span> <span class="number">40003</span><span class="string">ms</span> <span class="string">for</span> <span class="string">sessionid</span> <span class="number">0x1508e4d86eb88ef</span><span class="string">,</span> <span class="string">closing</span> <span class="string">socket</span> <span class="string">connection</span> <span class="string">and</span> <span class="string">attempting</span> <span class="string">reconnect</span></div><div class="line"></div><div class="line"><span class="string">Unable</span> <span class="string">to</span> <span class="string">reconnect</span> <span class="string">to</span> <span class="string">ZooKeeper</span> <span class="string">service,</span> <span class="string">session</span> <span class="number">0x1508e4d86eb88f5</span> <span class="string">has</span> <span class="string">expired,</span> <span class="string">closing</span> <span class="string">socket</span> <span class="string">connection</span></div></pre></td></tr></table></figure>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="string">Opening</span> <span class="string">socket</span> <span class="string">connection</span> <span class="string">to</span> <span class="string">server</span> <span class="string">server1.lt.com/192.168.1.91:2181.</span> <span class="string">Will</span> <span class="string">not</span> <span class="string">attempt</span> <span class="string">to</span> <span class="string">authenticate</span> <span class="string">using</span> <span class="string">SASL</span> <span class="string">(unknown</span> <span class="string">error)</span></div></pre></td></tr></table></figure>
<ul>
<li>参数说明<br>hbase参数</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="string">hbase.regionserver.lease.period</span></div><div class="line"><span class="string">默认值：60000</span></div><div class="line"><span class="string">说明：客户端租用HRegion</span> <span class="string">server</span> <span class="string">期限，即超时阀值。</span></div><div class="line"><span class="string">调优：这个配合hbase.client.scanner.caching使用，如果内存够大，但是取出较多数据后计算过程较长，可能超过这个阈值，适当可设置较长的响应时间以防被认为宕机</span></div></pre></td></tr></table></figure>
<p>zookeeper参数<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="string">zookeeper.session.timeout</span></div><div class="line"><span class="string">默认值：60000</span></div><div class="line"><span class="string">说明：ZooKeeper</span> <span class="string">服务器允许客户端协商的最大会话超时时间（以毫秒为单位）</span></div><div class="line"><span class="string">调优：zookeeper的超时时间不要设置太大，在服务挂掉的情况下，会反映很慢。</span></div></pre></td></tr></table></figure></p>
<ul>
<li>解决方式<br>在CM的Hbase配置hbase.regionserver.lease.period默认值改为4（分钟）<br>在CM的Hbase配置hbase.rpc.timeout默认值改为5（分钟）</li>
</ul>
<h1 id="Hbase数据操作失败"><a href="#Hbase数据操作失败" class="headerlink" title="Hbase数据操作失败"></a>Hbase数据操作失败</h1><p>问题描述：connection to slave3.lt.com/192.168.1.103:60020 from geosmart: closing ipc connection to slave3.lt.com/192.168.1.103:60020: Connection refused: no further information<br>java.net.ConnectException: Connection refused: no further information</p>
<h1 id="Hive-UDTF问题"><a href="#Hive-UDTF问题" class="headerlink" title="Hive UDTF问题"></a>Hive UDTF问题</h1><p>问题日志：Error while compliling statement:Failed IndexOutOfBoundException Index.1 Size.1<br>解决方案：<br>init初始化中的ArrayList<ObjectInspector> 和fieldNames个数和类型要对应一致</p>
<h1 id="Hive-UDTF-code-2问题"><a href="#Hive-UDTF-code-2问题" class="headerlink" title="Hive UDTF code 2问题"></a>Hive UDTF code 2问题</h1><p>问题日志：Error while processing statement: FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask<br>解决方案：/var/log/hive中查看错误日志定位错误</p>
<h1 id="HUE新建HDFS目录"><a href="#HUE新建HDFS目录" class="headerlink" title="HUE新建HDFS目录"></a>HUE新建HDFS目录</h1><p>问题描述: you are a Hue admin but not a HDFS superuser, “hdfs” or part of HDFS supergroup, “supergroup”<br>解决方案：在hue中新增hdfs用户，以hdfs用户登录创建目录和上传文件</p>
<h1 id="Hive-Metastore-canary-创建数据库失败"><a href="#Hive-Metastore-canary-创建数据库失败" class="headerlink" title="Hive Metastore canary 创建数据库失败"></a>Hive Metastore canary 创建数据库失败</h1><p>问题描述： Hive Metastore canary 创建数据库失败<br>日志：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="string">Caused</span> <span class="attr">by:</span> <span class="string">org.datanucleus.exceptions.NucleusException:</span> <span class="string">Attempt</span> <span class="string">to</span> <span class="string">invoke</span> <span class="string">the</span> <span class="string">"BONECP"</span> <span class="string">plugin</span> <span class="string">to</span> <span class="string">create</span> <span class="string">a</span> <span class="string">ConnectionPool</span> <span class="string">gave</span> <span class="string">an</span> <span class="string">error</span> <span class="string">:</span></div><div class="line"><span class="string">The</span> <span class="string">specified</span> <span class="string">datastore</span> <span class="string">driver</span> <span class="string">("com.mysql.jdbc.Driver")</span> <span class="string">was</span> <span class="string">not</span> <span class="string">found</span> <span class="string">in</span> <span class="string">the</span> <span class="string">CLASSPATH.</span> <span class="string">Please</span> <span class="string">check</span> <span class="string">your</span> <span class="string">CLASSPATH</span> <span class="string">specification,</span> <span class="string">and</span> <span class="string">the</span> <span class="string">name</span> <span class="string">of</span> <span class="string">the</span> <span class="string">driver</span></div></pre></td></tr></table></figure>
<p>问题定位：读取hive数据时报找不到mysql驱动<br>问题解决：</p>
<pre><code>*    尝试1
</code></pre><p><code>/opt/cloudera/parcels/CDH-5.4.7-1.cdh5.4.7.p0.3/lib/hive/lib</code><br><code>cp  /opt/cloudera/parcels/CDH-5.4.7-1.cdh5.4.7.p0.3/lib/sqoop/lib/mysql-connector-java-5.1.36-bin.jar   /opt/cloudera/parcels/CDH-5.4.7-1.cdh5.4.7.p0.3/lib/hive/lib</code></p>
<pre><code>*  尝试2
</code></pre><p>在<code>/etc/hive/conf.cloudera.hive/hive-env.sh</code>中发现一句<code>$(find /usr/share/java/mysql-connector-java.jar</code><br>于是将驱动拷贝到指定目录解决问题<br><code>cp  /mnt/mysql-connector-java-5.1.36-bin.jar     /usr/share/java/mysql-connector-java.jar</code><br><code>cp  /mnt/mysql-connector-java-5.1.36-bin.jar    /opt/cloudera/parcels/CDH-5.4.7-1.cdh5.4.7.p0.3/lib/hadoop</code><br>解决问题</p>
<p>2）hive数据库初始化问题<br>问题日志：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="string">Query</span> <span class="string">for</span> <span class="string">candidates</span> <span class="string">of</span> <span class="string">org.apache.hadoop.hive.metastore.model.MVersionTable</span> <span class="string">and</span> <span class="string">subclasses</span> <span class="string">resulted</span> <span class="string">in</span> <span class="literal">no</span> <span class="string">possible</span> <span class="string">candidates</span></div><div class="line"><span class="string">Required</span> <span class="string">table</span> <span class="string">missing</span> <span class="string">:</span> <span class="string">"`VERSION`"</span> <span class="string">in</span> <span class="string">Catalog</span> <span class="string">""</span> <span class="string">Schema</span> <span class="string">""</span><span class="string">.</span> <span class="string">DataNucleus</span> <span class="string">requires</span> <span class="string">this</span> <span class="string">table</span> <span class="string">to</span> <span class="string">perform</span> <span class="string">its</span> <span class="string">persistence</span> <span class="string">operations.</span> <span class="string">Either</span> <span class="string">your</span> <span class="string">MetaData</span> <span class="string">is</span> <span class="string">incorrect,</span> <span class="string">or</span> <span class="string">you</span> <span class="string">need</span> <span class="string">to</span> <span class="string">enable</span> <span class="string">"datanucleus.autoCreateTables"</span></div><div class="line"><span class="string">org.datanucleus.store.rdbms.exceptions.MissingTableException:</span> <span class="string">Required</span> <span class="string">table</span> <span class="string">missing</span> <span class="string">:</span> <span class="string">"`VERSION`"</span> <span class="string">in</span> <span class="string">Catalog</span> <span class="string">""</span> <span class="string">Schema</span> <span class="string">""</span><span class="string">.</span> <span class="string">DataNucleus</span> <span class="string">requires</span> <span class="string">this</span> <span class="string">table</span> <span class="string">to</span> <span class="string">perform</span> <span class="string">its</span> <span class="string">persistence</span> <span class="string">operations.</span> <span class="string">Either</span> <span class="string">your</span> <span class="string">MetaData</span> <span class="string">is</span> <span class="string">incorrect,</span> <span class="string">or</span> <span class="string">you</span> <span class="string">need</span> <span class="string">to</span> <span class="string">enable</span> <span class="string">"datanucleus.autoCreateTables"</span></div><div class="line">    <span class="string">at</span> <span class="string">org.datanucleus.store.rdbms.table.AbstractTable.exists(AbstractTable.java:485)</span></div></pre></td></tr></table></figure>
<p><a href="http://community.cloudera.com/t5/Batch-SQL-Apache-Hive/Reinstalling-Hive-Metastore-Database/td-p/24015">解决参考:Reinstalling-Hive-Metastore-Database</a></p>
<h2 id="在cm中删除oozie、hue和hive服务，重建数据库"><a href="#在cm中删除oozie、hue和hive服务，重建数据库" class="headerlink" title="在cm中删除oozie、hue和hive服务，重建数据库"></a>在cm中删除oozie、hue和hive服务，重建数据库</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"># mysql -uroot -proot</div><div class="line"><span class="keyword">drop</span> <span class="keyword">database</span> hive;</div><div class="line"><span class="keyword">drop</span> <span class="keyword">database</span> hue;</div><div class="line"><span class="keyword">drop</span> <span class="keyword">database</span> oozie;</div><div class="line"><span class="keyword">create</span> <span class="keyword">database</span> hive <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci;  </div><div class="line"><span class="keyword">create</span> <span class="keyword">database</span> hue <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci;</div><div class="line"><span class="keyword">create</span> <span class="keyword">database</span> oozie <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci;</div></pre></td></tr></table></figure>
<h2 id="重新添加hive服务"><a href="#重新添加hive服务" class="headerlink" title="重新添加hive服务"></a>重新添加hive服务</h2><p>配置数据库192.168.1.1(server)/hive(db)/root(user)/root(psd)</p>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> Hadoop </tag>
            
            <tag> CDH </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hadoop集群离线部署]]></title>
      <url>http://geosmart.github.io/2015/10/20/Hadoop%E9%9B%86%E7%BE%A4%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2/</url>
      <content type="html"><![CDATA[<p>GFW墙的没人性，只能费时费力搞个离线安装教程，一路遇到很多问题，稍微深入了解了一些ClouderaManager的内部实现，步骤概要：<br>IP配置&gt;Host配置&gt;关闭iptables防火墙&gt;关闭SELinux&gt;配置NTP时钟服务&gt;SSH无密码登陆&gt;安装JDK&gt;<br>配置CM安装包&gt;配置Parcel&gt;配置MySQL&gt;初始化SCM数据库&gt;复制到Agent机器&gt;<br>启动CM Server&gt;配置Service&gt;设置Server/Agent开机启动</p>
<hr>
<a id="more"></a>
<h1 id="部署文档参考"><a href="#部署文档参考" class="headerlink" title="部署文档参考"></a>部署文档参考</h1><p><a href="http://blog.csdn.net/scgaliguodong123_/article/details/46661881">离线安装Cloudera Manager5.3.4与CDH5.3.4</a><br><a href="http://www.tuicool.com/articles/ENjmeaY">离线安装Cloudera Manager 5和CDH5(最新版5.1.3) 完全教程</a><br><a href="http://www.cnblogs.com/modestmt/p/4540818.html">离线安装 Cloudera ( CDH 5.x )</a><br><a href="http://www.aboutyun.com/thread-8921-1-1.html">离线安装 Cloudera</a><br><a href="http://www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/cm_ig_install_path_b.html#cmig_topic_6_6">官方教程</a><br><a href="http://www.cloudera.com/content/www/en-us/documentation/enterprise/latest/topics/cdh_vd_cdh5_maven_repo.html#concept_emz_fg3_kq_unique_2">cdh对应hadoop版本</a></p>
<h1 id="软件准备"><a href="#软件准备" class="headerlink" title="软件准备"></a>软件准备</h1><p><a href="http://www.cloudera.com/content/www/en-us/documentation/enterprise/latest/topics/cm_vd.html">官方资源地址</a></p>
<ul>
<li>JDK7最低版本：1.7.0_67</li>
<li>cloudera-manager-installer：<a href="http://archive.cloudera.com/cm5/installer/latest/cloudera-manager-installer.bin">下载地址</a></li>
<li>cloudera-manager-bin:<a href="https://archive.cloudera.com/cm5/cm/5/">下载地址</a></li>
<li>CDH Parcel：<a href="http://archive.cloudera.com/cdh5/parcels/latest/">下载地址</a></li>
</ul>
<h1 id="虚拟机准备"><a href="#虚拟机准备" class="headerlink" title="虚拟机准备"></a>虚拟机准备</h1><p>Cloudera Manager+MySQL</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">Cloudera Manager</div><div class="line">HostMonitor</div><div class="line">Event Server</div><div class="line">Activity Monitor</div><div class="line">Service Monitor</div><div class="line">Alert Publisher </div><div class="line">MySQL</div></pre></td></tr></table></figure>
<p>Master</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">HDFS：Active NameNode</div><div class="line">Hbase：Active Master</div><div class="line">YARN：Active ResourceManager,JobHistory Server</div></pre></td></tr></table></figure>
<p>Standby Master </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">HDFS：Standby NameNode、DataNode</div><div class="line">Hbase：Standby Master、RegionServer</div><div class="line">YARN：Standby ResourceManager,Node Manager</div><div class="line">HUE：Hue Server</div></pre></td></tr></table></figure>
<p>Slave1</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">HDFS：DataNode、FailoverController、JournalNode</div><div class="line">Hbase：RegionServer</div><div class="line">YARN：Node Manager</div><div class="line">Impala：Impala CatalogServer,Impala StateStore,Impala lama ApplicationMaster</div><div class="line">Oozie：Oozie Server</div><div class="line">Hive：Hive Server</div><div class="line">Sor：Solr Server</div><div class="line">ZoomKeeper：zoomKeeper Server</div></pre></td></tr></table></figure>
<p>Slave2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">HDFS：DataNode、FailoverController、JournalNode</div><div class="line">Hbase：RegionServer</div><div class="line">YARN：Node Manager</div><div class="line">Impala：Impala Daemon</div><div class="line">Hive：Hive Metastore Server</div><div class="line">Sor：Solr Server</div><div class="line">ZoomKeeper：zoomKeeper Server</div></pre></td></tr></table></figure>
<p>Slave3</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">HDFS：DataNode、FailoverController、JournalNode</div><div class="line">Hbase：RegionServer</div><div class="line">YARN：Node Manager</div><div class="line">Impala：Impala Daemon</div><div class="line">Spark：Spark History Server</div><div class="line">Hive：Hive Metastore Server</div><div class="line">Sor：Solr Server</div><div class="line">ZoomKeeper：zoomKeeper Server</div></pre></td></tr></table></figure>
<p>Slave4</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">HDFS：DataNode</div><div class="line">Hbase：RegionServer</div><div class="line">YARN：Node Manager</div><div class="line">Impala：Impala Daemon</div></pre></td></tr></table></figure>
<h1 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h1><p>将 JDK 提取至 /usr/java/jdk-version；例如：/usr/java/jdk1.7.0_80<br>将装有 JDK 的目录通过符号链接至 /usr/java/default；例如：<br>ln -s /usr/java/jdk.1.7.0_80 /usr/java/default </p>
<h1 id="MySQL数据库配置"><a href="#MySQL数据库配置" class="headerlink" title="MySQL数据库配置"></a>MySQL数据库配置</h1><h2 id="安装配置MySQL"><a href="#安装配置MySQL" class="headerlink" title="安装配置MySQL"></a>安装配置MySQL</h2><h2 id="配置SCM数据库"><a href="#配置SCM数据库" class="headerlink" title="配置SCM数据库"></a>配置SCM数据库</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">--hive数据库</span></div><div class="line"><span class="keyword">create</span> <span class="keyword">database</span> hive <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci;</div><div class="line"><span class="comment">--集群监控数据库</span></div><div class="line"><span class="keyword">create</span> <span class="keyword">database</span> amon <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci;</div><div class="line"><span class="comment">--hue数据库</span></div><div class="line"><span class="keyword">create</span> <span class="keyword">database</span> hue <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci;</div><div class="line"><span class="comment">--oozie数据库</span></div><div class="line"><span class="keyword">create</span> <span class="keyword">database</span> oozie <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span> utf8 <span class="keyword">COLLATE</span> utf8_general_ci;</div><div class="line"></div><div class="line"><span class="keyword">grant</span> all <span class="keyword">privileges</span> <span class="keyword">on</span> *.* <span class="keyword">to</span> <span class="string">'root'</span>@<span class="string">'%'</span> <span class="keyword">identified</span> <span class="keyword">by</span> <span class="string">'root'</span> <span class="keyword">with</span> <span class="keyword">grant</span> <span class="keyword">option</span>;</div><div class="line"></div><div class="line"><span class="keyword">grant</span> all <span class="keyword">privileges</span> <span class="keyword">on</span> *.* <span class="keyword">to</span> <span class="string">'root'</span>@<span class="string">'master'</span> <span class="keyword">identified</span> <span class="keyword">by</span> <span class="string">'root'</span> <span class="keyword">with</span> <span class="keyword">grant</span> <span class="keyword">option</span>;</div><div class="line"><span class="keyword">grant</span> all <span class="keyword">privileges</span> <span class="keyword">on</span> *.* <span class="keyword">to</span> <span class="string">'root'</span>@<span class="string">'192.168.1.100'</span> <span class="keyword">identified</span> <span class="keyword">by</span> <span class="string">'root'</span> <span class="keyword">with</span> <span class="keyword">grant</span> <span class="keyword">option</span>;</div><div class="line"><span class="keyword">grant</span> all <span class="keyword">privileges</span> <span class="keyword">on</span> *.* <span class="keyword">to</span> <span class="string">'root'</span>@<span class="string">'192.168.1.183'</span> <span class="keyword">identified</span> <span class="keyword">by</span> <span class="string">'root'</span> <span class="keyword">with</span> <span class="keyword">grant</span> <span class="keyword">option</span>;</div><div class="line"><span class="keyword">flush</span> <span class="keyword">privileges</span>;</div></pre></td></tr></table></figure>
<h1 id="安装cloudera-manager"><a href="#安装cloudera-manager" class="headerlink" title="安装cloudera-manager"></a>安装cloudera-manager</h1><p>主节点解压安装<br>cloudera manager的目录默认位置在/opt下，<br>解压：<code>cd /opt &amp;&amp; tar xzvf cloudera-manager*.tar.gz</code></p>
<h1 id="添加cloudera-scm用户："><a href="#添加cloudera-scm用户：" class="headerlink" title="添加cloudera-scm用户："></a>添加cloudera-scm用户：</h1><p>Agent节点执行：useradd –system –home=/opt/cm/run/cloudera-scm-server/ –no-create-home –shell=/bin/false –comment  “Cloudera SCM User” cloudera-scm</p>
<h1 id="更改cloudera-scm用户目录"><a href="#更改cloudera-scm用户目录" class="headerlink" title="更改cloudera-scm用户目录"></a>更改cloudera-scm用户目录</h1><ul>
<li>查看用户ID:id cloudera-scm</li>
<li>查看用户home：echo ~cloudera-scm</li>
<li>修改用户home：usermod -d /opt/cm/run/cloudera-scm-server/ -u ${用户ID} cloudera-scm<br>如：usermod -d /opt/cm/run/cloudera-scm-server/ -u 493 cloudera-scm</li>
</ul>
<h1 id="安装-mysql-connector："><a href="#安装-mysql-connector：" class="headerlink" title="安装 mysql connector："></a>安装 mysql connector：</h1><p><a href="http://www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/cm_ig_mysql.html?scroll=cmig_topic_5_5">外部MySQL数据库配置</a><br><a href="http://www.cnblogs.com/peijie-tech/articles/4446011.html">mysql-connector-java与mysql的版本对应关系</a></p>
<ul>
<li>下载<a href="http://ftp.ntu.edu.tw/MySQL/Downloads/Connector-J/">mysql-connector-java-5.1.36.tar.gz</a>文件中提取 JDBC 驱动程序 JAR 文件。</li>
<li>解压：<code>tar zxvf mysql-connector-java-5.1.36.tar.gz</code>，</li>
<li>解压后找到mysql-connector-java-5.1.33-bin.jar，放到/opt/cm/share/cmf/lib/中。</li>
</ul>
<h1 id="初始化CM5的数据库："><a href="#初始化CM5的数据库：" class="headerlink" title="初始化CM5的数据库："></a>初始化CM5的数据库：</h1><p>在SCM主节点初始化SCM数据库<br>格式:scm_prepare_database.sh 数据库类型 数据库 服务器IP 用户名 密码 –scm-host Cloudera_Manager_Server机器IP scm scm scm<br>如：<code>/opt/cm/share/cmf/schema/scm_prepare_database.sh  mysql -h 192.168.1.161 -uroot -proot --scm-host 192.168.1.100 scm scm scm</code><br>重新执行的话，需要在mysql服务器执行  <code>drop database scm;</code></p>
<h1 id="Agent配置"><a href="#Agent配置" class="headerlink" title="Agent配置"></a>Agent配置</h1><ul>
<li>修改配置文件<br><code>/opt/cm/etc/cloudera-scm-agent/config.ini</code>中的server_host为主节点的主机名。</li>
<li>务必解压后不能启动server和agent，纯净版本同步Agent到其他节点<br><code>scp -r /opt/cm root@192.168.1.91:/opt/</code>  </li>
</ul>
<p>复制运行中的agent需执行以下脚本后复制</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">service cloudera-scm-agent stop </div><div class="line">chkconfig cloudera-scm-agent off  </div><div class="line">poweroff</div></pre></td></tr></table></figure>
<ul>
<li>修改hostname、hosts</li>
</ul>
<h1 id="准备Parcels，用以安装CDH5"><a href="#准备Parcels，用以安装CDH5" class="headerlink" title="准备Parcels，用以安装CDH5"></a>准备Parcels，用以安装CDH5</h1><p>将CHD5相关的Parcel包放到主节点的/opt/cloudera/parcel-repo/目录中（parcel-repo需要手动创建）。<br>相关的文件如下：</p>
<blockquote>
<p>CDH-5.4.7-1.cdh5.4.7.p0.3-el6.parcel<br>CDH-5.4.7-1.cdh5.4.7.p0.3-el6.parcel.sha1<br>manifest.json</p>
</blockquote>
<p>将CDH-5.4.7-1.cdh5.4.7.p0.3-el6.parcel.sha1，重命名为CDH-5.4.7-1.cdh5.4.7.p0.3-el6.parcel.sha，这点必须注意，否则，系统会重新下载CDH-5.4.7-1.cdh5.4.7.p0.3-el6.parcel文件。</p>
<h1 id="启动脚本"><a href="#启动脚本" class="headerlink" title="启动脚本"></a>启动脚本</h1><ul>
<li>启动cloudera manager server服务：<code>/opt/cm/etc/init.d/cloudera-scm-server start</code></li>
<li>启动cloudera manager agent服务：<code>/opt/cm/etc/init.d/cloudera-scm-agent start</code></li>
</ul>
<h1 id="设置为-开机自动启动"><a href="#设置为-开机自动启动" class="headerlink" title="设置为 开机自动启动"></a>设置为 开机自动启动</h1><ul>
<li>server端</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">echo "/opt/cm/etc/init.d/cloudera-scm-server start" &gt;&gt; /etc/rc.local </div><div class="line">echo "/opt/cm/etc/init.d/cloudera-scm-agent start" &gt;&gt; /etc/rc.local</div><div class="line">cat  /etc/rc.local</div></pre></td></tr></table></figure>
<ul>
<li>agent端</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">启动cloudera manager agent服务</span></div><div class="line">echo "/opt/cm/etc/init.d/cloudera-scm-agent start" &gt;&gt; /etc/rc.local</div><div class="line">cat  /etc/rc.local</div></pre></td></tr></table></figure>
<ul>
<li>chkconfig服务方式更优，但目前无效，待完善TODO</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">启动cloudera manager server服务 </span></div><div class="line">cp /opt/cm/etc/init.d/cloudera-scm-server /etc/init.d/cloudera-scm-server</div><div class="line">chkconfig cloudera-scm-server on</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash">启动cloudera manager agent服务</span></div><div class="line">cp /opt/cm/etc/init.d/cloudera-scm-agent /etc/init.d/cloudera-scm-agent</div><div class="line">chkconfig cloudera-scm-agent on</div></pre></td></tr></table></figure>
<h1 id="CDH5的安装配置"><a href="#CDH5的安装配置" class="headerlink" title="CDH5的安装配置"></a>CDH5的安装配置</h1><p>进入cm网站：192.168.1.100:7180</p>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> Hadoop </tag>
            
            <tag> CDH </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker学习笔记]]></title>
      <url>http://geosmart.github.io/2015/10/03/Docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>dockerfile就像人体的DNA，提供自动构建一切的元数据。</p>
<hr>
<a id="more"></a>
<h1 id="Docker基本概念"><a href="#Docker基本概念" class="headerlink" title="Docker基本概念"></a>Docker基本概念</h1><h2 id="镜像（Image）"><a href="#镜像（Image）" class="headerlink" title="镜像（Image）"></a>镜像（Image）</h2><p>Docker 镜像就是一个只读的模板。镜像可以用来创建 Docker 容器。</p>
<h2 id="容器（Container）"><a href="#容器（Container）" class="headerlink" title="容器（Container）"></a>容器（Container）</h2><p>Docker 利用容器来运行应用。<br>容器是从镜像创建的运行实例。它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。<br>可以把容器看做是一个简易版的 Linux 环境（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。<br>*注：镜像是只读的，容器在启动的时候创建一层可写层作为最上层。</p>
<h2 id="仓库（Repository）"><a href="#仓库（Repository）" class="headerlink" title="仓库（Repository）"></a>仓库（Repository）</h2><p>仓库是集中存放镜像文件的场所。有时候会把仓库和仓库注册服务器（Registry）混为一谈，并不严格区分。实际上，仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag）。<br>仓库分为公开仓库（Public）和私有仓库（Private）两种形式。<br>*注：Docker 仓库的概念跟 Git 类似，注册服务器可以理解为 GitHub 这样的托管服务。</p>
<p>理解了这三个概念，就理解了 Docker 的整个生命周期。</p>
<h1 id="Docker相关术语"><a href="#Docker相关术语" class="headerlink" title="Docker相关术语"></a>Docker相关术语</h1><h2 id="LXC"><a href="#LXC" class="headerlink" title="LXC"></a>LXC</h2><p>LXC（Linux Container）Linux Container容器是一种内核虚拟化技术，可以提供轻量级的虚拟化，以便隔离进程和资源，而且不需要提供指令解释机制以及全虚拟化的其他复杂性。相当于C++中的NameSpace。容器有效地将由单个操作系统管理的资源划分到孤立的组中，以更好地在孤立的组之间平衡有冲突的资源使用需求。与传统虚拟化技术相比，它的优势在于：<br>（1）与宿主机使用同一个内核，性能损耗小；<br>（2）不需要指令级模拟；<br>（3）不需要即时(Just-in-time)编译；<br>（4）容器可以在CPU核心的本地运行指令，不需要任何专门的解释机制；<br>（5）避免了准虚拟化和系统调用替换中的复杂性；<br>（6）轻量级隔离，在隔离的同时还提供共享机制，以实现容器与宿主机的资源共享。<br>总结：Linux Container是一种轻量级的虚拟化的手段。<br>Linux Container提供了在单一可控主机节点上支持多个相互隔离的server container同时执行的机制。Linux Container有点像chroot，提供了一个拥有自己进程和网络空间的虚拟环境，但又有别于虚拟机，因为lxc是一种操作系统层次上的资源的虚拟化。</p>
<h2 id="Hypervisor"><a href="#Hypervisor" class="headerlink" title="Hypervisor"></a>Hypervisor</h2><p>Hypervisor是一种运行在物理服务器和操作系统之间的中间软件层,可允许多个操作系统和应用共享一套基础物理硬件，因此也可以看作是虚拟环境中的“元”操作系统，它可以协调访问服务器上的所有物理设备和虚拟机，也叫虚拟机监视器（Virtual Machine Monitor）。Hypervisor是所有虚拟化技术的核心。非中断地支持多工作负载迁移的能力是Hypervisor的基本功能。当服务器启动并执行Hypervisor时，它会给每一台虚拟机分配适量的内存、CPU、网络和磁盘，并加载所有虚拟机的客户操作系统。</p>
<h1 id="容器VS-虚拟机"><a href="#容器VS-虚拟机" class="headerlink" title="容器VS 虚拟机"></a>容器VS 虚拟机</h1><p>容器会比虚拟机更高效，因为它们能够分享一个内核和分享应用程序库。相比虚拟机系统，这也将使得 Docker使用的内存更小，即便虚拟机利用了内存超量使用的技术。部署容器时共享底层的镜像层也可以减少存储占用。IBM 的 Boden Russel 已经做了一些基准测试来说明两者之间的不同。</p>
<p>相比虚拟机系统，容器具有较低系统开销的优势，所以在容器中，应用程序的运行效率将会等效于在同样的应用程序在虚拟机中运行，甚至效果更佳。</p>
<h1 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h1><ul>
<li>查看所有镜像：docker images：</li>
<li>删除所有镜像：docker rmi $(docker images | grep none | awk ‘{print $3}’ | sort -r)</li>
<li>删除所有容器：docker rm $(docker ps -a -q)</li>
<li>停止/启动/杀死一个容器：stop/start/kill &lt;容器名orID&gt; </li>
</ul>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><ol>
<li><p>docker: relocation error: docker: symbol dm_task_get_info_with_deferred_remove, version Base not defined in file libdevmapper.so.1.02 with link time reference<br>解决方案：<br>You may have to enable the public_ol6_latest repo in order to get this package.<br><code>sudo yum-config-manager --enable public_ol6_latest</code><br>And then install the package:<br><code>sudo yum install device-mapper-event-libs</code></p>
</li>
<li><p>Error response from daemon: EOF</p>
</li>
</ol>
<h1 id="Docker方案"><a href="#Docker方案" class="headerlink" title="Docker方案"></a>Docker方案</h1><h2 id="Kitematic"><a href="#Kitematic" class="headerlink" title="Kitematic"></a>Kitematic</h2><blockquote>
<p><a href="https://github.com/kitematic/kitematic">Kitematic</a> 是一个具有现代化的界面设计的自由开源软件，它可以让我们在 Docker 中交互式执行任务。Kitematic 设计的非常漂亮、界面美观。使用它，我们可以简单快速地开箱搭建我们的容器而不需要输入命令，可以在图形用户界面中通过简单的点击从而在容器上部署我们的应用。<br>Kitematic 集成了 Docker Hub，允许我们搜索、拉取任何需要的镜像，并在上面部署应用。它同时也能很好地切换到命令行用户接口模式。目前，它包括了自动映射端口、可视化更改环境变量、配置卷、流式日志以及其它功能。</p>
</blockquote>
<p><a href="http://www.linuxidc.com/Linux/2015-09/122601.htm">参考教程</a><br>安装问题</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Error creating machine: exit status 1</div><div class="line">You will want to check the provider to make sure the machine and associated resources were properly removed.</div></pre></td></tr></table></figure>
<p>待解决：<a href="https://github.com/docker/toolbox/issues/245">github issue</a></p>
<h1 id="待解决问题"><a href="#待解决问题" class="headerlink" title="待解决问题"></a>待解决问题</h1><h2 id="如何自动部署Github程序到Docker镜像"><a href="#如何自动部署Github程序到Docker镜像" class="headerlink" title="如何自动部署Github程序到Docker镜像"></a>如何自动部署Github程序到Docker镜像</h2><h2 id="构建搭载Tomcat环境的镜像"><a href="#构建搭载Tomcat环境的镜像" class="headerlink" title="构建搭载Tomcat环境的镜像"></a>构建搭载Tomcat环境的镜像</h2><h2 id="部署前端web应用"><a href="#部署前端web应用" class="headerlink" title="部署前端web应用"></a>部署前端web应用</h2><h2 id="部署后端Java服务"><a href="#部署后端Java服务" class="headerlink" title="部署后端Java服务"></a>部署后端Java服务</h2>]]></content>
      
        <categories>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Tomcat服务器运维]]></title>
      <url>http://geosmart.github.io/2015/10/03/Tomcat%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4/</url>
      <content type="html"><![CDATA[<p>记录Tomcat服务器的配置安装脚本</p>
<hr>
<a id="more"></a>
<h1 id="Tomcat安装"><a href="#Tomcat安装" class="headerlink" title="Tomcat安装"></a>Tomcat安装</h1><h2 id="配置系统环境变量"><a href="#配置系统环境变量" class="headerlink" title="配置系统环境变量"></a>配置系统环境变量</h2><ul>
<li>JAVA_HOME=D:\java\JDK1.6</li>
<li>PATH环境变量加入：%JAVA_HOME%\bin</li>
</ul>
<h2 id="安装Tomcat"><a href="#安装Tomcat" class="headerlink" title="安装Tomcat"></a>安装Tomcat</h2><ul>
<li>开始-运行-cmd</li>
<li>输入：cd D:\tomcat\bin进入tomcat安装目录</li>
<li>输入：service install tomcat7进行安装（xx为tomcat服务名称，可随意给，也可不设置）</li>
</ul>
<h2 id="设置为开机启动"><a href="#设置为开机启动" class="headerlink" title="设置为开机启动"></a>设置为开机启动</h2><p>开始-运行-services.msc进入服务管理器，将刚才安装的tomcat服务设置为自动，并启动，此时tomcat已成功安装并成功注册为自动启动的系统服务。</p>
<h2 id="卸载Tomcat"><a href="#卸载Tomcat" class="headerlink" title="卸载Tomcat"></a>卸载Tomcat</h2><ul>
<li>输入：cd D:\tomcat\bin进入tomcat安装目录</li>
<li>输入：service remove tomcat7进行卸载（xx为已安装tomcat服务的名称，以前没设置就不用写）</li>
</ul>
<h1 id="tomcat内存配置"><a href="#tomcat内存配置" class="headerlink" title="tomcat内存配置"></a>tomcat内存配置</h1><h2 id="windows服务内存配置"><a href="#windows服务内存配置" class="headerlink" title="windows服务内存配置"></a>windows服务内存配置</h2><p>编辑tomcat\bin\service.bat<br>找到<code>&quot;%EXECUTABLE%&quot; //US//%SERVICE_NAME% --JvmOptions</code><br>新增<code>-Xms1024M;-Xmx2048M;-XX:PermSize=512M;-XX:MaxPermSize=1024M</code>;<br>然后卸载掉服务–&gt;安装服务–&gt;启动服务，生效。<br>在localhost:8080/manager/status 查看修改后的可用内存大小</p>
<h2 id="console控制台内存配置"><a href="#console控制台内存配置" class="headerlink" title="console控制台内存配置"></a>console控制台内存配置</h2><p>编辑catalina.bat，找到下面行修改</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="string">rem</span> <span class="bullet">-----</span> <span class="string">Execute</span> <span class="string">The</span> <span class="string">Requested</span> <span class="string">Command</span> <span class="bullet">---------------------------------------</span></div><div class="line"><span class="string">set</span> <span class="string">JAVA_OPTS=%JAVA_OPTS%</span> <span class="bullet">-server</span>  <span class="bullet">-Xms6400m</span> <span class="bullet">-Xmx6400m</span>  <span class="attr">-XX:MaxNewSize=2048m</span> <span class="attr">-XX:PermSize=512M</span> <span class="attr">-XX:MaxPermSize=1024m</span></div></pre></td></tr></table></figure>
<h2 id="Tomcat与Jetty"><a href="#Tomcat与Jetty" class="headerlink" title="Tomcat与Jetty"></a>Tomcat与Jetty</h2><ul>
<li>单纯比较 Tomcat与Jetty的性能意义不是很大，只能说在某种使用场景下，它表现的各有差异。因为它们面向的使用场景不尽相同。</li>
<li>从架构上来看 Tomcat 在处理少数非常繁忙的连接上更有优势，也就是说连接的生命周期如果短的话，Tomcat 的总体性能更高。而 Jetty 刚好相反，Jetty可以同时处理大量连接而且可以长时间保持这些连接。例如像一些 web 聊天应用非常适合用 Jetty 做服务器，像淘宝的 web 旺旺就是用 Jetty 作为 Servlet 引擎。由于 Jetty 的架构非常简单，作为服务器它可以按需加载组件，这样不需要的组件可以去掉，这样无形可以减少服务器本身的内存开销，处理一次请求也是可以减少产生的临时对象，这样性能也会提高。另外 Jetty 默认使用的是 NIO 技术在处理 I/O 请求上更占优势，Tomcat 默认使用的是 BIO，在处理静态资源时，Tomcat 的性能不如 Jetty。</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Tomcat </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[正则表达式学习笔记]]></title>
      <url>http://geosmart.github.io/2015/10/03/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>记录常用正则以及相关测试工具</p>
<h1 id="关于正则表达式"><a href="#关于正则表达式" class="headerlink" title="关于正则表达式"></a>关于正则表达式</h1><p>正则表达式（Regular Expression，在代码中常简写为regex、regexp或RE），计算机科学的一个概念。正则表达式使用单个字符串来描述、匹配一系列符合某个句法规则的字符串。在很多文本编辑器里，正则表达式通常被用来检索、替换那些符合某个模式的文本。<br>许多程序设计语言都支持利用正则表达式进行字符串操作。例如，在Perl中就内建了一个功能强大的正则表达式引擎。正则表达式这个概念最初是由Unix中的工具软件（例如sed和grep）普及开的。正则表达式通常缩写成“regex”，单数有regexp、regex，复数有regexps、regexes、regexen。</p>
<hr>
<a id="more"></a>
<h1 id="常用正则"><a href="#常用正则" class="headerlink" title="常用正则"></a>常用正则</h1><p>在编写处理字符串的程序或网页时，经常会有查找符合某些复杂规则的字符串的需要。正则表达式就是用于描述这些规则的工具。换句话说，正则表达式就是记录文本规则的代码。</p>
<h2 id="元字符"><a href="#元字符" class="headerlink" title="元字符"></a>元字符</h2><table>
<thead>
<tr>
<th>代码</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>.</td>
<td>匹配除换行符以外的任意字符</td>
</tr>
<tr>
<td>\w</td>
<td>匹配字母或数字或下划线或汉字</td>
</tr>
<tr>
<td>\s</td>
<td>匹配任意的空白符</td>
</tr>
<tr>
<td>\d</td>
<td>匹配数字</td>
</tr>
<tr>
<td>\b</td>
<td>匹配单词的开始或结束</td>
</tr>
<tr>
<td>^</td>
<td>匹配字符串的开始</td>
</tr>
<tr>
<td>$</td>
<td>匹配字符串的结束</td>
</tr>
</tbody>
</table>
<p>示例</p>
<ul>
<li>1号10号：<code>^[0-9]+号[0-9]+号?$</code></li>
<li>TAB+TAB关键词+TAB与TAA分隔符+TAA+TAA关键词，除TAB其余都可为空,如1号-10号：<br><code>^[0-9０-９零一二三四五六七八九十壹贰叁肆伍陆柒捌玖拾]+[号]?([-])?([0-9０-９零一二三四五六七八九十壹贰叁肆伍陆柒捌玖拾]+)?[号]?$</code></li>
</ul>
<h2 id="转义字符"><a href="#转义字符" class="headerlink" title="转义字符"></a>转义字符</h2><p>如果你想查找元字符本身的话，比如你查找.或\，就出现了问题：你没办法指定它们，因为它们会被解释成别的意思。这时你就得使用\来取消这些字符的特殊意义。因此，你应该使用\.和\*，要查找\本身，你也得用\.</p>
<table>
<thead>
<tr>
<th>代码</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>.</td>
<td>\.</td>
</tr>
<tr>
<td>*</td>
<td>\*</td>
</tr>
<tr>
<td>\</td>
<td>\\</td>
</tr>
</tbody>
</table>
<h2 id="重复"><a href="#重复" class="headerlink" title="重复"></a>重复</h2><table>
<thead>
<tr>
<th>代码</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>*</td>
<td>重复零次或更多次</td>
</tr>
<tr>
<td>+</td>
<td>重复一次或更多次</td>
</tr>
<tr>
<td>?</td>
<td>重复零次或一次</td>
</tr>
<tr>
<td>{n}</td>
<td>重复n次</td>
</tr>
<tr>
<td>{n,}</td>
<td>重复n次或更多次</td>
</tr>
<tr>
<td>{n,m}</td>
<td>重复n到m次</td>
</tr>
</tbody>
</table>
<h2 id="字符类"><a href="#字符类" class="headerlink" title="字符类"></a>字符类</h2><p>要想查找数字，字母或数字，空白是很简单的，因为已经有了对应这些字符集合的元字符，但是如果你想匹配没有预定义元字符的字符集合(比如元音字母a,e,i,o,u),应该怎么办？<br>指定一个字符范围，像[0-9]代表的含意与\d就是完全一致的：一位数字；同理[a-z0-9A-Z_]也完全等同于\w（如果只考虑英文的话）。</p>
<h2 id="分支条件"><a href="#分支条件" class="headerlink" title="分支条件"></a>分支条件</h2><p>正则表达式里的分枝条件指的是有几种规则，如果满足其中任意一种规则都应该当成匹配，具体方法是用 | 把不同的规则分隔开。</p>
<h2 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h2><p>可以用小括号来指定子表达式(也叫做分组)<br>如IP格式：：<code>(\d{1,3}\.){3}\d{1,3}</code>是一个简单的IP地址匹配表达式：\d{1,3}匹配1到3位的数字，(\d{1,3}.){3}匹配三位数字加上一个英文句号(这个整体也就是这个分组)重复3次，最后再加上一个一到三位的数字(\d{1,3})。</p>
<p>IP地址中每个数字都不能大于255.但是正则表达式中并不提供关于数学的任何功能，所以只能使用冗长的分组，选择，字符类来描述一个正确的IP地址：<code>((2[0-4]\d|25[0-5]|[01]?\d\d?)\.){3}(2[0-4]\d|25[0-5]|[01]?\d\d?)</code></p>
<h2 id="反义"><a href="#反义" class="headerlink" title="反义"></a>反义</h2><p>有时需要查找不属于某个能简单定义的字符类的字符。比如想查找除了数字以外，其它任意字符都行的情况，这时需要用到反义,<br>常用的反义代码  </p>
<table>
<thead>
<tr>
<th>代码</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>\w</td>
<td>匹配任意不是字母，数字，下划线，汉字的字符</td>
</tr>
<tr>
<td>\S</td>
<td>匹配任意不是空白符的字符</td>
</tr>
<tr>
<td>\D</td>
<td>匹配任意非数字的字符</td>
</tr>
<tr>
<td>\B</td>
<td>匹配不是单词开头或结束的位置</td>
</tr>
<tr>
<td>[^x]</td>
<td>匹配除了x以外的任意字符</td>
</tr>
<tr>
<td>[^aeiou]</td>
<td>匹配除了aeiou这几个字母以外的任意字符</td>
</tr>
</tbody>
</table>
<p>例子：<code>\S+</code>匹配不包含空白符的字符串；<code>&lt;a[^&gt;]+&gt;</code>匹配用尖括号括起来的以a开头的字符串。</p>
<h2 id="后向引用"><a href="#后向引用" class="headerlink" title="后向引用"></a>后向引用</h2><h2 id="零宽断言"><a href="#零宽断言" class="headerlink" title="零宽断言"></a>零宽断言</h2><h2 id="负向零宽断言"><a href="#负向零宽断言" class="headerlink" title="负向零宽断言"></a>负向零宽断言</h2><h2 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h2><h2 id="贪婪与懒惰"><a href="#贪婪与懒惰" class="headerlink" title="贪婪与懒惰"></a>贪婪与懒惰</h2><h2 id="处理选项"><a href="#处理选项" class="headerlink" title="处理选项"></a>处理选项</h2><h2 id="平衡组-递归匹配"><a href="#平衡组-递归匹配" class="headerlink" title="平衡组/递归匹配"></a>平衡组/递归匹配</h2><h1 id="测试工具"><a href="#测试工具" class="headerlink" title="测试工具"></a>测试工具</h1><p><a href="http://www.regexr.com/">regex在线测试</a> 这个专业！<br><a href="http://tool.oschina.net/regex//">oschina regex在线测试</a> 国内的还是不太靠谱！</p>
<h1 id="相关阅读"><a href="#相关阅读" class="headerlink" title="相关阅读"></a>相关阅读</h1><p>本文笔记内容参考<a href="http://deerchao.net/tutorials/regex/regex.htm">正则表达式30分钟入门教程</a></p>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> RegEx </tag>
            
            <tag> NLP </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[SublimeText-Markdown书写利器]]></title>
      <url>http://geosmart.github.io/2015/09/26/SublimeText-Markdown%E4%B9%A6%E5%86%99%E5%88%A9%E5%99%A8/</url>
      <content type="html"><![CDATA[<p>曾尝试寻找在线平台写博客</p>
<ul>
<li>segmentfault：专栏文章模块markdown编写可检测剪贴板图片，且需要审核；但是笔记模块不支持</li>
<li>csdn：改版的markdown编辑器很好，但是不支持粘帖图片，且存在删文风险 </li>
</ul>
<p>几经周折，最终还是选择了自己搭建写作环境：<code>sumblime配置markdown写作环境 + evernote笔记检索+hexo博客框架 + github.io发布</code>；<br>以sublimeText编辑器作为写作环境（markdown语法高亮/预览），以sublime-evernote发布到evernote，hexo搭建博客框架定期发布到github.io，<br>谨记编辑器够用就好，内容应始终放在第一位。</p>
<hr>
<a id="more"></a>
<h1 id="安装Package-Control"><a href="#安装Package-Control" class="headerlink" title="安装Package Control"></a>安装Package Control</h1><p>使用Ctrl+`快捷键或者通过View-&gt;Show Console菜单打开命令行，粘贴如下代码：</p>
<p><code>import urllib.request,os; pf = &#39;Package Control.sublime-package&#39;; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); open(os.path.join(ipp, pf), &#39;wb&#39;).write(urllib.request.urlopen( &#39;http://sublime.wbond.net/&#39; + pf.replace(&#39; &#39;,&#39;%20&#39;)).read())</code></p>
<h1 id="SublimeText快捷键"><a href="#SublimeText快捷键" class="headerlink" title="SublimeText快捷键"></a>SublimeText快捷键</h1><ul>
<li>命令面板：Ctrl+Shift+P’</li>
<li>列选择：Shirft+右键</li>
<li>行选择：Ctrl+L</li>
<li>全屏书写：Shirft + F11</li>
</ul>
<h1 id="SublimeText-用户配置"><a href="#SublimeText-用户配置" class="headerlink" title="SublimeText 用户配置"></a>SublimeText 用户配置</h1><p>主题：Material-Theme</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    <span class="attr">"color_scheme"</span>: <span class="string">"Packages/Monokai Extended/Monokai Extended Bright.tmTheme"</span>,</div><div class="line">    <span class="attr">"draw_centered"</span>: <span class="literal">false</span>,</div><div class="line">    <span class="attr">"font_face"</span>: <span class="string">"Consolas"</span>,</div><div class="line">    <span class="attr">"font_size"</span>: <span class="number">9</span>,</div><div class="line">    <span class="attr">"gutter"</span>: <span class="literal">true</span>,</div><div class="line">    <span class="attr">"ignored_packages"</span>:</div><div class="line">    [</div><div class="line">        <span class="string">"Markdown"</span>,</div><div class="line">        <span class="string">"Vintage"</span></div><div class="line">    ],</div><div class="line">    <span class="attr">"index_exclude_patterns"</span>:</div><div class="line">    [</div><div class="line">      <span class="string">"*.log"</span>,</div><div class="line">      <span class="string">"*.gitignore"</span></div><div class="line">    ],</div><div class="line">    <span class="attr">"line_numbers"</span>: <span class="literal">true</span>,</div><div class="line">    <span class="attr">"line_padding_bottom"</span>: <span class="number">1</span>,</div><div class="line">    <span class="attr">"line_padding_top"</span>: <span class="number">1</span>,</div><div class="line">    <span class="attr">"scroll_past_end"</span>: <span class="literal">true</span>,</div><div class="line">    <span class="attr">"tab_size"</span>: <span class="number">2</span>,</div><div class="line">    <span class="attr">"theme"</span>: <span class="string">"Material-Theme.sublime-theme"</span>,  </div><div class="line">    <span class="attr">"translate_tabs_to_spaces"</span>: <span class="literal">false</span>,</div><div class="line">    <span class="attr">"word_wrap"</span>: <span class="literal">true</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="Markdown插件"><a href="#Markdown插件" class="headerlink" title="Markdown插件"></a>Markdown插件</h1><h2 id="Markdown语法高亮：Monokai"><a href="#Markdown语法高亮：Monokai" class="headerlink" title="Markdown语法高亮：Monokai"></a>Markdown语法高亮：Monokai</h2><p>语法高亮：Monokai Extended<br><a href="https://github.com/jonschlinkert/sublime-monokai-extended">Github地址</a> <img src="sublimetext.png" alt="效果图"></p>
<h2 id="Markdown编辑：MarkdownEditing"><a href="#Markdown编辑：MarkdownEditing" class="headerlink" title="Markdown编辑：MarkdownEditing"></a>Markdown编辑：MarkdownEditing</h2><p>设置为MarkdownEditing&gt;MultiMarkDown<br><a href="https://github.com/SublimeText-Markdown/MarkdownEditing#key-bindings">官方文档</a></p>
<ul>
<li>选择内容设为链接：Ctrl + Win + V  </li>
<li>粘贴板内容设为链接：Ctrl + Win + R</li>
<li>插入链接：Ctrl + Win + K</li>
<li>插入图片：Shift + Win + K</li>
<li>加粗：Ctrl + Shift + B</li>
<li>斜体：Ctrl + Shift + I</li>
<li>标题：Ctrl + 1/2/3/4/5/6</li>
<li>显示Markdown文件标题：Ctrl + Shift + R</li>
</ul>
<h2 id="Markdown预览：OmniMarkupPreviewer"><a href="#Markdown预览：OmniMarkupPreviewer" class="headerlink" title="Markdown预览：OmniMarkupPreviewer"></a>Markdown预览：OmniMarkupPreviewer</h2><ul>
<li>Ctrl + Alt + O: 在浏览器中预览(实时无需刷新的哦)</li>
<li>Ctrl + Alt + X: 导出HTML</li>
<li>Ctrl + Alt + C: HTML标记拷贝至剪贴板</li>
</ul>
<h2 id="markdown样式"><a href="#markdown样式" class="headerlink" title="markdown样式"></a>markdown样式</h2><p>next主题修改：<code>/next/source/css/_variables/base.styl</code>文件中的<code>$font-family-chinese</code>、<code>$font-size-base</code>等属性定制</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">body</span> &#123;</div><div class="line">  <span class="attribute">position</span>: relative;</div><div class="line">  <span class="attribute">color</span>: <span class="number">#333</span>;</div><div class="line">  <span class="attribute">background</span>: <span class="number">#fff</span>;</div><div class="line">  <span class="attribute">font-size</span>: <span class="number">14.5px</span>;</div><div class="line">  <span class="attribute">line-height</span>: <span class="number">1.8</span>;</div><div class="line">  <span class="attribute">font-family</span>: Consolas, monaco, <span class="string">"Helvetica Neue"</span>, Helvetica, Arial, <span class="string">"Hiragino Sans GB"</span>, <span class="string">"Microsoft YaHei"</span>, STHeiti, <span class="string">"WenQuanYi Micro Hei"</span>, sans-serif;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="sublime配置笔记同步到evernote"><a href="#sublime配置笔记同步到evernote" class="headerlink" title="sublime配置笔记同步到evernote"></a>sublime配置笔记同步到evernote</h1><p><a href="http://www.jianshu.com/p/f5118d466f81/comments/2422205">参考配置sublime-evernote</a></p>
<p>Evernote 的快捷键在 Key Bindings——User配置</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[</div><div class="line">&#123; <span class="attr">"keys"</span>: [<span class="string">"super+e"</span>], <span class="attr">"command"</span>: <span class="string">"show_overlay"</span>, <span class="attr">"args"</span>: &#123;<span class="attr">"overlay"</span>: <span class="string">"command_palette"</span>, <span class="attr">"text"</span>: <span class="string">"Evernote: "</span>&#125; &#125;,</div><div class="line">&#123; <span class="attr">"keys"</span>: [<span class="string">"ctrl+e"</span>, <span class="string">"ctrl+s"</span>], <span class="attr">"command"</span>: <span class="string">"send_to_evernote"</span> &#125;,</div><div class="line">&#123; <span class="attr">"keys"</span>: [<span class="string">"ctrl+e"</span>, <span class="string">"ctrl+o"</span>], <span class="attr">"command"</span>: <span class="string">"open_evernote_note"</span> &#125;,</div><div class="line">&#123; <span class="attr">"keys"</span>: [<span class="string">"ctrl+e"</span>, <span class="string">"ctrl+u"</span>], <span class="attr">"command"</span>: <span class="string">"save_evernote_note"</span> &#125;,</div><div class="line">]</div></pre></td></tr></table></figure>
<p>如新增笔记：[“ctrl+e”, “ctrl+s”] 就是先按完ctrl + e 后再按 ctrl + s ；</p>
<p>sublime-evernote配置</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"> &#123;</div><div class="line">  <span class="attr">"code_friendly"</span>: <span class="literal">true</span>,</div><div class="line">  <span class="attr">"code_highlighting_style"</span>: <span class="string">"github"</span>,</div><div class="line">  <span class="attr">"extensions"</span>:</div><div class="line">  [</div><div class="line">    <span class="string">"md"</span></div><div class="line">  ],</div><div class="line">  <span class="attr">"noteStoreUrl"</span>: <span class="string">"https://www.evernote.com/shard/s56/notestore"</span>,</div><div class="line">  <span class="attr">"show_stacks"</span>: <span class="literal">true</span>,</div><div class="line">  <span class="attr">"token"</span>: <span class="string">"S=s56:U=63871d:E=15c7d92376e:C=15525e109a8:P=1cd:A=en-devtoken:V=2:H=b30896c360f9be6886b610bbb7dc7df3"</span>,</div><div class="line">  <span class="attr">"update_on_save"</span>: <span class="literal">true</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><h2 id="markdown笔记与evernote保留字冲突问题"><a href="#markdown笔记与evernote保留字冲突问题" class="headerlink" title="markdown笔记与evernote保留字冲突问题"></a>markdown笔记与evernote保留字冲突问题</h2><ul>
<li>问题描述：Evernote complained:The contents of the note are not valid. The inline HTML tag ‘String’ is not allowed in Evernote notes.Retry?    </li>
<li>问题解决：List<String>改为List&lt; String&gt;接警</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 工具 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Markdown </tag>
            
            <tag> TextEditor </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[《数学之美》读书笔记]]></title>
      <url>http://geosmart.github.io/2015/09/22/%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E/</url>
      <content type="html"><![CDATA[<p>谷歌吴军：数学之美</p>
<p>如何化繁为简，如何用数学去解决工程问题，如何跳出固有思维不断去思考创新。</p>
<hr>
<a id="more"></a>
<h1 id="系列二-–-谈谈中文分词"><a href="#系列二-–-谈谈中文分词" class="headerlink" title="系列二 – 谈谈中文分词"></a>系列二 – 谈谈中文分词</h1><p>2015-09-13 16:31:25<br>一般来讲，根据不同应用，汉语分词的颗粒度大小应该不同。比如，在机器翻译中，颗粒度应该大一些，“北京大学”就不能被分成两个词。而在语音识别中，“北京大学”一般 是被分成两个词。因此，不同的应用，应该有不同的分词系统</p>
<h1 id="系列三-–-隐含马尔可夫模型在语言处理中的应用"><a href="#系列三-–-隐含马尔可夫模型在语言处理中的应用" class="headerlink" title="系列三 – 隐含马尔可夫模型在语言处理中的应用"></a>系列三 – 隐含马尔可夫模型在语言处理中的应用</h1><p>2015-09-13 16:34:02<br>自然语言是人类交流信息的工具。很多自然语言处理问题都可以等同于通信系统中的解码问题 – 一个人根据接收到的信息，去猜测发话人要表达的意思。这其实就象通信中，我们根据接收端收到的信号去分析、理解、还原发送端传送过来的信息。</p>
<p>2015-09-13 16:35:28<br>在计算机中，如果我们要根据接收到的英语信息，推测说话者的汉语意思，就是机器翻译；如果我们要根据带有拼写错误的语句推测说话者想表达的正确意思，那就是自动纠错。</p>
<h1 id="系列-4-–-怎样度量信息"><a href="#系列-4-–-怎样度量信息" class="headerlink" title="系列 4 – 怎样度量信息?"></a>系列 4 – 怎样度量信息?</h1><p>2015-09-13 21:37:46<br>Google 一直以 “整合全球信息，让人人能获取，使人人能受益” 为使命</p>
<p>2015-09-13 21:40:33<br>一条信息的信息量大小和它的不确定性有直接的关系。</p>
<p>2015-09-13 21:40:44<br>信息量的度量就等于不确定性的多少。</p>
<p>2015-09-13 21:47:32<br>不同语言的冗余度差别很大，而汉语在所有语言中冗余度是相对小的。这和人们普遍的认识”汉语是最简洁的语言”是一致的。</p>
<h1 id="系列五-–-简单之美：布尔代数和搜索引擎的索引"><a href="#系列五-–-简单之美：布尔代数和搜索引擎的索引" class="headerlink" title="系列五 – 简单之美：布尔代数和搜索引擎的索引"></a>系列五 – 简单之美：布尔代数和搜索引擎的索引</h1><p>2015-09-13 21:48:42<br>建立一个搜索引擎大致需要做这样几件事：自动下载尽可能多的网页；建立快速有效的索引；根据相关性对网页进行公平准确的排序</p>
<p>2015-09-14 22:31:43<br>搜索引擎的索引就变成了一张大表：表的每一行对应一个关键词，而每一个关键词后面跟着一组数字，是包含该关键词 的文献序号。</p>
<p>2015-09-14 22:32:45<br>每当接受一个查询时，这个查询就被分送到许许多多服务器中，这些服务器 同时并行处理用户请求，并把结果送到主服务器进行合并处理，最后将结果返回给用户。</p>
<p>2015-09-14 22:33:05<br>不管索引如何复杂，查找的基本操作仍然是布尔运算。布尔运算把逻辑和数学联系起来了。它的最大好处是容易实现，速度快，这对于海量的信息查找是至关重要的。它的不足是只能给出是与否的判断，而不能给出量化的 度量。因此，所有搜索引擎在内部检索完毕后，都要对符合要求的网页根据相关性排序，然后才返回给用户。</p>
<h1 id="系列六-–-图论和网络爬虫"><a href="#系列六-–-图论和网络爬虫" class="headerlink" title="系列六 – 图论和网络爬虫"></a>系列六 – 图论和网络爬虫</h1><p>2015-09-14 22:33:57<br>如何自动下载互联网所有的网页呢，它要用到图论中的遍历（Traverse) 算法。</p>
<p>2015-09-14 22:35:57<br>“广度优先算法”（BFS)，因为它先要尽可能广地访问每个节点所直接连接的其他节点。</p>
<p>2015-09-14 22:36:22<br>“深度优先算法”（DFS)，因为它是一条路走到黑。</p>
<h1 id="系列七-–-信息论在信息处理中的应用"><a href="#系列七-–-信息论在信息处理中的应用" class="headerlink" title="系列七 – 信息论在信息处理中的应用"></a>系列七 – 信息论在信息处理中的应用</h1><p>2015-09-14 22:41:23<br>李开复博士在介绍他发明的 Sphinx 语音识别系统时谈到，如果不用任何语言模型（即零元语言模型）时，复杂度为997，也就是说句子中每个位置有 997 个可能的单词可以填入。如果（二元）语言模型只考虑前后词的搭配不考虑搭配的概率时，复杂度为60。虽然它比不用语言模型好很多，但是和考虑了搭配概率的二元语言模型相比要差很多，因为后者的复杂度只有20。</p>
<p>2015-09-14 22:41:40<br>信息论中仅次于熵的另外两个重要的概念是“互信息”（Mutual Information) 和“相对熵”（Kullback-Leibler Divergence)。</p>
<p>2015-09-14 22:42:00<br>“互信息”是信息熵的引申概念，它是对两个随机事件相关性的度量。</p>
<p>2015-09-14 22:45:15<br>信息论中另外一个重要的概念是“相对熵”，在有些文献中它被称为成“交叉熵”。在英语中是 Kullback-Leibler Divergence， 是以它的两个提出者库尔贝克和莱伯勒的名字命名的。相对熵用来衡量两个正函数是否相似，对于两个完全相同的函数，它们的相对熵等于零。在自然语言处理中可 以用相对熵来衡量两个常用词（在语法上和语义上）是否同义，或者两篇文章的内容是否相近等等。利用相对熵，我们可以到处信息检索中最重要的一个概念：词频率-逆向文档频率（TF/IDF)。</p>
<h1 id="系列八–-贾里尼克的故事和现代语言处理"><a href="#系列八–-贾里尼克的故事和现代语言处理" class="headerlink" title="系列八– 贾里尼克的故事和现代语言处理"></a>系列八– 贾里尼克的故事和现代语言处理</h1><p>2015-09-14 22:53:52<br>七十年代的 IBM 有点像九十年代的微软和今天的 Google, 给于杰出科学家作任何有兴趣研究的自由。在那种宽松的环境里，贾里尼克等人提出了统计语音识别的框架结构。 在贾里尼克以前，科学家们把语音识别问题当作人工智能问题和模式匹配问题。而贾里尼克把它当成通信问题，并用两个隐含马尔可夫模型（声学模型和语言模型） 把语音识别概括得清清楚楚。这个框架结构对至今的语音和语言处理有着深远的影响，它从根本上使得语音识别有实用的可能。 贾里尼克本人后来也因此当选美国工程院院士。</p>
<h1 id="系列九-–-如何确定网页和查询的相关性"><a href="#系列九-–-如何确定网页和查询的相关性" class="headerlink" title="系列九 – 如何确定网页和查询的相关性"></a>系列九 – 如何确定网页和查询的相关性</h1><p>2015-09-15 22:48:01<br>如果一个关键词只在很少的网页中出现，我们通过它就容易锁定搜索目标，它的权重也就应该大。反之如果一个词在大量网页中出现，我们看到它仍 然不很清楚要找什么内容，因此它应该小。概括地讲，假定一个关键词w在DW个网页中出现过，那么DW越大，w的权重越小，反之亦然。在信息检索中，使用最多的权重是“逆文本频率指数”</p>
<p>2015-09-15 22:49:07<br>ＴＦ／ＩＤＦ（term frequency/inverse document frequency) 的概念被公认为信息检索中最重要的发明。在搜索、文献分类和其他相关领域有广泛的应用。</p>
<p>2015-09-15 22:50:46<br>信息论的学者们已经发现并指出，其实 IDF 的概念就是一个特定条件下、关键词的概率分布的交叉熵（Kullback-Leibler Divergence)（详见上一系列）。这样，信息检索相关性的度量，又回到了信息论。</p>
<h1 id="系列十-有限状态机和地址识别"><a href="#系列十-有限状态机和地址识别" class="headerlink" title="系列十 有限状态机和地址识别"></a>系列十 有限状态机和地址识别</h1><p>2015-09-16 22:00:29<br>地址的识别和分析是本地搜索必不可少的技术，尽管有许多识别和分析地址的方法，最有效的是有限状态机。</p>
<p>2015-09-16 22:00:55<br>一个有限状态机是一个特殊的有向图（参见有关图论的系列），它包括一些状态（节点）和连接这些状态的有向弧。</p>
<p>2015-09-16 22:02:38<br>使用有限状态机识别地址，关键要解决两个问题，即通过一些有效的地址建立状态机，以及给定一个有限状态机后，地址字串的匹配算法。</p>
<p>2015-09-16 22:04:22<br>基于有限状态机的地址识别方法在实用中会有一些问题：当用户输入的地址不太标准或者有错别字时，有限状态机会束手无策，因为它只能进行严格匹配。（其实，有限状态机在计算机科学中早期的成功应用是在程序语言编译器的设计中。一个能运行的程序在语法上必须是没有错的，所以不需要模糊匹配。而自然语言则很随意，无法用简单的语法描述。）<br>为了解决这个问题，我们希望有一个能进行模糊匹配、并给出一个字串为正确地址的可能性。为了实现这一目的，科学家们提出了基于概率的有限状态机。这种基于概率的有限状态机和离散的马尔可夫链（详见前面关于马尔可夫模型的系列）基本上等效。</p>
<h1 id="十四-谈谈数学模型的重要性"><a href="#十四-谈谈数学模型的重要性" class="headerlink" title="十四 谈谈数学模型的重要性"></a>十四 谈谈数学模型的重要性</h1><p>2015-09-17 21:57:04</p>
<ol>
<li>一个正确的数学模型应当在形式上是简单的。（托勒密的模型显然太复杂。）</li>
<li>一个正确的模型在它开始的时候可能还不如一个精雕细琢过的错误的模型来的准确，但是，如果我们认定大方向是对的，就应该坚持下去。（日心说开始并没有地心说准确。）</li>
<li>大量准确的数据对研发很重要。</li>
<li>正确的模型也可能受噪音干扰，而显得不准确；这时我们不应该用一种凑合的修正方法来弥补它，而是要找到噪音的根源，这也许能通往重大发现。</li>
</ol>
<p>2015-09-17 21:57:17<br>在网络搜索的研发中，我们在前面提到的单文本词频/逆文本频率指数（TF/IDF) 和网页排名（page rank)都相当于是网络搜索中的”椭圆模型”，它们都很简单易懂。</p>
<h1 id="系列十六（上）-不要把所有的鸡蛋放在一个篮子里"><a href="#系列十六（上）-不要把所有的鸡蛋放在一个篮子里" class="headerlink" title="系列十六（上） 不要把所有的鸡蛋放在一个篮子里"></a>系列十六（上） 不要把所有的鸡蛋放在一个篮子里</h1><p>2015-09-21 22:08:08<br>最大熵原理指出，当我们需要对一个随机事件的概率分布进行预测时，我们的预测应当满足全部已知的条件，而对未知的情况不要做任何主观假设。（不做主观假设这点很重要。）在这种情况下，概率分布最均匀，预测的风险最小。因为这时概率分布的信息熵最大，所以人们称这种模型叫”最大熵模型”。我们常说，不要把所有的鸡蛋放在一个篮子里，其实就是最大熵原理的一个朴素的说法，因为当我们遇到不确定性时，就要保留各种可能性。</p>
<h1 id="系列十六-（下）－-不要把所有的鸡蛋放在一个篮子里"><a href="#系列十六-（下）－-不要把所有的鸡蛋放在一个篮子里" class="headerlink" title="系列十六 （下）－ 不要把所有的鸡蛋放在一个篮子里"></a>系列十六 （下）－ 不要把所有的鸡蛋放在一个篮子里</h1><p>2015-09-21 22:14:07<br>最原始的最大熵模型的训练方法是一种称为通用迭代算法 GIS(generalized iterative scaling) 的迭代 算法。GIS 的原理并不复杂，大致可以概括为以下几个步骤：</p>
<ol>
<li>假定第零次迭代的初始模型为等概率的均匀分布。</li>
<li>用第 N 次迭代的模型来估算每种信息特征在训练数据中的分布，如果超过了实际的，就把相应的模型参数变小；否则，将它们便大。</li>
<li>重复步骤 2 直到收敛。</li>
</ol>
<p>2015-09-21 22:19:29<br>最大熵模型，可以说是集简与繁于一体，形式简单，实现复杂。</p>
<h1 id="系列十八-－-矩阵运算和文本处理中的分类问题"><a href="#系列十八-－-矩阵运算和文本处理中的分类问题" class="headerlink" title="系列十八 － 矩阵运算和文本处理中的分类问题"></a>系列十八 － 矩阵运算和文本处理中的分类问题</h1><p>2015-09-21 22:36:15<br>分类的关键是计算相关性。我们首先对两个文本计算出它们的内容词，或者说实词的向量，然后求这两个向量的夹角。当这两个向量夹角为零时，新闻就相关；当它们垂直或者说正交时，新闻则无关。</p>
<h1 id="系列十九-－-马尔可夫链的扩展-贝叶斯网络"><a href="#系列十九-－-马尔可夫链的扩展-贝叶斯网络" class="headerlink" title="系列十九 － 马尔可夫链的扩展 贝叶斯网络"></a>系列十九 － 马尔可夫链的扩展 贝叶斯网络</h1><p>2015-09-21 22:39:58<br>马尔可夫链 (Markov Chain)，它描述了一种状态序列，其每个状态值取决于前面有限个状态。这种模型，对很多实际问题来讲是一种很粗略的简化。在现实生活中，很多事物相互的关系并不能用一条链来串起来。它们之间的关系可能是交叉的、错综复杂的。</p>
<p>2015-09-21 22:39:35<br>贝叶斯网络。其中每个圆圈表示一个状态。状态之间的连线表示它们的因果关系。比如从心血管疾病出发到吸烟的弧线表示心血管疾病可能和吸烟有关。当然，这些关系可以有一个量化的可信度 (belief)，用一个概率描述。我们可以通过这样一张网络估计出一个人的心血管疾病的可能性。在网络中每个节点概率的计算，可以用贝叶斯公式来进行，贝叶斯网络因此而得名。由于网络的每个弧有一个可信度，贝叶斯网络也被称作信念网络 (belief networks)。</p>
<h1 id="系列二十-－自然语言处理的教父-马库斯"><a href="#系列二十-－自然语言处理的教父-马库斯" class="headerlink" title="系列二十 －自然语言处理的教父 马库斯"></a>系列二十 －自然语言处理的教父 马库斯</h1><p>2015-09-21 22:43:25<br>PennTree Bank 覆盖多种语言（包括中文）。每一种语言，它有几十万到几百万字的有代表性的句子，每个句子都有的词性标注，语法分析树等等。LDC 语料库如今已成为全世界自然语言处理科学家共用的数据库。如今，在自然语言处理方面发表论文，几乎都要提供基于 LDC 语料库的测试结果。</p>
<h1 id="系列二十二-由电视剧《暗算》所想到的"><a href="#系列二十二-由电视剧《暗算》所想到的" class="headerlink" title="系列二十二 由电视剧《暗算》所想到的"></a>系列二十二 由电视剧《暗算》所想到的</h1><p>2015-09-21 22:54:10<br>来设计一个密码系统，对这个明码加密。<br>1，找两个很大的素数（质数）P 和 Q，越大越好，比如 100 位长的, 然后计算它们的乘积 N=P×Q，M=（P-1）×（Q-1）。<br>2，找一个和 M 互素的整数 E，也就是说 M 和 E 除了 1 以外没有公约数。<br>3，找一个整数 D，使得 E×D 除以 M 余 1，即 E×D mod M = 1。<br>现在，世界上先进的、最常用的密码系统就设计好了，其中 E 是公钥谁都可以用来加密，D 是私钥用于解密，一定要自己保存好。乘积 N 是公开的，即使敌人知道了也没关系。<br>现在，我们用下面的公式对 X 加密，得到密码 Y。<br>好了，现在没有密钥 D，神仙也无法从 Y 中恢复 X。如果知道 D，根据费尔马小定理，则只要按下面的公式就可以轻而易举地从 Y 中得到 X。</p>
<hr>
<p>多看笔记 来自多看阅读 for Kindle<br>多看ID: geosmart</p>
]]></content>
      
        <categories>
            
            <category> 读书笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MySQL数据库使用笔记]]></title>
      <url>http://geosmart.github.io/2015/09/21/MySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>记录一些常用的MysQL运维脚本和常见问题</p>
<hr>
<a id="more"></a>
<p><a href="http://dev.mysql.com/doc/refman/5.7/en/string-functions.html">MySQL函数文档</a></p>
<h1 id="linux重置mysql-root密码"><a href="#linux重置mysql-root密码" class="headerlink" title="linux重置mysql root密码"></a>linux重置mysql root密码</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"># 新建文件</div><div class="line">touch /mnt/script/mysql-init</div><div class="line"># 文件内容为</div><div class="line"><span class="keyword">SET</span> <span class="keyword">PASSWORD</span> <span class="keyword">FOR</span> <span class="string">'root'</span>@<span class="string">'localhost'</span> = <span class="keyword">PASSWORD</span>(<span class="string">'MyNewPass'</span>);</div><div class="line"># 查看mysqld进程ID并杀掉</div><div class="line">service mysqld status</div><div class="line"><span class="keyword">kill</span> $&#123;pid&#125;</div><div class="line"># 重启mysql服务并重置root密码</div><div class="line">mysqld_safe <span class="comment">--init-file=/mnt/script/mysql-init &amp;</span></div></pre></td></tr></table></figure>
<h1 id="重启mysql服务"><a href="#重启mysql服务" class="headerlink" title="重启mysql服务"></a>重启mysql服务</h1><p>service mysqld restart</p>
<h1 id="MySQL开启远程连接"><a href="#MySQL开启远程连接" class="headerlink" title="MySQL开启远程连接"></a>MySQL开启远程连接</h1><p>问题：Access denied for user ‘root’@’192.168.1.172’ (using password: YES)<br>解决：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">mysql -uroot -proot</div><div class="line"><span class="keyword">show</span> <span class="keyword">grants</span>;</div><div class="line"><span class="keyword">use</span> mysql</div><div class="line"><span class="keyword">select</span> host,<span class="keyword">user</span>,<span class="keyword">password</span> <span class="keyword">from</span> <span class="keyword">user</span>;</div><div class="line"><span class="keyword">update</span> <span class="keyword">user</span> <span class="keyword">set</span> host=<span class="string">'%'</span> <span class="keyword">where</span> <span class="keyword">user</span>=<span class="string">"root"</span> <span class="keyword">and</span> host;</div><div class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'root'</span>@<span class="string">'%'</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> <span class="keyword">OPTION</span>;</div><div class="line"><span class="keyword">FLUSH</span> <span class="keyword">PRIVILEGES</span>;</div></pre></td></tr></table></figure>
<h1 id="mysql-新建用户，设置权限"><a href="#mysql-新建用户，设置权限" class="headerlink" title="mysql 新建用户，设置权限"></a>mysql 新建用户，设置权限</h1><p>DROP USER ‘ugc’@’%’;<br>CREATE USER ‘ugc’@’%’ IDENTIFIED BY ‘ugc’;<br>GRANT ALL PRIVILEGES ON <em> . </em> TO ‘ugc’@’%’  Identified by ‘ugc’;<br>GRANT ALL PRIVILEGES ON <em> . </em> TO ‘ugc’@’localhost’  Identified by ‘ugc’;<br>FLUSH PRIVILEGES;</p>
<h1 id="登陆"><a href="#登陆" class="headerlink" title="登陆"></a>登陆</h1><p>mysql -uugc -pugc</p>
<h1 id="建库"><a href="#建库" class="headerlink" title="建库"></a>建库</h1><p>CREATE DATABASE  ugc;</p>
<h1 id="数据导入"><a href="#数据导入" class="headerlink" title="数据导入"></a>数据导入</h1><p>单个导入：<code>source  data.sql</code><br>如：<code>cd /tmp/ugc-data/ &amp;&amp; find . -name &#39;echzutravel.sql&#39; | awk &#39;{ print &quot;source&quot;,$0 }&#39; | mysql --batch -u ugc -p ugc</code></p>
<p>批量导入：<code>find . -name &#39;*.sql&#39; | awk &#39;{ print &quot;source&quot;,$0 }&#39; | mysql --batch -u root -p db_name</code><br>如导入/tmp/ugc-data/目录的所有sql文件到ugc库：<code>cd /tmp/ugc-data/ &amp;&amp; find . -name &#39;*.sql&#39; | awk &#39;{ print &quot;source&quot;,$0 }&#39; | mysql --batch -u ugc -p ugc</code></p>
<h1 id="数据导出"><a href="#数据导出" class="headerlink" title="数据导出"></a>数据导出</h1><ol>
<li>导出整个数据库<br>mysqldump -u 用户名 -p 数据库名 &gt; 导出的文件名<br>mysqldump -u wcnc -p smgp_apps_wcnc &gt; wcnc.sql</li>
<li>导出一个表<br>mysqldump -u 用户名 -p 数据库名表名&gt; 导出的文件名<br>mysqldump -u wcnc -p smgp_apps_wcnc users&gt; wcnc_users.sql</li>
<li>导出一个数据库结构<br>mysqldump -u wcnc -p -d –add-drop-table smgp_apps_wcnc &gt;d:wcnc_db.sql<br>-d 没有数据 –add-drop-table 在每个create语句之前增加一个drop table</li>
</ol>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># 数据库备份</div><div class="line">`mysqldump geocodingdb  -ugeocodingdb -pgeocodingdb   <span class="comment">--routines --comments &gt; /uadb/geocodingdb.sql`</span></div><div class="line"># 压缩备份</div><div class="line">`mysqldump standarddb  -ustandarddb -pstandarddb  <span class="comment">--routines   --comments   | gzip -v &gt; /uadb/standarddb.gz`</span></div><div class="line"># 压缩已有备份sql</div><div class="line">`zip -r   /uadb/uadb.bakcup.suzhou.0512.zip  /uadb/uadb.bakcup.suzhou.0512`</div><div class="line"># 数据库还原</div><div class="line">`mysql   -ugeocodingdb -pgeocodingdb geocodingdb   <span class="comment">--comments  &lt; /uadb/geocodingdb.sql`</span></div></pre></td></tr></table></figure>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="Too-many-connections"><a href="#Too-many-connections" class="headerlink" title="Too many connections"></a>Too many connections</h2><p>查看最大连接数：show variables like ‘max_connections’;<br>查询一下服务器响应的最大连接数： show global status like ‘Max_used_connections’;<br>show status like ‘%connection%’;<br>显示当前运行的Query： show processlist;<br>设置新的最大连接数为5000：<br>1）shell临时修改： set GLOBAL max_connections=5000;<br>2）在/etc/my.cnf 中修改连接max_connections = 5000</p>
<h1 id="Packet-for-query-is-too-large"><a href="#Packet-for-query-is-too-large" class="headerlink" title="Packet for query is too large"></a>Packet for query is too large</h1><ul>
<li>关于max_allowed_packet参数<br>MySQL根据配置文件会限制Server接受的数据包大小。有时候大的插入和更新会受 max_allowed_packet 参数限制，导致写入或者更新失败。</li>
<li>查询：show VARIABLES like ‘%max_allowed_packet%’;</li>
<li>命令行中修改：set global max_allowed_packet = 2<em>1024</em>1024*10;</li>
<li>在windows（my.ini），Linux（/etc/my.cnf）中 修改：max_allowed_packet = 20M</li>
</ul>
<h1 id="Host-is-blocked-because-of-many-connection-errors"><a href="#Host-is-blocked-because-of-many-connection-errors" class="headerlink" title="Host is blocked because of many connection errors"></a>Host is blocked because of many connection errors</h1><ul>
<li>错误描述：An error occurred while establishing the connection: message from server: “Host ‘192.168.1.174’ is blocked because of many connection errors; unblock with ‘mysqladmin flush-hosts’”</li>
<li>查询：show VARIABLES like ‘%max_connect_errors%’;</li>
<li>命令行中修改：set global max_connect_errors =1000;</li>
<li>在windows（my.ini），Linux（/etc/my.cnf）中 修改：max_connect_errors= 1000</li>
</ul>
<h1 id="No-buffer-space-available-maximum-connections-reached"><a href="#No-buffer-space-available-maximum-connections-reached" class="headerlink" title="No buffer space available (maximum connections reached?)"></a>No buffer space available (maximum connections reached?)</h1><ul>
<li>错误描述：大量数据库连接运行sql，抛出异常java.net.SocketException: No buffer space available (maximum connections reached?): JVM_Bind,在运行 Windows Server 2008 R2 或 Windows 7 的多处理器计算机上的内核套接字泄漏</li>
<li>解决：winServer2008多处理器计算机上的内核套接字泄漏bug，下载补丁修复<br>The reason we got this error is a bug in Windows Server 2008 R2 / Windows 7. The kernel leaks loopback sockets due to a race condition on machines with more than one core,<br><a href="http://support.microsoft.com/kb/2577795">patch 2577795</a> fixes the issue:</li>
</ul>
<h2 id="You-can’t-specify-target-table-‘Place’-for-update-in-FROM-clause"><a href="#You-can’t-specify-target-table-‘Place’-for-update-in-FROM-clause" class="headerlink" title="You can’t specify target table ‘Place’ for update in FROM clause"></a>You can’t specify target table ‘Place’ for update in FROM clause</h2><p>执行错误：DELETE   FROM  Place where guid in (select guid  from  Place  where address like ‘%市%区’ and address   not  like ‘%南海区%’) ;<br>修改为：DELETE   FROM  Place whereguid in (select  * from (select guid  from  Place  where address like ‘%市%区’ and address   not  like ‘%南海区%’)  as t);</p>
<h2 id="mysql表名区分大小写"><a href="#mysql表名区分大小写" class="headerlink" title="mysql表名区分大小写"></a>mysql表名区分大小写</h2><p>MySQL在Windows下数据库名、表名、列名、别名都不区分大小写。<br>如果想大小写区分，在my.ini 里面的mysqld部分，加入 lower_case_table_names=0</p>
<h2 id="查询表的字段名称"><a href="#查询表的字段名称" class="headerlink" title="查询表的字段名称"></a>查询表的字段名称</h2><p>select column_name from information_schema.columns where table_name = ‘ExtractedAddress’ and column_name like ‘地名%’ and  column_name &lt;&gt; ‘地名’</p>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Markdown常用语法]]></title>
      <url>http://geosmart.github.io/2015/09/18/Markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/</url>
      <content type="html"><![CDATA[<p>记录一些markdown的语法和使用示例</p>
<a id="more"></a>
<h1 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h1><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><h1 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h1><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><h1 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h1><blockquote>
<p><code>![geosmart](https://avatars1.githubusercontent.com/u/3156608?v=3&amp;s=64)</code><br><img src="https://avatars1.githubusercontent.com/u/3156608?v=3&amp;s=64" alt="geosmart"></p>
</blockquote>
<h1 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h1><blockquote>
<p><code>[geosmart](geosmart.github.io)</code><br><a href="geosmart.github.io">geosmart</a></p>
</blockquote>
<h1 id="粗体"><a href="#粗体" class="headerlink" title="粗体"></a>粗体</h1><h1 id="斜体"><a href="#斜体" class="headerlink" title="斜体"></a>斜体</h1><h1 id="删除线"><a href="#删除线" class="headerlink" title="删除线"></a>删除线</h1><blockquote>
<p><code>~~这是一条删除线~~</code><br><del>这是一条删除线</del></p>
</blockquote>
<h1 id="分割线"><a href="#分割线" class="headerlink" title="分割线"></a>分割线</h1><hr>
<hr>
<h1 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h1><figure class="highlight markdown"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">|Header |Column 1 | Column 2 | Column 3  |</div><div class="line">|:--- |:---- |:----:| ----:|</div><div class="line">|1. Row| is | is | is  |</div><div class="line">|2. Row| left | nicely | right  |</div><div class="line">|3. Row| aligned | centered | aligned  |</div></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th style="text-align:left">Header</th>
<th style="text-align:left">Column 1</th>
<th style="text-align:center">Column 2</th>
<th style="text-align:right">Column 3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1. Row</td>
<td style="text-align:left">is</td>
<td style="text-align:center">is</td>
<td style="text-align:right">is</td>
</tr>
<tr>
<td style="text-align:left">2. Row</td>
<td style="text-align:left">left</td>
<td style="text-align:center">nicely</td>
<td style="text-align:right">right</td>
</tr>
<tr>
<td style="text-align:left">3. Row</td>
<td style="text-align:left">aligned</td>
<td style="text-align:center">centered</td>
<td style="text-align:right">aligned</td>
</tr>
</tbody>
</table>
]]></content>
      
        <categories>
            
            <category> 工具 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Markdown </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[GATE中文自然语言处理学习笔记]]></title>
      <url>http://geosmart.github.io/2015/09/17/GATE%E4%B8%AD%E6%96%87%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p><img src="https://gate.ac.uk/plugins/gau-0.1/images/logo-gate.png" alt=""></p>
<h1 id="GATE"><a href="#GATE" class="headerlink" title="GATE"></a>GATE</h1><blockquote>
<p>GATE(文本工程通用框架)项目开始于 1995 年英国的谢菲尔德大学.经历了近 20 年的不断发展，GATE 已经被应用于广泛的研究和项目开发。  </p>
</blockquote>
<ul>
<li>GATE 框架采用了基于组件的软件开发方式和面向对象的灵活编程。</li>
<li>GATE 框架是由纯 Java 语言开发的免费开源软件，遵循 GNU library license。</li>
<li>GATE 使用的编码方式是Unicode，可以支持多种语言编码，并且针对各种斯拉夫语言、日尔曼语言、拉丁系语言和印度语做过系统测试。</li>
<li>GATE 支持的文档类型包括 XML、RTF、Email、HTML、SGML以及纯文本文件。</li>
<li>GATE 作为一个框架，规定其框架内所有的自然语言处理软件系统元素都可以有效的被细分成不同的几种组件，在 GATE 中它们被称为资源。在 GATE 框架下组件的集合被称为 CREOLE。CREOLE 组件是通过 Java Beans 的形式来实现的，CREOLE 在 GATE中分为三种形式：语言组件（LR），处理组件(PR)和可视化组件(VR)。</li>
</ul>
<hr>
<a id="more"></a>
<h2 id="GATE资源："><a href="#GATE资源：" class="headerlink" title="GATE资源："></a>GATE资源：</h2><blockquote>
<p><a href="http://gatechinese.com/blog/category/gate%E4%B8%AD%E6%96%87%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">GATE中文自然语言处理</a></p>
</blockquote>
<p><img src="GATEFrame.png" alt="GATE框架"></p>
<h1 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h1><h2 id="CorpusController"><a href="#CorpusController" class="headerlink" title="CorpusController"></a>CorpusController</h2><h2 id="RealtimeCorpusController"><a href="#RealtimeCorpusController" class="headerlink" title="RealtimeCorpusController"></a>RealtimeCorpusController</h2><h2 id="SerialAnalyserController"><a href="#SerialAnalyserController" class="headerlink" title="SerialAnalyserController"></a>SerialAnalyserController</h2><h1 id="Gazetteer"><a href="#Gazetteer" class="headerlink" title="Gazetteer"></a>Gazetteer</h1><p>词典库（Gazetteer）由一组词典列表组成，列表包含实体名称如城市，组织机构，星期等。列表用于发现文本中包含这些名称的文档和命名实体识别。通常词“词典库”可交替地用于实体列表集合，并利用这些列表发现文本中出现这些名称的处理资源。<br>当词典库PR在一个文件上运行时，每个匹配的文本字符串创建一个标注类型Lookup。词典库通常不依靠Token或任何其它标注，而是基于文档的字词内容发现相匹配的字符串。这意味着一个条目可以跨越多个词，也可以把开始和结束作为一个词。<br>如果一个词典库正工作的文本恰好满足词语边界，则词典发现词语边界的方法不同于GATE tokeniser发现词语边界的方法。如果文本中所有词典实体匹配好了，则创建一个Lookup标注。<br>词典库实体怎样匹配文本的细节取决于词典库处理资源及其参数。  </p>
<h2 id="Gazetteer生效机制"><a href="#Gazetteer生效机制" class="headerlink" title="Gazetteer生效机制"></a>Gazetteer生效机制</h2><p>入口:list.def<br>gazetteer： xx.lst<br>格式：<code>gazetteerFileName:marjorType:minorType</code></p>
<h2 id="ANNIE词典库"><a href="#ANNIE词典库" class="headerlink" title="ANNIE词典库"></a>ANNIE词典库</h2><p>ANNIE词典库是由ANNIE插件提供的。每个独立的词典都是一个普通的文本文件，每行一个条目。</p>
<h2 id="GAZE词典库"><a href="#GAZE词典库" class="headerlink" title="GAZE词典库"></a>GAZE词典库</h2><p>Gaze是一个编辑词典列表，定义词典和把词典映射到本体的工具。即适用于Plain/Linear 词典（默认）、Hash词典库也适用于Ontology-enabled 词典 (Onto词典)。每当执行保存操作时，重新初始化词典PR关联的视图。注意GAZE不生产规模非常大的词典 (我们假设不浏览超过4000实体，不拷贝超过10000个实体)。</p>
<h2 id="Onto词典"><a href="#Onto词典" class="headerlink" title="Onto词典"></a>Onto词典</h2><p>Onto词典或者Hierarchical词典，是一个处理资源，能将特定词典列表的实体加入到GATE本体语言资源的类中。Onto词典指定类而不是主要或次要类型，意识到列表和类ID之间的映射关系。Gaze可视资源能显示列表，本体映射和本体类等级，也提供编辑这些内容的方法。</p>
<h2 id="Hash词典"><a href="#Hash词典" class="headerlink" title="Hash词典"></a>Hash词典</h2><p>Hash词典是<a href="http://www.ontotext.com/">OntoText Lab</a>完成的一个词典。它的实现基于几个java.util.HashMap对象简单的查找，并由Atanas Kiryakov的奇妙想法——在HashMaps的搜寻快于在有限状态机的搜寻而得到启发。Hash词典处理资源是ANNIE插件的一部分。<br>词典处理资源用以下方式实现：每个短语，即每一个列表条目被分割成几个部分，各部分取决于位于它们之间的空格，例如，短语：“form is emptiness”有三个部分：“form”， “is”和“emptiness”。也有一个HashMaps列表：mapsList和列表中最长的短语有同样多的元素。所以第一部分短语放在第一个映射。第一部分+空格+第二部分被放置在第二个映射等。完整的词组是放置在适当的映射，并引用一个查找对象是相连。</p>
<h2 id="Flexible词典"><a href="#Flexible词典" class="headerlink" title="Flexible词典"></a>Flexible词典</h2><p>Flexible词典提供用户灵活的弹性选择他们自己定制的输入和一个外部词典。例如，用户可能想将文本的词语替换成他们的基本形式(这是一种形态学分析仪的输出)或在运行词典之前分割中文文本(用中文Tokeniser)。<br>The Flexible 词典 performs lookup over a document based on the values of an arbitrary feature of an arbitrary annotation type, by using an externally provided 词典.使用外部词典是很重要的，这允许使用任何类型的词典(例如本体词典)。</p>
<h2 id="词典列表collection"><a href="#词典列表collection" class="headerlink" title="词典列表collection"></a>词典列表collection</h2><p>词典列表collection直接从一组标注的训练文本收集实体事件，构成有实体的词典列表。实体类型和词典列表的结构是由用户定义的。一旦列表collection，一个语义语法用于寻找新文本相同的实体。<br>如果没有列表存在，对于每个标注类型要先创建一个空列表。处理资源运行前，列表集必须加载到GATE。如果已有列表存在，列表只是简单的增加任何新实体。列表collection只收集每个实体的一个事件：在添加新的之前要先检查实体已经不存在。</p>
<h2 id="OntoRoot词典"><a href="#OntoRoot词典" class="headerlink" title="OntoRoot词典"></a>OntoRoot词典</h2><p>OntoRoot词典是一种动态创建的词典，即结合其他少量的通用Gate资源，对于给定的本体的内容产生基于本体的标注。这个词典是“Gazetteer_Ontology_Based”插件的一部分，已开发成为TAO项目的一部分。</p>
<h2 id="大型KB词典"><a href="#大型KB词典" class="headerlink" title="大型KB词典"></a>大型KB词典</h2><p>大型KB 词典为ontology-aware自然语言处理提供支持。你可以从RDF装载任何本体，然后使用词典获得lookup标注，标注有实例和类URI。<br>大型KB词典作为插件词典 LKB存在。<br>当前版本的大型KB  词典不使用GATE本体语言资源。相反，它使用自己的原理去加载处理本体。当前版本在不久的未来可能会显著改变。<br>大型KB 词典是从语义搜索平台Ontotext KIM中的一个组件学习起来的。这词典是由KIM发展团队开发的（见<a href="http://nmwiki.ontotext.com/lkb_Gazetteer/team-list.html）。在kim名称左边你可以找到源代码、资料/文件管理或源文件。">http://nmwiki.ontotext.com/lkb_Gazetteer/team-list.html）。在kim名称左边你可以找到源代码、资料/文件管理或源文件。</a></p>
<h1 id="JAPE"><a href="#JAPE" class="headerlink" title="JAPE"></a>JAPE</h1><p>JAPE 的全称是 a Java Annotation Patterns Engine，Java 标注模式引擎，<br>JAPE 提供了基于正规表达式的标注有限状态转换。JAPE 是通用模式定义语言 CPSL(Common Pattern Specification Language1)的一个版本。我们通过 JAPE 语言可以编写 GATE 能够识别的规则，通过这些规则来进行较准确的命名实体识别。</p>
<h2 id="grammer-jape"><a href="#grammer-jape" class="headerlink" title="grammer-jape"></a>grammer-jape</h2><p>入口：base.jape<br>MultiPhase:<br>Phases: 列表<br>jape：:xx.jape<br>示例：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//沿西部干线由南向北行驶至六合区程桥街道荷花社区方桥河桥路段</span></div><div class="line">Phase: spacepattern_path</div><div class="line">Input: Lookup  AtomToken Token Location</div><div class="line">Options: control = appelt  debug = <span class="literal">true</span></div><div class="line">Rule: path1</div><div class="line">Priority: <span class="number">4120</span></div><div class="line">(</div><div class="line">&#123;Lookup.majorType == sp_path,Lookup.minorType==prefix&#125;</div><div class="line">((&#123;AtomToken&#125;)[<span class="number">1</span>,<span class="number">30</span>]):context</div><div class="line">&#123;Lookup.majorType == sp_path,Lookup.minorType==suffix&#125;</div><div class="line">):path</div><div class="line">--&gt;</div><div class="line">:path.Path = &#123; type = Path, context = :context@string &#125;</div></pre></td></tr></table></figure>
<p>relationship如何构建？<br>annotation和entity的关系如何构建</p>
<h2 id="JAPE标注类型"><a href="#JAPE标注类型" class="headerlink" title="JAPE标注类型"></a>JAPE标注类型</h2><ul>
<li>Lookup：Annie默认标注结果  </li>
<li>Token：Lang_Chinese，最长分词，包含符号<br>用途：数字，附号标注  </li>
<li><p>IKAToken：IKanalyzer分词标注—两两分词，不处理符号</p>
<ul>
<li>采用了特有的”正向迭代最细粒度切分算法”，具有80万字/秒的高速处理能力</li>
<li>采用了多子处理器分析模式，支持：英文字母（IP地址、Email、URL）、数字（日期，常用中文数量词，罗马数字，科学计数法），中文词汇（姓名、地名处理）等分词处理。</li>
<li>优化的词典存储，更小的内存占用。支持用户词典扩展定义</li>
<li>针对Lucene全文检索优化的查询分析器IKQueryParser；采用歧义分析算法优化查询关键字的搜索排列组合，能极大的提高Lucene检索的命中率。</li>
</ul>
</li>
<li><p>AtomToken：原子分词，最细颗粒度分词  </p>
</li>
</ul>
<h2 id="Tokeniser-Rules"><a href="#Tokeniser-Rules" class="headerlink" title="Tokeniser Rules"></a>Tokeniser Rules</h2><p>Tokeniser Rules标注解析器。根据数字、标点符号和单词将文本分解成不同的Token。目的是将标记解析效率最大化，并通过语法规则（Grammar rules）减轻负担以此提高标记解析工作的灵活性。<br>JAPE规则包括两部分，LHS和RHS，与LHS匹配上的标注集将会按照RHS的操作执行。</p>
<ul>
<li><p>LHS(left hand sode)包含正规表达式操作符（比如*, ?, +）的标注模式<br>  | 或者</p>
<ul>
<li>零次或者多次发生<br>? 零次或者一次发生</li>
</ul>
<ul>
<li>一次或者多次发生</li>
</ul>
</li>
<li><p>RHS(right hand side)包含了标注集操作描述，格式：<code>{LHS} &gt; {Annotation type};{attribute1}={value1};...;{attributen}={value n}</code></p>
</li>
</ul>
<h2 id="Token-Types"><a href="#Token-Types" class="headerlink" title="Token Types"></a>Token Types</h2><p>Word、Number、Symbol、Punctuation、SpaceToken</p>
<h2 id="JAPE优先级控制类型"><a href="#JAPE优先级控制类型" class="headerlink" title="JAPE优先级控制类型"></a>JAPE优先级控制类型</h2><ul>
<li>Brill:  Brill 默认的控制风格，作用是在给定的范围内对文档进行匹配并添加类型，当多个匹配规则都匹配到一个文本时默认都会把相应的类型添加上去，这些类型没有重要等级。</li>
<li>All: All 作用类似于Brill，但是All的匹配支持内嵌匹配</li>
<li>First First只匹配第一个匹配到的匹配规则并添加对应类型，所以此时使用’*’,’?’或’+’这类匹配规则是不恰当的</li>
<li>Once:  Once 一旦匹配到匹配规则，则整个JAPE解析直接退出</li>
<li>Appelt: Applet 根据优先规则，匹配唯一一个匹配规则</li>
</ul>
<h2 id="JAPE高亮插件"><a href="#JAPE高亮插件" class="headerlink" title="JAPE高亮插件"></a>JAPE高亮插件</h2><p>找到一个Linux平台的，gedit的插件：<a href="http://joenoodles.com/2012/10/jape-syntax-highlighting">jape-syntax-highlighting</a>，待尝试</p>
<p>当前处理方式</p>
<ol>
<li>myeclipse设置*.jape默认打开程序为sublime text<br><code>General&gt;Editors&gt;File Associations</code></li>
<li>在sublime text代开jape后缀文件，并将Syntax设置为open all with current extention as java</li>
<li>sublimet text3安装SublimeAStyleFormatter插件进行代码格式化<ul>
<li><code>ctrl+alt+f</code>: Format current file  </li>
<li><code>ctrl+k, ctrl+f</code>: Format current selection<br>TODO：暂不能自动格式化jape，和语法高亮报错</li>
</ul>
</li>
</ol>
<h1 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h1><h1 id="relationshioType的定义原理"><a href="#relationshioType的定义原理" class="headerlink" title="relationshioType的定义原理"></a>relationshioType的定义原理</h1><p>sentence（有限状态机）包含关系，根据实际情况定义<br>Temporal+SpacePattern(Region+Path)+person</p>
<h1 id="GATE在多线程中的配置"><a href="#GATE在多线程中的配置" class="headerlink" title="GATE在多线程中的配置"></a>GATE在多线程中的配置</h1><p><a href="https://gate.ac.uk/sale/tao/#x1-1760007.14">Using GATE Embedded in a Multithreaded Environment</a><br>All the standard ANNIE PRs are safe when independent instances are used in diﬀerent threads concurrently, as are the standard transient document, transient corpus and controller classes. A typical pattern of development for a multithreaded GATE-based application is:</p>
<pre><code>* Develop your GATE processing pipeline in GATE Developer.
* Save your pipeline as a .gapp ﬁle.
* In your application’s initialisation phase, load n copies of the pipeline using `PersistenceManager.loadObjectFromFile()` , or load the pipeline once and then make copies of it using `Factory.duplicate`, and either give one copy to each thread or store them in a pool (e.g. a LinkedList).
* When you need to process a text, get one copy of the pipeline from the pool, and return it to the pool when you have ﬁnished processing.
</code></pre><p>Alternatively you can use the Spring Framework as described in the next section to handle the pooling for you.</p>
<h2 id="Spring-pooling"><a href="#Spring-pooling" class="headerlink" title="Spring pooling"></a>Spring pooling</h2><p><a href="https://gist.github.com/geosmart/ee8ca82b03dfa10a2bdb58767060fa6f">Spring集成GATE池资源管理</a></p>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="spring集成开发的plugin如何在gate中运行"><a href="#spring集成开发的plugin如何在gate中运行" class="headerlink" title="spring集成开发的plugin如何在gate中运行"></a>spring集成开发的plugin如何在gate中运行</h2><p>由于插件最终需在gate框架中运行，建议以maven进行项目包/结构管理，fatjar编译打包；  </p>
<ul>
<li>参考Lang_Chinese插件修改gapp(根据creole.xml)，新增PR配置<br><a href="https://gate.ac.uk/sale/tao/splitch3.html">gapp参考</a><br>配置文件参考</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version="1.0"?&gt;</div><div class="line"><span class="comment">&lt;!-- Geocoding 地址解析 --&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">CREOLE-DIRECTORY</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">JAR</span> <span class="attr">SCAN</span>=<span class="string">"true"</span>&gt;</span>gto.geocoding.jar<span class="tag">&lt;/<span class="name">JAR</span>&gt;</span></div><div class="line"></div><div class="line">  <span class="tag">&lt;<span class="name">JAR</span>&gt;</span>lib/util-1.2.jar<span class="tag">&lt;/<span class="name">JAR</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">JAR</span>&gt;</span>lib/uadb.trext-1.2.jar<span class="tag">&lt;/<span class="name">JAR</span>&gt;</span></div><div class="line"></div><div class="line">  <span class="tag">&lt;<span class="name">CREOLE</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">RESOURCE</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">NAME</span>&gt;</span>GeocodingProcesser<span class="tag">&lt;/<span class="name">NAME</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">COMMENT</span>&gt;</span>地址正向解析<span class="tag">&lt;/<span class="name">COMMENT</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">HELPURL</span>&gt;</span>http://gisc.chzu.edu.cn/mysnspace/geocoding<span class="tag">&lt;/<span class="name">HELPURL</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">CLASS</span>&gt;</span>gto.geocoding.processor.GeocodingProcessMain<span class="tag">&lt;/<span class="name">CLASS</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">PARAMETER</span> <span class="attr">NAME</span>=<span class="string">"inputASName"</span> <span class="attr">RUNTIME</span>=<span class="string">"true"</span> <span class="attr">DEFAULT</span>=<span class="string">"GTO"</span></span></div><div class="line"><span class="tag">        <span class="attr">COMMENT</span>=<span class="string">"The annotation set to be used as input for the transducer"</span></span></div><div class="line"><span class="tag">        <span class="attr">OPTIONAL</span>=<span class="string">"false"</span>&gt;</span>java.lang.String</div><div class="line">      <span class="tag">&lt;/<span class="name">PARAMETER</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">PARAMETER</span> <span class="attr">NAME</span>=<span class="string">"outputASName"</span> <span class="attr">RUNTIME</span>=<span class="string">"true"</span> <span class="attr">DEFAULT</span>=<span class="string">"GTO"</span></span></div><div class="line"><span class="tag">        <span class="attr">COMMENT</span>=<span class="string">"The annotation set to be used as output for the transducer"</span></span></div><div class="line"><span class="tag">        <span class="attr">OPTIONAL</span>=<span class="string">"true"</span>&gt;</span>java.lang.String</div><div class="line">      <span class="tag">&lt;/<span class="name">PARAMETER</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">PARAMETER</span> <span class="attr">NAME</span>=<span class="string">"geocodingMethod"</span> <span class="attr">RUNTIME</span>=<span class="string">"true"</span> <span class="attr">DEFAULT</span>=<span class="string">"LT"</span></span></div><div class="line"><span class="tag">        <span class="attr">COMMENT</span>=<span class="string">"The GeocodingMethodEnum to geocoding"</span> <span class="attr">OPTIONAL</span>=<span class="string">"false"</span>&gt;</span>java.lang.String</div><div class="line">      <span class="tag">&lt;/<span class="name">PARAMETER</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">PARAMETER</span> <span class="attr">NAME</span>=<span class="string">"geocodingUrl"</span> <span class="attr">RUNTIME</span>=<span class="string">"true"</span> <span class="attr">DEFAULT</span>=<span class="string">"http://192.168.1.52:8080/uadb.app/rest/v100/dz/geocoding"</span></span></div><div class="line"><span class="tag">        <span class="attr">COMMENT</span>=<span class="string">"The geocoding url"</span> <span class="attr">OPTIONAL</span>=<span class="string">"false"</span>&gt;</span>java.lang.String</div><div class="line">      <span class="tag">&lt;/<span class="name">PARAMETER</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">RESOURCE</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">CREOLE</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">CREOLE-DIRECTORY</span>&gt;</span></div></pre></td></tr></table></figure>
<ul>
<li>将插件复制于GATE\plugins根目录内；  </li>
<li>在gate中手动配置PR顺序，执行标注无误后，另存为gapp<br>urlList新增URLHolder</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">gate.util.persistence.PersistenceManager-URLHolder</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">urlString</span>&gt;</span>$relpath$../../../../gto.geocoding/<span class="tag">&lt;/<span class="name">urlString</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">gate.util.persistence.PersistenceManager-URLHolder</span>&gt;</span></div></pre></td></tr></table></figure>
<ul>
<li>CollectionPersistence新增PRPersistence  </li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">gate.util.persistence.PRPersistence</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">runtimeParams</span> <span class="attr">class</span>=<span class="string">"gate.util.persistence.MapPersistence"</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">mapType</span>&gt;</span>gate.util.SimpleFeatureMapImpl<span class="tag">&lt;/<span class="name">mapType</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">localMap</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">entry</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">string</span>&gt;</span>inputASName<span class="tag">&lt;/<span class="name">string</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">string</span>&gt;</span>GTO<span class="tag">&lt;/<span class="name">string</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">entry</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">entry</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">string</span>&gt;</span>outputASName<span class="tag">&lt;/<span class="name">string</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">string</span>&gt;</span>GTO<span class="tag">&lt;/<span class="name">string</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">entry</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">entry</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">string</span>&gt;</span>geocodingMethod<span class="tag">&lt;/<span class="name">string</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">string</span>&gt;</span>LT<span class="tag">&lt;/<span class="name">string</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">entry</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">entry</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">string</span>&gt;</span>geocodingUrl<span class="tag">&lt;/<span class="name">string</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">string</span>&gt;</span>http://192.168.1.52:8080/uadb.app/rest/v100/dz/geocoding<span class="tag">&lt;/<span class="name">string</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">entry</span>&gt;</span></div><div class="line">      <span class="tag">&lt;/<span class="name">localMap</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">runtimeParams</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">resourceType</span>&gt;</span>gto.geocoding.processor.GeocodingProcessMain<span class="tag">&lt;/<span class="name">resourceType</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">resourceName</span>&gt;</span>GeocodingProcess<span class="tag">&lt;/<span class="name">resourceName</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">initParams</span> <span class="attr">class</span>=<span class="string">"gate.util.persistence.MapPersistence"</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">mapType</span>&gt;</span>gate.util.SimpleFeatureMapImpl<span class="tag">&lt;/<span class="name">mapType</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">localMap</span>/&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">initParams</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">features</span> <span class="attr">class</span>=<span class="string">"gate.util.persistence.MapPersistence"</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">mapType</span>&gt;</span>gate.util.SimpleFeatureMapImpl<span class="tag">&lt;/<span class="name">mapType</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">localMap</span>/&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">features</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">gate.util.persistence.PRPersistence</span>&gt;</span></div></pre></td></tr></table></figure>
<h2 id="Jface运行GATE环境路径设置问题"><a href="#Jface运行GATE环境路径设置问题" class="headerlink" title="Jface运行GATE环境路径设置问题"></a>Jface运行GATE环境路径设置问题</h2><p>问题：GATE环境，以Fatjar打包JFace程序，错误日志：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">Could not check plugin-mappings.xml</div><div class="line">java.net.MalformedURLException: no protocol: plugin-mappings.xml</div><div class="line">gate.util.GateException: java.net.MalformedURLException: no protocol: creole.xml      </div><div class="line">gate.creole.ResourceInstantiationException:Couldnot get resource data <span class="keyword">for</span> gate.corpora.CorpusImpl.</div><div class="line">You may need first to load the plugin that contains your resource.</div><div class="line">For example, to create a gate.creole.tokeniser.DefaultTokeniser</div><div class="line">you need first to load the ANNIE plugin.</div><div class="line">Go to the menu File-&gt;Manage CREOLE plugins or use the method</div><div class="line">Gate.getCreoleRegister().registerDirectories(pluginDirectoryURL)</div></pre></td></tr></table></figure>
<p>解决：路径问题，单斜杠改成双斜杠</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//错误</span></div><div class="line">System.setProperty(<span class="string">"gate.builtin.ic.dir"</span>, <span class="keyword">new</span> File(gateDir + <span class="string">"/resources/creole"</span>).toURL().toURI().toString());</div><div class="line"><span class="comment">//正确</span></div><div class="line">String builtinDir = <span class="keyword">new</span> File(gateDir + <span class="string">"\\resources\\creole"</span>).toURI().toURL().toString();</div><div class="line">System.setProperty(<span class="string">"gate.builtin.creole.dir"</span>, builtinDir);</div></pre></td></tr></table></figure>
<h2 id="gate插件加载错误"><a href="#gate插件加载错误" class="headerlink" title="gate插件加载错误"></a>gate插件加载错误</h2><ul>
<li>错误日志</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">gate.creole.ResourceInstantiationException: Could not get resource data <span class="keyword">for</span> gate.creole.gazetteer.DefaultGazetteer.</div><div class="line">gate.creole.gazetteer.DefaultGazetteer can be found in the ANNIE plugin</div></pre></td></tr></table></figure>
<ul>
<li><p>问题定位：需要在GATE中注册ANNIE插件，初始化后千万别忘得了！</p>
</li>
<li><p>解决方案：</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">boolean</span> initialized = <span class="keyword">false</span>;</div><div class="line">String gateDir = System.getProperty(<span class="string">"user.dir"</span>) + <span class="string">"/src/main/resources/gate"</span>;</div><div class="line"></div><div class="line"><span class="meta">@Before</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">startup</span><span class="params">()</span> </span>&#123;</div><div class="line">System.out.println(<span class="string">"---startup"</span>);</div><div class="line"></div><div class="line"><span class="keyword">if</span> (!initialized) &#123;</div><div class="line">  <span class="comment">// 初始化GATE环境</span></div><div class="line">  gateCommonService.setGateDir(gateDir);</div><div class="line">  gateCommonService.initGate();</div><div class="line">  <span class="comment">//注册插件</span></div><div class="line">  gateCommonService.registerGatePlugins(<span class="keyword">new</span> String[] &#123;<span class="string">"ANNIE"</span>, <span class="string">"Lang_Chinese"</span>&#125;);</div><div class="line">  initialized = <span class="keyword">true</span>;</div><div class="line">&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">registerGatePlugins</span><span class="params">(String[] pluginNames)</span> </span>&#123;</div><div class="line">  <span class="keyword">for</span> (String pluginName : pluginNames) &#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      URL pathUrl = getGatePluginPath(pluginName);</div><div class="line">      Gate.getCreoleRegister().registerDirectories(pathUrl);</div><div class="line">    &#125; <span class="keyword">catch</span> (GateException e) &#123;</div><div class="line">      e.printStackTrace();</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="Linux中gate初始化错误"><a href="#Linux中gate初始化错误" class="headerlink" title="Linux中gate初始化错误"></a>Linux中gate初始化错误</h2><ul>
<li>错误日志</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Using file:/uadb/uadb.etl.pre/resources/gate/%<span class="number">5</span>Cresources%<span class="number">5</span>Ccreole/ as built-in CREOLE directory URL</div><div class="line"> <span class="number">2015</span>-<span class="number">11</span>-<span class="number">10</span> <span class="number">22</span>:<span class="number">08</span>:<span class="number">26</span>,<span class="number">255</span> [main] [gate.creole.CreoleRegisterImpl] [WARN] - Could not check plugin-mappings.xml</div><div class="line"> java.io.FileNotFoundException: /uadb/uadb.etl.pre/resources/gate/\resources\creole/plugin-mappings.xml (No such file or directory)</div></pre></td></tr></table></figure>
<ul>
<li><p>问题定位：window下用的\和\符号在linux下和unix下不可用</p>
</li>
<li><p>解决方案：路径符号由\改成//</p>
</li>
</ul>
<h2 id="Spring集成GATE，Fatjar打包后的标注乱码问题"><a href="#Spring集成GATE，Fatjar打包后的标注乱码问题" class="headerlink" title="Spring集成GATE，Fatjar打包后的标注乱码问题"></a>Spring集成GATE，Fatjar打包后的标注乱码问题</h2><ul>
<li>问题描述：main和junit测试标注正常，但fatjar打包后的程序业务标注未生成<br>  应标注：[Number, Token, Lookup, SpaceToken, Split, Sentence, IKAToken, AtomToken, Context, Place, Mapcode, Location, Region,Scale, Entity]<br>  实际标注：[Split, Token, SpaceToken, DEFAULT_TOKEN, Sentence, IKAToken,AtomToken]</li>
<li>问题定位<br>chineseNE子管道配置的标注有问题，多出个DEFAULT_TOKEN，Sentence正常标注，但未生成Number和Lookup标注，</li>
<li>解决方案<br>gate环境用spring集成，程序是调用gapp执行标注piopeline，jape和gazetteer等资源都是外部化的，为什么不行？<br>进行各种测试排除，发现输出日志中错误的都是乱码，断定是读文件的编码问题！！！这种问题，解决过程中纠结的要死，解决了感觉自己绝逼傻透了！<br>想起那首记忆深刻的程序员之诗，<code>手持两把锟斤拷，口中直呼烫烫烫，脚踏千朵屯屯屯，笑看万物锘锘锘</code></li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//错误</span></div><div class="line">Document doc = Factory.newDocument(file.toURI().toURL());</div><div class="line"><span class="comment">//正确</span></div><div class="line">Document doc = Factory.newDocument(file.toURI().toURL(), <span class="string">"UTF-8"</span>);</div></pre></td></tr></table></figure>
<h2 id="Gazetteer问题"><a href="#Gazetteer问题" class="headerlink" title="Gazetteer问题"></a>Gazetteer问题</h2><ul>
<li>问题描述：Correct format for gazetteer entry features is: <a href="[separator][featureName]=[featureValue]">entry</a>*</li>
<li>解决：gazetteer辞典中不能带有冒号，会识别成<code>list.def</code>然后抛错</li>
</ul>
]]></content>
      
        <categories>
            
            <category> NLP </category>
            
        </categories>
        
        
        <tags>
            
            <tag> NLP </tag>
            
            <tag> 大数据 </tag>
            
            <tag> GATE </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Maven使用笔记]]></title>
      <url>http://geosmart.github.io/2015/09/15/Maven%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<h1 id="关于Maven"><a href="#关于Maven" class="headerlink" title="关于Maven"></a>关于Maven</h1><p>Maven是基于项目对象模型(POM)，可以通过一小段描述信息来管理项目的构建，报告和文档的软件项目管理工具。  </p>
<p>本文记录Maven开发过程中常用的脚本和遇到的问题。</p>
<hr>
<a id="more"></a>
<h1 id="Maven-Dependency"><a href="#Maven-Dependency" class="headerlink" title="Maven Dependency"></a>Maven Dependency</h1><p>在POM 4中，<dependency>中还引入了<scope>，它主要管理依赖的部署。目前<scope>可以使用5个值：</p>
<pre><code>* compile，缺省值，适用于所有阶段，会随着项目一起发布。
* provided，类似compile，期望JDK、容器或使用者会提供这个依赖。如servlet.jar。
* runtime，只在运行时使用，如JDBC驱动，适用运行和测试阶段。
* test，只在测试时使用，用于编译和运行测试代码。不会随项目发布。
* system，类似provided，需要显式提供包含依赖的jar，Maven不会在Repository中查找它。
</code></pre><h1 id="Maven常用指令"><a href="#Maven常用指令" class="headerlink" title="Maven常用指令"></a>Maven常用指令</h1><p><code>package</code>：打包<br><code>war:exploded</code>：编译不生成war包<br><code>install</code>：安装到本地资源库<br>     eg：<code>mvn install:install-file -Dfile=lt.util-1.0.jar -DgroupId=com.lt -DartifactId=util -Dversion=1.0 -Dpackaging=jar</code><br><code>process-resources</code>：编译并打包资源<br>新建项目：<code>mvn archetype:generate -DgroupId=com.lt -DartifactId=uadb.etl -DarchetypeArtifactIdmaven-archetype-webapp -DinteractiveMode=false</code></p>
<h1 id="maven-dependency-exclusion"><a href="#maven-dependency-exclusion" class="headerlink" title="maven dependency exclusion"></a>maven dependency exclusion</h1><h1 id="maven远程库"><a href="#maven远程库" class="headerlink" title="maven远程库"></a>maven远程库</h1><ul>
<li><p><a href="https://search.maven.org/#search">https://search.maven.org/#search</a></p>
</li>
<li><p><a href="http://maven-repository.com/">http://maven-repository.com/</a></p>
</li>
<li><p><a href="http://mvnrepository.com/">http://mvnrepository.com/</a></p>
</li>
<li><p><a href="http://repository.apache.org/snapshots/">http://repository.apache.org/snapshots/</a></p>
</li>
<li><p><a href="http://maven.outofmemory.cn/">http://maven.outofmemory.cn/</a></p>
</li>
</ul>
<p>当然，在国内还是老实参考<a href="http://maven.oschina.net/help.html">开源中国社区的教程</a>配置maven<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"> <span class="tag">&lt;<span class="name">mirrors</span>&gt;</span></div><div class="line">true<span class="tag">&lt;<span class="name">mirror</span>&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">id</span>&gt;</span>nexus-osc<span class="tag">&lt;/<span class="name">id</span>&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">name</span>&gt;</span>Nexus osc<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.oschina.net/content/groups/public/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></div><div class="line">true<span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></div><div class="line">true<span class="tag">&lt;<span class="name">mirror</span>&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">id</span>&gt;</span>nexus-osc-thirdparty<span class="tag">&lt;/<span class="name">id</span>&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>thirdparty<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">name</span>&gt;</span>Nexus osc thirdparty<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.oschina.net/content/repositories/thirdparty/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></div><div class="line">true<span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">mirrors</span>&gt;</span></div></pre></td></tr></table></figure></p>
<p><a href="https://www.1maven.com/index.html">maven依赖离线下载-1maven</a></p>
<h1 id="上传项目到Maven-Central-Repository"><a href="#上传项目到Maven-Central-Repository" class="headerlink" title="上传项目到Maven Central Repository"></a>上传项目到Maven Central Repository</h1><h2 id="Maven本地开发"><a href="#Maven本地开发" class="headerlink" title="Maven本地开发"></a>Maven本地开发</h2><ul>
<li>下载apache-maven</li>
<li>设置本地库路径<br>在maven\config\settings.xml中设置本地库路径：<code>&lt;localRepository&gt;D:\Dev\Maven-Respository&lt;/localRepository&gt;</code></li>
<li>在Myeclipse中设置安装路径<br>在<code>Window&gt;Preferences&gt;Myeclipse&gt;Maven4Myeclipse&gt;Installations</code>中执行Add加入本地maven路径<br>在<code>Window&gt;Preferences&gt;Myeclipse&gt;Maven4Myeclipse&gt;User Settings</code>中Browser选择maven\config\settings.xml，执行Update Settings，Reindex</li>
</ul>
<h2 id="maven引用本地jar包"><a href="#maven引用本地jar包" class="headerlink" title="maven引用本地jar包"></a>maven引用本地jar包</h2><p>假设将包htmlparser.jar放入了项目下的lib目录中 -&gt; ${project}/lib/htmlparser.jar,则pom.xml中应该配置如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span>  </div><div class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.htmlparser<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>  </div><div class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>htmlparser<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>  </div><div class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span>  </div><div class="line">  <span class="tag">&lt;<span class="name">scope</span>&gt;</span>system<span class="tag">&lt;/<span class="name">scope</span>&gt;</span>  </div><div class="line">  <span class="tag">&lt;<span class="name">systemPath</span>&gt;</span>$&#123;project.basedir&#125;/lib/htmlparser.jar<span class="tag">&lt;/<span class="name">systemPath</span>&gt;</span>  </div><div class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div></pre></td></tr></table></figure></p>
<h2 id="Maven项目聚合"><a href="#Maven项目聚合" class="headerlink" title="Maven项目聚合"></a>Maven项目聚合</h2><p>为解决多个依赖项目自动打包，可通过聚合maven项目解决<br>pom示例<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></div><div class="line"><span class="tag">	<span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></div><div class="line">true<span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></div><div class="line"></div><div class="line">true<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.lt.util<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">true<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>util.aggregation<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">true<span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">true<span class="tag">&lt;<span class="name">packaging</span>&gt;</span>pom<span class="tag">&lt;/<span class="name">packaging</span>&gt;</span></div><div class="line"></div><div class="line">true<span class="tag">&lt;<span class="name">name</span>&gt;</span>util.aggregation<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line"></div><div class="line">true<span class="tag">&lt;<span class="name">properties</span>&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></div><div class="line">true<span class="tag">&lt;/<span class="name">properties</span>&gt;</span></div><div class="line">true<span class="tag">&lt;<span class="name">modules</span>&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">module</span>&gt;</span>../util.common<span class="tag">&lt;/<span class="name">module</span>&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">module</span>&gt;</span>../util.jdbc<span class="tag">&lt;/<span class="name">module</span>&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">module</span>&gt;</span>../util.web<span class="tag">&lt;/<span class="name">module</span>&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">module</span>&gt;</span>../util.geo<span class="tag">&lt;/<span class="name">module</span>&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">module</span>&gt;</span>../util.hibernate<span class="tag">&lt;/<span class="name">module</span>&gt;</span></div><div class="line">true<span class="tag">&lt;/<span class="name">modules</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></div></pre></td></tr></table></figure></p>
<p>通过<code>mvn clean install</code>进行打包</p>
<h2 id="Maven项目依赖继承"><a href="#Maven项目依赖继承" class="headerlink" title="Maven项目依赖继承"></a>Maven项目依赖继承</h2><p><code>uadb.parent</code>项目<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></div><div class="line"><span class="tag">	<span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></div><div class="line">true<span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></div><div class="line"></div><div class="line">true<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.lt.uadb<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">true<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>uadb.parent<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">true<span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">true<span class="tag">&lt;<span class="name">packaging</span>&gt;</span>pom<span class="tag">&lt;/<span class="name">packaging</span>&gt;</span></div><div class="line"></div><div class="line">true<span class="tag">&lt;<span class="name">name</span>&gt;</span>uadb.parent<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">true<span class="comment">&lt;!-- 项目属性 --&gt;</span></div><div class="line">true<span class="tag">&lt;<span class="name">properties</span>&gt;</span></div><div class="line">truetrue<span class="comment">&lt;!-- framework --&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">jdk.version</span>&gt;</span>1.7<span class="tag">&lt;/<span class="name">jdk.version</span>&gt;</span></div><div class="line">truetrue<span class="comment">&lt;!-- test --&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">junit.version</span>&gt;</span>4.8.2<span class="tag">&lt;/<span class="name">junit.version</span>&gt;</span></div><div class="line">truetrue<span class="comment">&lt;!-- encode --&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></div><div class="line">true<span class="tag">&lt;/<span class="name">properties</span>&gt;</span></div><div class="line">true<span class="tag">&lt;<span class="name">dependencyManagement</span>&gt;</span></div><div class="line"></div><div class="line">truetrue<span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></div><div class="line">truetruetrue<span class="comment">&lt;!--test --&gt;</span></div><div class="line">truetruetrue<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">truetruetruetrue<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">truetruetruetrue<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">truetruetruetrue<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;junit.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">truetruetruetrue<span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></div><div class="line">truetruetrue<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line">truetrue<span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></div><div class="line">true<span class="tag">&lt;/<span class="name">dependencyManagement</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></div></pre></td></tr></table></figure></p>
<p>child项目引用parent项目<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></div><div class="line"><span class="tag">	<span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></div><div class="line">true<span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></div><div class="line">true<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>uadb.etl.pre<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">true<span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">true<span class="tag">&lt;<span class="name">name</span>&gt;</span>uadb.etl.pre<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">true<span class="tag">&lt;<span class="name">packaging</span>&gt;</span>jar<span class="tag">&lt;/<span class="name">packaging</span>&gt;</span></div><div class="line"></div><div class="line">true<span class="tag">&lt;<span class="name">parent</span>&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.lt.uadb<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>uadb.parent<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">true<span class="tag">&lt;/<span class="name">parent</span>&gt;</span></div><div class="line">true<span class="comment">&lt;!-- 项目属性 --&gt;</span></div><div class="line">true<span class="tag">&lt;<span class="name">properties</span>&gt;</span></div><div class="line">truetrue<span class="comment">&lt;!-- framework --&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">jdk.version</span>&gt;</span>1.7<span class="tag">&lt;/<span class="name">jdk.version</span>&gt;</span></div><div class="line">truetrue<span class="comment">&lt;!-- test --&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">junit.version</span>&gt;</span>4.8.2<span class="tag">&lt;/<span class="name">junit.version</span>&gt;</span></div><div class="line">truetrue<span class="comment">&lt;!-- encode --&gt;</span></div><div class="line">truetrue<span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></div><div class="line">true<span class="tag">&lt;/<span class="name">properties</span>&gt;</span></div><div class="line"></div><div class="line">true<span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></div><div class="line">truetruetrue<span class="comment">&lt;!--test --&gt;</span></div><div class="line">  		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">  			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">  			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">  		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line">true<span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></div></pre></td></tr></table></figure></p>
<h1 id="复制依赖项"><a href="#复制依赖项" class="headerlink" title="复制依赖项"></a>复制依赖项</h1><p>dependency:copy-dependencies<br>输出到target/deps</p>
<h1 id="在Github搭建个人Maven仓库"><a href="#在Github搭建个人Maven仓库" class="headerlink" title="在Github搭建个人Maven仓库"></a>在Github搭建个人Maven仓库</h1><h2 id="deploy到本地目录"><a href="#deploy到本地目录" class="headerlink" title="deploy到本地目录"></a>deploy到本地目录</h2><h2 id="本地目录提交到gtihub上"><a href="#本地目录提交到gtihub上" class="headerlink" title="本地目录提交到gtihub上"></a>本地目录提交到gtihub上</h2><h2 id="配置github地址为仓库地址"><a href="#配置github地址为仓库地址" class="headerlink" title="配置github地址为仓库地址"></a>配置github地址为仓库地址</h2><h1 id="Maven问题记录"><a href="#Maven问题记录" class="headerlink" title="Maven问题记录"></a>Maven问题记录</h1><ul>
<li>本地库有改jar包但是依旧无法编译<br>本地下载的Zip已损坏，删除本地库中的jar文件和目录，重新从远处库下载</li>
</ul>
<ul>
<li><p>远程库只能下载索引，不能下载jar！<br>日志：The container ‘Maven Dependencies’ references non existing library ‘D:\soft\Maven\Maven-Respository\org\apache\ant\ant\1.9.3\ant-1.9.3.jar’<br>解决：<br>So I get you are using Eclipse with the M2E plugin. Try to update your Maven configuration : In the Project Explorer, right-click on the project, Maven -&gt; Update project.<br>If the problem still remains, try to clean your project: right-click on your pom.xml, Run as -&gt; Maven build (the second one). Enter “clean package” in the Goals fields. Check the Skip Tests box. Click on the Run button.</p>
</li>
<li><p>cannot find maven installation embedded<br>Simply remove the external maven installation. When you restart eclipse, the embedded maven will reappear.</p>
</li>
<li><p>install offline问题<br>The repository system is offline but the artifact org.apache.maven.plugins:maven-install-plugin:pom:2.3.1 is not available in the local repository.<br>取消勾选offline选项,重新执行install</p>
</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 后端技术 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> J2EE </tag>
            
            <tag> Maven </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[SQLite数据库使用笔记]]></title>
      <url>http://geosmart.github.io/2015/09/15/SQLite%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<h1 id="SQLite特点"><a href="#SQLite特点" class="headerlink" title="SQLite特点"></a>SQLite特点</h1><p>SQLite只支持库级锁，同时只能允许一个写操作。但SQLite尽量延迟申请X锁，直到数据块真正写盘时才申请X锁，非常巧妙而有效。</p>
<ol>
<li>SQLite支持3种线程模式:单线程,多线程,串行</li>
<li>可使用WAL（Write-Ahead Logging）模式时，写操作是append到WAL文件，而不直接改动数据库文件，因此数据库文件可以被同时读取。当执行checkpoint操作时，WAL文件的内容会被写回数据库文件。当WAL文件达到SQLITE_DEFAULT_WAL_AUTOCHECKPOINT（默认值是1000）页（默认大小是1KB）时，会自动使用当前COMMIT的线程来执行checkpoint操作。也可以关闭自动checkpoint，改为手动定期<br>checkpoint。jdbc可通过setJournalMode(JournalMode.WAL)/setJounalSizeLimit实现</li>
<li>事务是和数据库连接相关的，每个数据库连接（使用pager来）维护自己的事务，且同时只能有一个事务（但是可以用SAVEPOINT来实现内嵌事务）。</li>
</ol>
<hr>
<a id="more"></a>
<p><a href="http://www.sqlite.org/wal.html">官方文档</a><br><a href="http://www.cnblogs.com/wuhenke/archive/2011/11/20/2256618.html">sqlite在多线程下的应用</a></p>
<h2 id="WAL模式"><a href="#WAL模式" class="headerlink" title="WAL模式"></a>WAL模式</h2><ul>
<li>-shm文件包含-wal文件的数据索引，-shm文件提升-wal文件的读性能</li>
<li>如果-shm文件被删除，下次数据库连接时会自动新建一个-shm文件 </li>
<li>如果执行了checkpoint命令，-war文件可以删除</li>
</ul>
<h2 id="VACUUM命令"><a href="#VACUUM命令" class="headerlink" title="VACUUM命令"></a>VACUUM命令</h2><p>VACUUM命令用于重建数据库文件， 执行VACUUM 时，会拷贝整个数据库到Transient databases临时文件中，然后覆盖写回到原来的数据库文件中。<br>写回过程中会创建rollback journal or write-ahead log WAL file以保证transaction atomic。当vacuum执行完毕，临时文件被删除。   </p>
<p>重建数据库文件的原因有以下几点</p>
<ol>
<li>当大量数据被删除后，数据库文件中会有很多空块,空页和碎片，VACUUM rebuild数据库文件，移除这些空块，减少所占的磁盘空间</li>
<li>频繁的inserts, updates, and deletes 导致数据库文件中很多碎片，VACUUM 重建数据库文件使得表，索引连续的存储, 减少空闲页， 减少所占的磁盘空间</li>
<li>当page_size 或用pragma auto_vacuum 命令修改这两个值时， SQLite会自动执行VACUMM</li>
<li>VACUUM只对main数据库有效，对ATTACHED数据库无效</li>
<li>如果数据库中还有其他transaction， VACUUM将执行失败</li>
<li>除了使用VACUUM外，还可以使用PRAGMA auto_vacuum控制vacuum的执行<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">PRAGMA auto_vacuum;</div><div class="line">PRAGMA auto_vacuum = 0 | NONE | 1 | FULL | 2 | INCREMENTAL;</div></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="synchronous参数"><a href="#synchronous参数" class="headerlink" title="synchronous参数"></a>synchronous参数</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">PRAGMA synchronous = FULL; (2)</div><div class="line">PRAGMA synchronous = NORMAL; (1)</div><div class="line">PRAGMA synchronous = OFF; (0)</div></pre></td></tr></table></figure>
<h2 id="FULL"><a href="#FULL" class="headerlink" title="FULL"></a>FULL</h2><p>当synchronous设置为FULL (2), SQLite数据库引擎在紧急时刻会暂停以确定数据已经写入磁盘。这使系统崩溃或电源出问题时能确保数据库在重起后不会损坏。FULL synchronous很安全但很慢。</p>
<h2 id="NORMAL"><a href="#NORMAL" class="headerlink" title="NORMAL"></a>NORMAL</h2><p>当synchronous设置为NORMAL, SQLite数据库引擎在大部分紧急时刻会暂停，但不像FULL模式下那么频繁。 NORMAL模式下有很小的几率(但不是不存在)发生电源故障导致数据库损坏的情况。但实际上，在这种情况 下很可能你的硬盘已经不能使用，或者发生了其他的不可恢复的硬件错误。</p>
<h2 id="OFF"><a href="#OFF" class="headerlink" title="OFF"></a>OFF</h2><p>设置为synchronous OFF (0)时，SQLite在传递数据给系统以后直接继续而不暂停。若运行SQLite的应用程序崩溃， 数据不会损伤，但在系统崩溃或写入数据时意外断电的情况下数据库可能会损坏。另一方面，在synchronous OFF时 一些操作可能会快50倍甚至更多。在SQLite 2中，缺省值为NORMAL.而在3中修改为FULL。  www.2cto.com</p>
<p>建议：<br>如果有定期备份的机制，而且少量数据丢失可接受，用OFF。</p>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="提交-wal修改到数据库main文件"><a href="#提交-wal修改到数据库main文件" class="headerlink" title="提交-wal修改到数据库main文件"></a>提交-wal修改到数据库main文件</h2><p>执行<code>VACUUM</code>命令即可生成最新的数据库-db文件</p>
<h2 id="如何删除使用中的SQLite数据库"><a href="#如何删除使用中的SQLite数据库" class="headerlink" title="如何删除使用中的SQLite数据库"></a>如何删除使用中的SQLite数据库</h2><p><a href="http://stackoverflow.com/questions/991489/i-cant-delete-a-file-in-java">参考</a></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 添加System.gc()和Thread.sleep进行强制删除 </span></div><div class="line">System.gc();</div><div class="line">Thread.sleep(<span class="number">1000</span>);</div><div class="line">FileDeleteStrategy.FORCE.delete(workFile);</div></pre></td></tr></table></figure>
<h2 id="SQLite开启WAL读写模式"><a href="#SQLite开启WAL读写模式" class="headerlink" title="SQLite开启WAL读写模式"></a>SQLite开启WAL读写模式</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">SQLiteConfig config = <span class="keyword">new</span> SQLiteConfig();</div><div class="line">config.setOpenMode(SQLiteOpenMode.READWRITE);</div><div class="line">config.setJournalMode(JournalMode.WAL); </div><div class="line">dataSource.setConfig(config);</div></pre></td></tr></table></figure>
<h2 id="SQLite批量更新"><a href="#SQLite批量更新" class="headerlink" title="SQLite批量更新"></a>SQLite批量更新</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"> <span class="comment">/**</span></div><div class="line"><span class="comment">  * 批量更新</span></div><div class="line"><span class="comment">  * </span></div><div class="line"><span class="comment">  * <span class="doctag">@param</span> updateSqlList</span></div><div class="line"><span class="comment">  */</span></div><div class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">batchUpdate</span><span class="params">(List&lt;String&gt; updateSqlList)</span> </span>&#123;</div><div class="line"><span class="keyword">if</span> (updateSqlList.size() &gt; <span class="number">0</span>) &#123;</div><div class="line">  <span class="keyword">try</span> &#123; </div><div class="line">trueConnection conn = dataSource.getConnection();</div><div class="line">trueStatement statement = conn.createStatement();</div><div class="line">true<span class="keyword">for</span> (String sql : updateSqlList) &#123;</div><div class="line">true  statement.addBatch(sql);</div><div class="line">true&#125;</div><div class="line">true<span class="keyword">int</span>[] count = statement.executeBatch();</div><div class="line"></div><div class="line">truelog.info(<span class="string">"SQLite-JDBC批量更新&#123;&#125;条"</span>, count.length);</div><div class="line">  &#125; <span class="keyword">catch</span> (SQLException e) &#123;</div><div class="line">truee.printStackTrace();</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"> &#125;</div></pre></td></tr></table></figure>
<h2 id="sqlite除法运算保留小数问题"><a href="#sqlite除法运算保留小数问题" class="headerlink" title="sqlite除法运算保留小数问题"></a>sqlite除法运算保留小数问题</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span>  <span class="keyword">distinct</span> <span class="number">1</span>/<span class="number">100</span> <span class="keyword">from</span> 兴趣点</div><div class="line"># 结果：<span class="number">0</span></div><div class="line"></div><div class="line"><span class="keyword">select</span>  <span class="keyword">distinct</span> <span class="keyword">cast</span>(<span class="number">1</span> <span class="keyword">as</span> <span class="built_in">real</span>)/<span class="number">100</span>  <span class="keyword">from</span> 兴趣点</div><div class="line"># 结果：<span class="number">0.01</span></div></pre></td></tr></table></figure>
<h2 id="sqlite存储number型时小于0的值会以0存储"><a href="#sqlite存储number型时小于0的值会以0存储" class="headerlink" title="sqlite存储number型时小于0的值会以0存储"></a>sqlite存储number型时小于0的值会以0存储</h2><h2 id="sqlite3-8-shell连接数据库"><a href="#sqlite3-8-shell连接数据库" class="headerlink" title="sqlite3.8-shell连接数据库"></a>sqlite3.8-shell连接数据库</h2><p><code>cd /usr/local/sqlite &amp;&amp;  sqlite3 /uadb/data/geocodingdb.db</code></p>
<h2 id="Cannot-change-read-only-flag-after-establishing-a-connection"><a href="#Cannot-change-read-only-flag-after-establishing-a-connection" class="headerlink" title="Cannot change read-only flag after establishing a connection"></a>Cannot change read-only flag after establishing a connection</h2><p>日志：<code>[org.hibernate.engine.jdbc.spi.SqlExceptionHelper] [ERROR] - Cannot change read-only flag after establishing a connection. Use SQLiteConfig#setReadOnly and SQLiteConfig.createConnection().</code><br>解决：</p>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> J2EE </tag>
            
            <tag> SQLite </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[NLP学习笔记]]></title>
      <url>http://geosmart.github.io/2015/09/11/NLP%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>记录一些NLP学习过程中的专业名词</p>
<hr>
<a id="more"></a>
<h1 id="专业名词"><a href="#专业名词" class="headerlink" title="专业名词"></a>专业名词</h1><ul>
<li>NLP(Natural Language Processing)：自然语言处理，主要涉及计算机处理人类语言的数据结构和算法的计算科学。</li>
<li><p>Ontology本体：本体是一种描述术语（包含哪些词汇）及术语间关系（描述苹果、香蕉、水果之间的关系）的概念模型。<em>符号到本体的某种映射</em><br>本体是表达概念之间关系的有效手段，它是共享概念模型的明确的形式化规范说明，它在共享范围内描述了领域中的概念及概念之间的关系，使其具有明确的、形式化的定义,从而实现人机之间以及机器之间的信息交互、知识共享与重用。</p>
</li>
<li><p>FSM(Finite-state machine)有限状态机：称状态机，是表示有限个状态以及在这些状态之间的转移和动作等行为的数学模型。</p>
</li>
<li><p>GATE(General Architecture for Text Engineering)文本工程通用框架</p>
</li>
<li><p>IR(Information Resolve)信息检索</p>
</li>
<li><p>IE(Information Extract)信息抽取</p>
</li>
<li><p>HMM(Hidden Markov Models)隐马尔科夫模型：一个隐马尔科夫模型它用来描述一个含有隐含未知参数的马尔可夫过程。其难点是从可观察的参数中确定该过程的隐含参数。然后利用这些参数来作进一步的分析，例如模式识别。  </p>
</li>
</ul>
<blockquote>
<p>由一个向量和两个矩阵(pi,A,B)描述的隐马尔科夫模型对于实际系统有着巨大的价值，虽然经常只是一种近似，但它们却是经得起分析的。隐马尔科夫模型通常解决的问题包括：</p>
<ol>
<li>对于一个观察序列匹配最可能的系统——评估，使用前向算法（forward algorithm）解决；</li>
<li>对于已生成的一个观察序列，确定最可能的隐藏状态序列——解码，使用Viterbi 算法（Viterbi algorithm）解决；</li>
<li>对于已生成的观察序列，决定最可能的模型参数——学习，使用前向-后向算法（forward-backward algorithm）解决。<br><a href="http://www.cnblogs.com/skyme/p/4651331.html">HMM扩展阅读</a></li>
</ol>
</blockquote>
<h2 id="GATE专业名词"><a href="#GATE专业名词" class="headerlink" title="GATE专业名词"></a>GATE专业名词</h2><ul>
<li><p>LR(Language Resource)：语言资源，与数据相关的资源，比如词典、文档和本体(Ontology)等。其中一些语言组件需要和软件搭配使用（比如，WordNet 使用了 C 和 Prolog语言的 API 的用户查询接口），虽然其中涉及了软件，但是由于 API 也是为语言资源服务的，所以我们仍然把这些资源定义为语言组件。</p>
</li>
<li><p>PR(Processing Resource)：处理资源，表示主要算法实体，如，解析算法，生成算法或n-元模型（ngram）建模算法。</p>
</li>
<li><p>VR（Pisual Resource）: 可视化资源，指构成 GATE 的可视化界面 GUI 的相关资源。</p>
</li>
<li><p>CREOLE(a Collection of Reusable Objects for Language Engineering)可重用语言引擎对象集合，提供了文本解析、文本抽取、结果测算等众多插件</p>
</li>
<li><p>ANNIE</p>
</li>
<li><p>Corpus 语料库，文档的集合</p>
</li>
</ul>
<h2 id="行业名词"><a href="#行业名词" class="headerlink" title="行业名词"></a>行业名词</h2><ul>
<li><p>GTO：geography text ontology</p>
</li>
<li><p>iCERS ：Integrated Crime Emergency Response System</p>
</li>
</ul>
<blockquote>
<p>Integrated Crime Emergency Response System (iCERS) is a large-scale spatio-temporal system which integrates all sorts of crime emergency service resources and majors its features as common codes used for public emergency events reporting.</p>
</blockquote>
<ul>
<li>CE2M ：Crime Emergency Event Model</li>
</ul>
<blockquote>
<p>The ontology for Crime Emergency Event Model (CE2M) is recommended as an effective means to implement semantic level integration. CE2M is stratified into three levels: Event, Process and Action. CE2M constructs the vocabulary and the common model for exchange of iCERS information, thus it becomes the common comprehension of each business subsystems.</p>
</blockquote>
<h1 id="相关阅读"><a href="#相关阅读" class="headerlink" title="相关阅读"></a>相关阅读</h1><ul>
<li>《数学之美》科普阅读  </li>
<li>《统计自然语处理基础》阅读中…</li>
<li>《概率论》</li>
</ul>
]]></content>
      
        <categories>
            
            <category> NLP </category>
            
        </categories>
        
        
        <tags>
            
            <tag> NLP </tag>
            
            <tag> 大数据 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[基于Solr的Hbase二级索引]]></title>
      <url>http://geosmart.github.io/2015/09/01/%E5%9F%BA%E4%BA%8ESolr%E7%9A%84Hbase%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95/</url>
      <content type="html"><![CDATA[<h1 id="关于Hbase二级索引"><a href="#关于Hbase二级索引" class="headerlink" title="关于Hbase二级索引"></a>关于Hbase二级索引</h1><p>HBase 是一个列存数据库，每行数据只有一个主键RowKey，无法依据指定列的数据进行检索。查询时需要通过RowKey进行检索，然后查看指定列的数据是什么，效率低下。在实际应用中，我们经常需要根据指定列进行检索，或者几个列进行组合检索，这就提出了建立 HBase 二级索引的需求。</p>
<p>二级索引构建方式：表索引、列索引、全文索引  </p>
<ul>
<li>表索引是将索引数据单独存储为一张表，通过 HBase Coprocessor 生成并访问索引数据。</li>
<li>列索引是将索引数据与源数据存储在相同的 Region 里，索引数据定义为一个单独的列族，也是利用 Coprocessor 来生成并访问索引数据。对于表索引，源数据表与索引表的数据一致性很难保证，访问两张不同的表也会增加 IO 开销和远程调用的次数。对于列索引，单表的数据容量会急剧增加，对同一 Region 里的多个列族进行 Split 或 Merge 等操作时可能会造成数据丢失或不一致。  </li>
<li>全文索引：以CDH5中的Lily HBase Indexer服务实现，其使用SolrCloud存储HBase的索引数据，Indexer索引和搜索不会影响HBase运行的稳定性和HBase数据写入的吞吐量，因为索引和搜索过程是完全分开并且异步的。Lily HBase Indexer在CDH5中运行必须依赖HBase、SolrCloud和Zookeeper服务。</li>
</ul>
<hr>
<a id="more"></a>
<p><img src="solr-query.png" alt="通过solr查询rowkey再查询Hbase"></p>
<h1 id="关于Key-Value-Indexer组件"><a href="#关于Key-Value-Indexer组件" class="headerlink" title="关于Key-Value Indexer组件"></a>关于Key-Value Indexer组件</h1><p><a href="http://www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/search_use_hbase_indexer_service.html?scroll=xd_583c10bfdbd326ba-204beb9-13ef1573a9e--7fbb">CDH官方文档</a><br><a href="https://github.com/NGDATA/hbase-indexer/wiki">hbase-indexer官方WIKI</a><br><a href="http://blog.cloudera.com/blog/2013/11/email-indexing-using-cloudera-search-and-hbase/">参考博客：Email Indexing Using Cloudera Search and HBase</a><br><a href="http://blog.csdn.net/kissmelove01/article/details/45043955">参考博客： Cloudera Search Solr初探</a><br><a href="http://ae.yyuap.com/pages/viewpage.action?pageId=920173">参考博客：一种基于UDH Search的HBase二级索引构建方案</a>     </p>
<p>CDH5.4中的Key-Value Indexer使用的是Lily HBase NRT Indexer服务，Lily HBase Indexer是一款灵活的、可扩展的、高容错的、事务性的，并且近实时的处理HBase列索引数据的分布式服务软件。它是NGDATA公司开发的Lily系统的一部分，已开放源代码。<br>Lily HBase Indexer使用SolrCloud来存储HBase的索引数据，当HBase执行写入、更新或删除操作时，Indexer通过HBase的replication功能来把这些操作抽象成一系列的Event事件，并用来保证写入Solr中的HBase索引数据的一致性。并且Indexer支持用户自定义的抽取，转换规则来索引HBase列数据。Solr搜索结果会包含用户自定义的columnfamily:qualifier字段结果，这样应用程序就可以直接访问HBase的列数据。而且Indexer索引和搜索不会影响HBase运行的稳定性和HBase数据写入的吞吐量，因为索引和搜索过程是完全分开并且异步的。<br>Lily HBase Indexer在CDH5中运行必须依赖HBase、SolrCloud和Zookeeper服务。</p>
<h1 id="使用-Lily-HBase-Batch-Indexer-进行索引"><a href="#使用-Lily-HBase-Batch-Indexer-进行索引" class="headerlink" title="使用 Lily HBase Batch Indexer 进行索引"></a>使用 Lily HBase Batch Indexer 进行索引</h1><p>借助 Cloudera Search，您可以利用 MapReduce 作业对 HBase 表进行批量索引。批量索引不需要以下操作：</p>
<ul>
<li>HBase 复制</li>
<li>Lily HBase Indexer 服务</li>
<li>通过 Lily HBase Indexer 服务注册 Lily HBase Indexer 配置<br>该索引器支持灵活的、自定义的、特定于应用程序的规则来将 HBase 数据提取、转换和加载到 Solr。Solr 搜索结果可以包含到存储在 HBase 中的数据的 columnFamily:qualifier 链接。这样，应用程序可以使用搜索结果集直接访问匹配的原始 HBase 单元格。</li>
</ul>
<h1 id="创建HBase集群的表中列索引的步骤："><a href="#创建HBase集群的表中列索引的步骤：" class="headerlink" title="创建HBase集群的表中列索引的步骤："></a>创建HBase集群的表中列索引的步骤：</h1><p><a href="https://github.com/NGDATA/hbase-indexer/wiki/Tutorial">Tutorial教程</a>  </p>
<ul>
<li>填充 HBase 表。</li>
<li>创建相应的 SolrCloud 集合</li>
<li>创建 Lily HBase Indexer 配置</li>
<li>创建 Morphline 配置文件</li>
<li>注册 Lily HBase Indexer Configuration 和 Lily HBase Indexer Service</li>
</ul>
<h2 id="填充-HBase-表"><a href="#填充-HBase-表" class="headerlink" title="填充 HBase 表"></a>填充 HBase 表</h2><p>在配置和启动系统后，创建 HBase 表并向其添加行。例如：<br>对于每个新表，在需要通过发出格式命令进行索引的每个列系列上设置 REPLICATION_SCOPE：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="meta">$</span><span class="bash"> hbase shell </span></div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash">测试数据：列簇设置REPLICATION_SCOPE</span></div><div class="line">disable 'User'</div><div class="line">drop  'User'</div><div class="line">create 'User', &#123;NAME =&gt; 'data', REPLICATION_SCOPE =&gt; 1&#125;  </div><div class="line"></div><div class="line">disable 'User'</div><div class="line">alter 'User', &#123;NAME =&gt; 'detail', REPLICATION_SCOPE =&gt; 1&#125;  </div><div class="line">enable 'User'</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash">新增CF</span></div><div class="line">disable 'User'</div><div class="line">alter 'User', &#123;NAME =&gt; 'detail', REPLICATION_SCOPE =&gt; 1&#125; </div><div class="line">enable 'User'</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash">修改现有</span></div><div class="line">disable 'User'</div><div class="line">alter 'User', &#123;NAME =&gt; 'data', REPLICATION_SCOPE =&gt; 1&#125; </div><div class="line">enable 'User'</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 插入测试数据 </span></div><div class="line">put 'User','row1','data:name','u1'</div><div class="line">put 'User','row1','data:psd','123'</div></pre></td></tr></table></figure>
<h2 id="创建相应的-SolrCloud-集合"><a href="#创建相应的-SolrCloud-集合" class="headerlink" title="创建相应的 SolrCloud 集合"></a>创建相应的 SolrCloud 集合</h2><p>用于 HBase 索引的 SolrCloud 集合必须具有可容纳 HBase 列系列的类型和要进行索引处理的限定符的 Solr 架构。若要开始，请考虑将包括一切 data 的字段添加到默认schema。一旦您决定采用一种schema，使用以下表单命令创建 SolrCloud 集合：</p>
<h3 id="user示例配置"><a href="#user示例配置" class="headerlink" title="user示例配置"></a>user示例配置</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> 生成实体配置文件：</span></div><div class="line">solrctl instancedir --generate $HOME/hbase-indexer/User</div></pre></td></tr></table></figure>
<p>编辑schema，需包含以下内容<br><code>vim $HOME/hbase-indexer/User/conf/schema.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">&lt;!-- 绑定rowkey--&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">field</span> <span class="attr">name</span>=<span class="string">"id"</span> <span class="attr">type</span>=<span class="string">"string"</span> <span class="attr">indexed</span>=<span class="string">"true"</span> <span class="attr">stored</span>=<span class="string">"true"</span> <span class="attr">required</span>=<span class="string">"true"</span> <span class="attr">multiValued</span>=<span class="string">"false"</span> /&gt;</span></div><div class="line"> </div><div class="line"><span class="tag">&lt;<span class="name">field</span> <span class="attr">name</span>=<span class="string">"name"</span> <span class="attr">type</span>=<span class="string">"string"</span> <span class="attr">indexed</span>=<span class="string">"true"</span> <span class="attr">stored</span>=<span class="string">"true"</span>/&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">field</span> <span class="attr">name</span>=<span class="string">"psd"</span> <span class="attr">type</span>=<span class="string">"string"</span> <span class="attr">indexed</span>=<span class="string">"true"</span> <span class="attr">stored</span>=<span class="string">"true"</span>/&gt;</span> </div><div class="line"><span class="tag">&lt;<span class="name">field</span> <span class="attr">name</span>=<span class="string">"address"</span> <span class="attr">type</span>=<span class="string">"string"</span> <span class="attr">indexed</span>=<span class="string">"true"</span> <span class="attr">stored</span>=<span class="string">"true"</span>/&gt;</span> </div><div class="line"><span class="tag">&lt;<span class="name">field</span> <span class="attr">name</span>=<span class="string">"photo"</span> <span class="attr">type</span>=<span class="string">"string"</span> <span class="attr">indexed</span>=<span class="string">"true"</span> <span class="attr">stored</span>=<span class="string">"true"</span>/&gt;</span></div></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> 创建 collection实例并将配置文件上传到 zookeeper：</span></div><div class="line">solrctl instancedir --create User  $HOME/hbase-indexer/User</div><div class="line"><span class="meta">#</span><span class="bash"> 上传到 zookeeper 之后，其他节点就可以从zookeeper下载配置文件。接下来创建 collection:</span></div><div class="line">solrctl collection --create User</div></pre></td></tr></table></figure>
<h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><p>在schema.xml中uniqueKey必须为rowkey,而rowkey默认使用’id’字段表示，<field>中必须要有uniqueKey对应的id字段。</p>
<h2 id="创建-Lily-HBase-Indexer-配置"><a href="#创建-Lily-HBase-Indexer-配置" class="headerlink" title="创建 Lily HBase Indexer 配置"></a>创建 Lily HBase Indexer 配置</h2><p><a href="https://github.com/NGDATA/hbase-indexer/wiki/Indexer-configuration">Indexer-configuration官方参考</a><br>在HBase-Solr的安装目录/usr/lib/hbase-solr/下，创建morphline-hbase-mapper.xml文件，文件内容如下：   </p>
<p><code>$ vim  $HOME/hbase-indexer/morphline-hbase-mapper.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version="1.0"?&gt;</div><div class="line"> <span class="comment">&lt;!-- table：需要索引的HBase表名称--&gt;</span></div><div class="line"> <span class="comment">&lt;!-- mapper：用来实现和读取指定的Morphline配置文件类，固定为MorphlineResultToSolrMapper--&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">indexer</span> <span class="attr">table</span>=<span class="string">"User"</span> <span class="attr">mapper</span>=<span class="string">"com.ngdata.hbaseindexer.morphline.MorphlineResultToSolrMapper"</span>&gt;</span></div><div class="line"> </div><div class="line">   <span class="comment">&lt;!--param中的name参数用来指定当前配置为morphlineFile文件 --&gt;</span></div><div class="line">   <span class="comment">&lt;!--value用来指定morphlines.conf文件的路径，绝对或者相对路径用来指定本地路径，如果是使用Cloudera Manager来管理morphlines.conf就直接写入值morphlines.conf"--&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">param</span> <span class="attr">name</span>=<span class="string">"morphlineFile"</span> <span class="attr">value</span>=<span class="string">"morphlines.conf"</span>/&gt;</span></div><div class="line"></div><div class="line">   <span class="comment">&lt;!-- The optional morphlineId identifies a morphline if there are multiple morphlines in morphlines.conf --&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">param</span> <span class="attr">name</span>=<span class="string">"morphlineId"</span> <span class="attr">value</span>=<span class="string">"userMap"</span>/&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">indexer</span>&gt;</span></div></pre></td></tr></table></figure>
<p>注意：当使用绝对或者相对路径来指定路径时，集群中的其它机器也要在配置路径上有该文件，如果是通过Cloudera Manager管理的话只需要在CM中修改后即可，CM会自动分发给集群。当然该配置文件还有很多其它参数可以配置，<a href="https://github.com/NGDATA/hbase-indexer/wiki/Indexer-configuration#table">扩展阅读</a>。</p>
<h2 id="创建-Morphline-配置文件"><a href="#创建-Morphline-配置文件" class="headerlink" title="创建 Morphline 配置文件"></a>创建 Morphline 配置文件</h2><p>Morphlines是一款开源的，用来减少构建hadoop ETL数据流程时间的应用程序。它可以替代传统的通过MapReduce来抽取、转换、加载数据的过程，提供了一系列的命令工具，<br>具体可以参见：<a href="http://kitesdk.org/docs/0.13.0/kite-morphlines/morphlinesReferenceGuide.html。">http://kitesdk.org/docs/0.13.0/kite-morphlines/morphlinesReferenceGuide.html。</a>  </p>
<p>对于HBase的其提供了extractHBaseCells命令来读取HBase的列数据。我们采用Cloudera Manager来管理morphlines.conf文件，使用CM来管理morphlines.  conf文件除了上面提到的好处之外，还有一个好处就是当我们需要增加索引列的时候，如果采用本地路径方式将需要重新注册Lily HBase Indexer的配置文件，而采用CM管理的话只需要修改morphlines.conf文件后重启Key-Value HBase Indexer服务即可。<br>具体操作为：进入Key-Value Store Indexer面板-&gt;配置-&gt;服务范围-&gt;Morphlines-&gt;Morphlines文件。在该选项加入如下配置：</p>
<p>注意：每个Collection对应一个morphline-hbase-mapper.xml    </p>
<p><img src="indexerConfig.png" alt="cdh lily hbase indexer config"></p>
<p><code>$ vim  /$HOME/morphlines.conf</code></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"><span class="string">SOLR_LOCATOR</span> <span class="string">:</span> <span class="string">&#123;</span></div><div class="line">  <span class="comment"># Name of solr collection</span></div><div class="line">  <span class="string">collection</span> <span class="string">:</span> <span class="string">collection</span></div><div class="line"></div><div class="line">  <span class="comment"># ZooKeeper ensemble</span></div><div class="line">  <span class="string">zkHost</span> <span class="string">:</span> <span class="string">"$ZK_HOST"</span></div><div class="line"><span class="string">&#125;</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="string">morphlines</span> <span class="string">:</span> <span class="string">[</span></div><div class="line"><span class="string">&#123;</span></div><div class="line"><span class="string">id</span> <span class="string">:</span> <span class="string">morphline</span></div><div class="line"><span class="string">importCommands</span> <span class="string">:</span> <span class="string">["org.kitesdk.**",</span> <span class="string">"com.ngdata.**"</span><span class="string">]</span></div><div class="line"></div><div class="line"><span class="string">commands</span> <span class="string">:</span> <span class="string">[</span></div><div class="line">  <span class="string">&#123;</span></div><div class="line">    <span class="string">extractHBaseCells</span> <span class="string">&#123;</span></div><div class="line">      <span class="string">mappings</span> <span class="string">:</span> <span class="string">[</span></div><div class="line">        <span class="string">&#123;</span></div><div class="line">          <span class="string">inputColumn</span> <span class="string">:</span> <span class="string">"data:name"</span></div><div class="line">          <span class="string">outputField</span> <span class="string">:</span> <span class="string">"data_name"</span></div><div class="line">          <span class="string">type</span> <span class="string">:</span> <span class="string">string</span></div><div class="line">          <span class="string">source</span> <span class="string">:</span> <span class="string">value</span></div><div class="line">        <span class="string">&#125;,</span></div><div class="line">        <span class="string">&#123;</span></div><div class="line">          <span class="string">inputColumn</span> <span class="string">:</span> <span class="string">"data:psd"</span></div><div class="line">          <span class="string">outputField</span> <span class="string">:</span> <span class="string">"data_psd"</span></div><div class="line">          <span class="string">type</span> <span class="string">:</span> <span class="string">string</span></div><div class="line">          <span class="string">source</span> <span class="string">:</span> <span class="string">value</span></div><div class="line">        <span class="string">&#125;,</span></div><div class="line">        <span class="string">&#123;</span></div><div class="line">          <span class="string">inputColumn</span> <span class="string">:</span> <span class="string">"data:address"</span></div><div class="line">          <span class="string">outputField</span> <span class="string">:</span> <span class="string">"data_address"</span></div><div class="line">          <span class="string">type</span> <span class="string">:</span> <span class="string">string</span></div><div class="line">          <span class="string">source</span> <span class="string">:</span> <span class="string">value</span></div><div class="line">        <span class="string">&#125;,</span></div><div class="line">        <span class="string">&#123;</span></div><div class="line">          <span class="string">inputColumn</span> <span class="string">:</span> <span class="string">"data:photo"</span></div><div class="line">          <span class="string">outputField</span> <span class="string">:</span> <span class="string">"data_photo"</span></div><div class="line">          <span class="string">type</span> <span class="string">:</span> <span class="string">string</span></div><div class="line">          <span class="string">source</span> <span class="string">:</span> <span class="string">value</span></div><div class="line">        <span class="string">&#125;</span></div><div class="line">      <span class="string">]</span></div><div class="line">    <span class="string">&#125;</span></div><div class="line">  <span class="string">&#125;</span></div><div class="line"></div><div class="line">  <span class="string">&#123;</span> <span class="string">logDebug</span> <span class="string">&#123;</span> <span class="string">format</span> <span class="string">:</span> <span class="string">"output record: &#123;&#125;"</span><span class="string">,</span> <span class="string">args</span> <span class="string">:</span> <span class="string">["@&#123;&#125;"]</span> <span class="string">&#125;</span> <span class="string">&#125;</span></div><div class="line"><span class="string">]</span></div><div class="line"><span class="string">&#125;</span></div><div class="line"><span class="string">]</span></div></pre></td></tr></table></figure>
<h2 id="注册-Lily-HBase-Indexer-Configuration-和-Lily-HBase-Indexer-Service"><a href="#注册-Lily-HBase-Indexer-Configuration-和-Lily-HBase-Indexer-Service" class="headerlink" title="注册 Lily HBase Indexer Configuration 和 Lily HBase Indexer Service"></a>注册 Lily HBase Indexer Configuration 和 Lily HBase Indexer Service</h2><p>当 Lily HBase Indexer 配置 XML文件的内容令人满意，将它注册到 Lily HBase Indexer Service。上传 Lily HBase Indexer 配置 XML文件至 ZooKeeper，由给定的 SolrCloud 集合完成此操作。例如：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">hbase-indexer add-indexer \</div><div class="line">--name userIndexer \</div><div class="line">--indexer-conf $HOME/hbase-indexer/User/conf/morphline-hbase-mapper.xml \</div><div class="line">--connection-param solr.zk=server1:2181/solr \</div><div class="line">--connection-param solr.collection=User \</div><div class="line">--zookeeper server1:2181</div></pre></td></tr></table></figure>
<h2 id="验证索引器是否已成功创建"><a href="#验证索引器是否已成功创建" class="headerlink" title="验证索引器是否已成功创建"></a>验证索引器是否已成功创建</h2><p>执行<code>$ hbase-indexer list-indexers</code>验证索引器是否已成功创建</p>
<p>更多帮助，请使用以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">hbase-indexer add-indexer --help</div><div class="line">hbase-indexer list-indexers --help</div><div class="line">hbase-indexer update-indexer --help</div><div class="line">hbase-indexer delete-indexer --help</div></pre></td></tr></table></figure>
<h2 id="测试是solr是否已新建索引"><a href="#测试是solr是否已新建索引" class="headerlink" title="测试是solr是否已新建索引"></a>测试是solr是否已新建索引</h2><p>写入数据时，在solr-webui控制台查看日志是否更新 </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">put 'User','row1','data','u1'</div><div class="line"></div><div class="line">put 'User','row1','data:name','u2'</div><div class="line"></div><div class="line">put 'User','row2','data:name','u2'</div><div class="line">put 'User','row2','data:psd','123'   </div><div class="line">put 'User','row2','data:address','address2'   </div><div class="line">put 'User','row2','data:photo','photo2'   </div><div class="line"></div><div class="line">put 'User','row2','data:name','u2'</div><div class="line">put 'User','row2','data:psd','123'   </div><div class="line">put 'User','row2','detail:address','address2'   </div><div class="line">put 'User','row2','detail:photo','photo2'  </div><div class="line"></div><div class="line"></div><div class="line">put 'User','row3','data:name','u2'</div><div class="line">put 'User','row3','data:psd','123'   </div><div class="line">put 'User','row3','detail:address','江苏省南京市'   </div><div class="line">put 'User','row3','detail:photo','phto3'</div></pre></td></tr></table></figure>
<p><img src="solr.png" alt="solr web ui查看最终结果"></p>
<p>折腾几天弄好，下一步是如何以构建好的索引Hbase实现多列条件的组合查询。  </p>
<h2 id="扩展命令"><a href="#扩展命令" class="headerlink" title="扩展命令"></a>扩展命令</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> solrctl</span></div><div class="line">solrctl instancedir --list </div><div class="line">solrctl collection --list </div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 更新coolection配置</span></div><div class="line">solrctl instancedir --update User $HOME/hbase-indexer/User</div><div class="line">solrctl collection --reload  User</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash">删除instancedir</span></div><div class="line">solrctl instancedir  --delete  User</div><div class="line"><span class="meta">#</span><span class="bash">删除collection</span></div><div class="line">solrctl collection --delete  User</div><div class="line"><span class="meta">#</span><span class="bash">删除collection所有doc</span></div><div class="line">solrctl collection --deletedocs User</div><div class="line"><span class="meta">#</span><span class="bash">删除User配置目录</span></div><div class="line">rm -rf $HOME/hbase-indexer/User</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> hbase-indexer</span></div><div class="line"><span class="meta">#</span><span class="bash"> 若修改了morphline-hbase-mapper.xml，需更新索引</span></div><div class="line">hbase-indexer update-indexer  -n userIndexer</div><div class="line"> </div><div class="line"><span class="meta">#</span><span class="bash"> 删除索引</span></div><div class="line">hbase-indexer delete-indexer  -n userIndexer</div></pre></td></tr></table></figure>
<h1 id="所遇问题QA"><a href="#所遇问题QA" class="headerlink" title="所遇问题QA"></a>所遇问题QA</h1><h2 id="Lily-HBase-Indexer-Service注册错误"><a href="#Lily-HBase-Indexer-Service注册错误" class="headerlink" title="Lily HBase Indexer Service注册错误"></a>Lily HBase Indexer Service注册错误</h2><p>详细日志<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[WARN ][<span class="number">08</span>:<span class="number">56</span>:<span class="number">49</span>,<span class="number">677</span>][.com:<span class="number">2181</span>)] org.apache.zookeeper.ClientCnxn - Session <span class="number">0x0</span> <span class="keyword">for</span> server <span class="keyword">null</span>, unexpected error, closing socket connection and attempting reconnect</div><div class="line">java.net.ConnectException: Connection refused</div><div class="line">     at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)</div><div class="line">     at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:<span class="number">739</span>)</div><div class="line">     at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:<span class="number">350</span>)</div><div class="line">     at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:<span class="number">1081</span>)</div></pre></td></tr></table></figure></p>
<p>解决：将帮助文档原文中的-zookeeper hbase-cluster-zookeeper:2181中hbase-cluster-zookeeper换成zoomkeeper的主机名</p>
<h2 id="schema-xm和morphline-conf配置问题"><a href="#schema-xm和morphline-conf配置问题" class="headerlink" title="schema.xm和morphline.conf配置问题"></a>schema.xm和morphline.conf配置问题</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ERROR  org.apache.solr.common.SolrException: ERROR: [doc=row3] unknown field <span class="string">'data'</span></div><div class="line">trueat org.apache.solr.update.DocumentBuilder.toDocument(DocumentBuilder.java:<span class="number">185</span>)</div></pre></td></tr></table></figure>
<p>解决方式：<br>Thanks for the response. In the meantime I got a solution which is fine for me using: <dynamicField name="*" type="string" indexed="true" stored="true" /> But type=”ignored” is a good hint once I want to get rid of the fields I do not need, thanks. –</p>
<p>schema新增配置：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dynamicField</span> <span class="attr">name</span>=<span class="string">"*"</span> <span class="attr">type</span>=<span class="string">"string"</span> <span class="attr">indexed</span>=<span class="string">"true"</span> <span class="attr">stored</span>=<span class="string">"true"</span> /&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">field</span> <span class="attr">name</span>=<span class="string">"data"</span> <span class="attr">type</span>=<span class="string">"string"</span> <span class="attr">indexed</span>=<span class="string">"true"</span> <span class="attr">stored</span>=<span class="string">"true"</span> <span class="attr">multiValued</span>=<span class="string">"true"</span>/&gt;</span></div></pre></td></tr></table></figure>
<p>修改schema.xml后，执行以下命令更新配置：<br>solrctl instancedir –update hbase-collection-user   $HOME/hbase-collection-user<br>solrctl collection  –reload  hbase-collection-user </p>
<p>修改Collection<br>当我们创建Collection完成后，如果需要修改schema.xml文件重新配置需要索引的字段可以按如下操作：  </p>
<ul>
<li>如果是修改原有schema.xml中字段值，而在solr中已经插入了索引数据，那么我们需要清空索引数据集，清空数据集可以通过solr API来完成。  </li>
<li>如果是在原有schema.xml中加入新的索引字段，那么可以跳过1，直接执行：  </li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">solrctl instancedir --update solrtest $HOME/solrtest   </div><div class="line">solrctl collection --reload solrtest</div></pre></td></tr></table></figure>
<h2 id="多个HbaseTable配置schema-xml和morphline-conf"><a href="#多个HbaseTable配置schema-xml和morphline-conf" class="headerlink" title="多个HbaseTable配置schema.xml和morphline.conf"></a>多个HbaseTable配置schema.xml和morphline.conf</h2><p>解决方式：<br><a href="https://github.com/jshmain/cloudera-search/blob/master/email-search/email-schema.xml">email-schema示例</a></p>
<p>Q：morphline.conf和morphline-hbase-mapper.xml文件是否每个HbaseTable都要对应配置一个?<br>A：每一个Hbase Table对应生成一个Solr的Collection索引，每个索引对应一个Lily HBase Indexer 配置文件morphlines.conf和morphline配置文件morphline-hbase-mapper.xml，其中morphlines.conf可由CDH的Key-Value Store Indexer控制台管理，以id区分</p>
<p>官方说明：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Creating a Lily HBase Indexer configuration  </div><div class="line">Individual Lily HBase Indexers are configured using the hbase-indexer command line utility.   </div><div class="line">Typically, there is one Lily HBase Indexer configuration for each HBase table,   </div><div class="line">but there can be as many Lily HBase Indexer configurations as there are tables and column families and corresponding collections in the SolrCloud.   </div><div class="line">Each Lily HBase Indexer configuration is defined in an XML file such as morphline-hbase-mapper.xml.</div></pre></td></tr></table></figure></p>
<h2 id="对HBaseTable已有数据新建索引"><a href="#对HBaseTable已有数据新建索引" class="headerlink" title="对HBaseTable已有数据新建索引"></a>对HBaseTable已有数据新建索引</h2><p>需要用到Lily HBase Indexer的批处理索引功能了</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">sudo hadoop --config /etc/hadoop/conf \</div><div class="line">jar /usr/lib/hbase-solr/tools/hbase-indexer-mr-1.5-cdh5.4.4-job.jar \</div><div class="line">--conf /etc/hbase/conf/hbase-site.xml \</div><div class="line">-D 'mapred.child.java.opts=-Xmx500m' \</div><div class="line">--hbase-indexer-zk master:2181 \</div><div class="line">--collection hbase-collection-user \</div><div class="line">--hbase-indexer-name userIndexer \</div><div class="line">--hbase-indexer-file $HOME/hbase-collection-user/conf/morphline-hbase-mapper.xml \</div><div class="line">--go-live \</div><div class="line">``` </div><div class="line">错误日志  </div><div class="line"></div><div class="line">``` java</div><div class="line">Caused by: java.io.IOException Can not find resource  solrconfig.xml in classpath </div><div class="line">or  /root/file:/tmp/hadoop-root/mapred/local/1441858645500/6a1a458e-35e2-4f66-82df-02795ba44e2c.solr.zip/collection1/conf</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> Hadoop </tag>
            
            <tag> CDH </tag>
            
            <tag> Hbase </tag>
            
            <tag> Solr </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[一路见识的SQL/NOSQL数据库ORM]]></title>
      <url>http://geosmart.github.io/2015/08/16/%E4%B8%80%E8%B7%AF%E8%A7%81%E8%AF%86%E7%9A%84SQL-NOSQL%E6%95%B0%E6%8D%AE%E5%BA%93ORM/</url>
      <content type="html"><![CDATA[<p>一路走来，关系数据库到非关系数据库，不觉已接触了不少的ORM框架也在这些ORM框架的基础上积累了一些通用的DAO，下面从 <em>学习笔记（原理、优势、劣势）</em> 和 <em>个人总结（踩过的坑，注意事项）</em> 两方面展开描述：</p>
<hr>
<a id="more"></a>
<h1 id="LINQ"><a href="#LINQ" class="headerlink" title="LINQ"></a>LINQ</h1><p>LINQ全称Language Integrated Query<br>大学期间接触DotNet/C#一般会对LINQ有所了解，印象中是封装了DAO层的数据库连接，可以通过一些如select/where/group by等关键词以熟悉的代码形式进行数据CRUD操作<br>下面是官方的LINQ的官方描述</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">LINQ to SQL 是 .NET Framework 3.5 版的一个组件，提供了用于将关系数据作为对象管理的运行时基础结构。</div><div class="line">在 LINQ to SQL 中，关系数据库的数据模型映射到用开发人员所用的编程语言表示的对象模型。</div><div class="line">当应用程序运行时，LINQ to SQL 会将对象模型中的语言集成查询转换为 SQL，然后将它们发送到数据库进行执行。</div><div class="line">当数据库返回结果时，LINQ to SQL 会将它们转换回您可以用您自己的编程语言处理的对象。</div><div class="line">使用 Visual Studio 的开发人员通常使用对象关系设计器，它提供了用于实现许多 LINQ to SQL 功能的用户界面。</div></pre></td></tr></table></figure>
<p>后来DotNET没深入学习了，工作的技术选型都是J2EE和一敏捷脚本类（Python）的方案，不做太多总结</p>
<h1 id="Spring-JDBC"><a href="#Spring-JDBC" class="headerlink" title="Spring-JDBC"></a>Spring-JDBC</h1><p><a href="http://docs.spring.io/spring/docs/current/spring-framework-reference/html/jdbc.html">官方文档</a><br>Spring Framework JDBC会封装处理JDBC底层的细节，让JDBC更友好，具体如下</p>
<p>Spring-JDBC自动处理的</p>
<ul>
<li>Open  connection.</li>
<li>Prepare and execute the statement.</li>
<li>Set up the loop to iterate through the results (if any).</li>
<li>Process any exception.</li>
<li>Handle transactions.</li>
<li>Close the connection, statement and resultset.<br>用户需设置的</li>
<li>Define connection parameters.</li>
<li>Specify the SQL statement.</li>
<li>Declare parameters and provide parameter values</li>
<li>Do the work for each iteration.</li>
</ul>
<h2 id="Spring-JDBC的使用概要"><a href="#Spring-JDBC的使用概要" class="headerlink" title="Spring-JDBC的使用概要"></a>Spring-JDBC的使用概要</h2><ul>
<li><p>JdbcTemplate - 这是经典的也是最常用的Spring对于JDBC访问的方案。这也是最低级别的封装, 其他的工作模式事实上在底层使用了JdbcTemplate作为其底层的实现基础。JdbcTemplate在JDK 1.4以上的环境上工作得很好。</p>
</li>
<li><p>NamedParameterJdbcTemplate - 对JdbcTemplate做了封装，提供了更加便捷的基于命名参数的使用方式而不是传统的JDBC所使用的“?”作为参数的占位符。这种方式在你需要为某个SQL指定许多个参数时，显得更加直观而易用。该特性必须工作在JDK 1.4以上。</p>
</li>
<li><p>SimpleJdbcTemplate - 这个类结合了JdbcTemplate和NamedParameterJdbcTemplate的最常用的功能，同时它也利用了一些Java5的特性所带来的优势，例如泛型、varargs和autoboxing等，从而提供了更加简便的API访问方式。需要工作在Java 5以上的环境中。</p>
</li>
<li><p>SimpleJdbcInsert 和 SimpleJdbcCall - 这两个类可以充分利用数据库元数据的特性来简化配置。通过使用这两个类进行编程，你可以仅仅提供数据库表名或者存储过程的名称以及一个Map作为参数。其中Map的key需要与数据库表中的字段保持一致。这两个类通常和SimpleJdbcTemplate配合使用。这两个类需要工作在JDK 5以上，同时数据库需要提供足够的元数据信息。</p>
</li>
<li><p>RDBMS 对象包括MappingSqlQuery, SqlUpdate and StoredProcedure - 这种方式允许你在初始化你的数据访问层时创建可重用并且线程安全的对象。该对象在你定义了你的查询语句，声明查询参数并编译相应的Query之后被模型化。一旦模型化完成，任何执行函数就可以传入不同的参数对之进行多次调用。这种方式需要工作在JDK 1.4以上。</p>
</li>
</ul>
<p>优势：强大、优雅、轻量、持续更新维护，与JDBC相对，减少了大量的冗余DAO层代码</p>
<h2 id="setMaxRows和setFetchSize"><a href="#setMaxRows和setFetchSize" class="headerlink" title="setMaxRows和setFetchSize"></a>setMaxRows和setFetchSize</h2><p>They do different things.<br>The setMaxRows = number of rows that can be returned overall.<br>setFetchSize = number that will be returned in each database roundtrip i.e.<br>setFetchSize Gives the JDBC driver a hint as to the number of rows that should be fetched from the database when more rows are needed for ResultSet objects genrated by this Statement.<br>setMaxRows Sets the limit for the maximum number of rows that any ResultSet object generated by this Statement object can contain to the given number.</p>
<h2 id="Spring-JDBC-Spring-JPA"><a href="#Spring-JDBC-Spring-JPA" class="headerlink" title="Spring JDBC +Spring JPA"></a>Spring JDBC +Spring JPA</h2><p>缓存可以用第三方，例如ehcached,或者mc</p>
<h2 id="拼接SQL"><a href="#拼接SQL" class="headerlink" title="拼接SQL"></a>拼接SQL</h2><p>拼接SQL注意需特别注意字段值中存在转义字符（如”\”,”‘“）的情况，应使用类PreparedStatement中?方式替换变量执行CRUD操作</p>
<h1 id="Hibernate"><a href="#Hibernate" class="headerlink" title="Hibernate"></a>Hibernate</h1><h1 id="MyBatis"><a href="#MyBatis" class="headerlink" title="MyBatis"></a>MyBatis</h1><p>MyBatis的前身叫iBatis，本是apache的一个开源项目, 2010年这个项目由apache software foundation 迁移到了google code，并且改名为MyBatis。<br>MyBatis 是支持定制化 SQL、存储过程以及高级映射的优秀的持久层框架。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以对配置和原生Map使用简单的 XML 或注解，将接口和 Java 的 POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录。<br>Mybatis的功能架构分为三层：</p>
<ol>
<li>API接口层<br>提供给外部使用的接口API，开发人员通过这些本地API来操纵数据库。接口层一接收到调用请求就会调用数据处理层来完成具体的数据处理。</li>
<li>数据处理层<br>负责具体的SQL查找、SQL解析、SQL执行和执行结果映射处理等。它主要的目的是根据调用的请求完成一次数据库操作。</li>
<li>基础支撑层<br>负责最基础的功能支撑，包括连接管理、事务管理、配置加载和缓存处理，这些都是共用的东西，将他们抽取出来作为最基础的组件。为上层的数据处理层提供最基础的支撑。</li>
</ol>
<h2 id="Mybatis与Hibernate比较"><a href="#Mybatis与Hibernate比较" class="headerlink" title="Mybatis与Hibernate比较"></a>Mybatis与Hibernate比较</h2><p>Mybatis：小巧、方便、高效、简单、直接、半自动、移植性低<br>Hibernate：强大、方便、高效、复杂、绕弯子、全自动、移植性高</p>
<h2 id="Mybatis应用场景"><a href="#Mybatis应用场景" class="headerlink" title="Mybatis应用场景"></a>Mybatis应用场景</h2><p>一直在用Hibnernate，抽取一个完善的DAO抽象类后会少很多工作，更受益与其更换数据库时超强的移植性，DAO层基本不作修改，更换数据库方言即可。但在以下场景时，Mybatis自有其可取之处：</p>
<ol>
<li>当无法对数据库结构做到控制和修改，Mybatis的灵活性将比hibernate更适合；</li>
<li>当系统数据处理量巨大，性能要求极为苛刻，这往往意味着我们必须通过经过高度优化的sql语句（或存储过程）才能达到系统性能设计指标，在这种情况下Mybatis会有更好的可控性和表现，可以进行细粒度的优化。</li>
</ol>
<h1 id="NOSQL"><a href="#NOSQL" class="headerlink" title="NOSQL"></a>NOSQL</h1><h2 id="Morphia"><a href="#Morphia" class="headerlink" title="Morphia"></a>Morphia</h2><h2 id="Jongo"><a href="#Jongo" class="headerlink" title="Jongo"></a>Jongo</h2><h2 id="Spring-Data-for-Hadoop"><a href="#Spring-Data-for-Hadoop" class="headerlink" title="Spring Data for Hadoop"></a>Spring Data for Hadoop</h2><h2 id="Kundera"><a href="#Kundera" class="headerlink" title="Kundera"></a>Kundera</h2><h1 id="Jackson-ObjectMapper"><a href="#Jackson-ObjectMapper" class="headerlink" title="Jackson-ObjectMapper"></a>Jackson-ObjectMapper</h1>]]></content>
      
        <categories>
            
            <category> 后端技术 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> ORM </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hadoop生态圈]]></title>
      <url>http://geosmart.github.io/2015/08/11/Hadoop%E7%94%9F%E6%80%81%E5%9C%88/</url>
      <content type="html"><![CDATA[<p>开始正式接触Hadoop，从CDH自动化分布式环境部署延伸的Hadoop生态圈的术语，列举如下：<br><a href="http://www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/glossary.html#topic_1_unique_3__title_27_unique_21">查看所有术语</a></p>
<hr>
<a id="more"></a>
<h1 id="Apache-Accumulo"><a href="#Apache-Accumulo" class="headerlink" title="Apache Accumulo"></a>Apache Accumulo</h1><p>基于谷歌 BigTable 设计的分类、分布键值存储。Accumulo 为在 HDFS 上运行的 NoSQL DBMS，支持高效存储和结构化数据检索，包括查询范围。Accumulo 表可用作 MapReduce 作业的输入和输出。Accumulo 功能包括自动负载平衡和分区、数据压缩和细粒度安全标签。</p>
<h1 id="Apache-Avro"><a href="#Apache-Avro" class="headerlink" title="Apache Avro"></a>Apache Avro</h1><p>在网上存储和传输数据的序列化系统。Avro 为 Avro 数据序列（通常称为“Avro 数据文件”）提供丰富的数据结构、紧凑的二级制编码和容器文件的支持。Avro 独立于语言，可使用多个语言绑定，包括 Java、C、C++、Python 和 Ruby。生成或使用文件的 CDH 中的所有组件支持 Avro 数据文件作为文件格式。<br>Avro 提供与系统（如 Apache Thrift）和协议缓冲类似的功能。</p>
<h1 id="Apache-Bigtop"><a href="#Apache-Bigtop" class="headerlink" title="Apache Bigtop"></a>Apache Bigtop</h1><p>开发封装和 Apache Hadoop 生态系统项目的互操作性测试的项目。</p>
<h1 id="Apache-Crunch"><a href="#Apache-Crunch" class="headerlink" title="Apache Crunch"></a>Apache Crunch</h1><p>用于编写、测试和运行 MapReduce 管道的 Java 库。请参见 Apache Crunch。</p>
<h1 id="Apache-Flume"><a href="#Apache-Flume" class="headerlink" title="Apache Flume"></a>Apache Flume</h1><p>一个分布式、可靠可用的系统，用于高效收集、聚合和移动大量文本或从多个不同源至集中式数据存储的流数据。</p>
<h1 id="Apache-Giraph"><a href="#Apache-Giraph" class="headerlink" title="Apache Giraph"></a>Apache Giraph</h1><p>一个在 Apache Hadoop 上运行的大型、容错的图像处理框架。</p>
<h1 id="Apache-Hadoop"><a href="#Apache-Hadoop" class="headerlink" title="Apache Hadoop"></a>Apache Hadoop</h1><p>一个免费的开源软件框架，支持数据密集型分布应用程序。Apache Hadoop的核心组件为 HDFS 和 MapReduce 和 YARN 处理框架。该术语也用于与 Hadoop 相关的生态系统项目，位于分布式计算和大规模数据处理的基础架构之下。</p>
<h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><p>MapReduce采用”分而治之”的思想，把对大规模数据集的操作，分发给一个主节点管理下的各个分节点共同完成，然后通过整合各个节点的中间结果，得到最终结果。简单地说，MapReduce就是”任务的分解与结果的汇总”。<br>在Hadoop中，用于执行MapReduce任务的机器角色有两个：一个是JobTracker；另一个是TaskTracker，JobTracker是用于调度工作的，TaskTracker是用于执行工作的。一个Hadoop集群中只有一台JobTracker。<br>在分布式计算中，MapReduce框架负责处理了并行编程中分布式存储、工作调度、负载均衡、容错均衡、容错处理以及网络通信等复杂问题，把处理过程高度抽象为两个函数：map和reduce，map负责把任务分解成多个任务，reduce负责把分解后多任务处理的结果汇总起来。<br>需要注意的是，用MapReduce来处理的数据集（或任务）必须具备这样的特点：待处理的数据集可以分解成许多小的数据集，而且每一个小数据集都可以完全并行地进行处理。</p>
<h2 id="MapReduce-v1-MRv1"><a href="#MapReduce-v1-MRv1" class="headerlink" title="MapReduce v1 (MRv1)"></a>MapReduce v1 (MRv1)</h2><ul>
<li>MapReduce 作业执行的运行时间框架。它定义两个守护程序：</li>
<li>JobTracker - 协调运行 MapReduce作业，并提供资源管理和作业生命周期管理。在 YARN 中，这些功能由两个单独组件执行。</li>
<li>TaskTracker - 运行 MapReduce 作业已拆分的任务。</li>
</ul>
<h2 id="WordCount流程"><a href="#WordCount流程" class="headerlink" title="WordCount流程"></a>WordCount流程</h2><p><a href="https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html">参考</a><br><a href="http://www.cnblogs.com/xia520pi/archive/2012/05/16/2504205.html">中文教程</a></p>
<ol>
<li>HUE新建输入文件：txt<br>HUE地址：<a href="http://server1.lt.com:8888/filebrowser/；或者在xshell中su">http://server1.lt.com:8888/filebrowser/；或者在xshell中su</a> hdfs切换用户新建文件：file01.txt，file02.txt  </li>
</ol>
<ul>
<li>查看输入文件 ：<code>hadoop fs -ls /user/uadb/exchange/input/wordCount/</code>  </li>
<li>查看输入文件内容：<code>hadoop fs -cat   /user/uadb/exchange/input/wordCount/file*.txt</code>  </li>
</ul>
<ol>
<li>上传apreduce程序：jar</li>
<li>运行MapReduce程序：<code>hadoop jar /uadb/wordCount.jar me.demo.hadoop.mapreduce.WordCount /user/uadb/exchange/input/wordCount/ /user/uadb/exchange/output/wordCount</code><br>FatJar打包：<code>hadoop jar /uadb/wordCount.jar com.simontuffs.onejar.Boot  /user/uadb/exchange/input/wordCount/ /user/uadb/exchange/output/wordCount</code></li>
<li>查看执行结果： <code>hadoop   fs  -cat   /user/uadb/exchange/output/wordCount/*-0000*</code></li>
</ol>
<h1 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h1><p>Apache Hadoop YARN （Yet Another Resource Negotiator，另一种资源协调者）是一种新的 Hadoop 资源管理器，它是一个通用资源管理系统，可为上层应用提供统一的资源管理和调度，它的引入为集群在利用率、资源统一管理和数据共享等方面带来了巨大好处。<br>YARN最初是为了修复MapReduce实现里的明显不足，并对可伸缩性（支持一万个节点和二十万个内核的集群）、可靠性和集群利用率进行了提升。YARN实现这些需求的方式是，把Job Tracker的两个主要功能（资源管理和作业调度/监控）分成了两个独立的服务程序——全局的资源管理（RM）和针对每个应用的应用 Master（AM），这里说的应用要么是传统意义上的MapReduce任务，要么是任务的有向无环图（DAG）。</p>
<p>运行分布式应用程序的通用体系结构。YARN 指定以下组件：</p>
<p>ResourceManager - 管理计算资源的全局分配至应用程序。<br>ApplicationMaster - 管理应用程序的生命周期<br>NodeManager - 启动和监视群集中机器上的计算容器<br>JobHistory Server - 跟踪已完成的应用程序<br>主应用程序为群集资源与资源管理器协商 - 按照多个容器的描述，每个应用程序拥有特定的内存限制 - 然后在这些容器中运行应用程序特定的进程。在群集节点上运行的节点管理器监督容器，确保应用程序未使用超出其已分配资源的资源。</p>
<p>MapReduce v2 (MRv2) 作为 YARN 应用程序实施。</p>
<h1 id="Apache-HBase"><a href="#Apache-HBase" class="headerlink" title="Apache HBase"></a>Apache HBase</h1><p>面向列的可伸缩分布式数据存储。它提供实时读/写随机访问 HDFS 托管的大规模数据集的权限。<br>Hbase Web UI：<a href="http://{master}:60010/">http://{master}:60010/</a></p>
<h2 id="Hbase表结构设计"><a href="#Hbase表结构设计" class="headerlink" title="Hbase表结构设计"></a>Hbase表结构设计</h2><p>在HBase中，数据是按Column Family来分割的，同一个Column Family下的所有列的数据放在一个文件（为简化下面的描述在此使用文件这个词，在HBase内部使用的是Store）中。</p>
<p>HBase本身的设计目标是 支持稀疏表，而 稀疏表通常会有很多列，但是每一行有值的列又比较少。<br>如果不使用Column Family的概念，那么有两种设计方案：<br>1.把所有列的数据放在一个文件中（也就是传统的按行存储）。那么当我们想要访问少数几个列的数据时，需要遍历每一行，读取整个表的数据，这样子是很低效的。<br>2.把每个列的数据单独分开存在一个文件中（按列存储）。那么当我们想要访问少数几个列的数据时，只需要读取对应的文件，不用读取整个表的数据，读取效率很高。然而，由于稀疏表通常会有很多列，这会导致文件数量特别多，这本身会影响文件系统的效率。</p>
<p>而Column Family的提出就是为了在上面两种方案中做一个折中。HBase中 将一个Column Family中的列存在一起，而不同Column Family的数据则分开。<br>由于在HBase中Column Family的数量通常很小，同时HBase建议把经常一起访问的比较类似的列放在同一个Column Family中，这样就可以在访问少数几个列时，只读取尽量少的数据。</p>
<h2 id="Hbase性能优化配置"><a href="#Hbase性能优化配置" class="headerlink" title="Hbase性能优化配置"></a>Hbase性能优化配置</h2><p>HBase Master 的 Java 堆栈大小（字节）-Master Default Group：377M（默认）&gt;<br>HBase RegionServer 的 Java 堆栈大小（字节）-RegionServer Default Group :588M（默认）&gt;1024M<br>HBase 客户端写入缓冲-hbase.client.write.buffer：2M（默认）&gt;</p>
<h2 id="HBaseMaster"><a href="#HBaseMaster" class="headerlink" title="HBaseMaster"></a>HBaseMaster</h2><p>HMaster 负责给HRegionServer分配区域,并且负责对集群环境中的HReginServer进行负载均衡，HMaster还负责监控集群环境中的HReginServer的运行状况，如果某一台HReginServer down机，HBaseMaster将会把不可用的HReginServer来提供服务的HLog和表进行重新分配转交给其他HReginServer来提供，HBaseMaster还负责对数据和表进行管理，处理表结构和表中数据的变更，因为在 META 系统表中存储了所有的相关表信息。并且HMaster实现了ZooKeeper的Watcher接口可以和zookeeper集群交互。</p>
<h2 id="HRegionServer"><a href="#HRegionServer" class="headerlink" title="HRegionServer"></a>HRegionServer</h2><p>HReginServer负责处理用户的读和写的操作。HReginServer通过与HBaseMaster通信获取自己需要服务的数据表，并向HMaster反馈自己的运行状况。当一个写的请求到来的时候，它首先会写到一个叫做HLog的write-ahead log中。HLog被缓存在内存中，称为Memcache，每一个HStore只能有一个Memcache。当Memcache到达配置的大小以后，将会创建一个MapFile，将其写到磁盘中去。这将减少HReginServer的内存压力。当一起读取的请求到来的时候，HReginServer会先在Memcache中寻找该数据，当找不到的时候，才会去在MapFiles 中寻找。</p>
<h2 id="HBase-Client"><a href="#HBase-Client" class="headerlink" title="HBase Client"></a>HBase Client</h2><p>HBase Client负责寻找提供需求数据的HReginServer。在这个过程中，HBase Client将首先与HMaster通信，找到ROOT区域。这个操作是Client和Master之间仅有的通信操作。一旦ROOT区域被找到以后，Client就可以通过扫描ROOT区域找到相应的META区域去定位实际提供数据的HReginServer。当定位到提供数据的HReginServer以后，Client就可以通过这个HReginServer找到需要的数据了。这些信息将会被Client缓存起来，当下次请求的时候，就不需要走上面的这个流程了。</p>
<h2 id="HBase-Service"><a href="#HBase-Service" class="headerlink" title="HBase Service"></a>HBase Service</h2><p>HBase Thrift Server和HBase REST Server是通过非Java程序对HBase进行访问的一种途径。</p>
<h1 id="Lily-HBase-Indexer"><a href="#Lily-HBase-Indexer" class="headerlink" title="Lily HBase Indexer"></a>Lily HBase Indexer</h1><p>Lily HBase Indexer provides the ability to quickly and easily search for any content stored in HBase.<br>It allows you to quickly and easily index HBase rows into Solr, without writing a line of code. It doesn’t require Lily, but originates from years of experience indexing HBase as part of Lily - the Customer Intelligence Data Management Platform from NGDATA.<br>Lily HBase Indexer drives HBase indexing support in Cloudera Search, the SEP trigger notification mechanism is used inside Lily as well.</p>
<p>Lily HBase NRT Indexer服务，Lily HBase Indexer是一款灵活的、可扩展的、高容错的、事务性的，并且近实时的处理HBase列索引数据的分布式服务软件。它是NGDATA公司开发的Lily系统的一部分，已开放源代码。Lily HBase Indexer使用SolrCloud来存储HBase的索引数据，当HBase执行写入、更新或删除操作时，Indexer通过HBase的replication功能来把这些操作抽象成一系列的Event事件，并用来保证写入Solr中的HBase索引数据的一致性。并且Indexer支持用户自定义的抽取，转换规则来索引HBase列数据。Solr搜索结果会包含用户自定义的columnfamily:qualifier字段结果，这样应用程序就可以直接访问HBase的列数据。而且Indexer索引和搜索不会影响HBase运行的稳定性和HBase数据写入的吞吐量，因为索引和搜索过程是完全分开并且异步的。Lily HBase Indexer在CDH5中运行必须依赖HBase、SolrCloud和Zookeeper服务。</p>
<h1 id="Morphlines"><a href="#Morphlines" class="headerlink" title="Morphlines"></a>Morphlines</h1><p><a href="http://kitesdk.org/docs/0.13.0/kite-morphlines/index.html">Morphlines</a>是一款开源的，用来减少构建hadoop ETL数据流程时间的应用程序。它可以替代传统的通过MapReduce来抽取、转换、加载数据的过程，提供了一系列的命令工具，<br>具体可以参见：<a href="http://kitesdk.org/docs/0.13.0/kite-morphlines/morphlinesReferenceGuide.html。">http://kitesdk.org/docs/0.13.0/kite-morphlines/morphlinesReferenceGuide.html。</a><br>对于HBase的其提供了extractHBaseCells命令来读取HBase的列数据。<br>我们采用Cloudera Manager来管理morphlines.conf文件，使用CM来管理morphlines.conf文件除了上面提到的好处之外，还有一个好处就是当我们需要增加索引列的时候，如果采用本地路径方式将需要重新注册Lily HBase Indexer的配置文件，而采用CM管理的话只需要修改morphlines.conf文件后重启Key-Value HBase Indexer服务即可,CM会自动分发给集群。</p>
<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><p>Hadoop分布式文件系统（Distributed File System）</p>
<ul>
<li>Namenode<br>Namenode 管理者文件系统的Namespace。它维护着文件系统树(filesystem tree)以及文件树中所有的文件和文件夹的元数据(metadata)。管理这些信息的文件有两个，分别是Namespace 镜像文件(Namespace image)和操作日志文件(edit log)，这些信息被Cache在RAM中，当然，这两个文件也会被持久化存储在本地硬盘。Namenode记录着每个文件中各个块所在的数据节点的位置信息，但是他并不持久化存储这些信息，因为这些信息会在系统启动时从数据节点重建。<br>Namenode结构图课抽象为如图：<br><img src="http://hadoop.apache.org/docs/r1.2.1/images/hdfsarchitecture.gif" alt="HDFS Architecture"><br>NameNode Web UI：<a href="http://master.lt.com:50070/">http://master.lt.com:50070/</a></li>
</ul>
<p>客户端(client)代表用户与namenode和datanode交互来访问整个文件系统。客户端提供了一些列的文件系统接口，因此我们在编程时，几乎无须知道datanode和namenode，即可完成我们所需要的功能。</p>
<ul>
<li>Datanode<br>Datanode是文件系统的工作节点，他们根据客户端或者是namenode的调度存储和检索数据，并且定期向namenode发送他们所存储的块(block)的列表。</li>
</ul>
<h1 id="Apache-Solr"><a href="#Apache-Solr" class="headerlink" title="Apache Solr"></a>Apache Solr</h1><p>Solr是Apache Lucene项目的开源企业搜索平台。其主要功能包括全文检索、命中标示、分面搜索、动态聚类、数据库集成，以及富文本（如Word、PDF）的处理。Solr是高度可扩展的，并提供了分布式搜索和索引复制。Solr 4还增加了NoSQL支持，以及基于Zookeeper的分布式扩展功能SolrCloud。</p>
<ul>
<li>Solr可用于Hbase的二级索引</li>
</ul>
<h1 id="Apache-Hive"><a href="#Apache-Hive" class="headerlink" title="Apache Hive"></a>Apache Hive</h1><p>Hadoop 的数据仓库系统，使用诸如 SQL 的语言（称为 HiveQL），有助于实现汇总和 HDFS 中存储的大数据集的分析。</p>
<h1 id="HiveServer"><a href="#HiveServer" class="headerlink" title="HiveServer"></a>HiveServer</h1><p>支持通过 Apache Thrift 连接将客户端连接至 Hive 的服务器进程。</p>
<h1 id="HiveServer2"><a href="#HiveServer2" class="headerlink" title="HiveServer2"></a>HiveServer2</h1><p>支持通过网络连接将客户端连接至 Hive 的服务器进程。这些客户端可以是本机命令行编辑器或使用 ODBC 或 JDBC 驱动程序的应用程序和工具。</p>
<h1 id="HiveQL"><a href="#HiveQL" class="headerlink" title="HiveQL"></a>HiveQL</h1><p>Hadoop 的一种查询语言，使用类似于标准 SQL 的语法，以在 HDFS 上执行 MapReduce 作业。HiveQL 不支持所有的 SQL 功能。不支持事务和物化视图，对索引和查询的支持有限。它支持不属于标准 SQL 的功能，如多表格，包括多表格插入和创建选择的表格。</p>
<p>在内部，编译器将 HiveQL 语句转换为 MapReduce 作业的有向无环图，提交至 Hadoop，以执行。Beeswax 包含在 Hue内，为 HiveQL 查询提供图形化前端。</p>
<h1 id="Apache-Mahout"><a href="#Apache-Mahout" class="headerlink" title="Apache Mahout"></a>Apache Mahout</h1><p>Hadoop 的机器学习库。它是您能够构建克扩展至大型数据集的机器学习库，从而简化了构建智能应用程序的任务。Mahout 支持的主要使用情形包括：</p>
<ul>
<li>建议挖掘 -基于过去偏好标识用户喜好，如在线购物建议。</li>
<li>群集 - 类似项目的组；如解决类似主题的文档</li>
<li>分类 - 学习现有类别中成员的共同之处，然后使用该信息分类新项目。</li>
<li>频繁的项目集挖掘 - 采用一组项目组（如查询会话或购物车中的条目），识别通常一起出现的项目。</li>
</ul>
<h1 id="Apache-Oozie"><a href="#Apache-Oozie" class="headerlink" title="Apache Oozie"></a>Apache Oozie</h1><p>协调数据接收、存储、转换和分析操作的工作流程和协调服务。</p>
<h1 id="Apache-Pig"><a href="#Apache-Pig" class="headerlink" title="Apache Pig"></a>Apache Pig</h1><p>数据流语言和在 MapReduce 顶部构建的并行执行框架。在内部，编译器将 Pig 语句转换为 MapReduce 作业的有向无环图，提交至 Hadoop，以执行。</p>
<h1 id="Apache-Sentry"><a href="#Apache-Sentry" class="headerlink" title="Apache Sentry"></a>Apache Sentry</h1><p>企业级大数据安全的下一步骤，为存储在 Apache Hadoop 中的数据提供细粒度授权。独立的安全模块，集成开源 SQL 查询引擎 Apache Hive 和 Cloudera Impala，Sentry 提供高级身份验证控制以为企业数据集启用多用户应用程序和跨职能流程。</p>
<h1 id="Apache-Spark"><a href="#Apache-Spark" class="headerlink" title="Apache Spark"></a>Apache Spark</h1><p>分布式计算的一般框架，为迭代和交互式处理提供出色性能。Spark 为 Java、Scala 和 Python 展示用户友好的 API。</p>
<h1 id="Apache-Sqoop"><a href="#Apache-Sqoop" class="headerlink" title="Apache Sqoop"></a>Apache Sqoop</h1><p>在 Hadoop 和外部结构化数据存储（如关系数据库）之间高效批量传输数据的工具。Sqoop 导入表格内容至 HDFS、Apache Hive 和 Apache HBase，并生成允许用户解译表架构的 Java 类。Sqoop 也可以从 Hadoop 存储中提取数据，并将记录从 HDFS 导出至外部结构化数据存储，如关系数据库和企业数据仓库。</p>
<p>Sqoop 有两个版本：Sqoop 和 Sqoop 2。Sqoop 要求客户端安装和配置。Sqoop 2 是基于网络的服务，具有客户命令行界面。拥有 Sqoop 2 连接器，在服务器上配置数据库驱动。</p>
<h1 id="Apache-ZooKeeper"><a href="#Apache-ZooKeeper" class="headerlink" title="Apache ZooKeeper"></a>Apache ZooKeeper</h1><p>维护配置信息、命名并提供分布式同步和组服务的集中式服务。</p>
<h1 id="CDH"><a href="#CDH" class="headerlink" title="CDH"></a>CDH</h1><p>Cloudera Apache Hadoop 分布包含核心 Hadoop（HDFS、MapReduce、YARN）以及以下相关项目：Apache Avro、Apache Flume、Fuse-DFS、Apache HBase、Apache Hive、Hue、Cloudera Impala、Apache Mahout、Apache Oozie、Apache Pig、Cloudera Search、Apache Sentry、Apache Spark、Apache Sqoop、Apache Whirr、Apache ZooKeeper、DataFu 和 Kite。</p>
<p>CDH 为免费 100% 开源，并在 Apache 2.0 许可证下许可。CDH 支持多个 Linux 分配。</p>
<h1 id="Cloudera-Manager"><a href="#Cloudera-Manager" class="headerlink" title="Cloudera Manager"></a>Cloudera Manager</h1><h2 id="Cloudera-Manager定义"><a href="#Cloudera-Manager定义" class="headerlink" title="Cloudera Manager定义"></a>Cloudera Manager定义</h2><p>CDH、Cloudera Impala 和 Cloudera Search 的端到瑞管理应用程序。Cloudera Manager 允许管理员轻松有效地协调、监控和管理 Hadoop 群集和 CDH 安装。</p>
<h2 id="Cloudera-Manager版本"><a href="#Cloudera-Manager版本" class="headerlink" title="Cloudera Manager版本"></a>Cloudera Manager版本</h2><p>Cloudera Manager 有两个可用版本：Cloudera Express 和 Cloudera Enterprise。</p>
<h3 id="Cloudera-Express"><a href="#Cloudera-Express" class="headerlink" title="Cloudera Express"></a>Cloudera Express</h3><p>免费下载，包含 CDH，涵盖企业级 Apache Hadoop、Apache HBase、Cloudera Impala、Cloudera Search、Apache Spark 和 Cloudera Manager 分布，提供强大的集群管理功能，如自动部署、集中管理、监控和诊断工具。Cloudera Express 使数据驱动的企业可评估 Apache Hadoop。</p>
<h2 id="Cloudera-Management-Service"><a href="#Cloudera-Management-Service" class="headerlink" title="Cloudera Management Service"></a>Cloudera Management Service</h2><p>Cloudera Management Service 可作为一组角色实施各种管理功能：</p>
<ul>
<li>Activity Monitor - 收集有关 MapReduce 服务运行的活动的信息。默认情况下未添加此角色。</li>
<li>Host Monitor - 收集有关主机的运行状况和指标信息</li>
<li>Service Monitor - 收集有关服务的运行状况和指标信息以及 YARN 和 Impala 服务中的活动信息</li>
<li>Event Server - 聚合 relevant Hadoop 事件并将其用于警报和搜索</li>
<li>Alert Publisher - 为特定类型的事件生成和提供警报</li>
<li>Reports Manager - 生成报告，它提供用户、用户组和目录的磁盘使用率的历史视图，用户和 YARN 池的处理活动，以及 HBase 表和命名空间。此角色未在 Cloudera Express 中添加。<br>Cloudera Manager 将单独管理每个角色，而不是作为 Cloudera Manager Server 的一部分进行管理，可实现可扩展性（例如，在大型部署中，它可用于将监控器角色置于自身的主机上）和隔离。</li>
</ul>
<p>此外，对于特定版本的 Cloudera Enterprise 许可证，Cloudera Management Service 还为 Cloudera Navigator 提供 Navigator Audit Server 和 Navigator Metadata Server 角色。</p>
<h1 id="Cloudera-Impala"><a href="#Cloudera-Impala" class="headerlink" title="Cloudera Impala"></a>Cloudera Impala</h1><p>可实时查询存储在 HDFS 或 Apache HBase 中数据的服务。它支持相同的元数据和 ODBC 和 JDBC 驱动程序作为 Apache Hive 和基于 Hive 标准查询语言 (HiveQL) 的查询语言。要避免延迟，Impala 规避 MapReduce 通过特殊分布式查询引擎（与商业并行 RDBMS 中的引擎相似）直接访问数据。</p>
<h1 id="Hue"><a href="#Hue" class="headerlink" title="Hue"></a>Hue</h1><p>为 CDH 服务构建自定义 GUI 应用程序的服务和包含以下内置应用程序的工具：Apache Pig、Apache HBase 和 Sqoop 2 shell，Apache Pig 编辑器、Beeswax Hive UI，Cloudera Impala 查询编辑器，Solr 搜索应用程序Hive 元存储管理器，Oozie 应用程序编辑器、调度程序和提交者，Apache HBase 浏览器，Sqoop 2 应用程序，HDFS 文件管理器和 MapReduce 和 YARN 作业浏览器。</p>
<p>主页：<a href="http://master.lt.com:8888/">http://master.lt.com:8888/</a><br>MapReduce任务查看：<a href="http://192.168.1.100:8888/jobbrowser/">http://192.168.1.100:8888/jobbrowser/</a><br>Hbase主页：<a href="http://192.168.1.100:8888/hbase">http://192.168.1.100:8888/hbase</a><br><a href="http://blog.cloudera.com/blog/2013/09/how-to-manage-hbase-data-via-hue/">Hue Hbase文档</a></p>
<p>Hive主页：<a href="http://192.168.1.100:8888/beeswax/">http://192.168.1.100:8888/beeswax/</a></p>
<p>##问题记录</p>
<ol>
<li>Hue-Hbase表中文字段插入和编辑问题</li>
</ol>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> Hadoop </tag>
            
            <tag> CDH </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hadoop集群部署]]></title>
      <url>http://geosmart.github.io/2015/08/08/Hadoop%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</url>
      <content type="html"><![CDATA[<h1 id="Hadoop版本区别"><a href="#Hadoop版本区别" class="headerlink" title="Hadoop版本区别"></a>Hadoop版本区别</h1><p>目前不收费的Hadoop版本主要有三个，分别是：</p>
<ol>
<li>Apache（最原始的版本，所有发行版均基于这个版本进行改进）</li>
<li>Cloudera版本（Cloudera’s Distribution Including Apache Hadoop，简称CDH）</li>
<li>Hortonworks版本(Hortonworks Data Platform，简称“HDP”），对于国内而言，绝大多数选择CDH版本，</li>
</ol>
<p>CDH和Apache版本主要区别：</p>
<ul>
<li>CDH对Hadoop版本的划分非常清晰，目前维护的有两个系列的版本，分别是cdh4和cdh5</li>
<li>由于Cloudera做Hadoop开发的，其他厂商仅是做Hadoop集成或CDH集成，和Hadoop trunk能最快的同步，保证业务的前向兼容性；</li>
<li>安全 CDH支持Kerberos安全认证，apache hadoop则使用简陋的用户名匹配认证</li>
<li>CDH文档清晰（包括中文文档），很多采用Apache版本的用户都会阅读CDH提供的文档，包括安装文档、升级文档等。</li>
<li>CDH支持Yum/Apt包，Tar包，RPM包，CM安装，Cloudera Manager三种方式安装,Apache hadoop只支持Tar包安装。</li>
</ul>
<hr>
<a id="more"></a>
<h1 id="关于CDH"><a href="#关于CDH" class="headerlink" title="关于CDH"></a>关于CDH</h1><p><a href="http：//www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/introduction.html">官方介绍</a><br>Cloudera 提供一个可扩展、灵活、集成的平台，可用来方便地管理您的企业中快速增长的多种多样的数据。业界领先的 Cloudera 产品和解决方案使您能够部署并管理 Apache Hadoop 和相关项目、操作和分析您的数据以及保护数据的安全。</p>
<p>Cloudera 提供下列产品和工具：</p>
<ul>
<li>CDH — Cloudera 分发的 Apache Hadoop 和其他相关开放源代码项目，包括 Impala 和 Cloudera Search。CDH 还提供安全保护以及与许多硬件和软件解决方案的集成。</li>
<li>Cloudera Manager — 一个复杂的应用程序，用于部署、管理、监控您的 CDH 部署并诊断问题。Cloudera Manager 提供 Admin Console，这是一种基于 Web 的用户界面，使您的企业数据管理简单而直接。它还包括 Cloudera Manager API，可用来获取群集运行状况信息和度量以及配置 Cloudera Manager。</li>
<li>Cloudera Navigator — CDH 平台的端到端数据管理工具。Cloudera Navigator 使管理员、数据经理和分析师能够了解 Hadoop 中的大量数据。Cloudera Navigator 中强大的审核、数据管理、沿袭管理和生命周期管理使企业能够遵守严格的法规遵从性和法规要求。</li>
<li>Cloudera Impala — 一种大规模并行处理 SQL 引擎，用于交互式分析和商业智能。其高度优化的体系结构使它非常适合用于具有联接、聚合和子查询的传统 BI 样式的查询。它可以查询来自各种源的 Hadoop 数据文件，包括由 MapReduce 作业生成的数据文件或加载到 Hive 表中的数据文件。YARN 和 Llama 资源管理组件让 Impala 能够共存于使用 Impala SQL 查询并发运行批处理工作负载的群集上。您可以通过 Cloudera Manager 用户界面管理 Impala 及其他 Hadoop 组件，并通过 Sentry 授权框架保护其数据。</li>
</ul>
<h1 id="Cloudera-QuickStart-VM"><a href="#Cloudera-QuickStart-VM" class="headerlink" title="Cloudera QuickStart VM"></a>Cloudera QuickStart VM</h1><p><a href="http：//www.cloudera.com/content/cloudera/en/downloads/quickstart_vms/cdh-5-4-x.html">下载地址</a><br>为方便开始使用CDH、Cloudera Manager、Cloudera Impala 和 Cloudera Search，这些虚拟机器包含您所需的一切。</p>
<h1 id="CDH安装步骤"><a href="#CDH安装步骤" class="headerlink" title="CDH安装步骤"></a>CDH安装步骤</h1><h2 id="CDH安装参考资料"><a href="#CDH安装参考资料" class="headerlink" title="CDH安装参考资料"></a>CDH安装参考资料</h2><ul>
<li><a href="http：//zh-cn.cloudera.com/content/cloudera/en/products-and-services/cloudera-enterprise.html">cloudera简介</a></li>
<li><a href="http：//www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/introduction.html">cdh5官方文档</a></li>
<li><a href="http：//www.cloudera.com/content/cloudera/en/documentation/core/latest/topics/cdh_ig_req_supported_versions.html">CDH5安装环境要求</a></li>
<li><a href="http：//www.cloudera.com/content/cloudera/en/documentation/core/latest/topics/installation_installation.html">CDH5的3种安装方式</a></li>
<li><a href="http：//www.cloudera.com/content/cloudera/en/documentation/core/latest/topics/cm_ig_install_path_a.html#concept_vk4_psb_zm_unique_4">在线Yum/Wget安装教程</a></li>
<li><a href="http：//www.aboutyun.com/thread-9219-1-1.html">在线Yum/Wget安装教程-中文</a></li>
</ul>
<h2 id="在线安装优势"><a href="#在线安装优势" class="headerlink" title="在线安装优势"></a>在线安装优势</h2><ol>
<li>联网安装、升级，非常方便</li>
<li>自动下载依赖软件包</li>
<li>Hadoop生态系统包自动匹配，不需要你寻找与当前Hadoop匹配的Hbase，Flume，Hive等软件，Yum/Apt会根据当前安装Hadoop版本自动寻找匹配版本的软件包，并保证兼容性。</li>
<li>自动创建相关目录并软链到合适的地方（如conf和logs等目录）；自动创建hdfs, mapred用户，hdfs用户是HDFS的最高权限用户，mapred用户则负责mapreduce执行过程中相关目录的权限。</li>
</ol>
<h2 id="在线安装步骤"><a href="#在线安装步骤" class="headerlink" title="在线安装步骤"></a>在线安装步骤</h2><h3 id="静态IP配置"><a href="#静态IP配置" class="headerlink" title="静态IP配置"></a>静态IP配置</h3><p><code>cd /mnt/scripts/batch-update-ip &amp;&amp; chmod +x static-ip.sh &amp;&amp; ./static-ip.sh localhost eth1 192.168.1 81 1</code><br>示例：<code>cd /mnt/scripts/batch-update-ip &amp;&amp; chmod +x static-ip.sh &amp;&amp; ./static-ip.sh slave3.lt.com eth1 192.168.1 103 1</code></p>
<p><a href="todo">脚本地址</a></p>
<h3 id="HostName配置-FQDN配置"><a href="#HostName配置-FQDN配置" class="headerlink" title="HostName配置/FQDN配置"></a>HostName配置/FQDN配置</h3><p>FQDN是Fully Qualified Domain Name的缩写, 含义是完整的域名. 例如, 一台机器主机名(hostname)是www, 域后缀(domain)是example.com, 那么该主机的FQDN应该是www.example.com.<br>注意：hosts配置不当，后面server和agent间通讯会存在问题，参考host配置如下：</p>
<ul>
<li>server/agent配置(master)</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> vim /etc/hosts</span></div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> solr/hue/hive server</span></div><div class="line">127.0.0.1 localhost.localdomain localhost</div><div class="line"></div><div class="line">192.168.1.90   cdhagent.lt.com cdhagent</div><div class="line"></div><div class="line">192.168.1.91   server1.lt.com server1</div><div class="line">192.168.1.92   server2.lt.com server2</div><div class="line">192.168.1.93   server3.lt.com server3</div><div class="line">192.168.1.94   server4.lt.com server4</div><div class="line">192.168.1.95   server5.lt.com server5</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> HDFS NameNode</span></div><div class="line">192.168.1.100  master.lt.com master</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> HDFS DataNode</span></div><div class="line">192.168.1.101  slave1.lt.com slave1</div><div class="line">192.168.1.102  slave2.lt.com slave2</div><div class="line">192.168.1.103  slave3.lt.com slave3</div><div class="line">192.168.1.104  slave4.lt.com slave4</div><div class="line">192.168.1.105  slave5.lt.com slave5</div><div class="line">192.168.1.106  slave6.lt.com slave6</div><div class="line">192.168.1.107  slave7.lt.com slave7</div><div class="line">192.168.1.108  slave8.lt.com slave8</div><div class="line">192.168.1.109  slave9.lt.com slave9</div><div class="line">192.168.1.110  slave10.lt.com slave10</div></pre></td></tr></table></figure>
<ul>
<li>network配置</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> vim /etc/sysconfig/network</span></div><div class="line">NETWORKING=yes</div><div class="line">HOSTNAME=master.lt.com</div><div class="line">NTPSERVERARGS=iburst</div></pre></td></tr></table></figure>
<p><em>TODO：可局域网搭建DNS服务器，Slave机器即可不配配置hosts</em></p>
<h3 id="SSH无密码登陆配置"><a href="#SSH无密码登陆配置" class="headerlink" title="SSH无密码登陆配置"></a>SSH无密码登陆配置</h3><p><em>TODO：补充github脚本地址</em><br>删除现有ssh配置（可选）：rm /root/.ssh/authorized_keys &amp;&amp; rm /root/.ssh/known_hosts<br><code>cd /mnt/scripts/batch-ssh &amp;&amp; chmod +x keygen_master.sh &amp;&amp; ./keygen_master.sh</code></p>
<h3 id="iptables防火墙配置"><a href="#iptables防火墙配置" class="headerlink" title="iptables防火墙配置"></a>iptables防火墙配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#查看防火墙状态</span></div><div class="line">service iptables status</div><div class="line"><span class="comment">#关闭防火墙</span></div><div class="line">service iptables stop</div><div class="line"><span class="comment">#永久关闭防火墙</span></div><div class="line">chkconfig iptables off</div></pre></td></tr></table></figure>
<h3 id="selinux强制访问控制安全配置"><a href="#selinux强制访问控制安全配置" class="headerlink" title="selinux强制访问控制安全配置"></a>selinux强制访问控制安全配置</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">查看SELinux状态</span></div><div class="line">/usr/sbin/sestatus -v</div><div class="line"><span class="meta">#</span><span class="bash">或命令</span></div><div class="line">getenforce</div><div class="line"><span class="meta">#</span><span class="bash">关闭SELinux</span></div><div class="line"><span class="meta">#</span><span class="bash">1. 临时关闭（不用重启机器）：</span></div><div class="line">setenforce 0                  ##设置SELinux 成为permissive模式</div><div class="line">                              ##setenforce 1 设置SELinux 成为enforcing模式</div><div class="line"><span class="meta">#</span><span class="bash">2. 修改配置文件</span></div><div class="line">vim /etc/selinux/config</div><div class="line"><span class="meta">#</span><span class="bash">将SELINUX=enforcing改为SELINUX=disabled</span></div><div class="line"><span class="meta">#</span><span class="bash">3. reboot</span></div></pre></td></tr></table></figure>
<h3 id="swap配置"><a href="#swap配置" class="headerlink" title="swap配置"></a>swap配置</h3><p>Cloudera 建议将 /proc/sys/vm/swappiness 设置为 0。默认设置为 60。<br>查看当前swap分区设置<code>cat /proc/sys/vm/swappiness</code><br>临时修改值：<code>sudo sysctl vm.swappiness=0</code><br>永久修改值：<code>vim /etc/sysctl.conf</code>，在最后加一行<code>vm.swappiness = 0</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">swappiness的值的大小对如何使用swap分区是有着很大的联系</div><div class="line">swappiness=0的时候表示最大限度使用物理内存，然后才是 swap空间</div><div class="line">swappiness＝100的时候表示积极的使用swap分区，并且把内存上的数据及时的搬运到swap空间里面</div></pre></td></tr></table></figure>
<h3 id="安装NTP服务"><a href="#安装NTP服务" class="headerlink" title="安装NTP服务"></a>安装NTP服务</h3><p><a href="http://acooly.iteye.com/blog/1993484">NTP配置教程</a><br>集群中所有主机必须保持时间同步，如果时间相差较大会引起各种问题。 具体思路如下：<br>master节点作为ntp服务器与外界对时中心同步时间，随后对所有datanode节点提供时间同步服务。<br>所有datanode节点以master节点为基础同步时间。<br>所有节点安装相关组件： <code>yum install ntp</code> 。<br>配置开机启动： <code>chkconfig ntpd on</code> ,<br>检查是否设置成功： <code>chkconfig --list ntpd</code> 其中2-5为on状态就代表成功。</p>
<ul>
<li>主节点配置<br>在配置之前，先使用ntpdate手动同步一下时间，免得本机与对时中心时间差距太大，使得ntpd不能正常同步。 ntpdate -u 202.112.29.82<br>编辑<code>/etc/ntp.conf</code>配置文件，配置完成后启动服务<code>service ntpd start</code></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">driftfile /var/lib/ntp/drift</div><div class="line"></div><div class="line">restrict default kod nomodify notrap nopeer noquery</div><div class="line">restrict -6 default kod nomodify notrap nopeer noquery</div><div class="line"></div><div class="line">restrict 127.0.0.1</div><div class="line">restrict -6 ::1</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash">允许内网其他机器同步时间</span></div><div class="line">restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 中国这边最活跃的时间服务器 : http://www.pool.ntp.org/zone/cn</span></div><div class="line">server 3.cn.pool.ntp.org perfer  </div><div class="line">server 1.asia.pool.ntp.org         </div><div class="line">server 3.asia.pool.ntp.org</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 外部时间服务器不可用时，以本地时间作为时间服务</span></div><div class="line">server  127.127.1.0     # local clock</div><div class="line">fudge   127.127.1.0 stratum 10</div><div class="line"></div><div class="line">includefile /etc/ntp/crypto/pw</div><div class="line"></div><div class="line">keys /etc/ntp/keys</div><div class="line">server 127.127.1.0 iburst</div></pre></td></tr></table></figure>
<p>查看配置结果：   </p>
<ul>
<li><code>netstat -tlunp | grep ntp</code> 查看服务连接和监听</li>
<li><code>ntpq -p</code>查看网络中的NTP服务器，同时显示客户端和每个服务器的关系</li>
<li><p><code>ntpstat</code> 查看时间同步状态</p>
</li>
<li><p>NTP客户端配置<br>编辑<code>/etc/ntp.conf</code>配置文件，配置完成后启动服务<code>service ntpd restart</code></p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">driftfile /var/lib/ntp/drift</div><div class="line">restrict 127.0.0.1</div><div class="line">restrict -6 ::1</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 配置时间服务器为本地的时间服务器</span></div><div class="line">server 192.168.1.100</div><div class="line"></div><div class="line">restrict 192.168.1.100 nomodify notrap noquery</div><div class="line"></div><div class="line">server  127.127.1.0     # local clock</div><div class="line">fudge   127.127.1.0 stratum 10</div><div class="line"></div><div class="line">includefile /etc/ntp/crypto/pw</div><div class="line"></div><div class="line">keys /etc/ntp/keys</div></pre></td></tr></table></figure>
<h3 id="cloudera-manager-installer-bin安装"><a href="#cloudera-manager-installer-bin安装" class="headerlink" title="cloudera-manager-installer.bin安装"></a>cloudera-manager-installer.bin安装</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">wget http：//archive.cloudera.com/cm5/installer/latest/cloudera-manager-installer.bin</div><div class="line">chmod u+x cloudera-manager-installer.bin</div><div class="line">sudo ./cloudera-manager-installer.bin</div></pre></td></tr></table></figure>
<h3 id="在线配置"><a href="#在线配置" class="headerlink" title="在线配置"></a>在线配置</h3><p>打开http：//{host}：7180/cmf/login<br>默认用户名/密码：admin/admin<br><a href="http：//www.aboutyun.com/thread-9189-1-1.html">cloudera配置文件</a></p>
<h1 id="CDH5运维相关"><a href="#CDH5运维相关" class="headerlink" title="CDH5运维相关"></a>CDH5运维相关</h1><h2 id="系统服务"><a href="#系统服务" class="headerlink" title="系统服务"></a>系统服务</h2><p>服务查询：<code>service --status-all| grep cloudera</code><br><em>服务端</em>  </p>
<ul>
<li>cloudera-scm-server</li>
<li>cloudera-scm-server-db<br><em>客户端</em>  </li>
<li>cloudera-scm-agent</li>
</ul>
<h2 id="嵌入式-PostgreSQL-数据库"><a href="#嵌入式-PostgreSQL-数据库" class="headerlink" title="嵌入式 PostgreSQL 数据库"></a>嵌入式 PostgreSQL 数据库</h2><p><a href="http://www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/cm_ig_embed_pstgrs.html">嵌入式 PostgreSQL 数据库</a><br><a href="http://www.linuxidc.com/Linux/2013-10/91446.htm">修改postgresql配置允许远程访问</a>  </p>
<ul>
<li>scm数据库密码</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> cat /etc/cloudera-scm-server/db.properties</span></div><div class="line">com.cloudera.cmf.db.type=postgresql</div><div class="line">com.cloudera.cmf.db.host=localhost:7432</div><div class="line">com.cloudera.cmf.db.name=scm</div><div class="line">com.cloudera.cmf.db.user=scm</div><div class="line">com.cloudera.cmf.db.password=30MCe9Mxuk</div></pre></td></tr></table></figure>
<ul>
<li>root密码： <code>/var/lib/cloudera-scm-server-db/data/generated_password.txt</code></li>
</ul>
<h2 id="卸载Cloudera"><a href="#卸载Cloudera" class="headerlink" title="卸载Cloudera"></a>卸载Cloudera</h2><p><a href="http://www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/cm_ig_uninstall_cm.html">卸载 Cloudera Manager 和托管软件</a><br><a href="http://student-lp.iteye.com/blog/2158887">参考博客</a></p>
<h2 id="Cloudera-Manager-API"><a href="#Cloudera-Manager-API" class="headerlink" title="Cloudera Manager API"></a>Cloudera Manager API</h2><p><a href="http://zh-cn.cloudera.com/content/cloudera/en/documentation.html">官方文档</a><br>Cloudera Manager API 提供了配置和服务生命周期管理、服务运行状况信息和指标，并允许您配置 Cloudera Manager 本身。此 API 与 Cloudera Manager Admin Console 在同一主机和端口上接受服务，不需要任何额外过程或额外配置。此 API 支持 HTTP 基本验证，接受的用户和凭据与 Cloudera Manager Admin Console 相同。</p>
<h2 id="Cloudera-Management-Service"><a href="#Cloudera-Management-Service" class="headerlink" title="Cloudera Management Service"></a>Cloudera Management Service</h2><p>Cloudera Management Service 可作为一组角色实施各种管理功能：<br>Activity Monitor - 收集有关 MapReduce 服务运行的活动的信息。默认情况下未添加此角色。<br>Host Monitor - 收集有关主机的运行状况和指标信息<br>Service Monitor - 收集有关服务的运行状况和指标信息以及 YARN 和 Impala 服务中的活动信息<br>Event Server - 聚合 relevant Hadoop 事件并将其用于警报和搜索<br>Alert Publisher - 为特定类型的事件生成和提供警报<br>Reports Manager - 生成报告，它提供用户、用户组和目录的磁盘使用率的历史视图，用户和 YARN 池的处理活动，以及 HBase 表和命名空间。此角色未在 Cloudera Express 中添加。<br>Cloudera Manager 将单独管理每个角色，而不是作为 Cloudera Manager Server 的一部分进行管理，可实现可扩展性（例如，在大型部署中，它可用于将监控器角色置于自身的主机上）和隔离。</p>
<p>此外，对于特定版本的 Cloudera Enterprise 许可证，Cloudera Management Service 还为 Cloudera Navigator 提供 Navigator Audit Server 和 Navigator Metadata Server 角色。</p>
<h1 id="安装问题记录"><a href="#安装问题记录" class="headerlink" title="安装问题记录"></a>安装问题记录</h1><ol>
<li>无法发出查询：未能连接到 Host Monitor</li>
</ol>
<p>解决方式：新增cloudera management services ,注意新增的目标机器因为scm-server安装的同一台机器，机器内存最好&gt;=8G</p>
<ol>
<li>urlopen error [Errno 111] Connection refused</li>
</ol>
<ul>
<li>问题场景：CM中主机CDH5安装Parcel完成后无法分配和激活Agent</li>
<li>详细日志<blockquote>
<p>downloader INFO  Finished download [ url： http：//master.lt.com：7180/cmf/parcel/download/CDH-5.4.4-1.cdh5.4.4.p0.4-el6.parcel, state： exception, total_bytes： 0, downloaded_bytes： 0, start_time： 2015-08-11 22：18：32, download_end_time： , end_time： 2015-08-11 22：18：33, code： 600, exception： <urlopen error [Errno 111] Connection refused>, path： None ]</p>
</blockquote>
</li>
<li>错误分析：在slave机器执行<code>nc -v master.lt.com  7182</code> 返回refused，判断是host配置有误导致dns解析不了</li>
<li>解决方式：在slave1的hosts中新增master的域名解析</li>
</ul>
<ol>
<li>正在获取安装锁问题</li>
</ol>
<ul>
<li>问题描述：意外中止安装后重新安装提示”正在获取安装锁…“  ；</li>
<li>问题解决：在Manager节点运行<code>rm /tmp/.scm_prepare_node.lock</code>删除Manager的lock文件后重新安装即可；</li>
</ul>
<ol>
<li>对于此 Cloudera Manager 版本 (5.4.7) 太新的 CDH 版本不会显示</li>
</ol>
<ul>
<li>问题描述：Versions of CDH that are too new for this version of Cloudera Manager (5.4.7) will not be shown.</li>
<li>问题定位：PARCELS表fileName=CDH-5.4.7-1.cdh5.4.7.p0.3-el6.parcel的hash值为null，判断为parcel文件问题或scm数据库生成干扰问题</li>
<li>解决思路：判断为/opt/cloudera/parcel-repo/目录内的本地parcel应该在scm数据库初始化结束后再放入</li>
<li>问题解决：停止server&gt;重置scm数据库&gt;启动server&gt;复制parcel到/opt/cloudera/parcel-repo/目录</li>
</ul>
<p><a href="https://community.cloudera.com/t5/Cloudera-Manager-Installation/Can-t-find-CM-5-4-2-for-Trusty-or-Precise/td-p/28685">参考</a></p>
<ol>
<li><p>[Errno 2] No such file or directory: u’/opt/cloudera/parcels/CDH-5.4.7-1.cdh5.4.7.p0.3/meta/parcel.json’ - master.lt.com<br>需要存在目录：/opt/cloudera/parcel-cache</p>
</li>
<li><p>启用透明大页面问题</p>
</li>
</ol>
<ul>
<li>问题描述：已启用“透明大页面”，它可能会导致重大的性能问题。版本为“CentOS release 6.5 (Final)”且发行版为“2.6.32-431.el6.x86_64”的 Kernel 已将 enabled 设置为“[always] madvise never”，并将 defrag 设置为“[always] madvise never”。</li>
<li>问题解决：运行“echo never &gt; /sys/kernel/mm/redhat_transparent_hugepage/defrag”以禁用此设置，然后将同一命令添加到一个 init 脚本中，如 /etc/rc.local，</li>
</ul>
<ol>
<li>修改Cloudera Manager 管理机器的IP<br><a href="http://www.cnblogs.com/chenfool/archive/2014/05/27/3756066.html">解决方案</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 大数据 </category>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> Hadoop </tag>
            
            <tag> CDH </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Python安装升级教程]]></title>
      <url>http://geosmart.github.io/2015/08/05/Python%E5%AE%89%E8%A3%85%E5%8D%87%E7%BA%A7%E6%95%99%E7%A8%8B/</url>
      <content type="html"><![CDATA[<h1 id="升级前安装依赖"><a href="#升级前安装依赖" class="headerlink" title="升级前安装依赖"></a>升级前安装依赖</h1><p><code>yum groupinstall &quot;Development tools&quot;</code></p>
<h1 id="Python-2-7-9-下载-gt-解压-gt-编译-gt-安装"><a href="#Python-2-7-9-下载-gt-解压-gt-编译-gt-安装" class="headerlink" title="Python 2.7.9 下载&gt;解压&gt;编译&gt;安装"></a>Python 2.7.9 下载&gt;解压&gt;编译&gt;安装</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">wget https://www.python.org/ftp/python/2.7.9/Python-2.7.9.tgz </div><div class="line">tar jxvf Python-2.7.9.tgz   </div><div class="line">mv Python-2.7.9  python</div><div class="line">cd python</div><div class="line">./configure --prefix=/usr/local/python</div><div class="line">make &amp;&amp; make altinstall</div></pre></td></tr></table></figure>
<ul>
<li>关于altinstall<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"> Warning</div><div class="line">make install can overwrite or masquerade the python binary. make altinstall is therefore recommended instead of make install since it only installs exec_prefix/bin/pythonversion.</div></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="修改系统默认Python"><a href="#修改系统默认Python" class="headerlink" title="修改系统默认Python"></a>修改系统默认Python</h1><ol>
<li>查看已有python版本<br><code>python -V</code></li>
<li>查看Python版本<br><code>/usr/local/python/bin/python2.7 -V</code></li>
<li>将系统默认Python改为新安装的Python<br><code>ln -fs /usr/local/python/bin/python2.7 /usr/bin/python</code></li>
</ol>
<h1 id="yum无法运行问题"><a href="#yum无法运行问题" class="headerlink" title="yum无法运行问题"></a>yum无法运行问题</h1><p>进行更改后，yum会无法运行了。修改/usr/bin/yum文件，将第一行的<br><code>#!/usr/bin/python</code><br>中的python改为系统原有的python版本，如下：<br><code>#!/usr/bin/python2.6</code>  </p>
]]></content>
      
        <categories>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> Python </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[IIS与Tomcat共享80端口]]></title>
      <url>http://geosmart.github.io/2015/08/03/IIS%E4%B8%8ETomcat%E5%85%B1%E4%BA%AB80%E7%AB%AF%E5%8F%A3/</url>
      <content type="html"><![CDATA[<p>微信公众号有80端口要求，但是80端口已运行了一个项目，如何将后端J2EE实现的服务集成到80端口，即Tomcat集成进IIS。<br>调研了三种方案，Apache Tomcat Connector（isapi_redirect实现）、ARR（IIS中的反向代理）和 IIS2Tomcat(BonCode AJP实现)，按照最轻量最简洁的部署要求，最终采用AJP实现。</p>
<hr>
<a id="more"></a>
<h1 id="isapi-redirect"><a href="#isapi-redirect" class="headerlink" title="isapi_redirect"></a>isapi_redirect</h1><p><a href="http://tomcat.apache.org/connectors-doc/webserver_howto/iis.html">官方参考</a><br>实现思路： </p>
<ol>
<li>The IIS-Tomcat redirector is an IIS plugin (filter + extension), IIS load the redirector plugin and calls its filter function for each in-coming request.</li>
<li>The filter then tests the request URL against a list of URI-paths held inside uriworkermap.properties, If the current request matches one of the entries in the list of URI-paths, the filter transfers the request to the extension.</li>
<li>The extension collects the request parameters and forwards them to the appropriate worker using the defined protocol like ajp13.</li>
<li>The extension collects the response from the worker and returns it to the browser<br>配置注册表，DLL等步骤繁琐，易出错，如官方所说你很难一次性配置成功-_-</li>
</ol>
<h1 id="ARR"><a href="#ARR" class="headerlink" title="ARR"></a>ARR</h1><p>ARR：Application Request Routing，类似Nginx的反向代理<br><a href="http://www.iisadmin.co.uk/?p=326">配置教程</a><br>ARR is a good starting point if you want to connect Apache Tomcat to IIS 7, however, there are some issues especially under load that make this less than ideal solution. </p>
<ol>
<li>There are still differences in the way headers are handled between ARR and Tomcat and not all are transferred.  </li>
<li>ARR will be heavier on the network as it requires that http data is transferred in full byte length without being able to take advantage of binary compression and byte encoding the AJP protocol offers.  </li>
<li>Under load ARR will not be aware of Tomcat thread handling resulting in unnecessarily dropped connections. </li>
<li>Secure (https) connections cannot be easily handled if tomcat needs to be aware of certificates used. </li>
</ol>
<h1 id="AJP"><a href="#AJP" class="headerlink" title="AJP"></a>AJP</h1><p>AJP：Apache JServ Protocol version<br><a href="https://github.com/Bilal-S/iis2tomcat">项目地址</a><br><a href="http://tomcatiis.riaforge.org">下载地址（需翻墙）</a><br><a href="http://blog.csdn.net/zhang_hui_cs/article/details/9399373#reply">参考博客</a><br><a href="http://v.youku.com/v_show/id_XNTg1MTgyODgw.html">详细配置视频教程</a>  </p>
<h2 id="默认网站二级应用程序配置要点"><a href="#默认网站二级应用程序配置要点" class="headerlink" title="默认网站二级应用程序配置要点"></a>默认网站二级应用程序配置要点</h2><ol>
<li>在IIS下新增网站examples，或者在默认网站中新增应用程序examples,物理路径指向<code>｛catalina_home｝/webapps/examples</code>；</li>
<li>执行Connector_Setup.exe安装，默认参数即可，选择指定的IIS网站，如examples；</li>
<li>应用程序池的托管管道模式设置为集成；</li>
<li>在examples根目录新增配置BIN目录（包含BonCodeAJP13.dll、BonCodeIIS.dll），并在根目录新增web.config，内容如下：</li>
</ol>
<ul>
<li>完整配置</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</div><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">system.webServer</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">validation</span> <span class="attr">validateIntegratedModeConfiguration</span>=<span class="string">"false"</span>/&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">handlers</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">add</span> <span class="attr">name</span>=<span class="string">"BonCodeForAll"</span> <span class="attr">path</span>=<span class="string">"*"</span> <span class="attr">verb</span>=<span class="string">"*"</span> <span class="attr">type</span>=<span class="string">"BonCodeIIS.BonCodeCallHandler"</span> <span class="attr">resourceType</span>=<span class="string">"Unspecified"</span> <span class="attr">preCondition</span>=<span class="string">"integratedMode"</span> /&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">add</span> <span class="attr">name</span>=<span class="string">"BonCode-Tomcat-JSP-Handler"</span> <span class="attr">path</span>=<span class="string">"*.jsp"</span> <span class="attr">verb</span>=<span class="string">"*"</span> <span class="attr">type</span>=<span class="string">"BonCodeIIS.BonCodeCallHandler"</span> <span class="attr">preCondition</span>=<span class="string">"integratedMode"</span> /&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">add</span> <span class="attr">name</span>=<span class="string">"BonCode-Tomcat-CFC-Handler"</span> <span class="attr">path</span>=<span class="string">"*.cfc"</span> <span class="attr">verb</span>=<span class="string">"*"</span> <span class="attr">type</span>=<span class="string">"BonCodeIIS.BonCodeCallHandler"</span> <span class="attr">preCondition</span>=<span class="string">"integratedMode"</span> /&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">add</span> <span class="attr">name</span>=<span class="string">"BonCode-Tomcat-CFM-Handler"</span> <span class="attr">path</span>=<span class="string">"*.cfm"</span> <span class="attr">verb</span>=<span class="string">"*"</span> <span class="attr">type</span>=<span class="string">"BonCodeIIS.BonCodeCallHandler"</span> <span class="attr">preCondition</span>=<span class="string">"integratedMode"</span> /&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">handlers</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">defaultDocument</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">files</span>&gt;</span></div><div class="line">                <span class="tag">&lt;<span class="name">add</span> <span class="attr">value</span>=<span class="string">"index.jsp"</span> /&gt;</span></div><div class="line">                <span class="tag">&lt;<span class="name">add</span> <span class="attr">value</span>=<span class="string">"index.cfm"</span> /&gt;</span></div><div class="line">            <span class="tag">&lt;/<span class="name">files</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">defaultDocument</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">system.webServer</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure>
<ul>
<li>精简配置</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</div><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">system.webServer</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">validation</span> <span class="attr">validateIntegratedModeConfiguration</span>=<span class="string">"false"</span>/&gt;</span>  </div><div class="line">    <span class="tag">&lt;/<span class="name">system.webServer</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure>
<p>若完整配置报错，采用精简配置即可。</p>
<h3 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h3><ol>
<li>在唯一密钥属性“name”设置为“BonCode-Tomcat-JSP-Handler”时，无法添加类型为“add”的重复集合项<br>解决：改用精简配置</li>
</ol>
]]></content>
      
        <categories>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> J2EE </tag>
            
            <tag> Web服务器 </tag>
            
            <tag> IIS </tag>
            
            <tag> Tomcat </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[backbone.marionette学习要点]]></title>
      <url>http://geosmart.github.io/2015/07/28/backbone-marionette%E5%AD%A6%E4%B9%A0%E8%A6%81%E7%82%B9/</url>
      <content type="html"><![CDATA[<h1 id="Marionette（Backbone的牵线木偶）"><a href="#Marionette（Backbone的牵线木偶）" class="headerlink" title="Marionette（Backbone的牵线木偶）"></a>Marionette（Backbone的牵线木偶）</h1><p>提供rendering、template管理、UI对象</p>
<h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><p>rest数据，event事件</p>
<h1 id="Collection：List"><a href="#Collection：List" class="headerlink" title="Collection：List"></a>Collection：List<model></h1><h1 id="View"><a href="#View" class="headerlink" title="View"></a>View</h1><h2 id="ItemView"><a href="#ItemView" class="headerlink" title="ItemView"></a>ItemView</h2><ul>
<li>Backbone.View的扩展，用于渲染Backbone.Model</li>
<li>拥有modelEvents属性，可绑定View方法</li>
</ul>
<h2 id="CollectionView"><a href="#CollectionView" class="headerlink" title="CollectionView"></a>CollectionView</h2><ul>
<li>用于渲染Backbone.Collection</li>
<li>可渲染List<ItemView></li>
<li>拥有collectionEvents/childEvents属性，</li>
<li>add/remove/reset/etc后自动更新视图</li>
<li>支持Filtering（filter方法）、Sorting（comparator属性）</li>
<li>支持Pagination</li>
</ul>
<h2 id="CompositeView"><a href="#CompositeView" class="headerlink" title="CompositeView"></a>CompositeView</h2><ul>
<li>renders a Collection within a template</li>
<li>ItemView（model）和CollectionView（collection）的组合</li>
<li>用于detail/table/nested lists/treeview类型的场景</li>
</ul>
<h1 id="View-Containers"><a href="#View-Containers" class="headerlink" title="View Containers"></a>View Containers</h1><h2 id="Region"><a href="#Region" class="headerlink" title="Region"></a>Region</h2><p>View容器，渲染至DOM，DOM和Backbone的桥梁</p>
<h2 id="LayoutView"><a href="#LayoutView" class="headerlink" title="LayoutView"></a>LayoutView</h2><ul>
<li>用于复杂嵌套布局，multi-view组成的widget</li>
<li>Region容器</li>
<li>render all in one call</li>
</ul>
<h1 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h1><p>initialization初始化和 bootstrapping引导程序</p>
<h1 id="Module"><a href="#Module" class="headerlink" title="Module"></a>Module</h1><p>类似Application，多个Modules组成Application<br>可控制start/stop模块（及其子模块）</p>
<h1 id="Controller"><a href="#Controller" class="headerlink" title="Controller"></a>Controller</h1><p>组件间的交互，用于复杂业务逻辑的业务场景</p>
<p>layouts/regions：动态create/display/dispose页面dom</p>
<h1 id="event-aggregrator"><a href="#event-aggregrator" class="headerlink" title="event aggregrator"></a>event aggregrator</h1><p>可bind/trigger事件<br>module/application级别的事件通道，其他所有模块都可监听，可用于如用户登陆成功的业务场景</p>
<h1 id="Commands"><a href="#Commands" class="headerlink" title="Commands"></a>Commands</h1><p>多处触发，一处处理</p>
<h1 id="Request-Response"><a href="#Request-Response" class="headerlink" title="Request/Response"></a>Request/Response</h1><p>用于提供Application Level Data，如购物车当前状态<br>提供全局状态，无需所有模块都做处理，但易被滥用，当全局可操作时难预测其影响</p>
<p>appRouter：</p>
]]></content>
      
        <categories>
            
            <category> 前端技术 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Backbone </tag>
            
            <tag> Marionette </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[《谜踪之国》读书笔记]]></title>
      <url>http://geosmart.github.io/2015/07/21/%E3%80%8A%E8%B0%9C%E8%B8%AA%E4%B9%8B%E5%9B%BD%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>谜踪之国-天下霸唱<br>探险类的，没有藏地密码写的精彩</p>
<hr>
<a id="more"></a>
<h1 id="第三话-海森堡不确定原理"><a href="#第三话-海森堡不确定原理" class="headerlink" title="第三话　海森堡不确定原理"></a>第三话　海森堡不确定原理</h1><p>2015-07-14 13:43:29<br>世事茫茫如大海，人生何处无风波。</p>
<p>2015-07-14 19:12:50<br>当可执其端而理其绪，举一隅而知三隅；随机生变，鬼神莫测；分寸即定，任意纵横；通篇玩熟，定教四海扬名</p>
<p>2015-07-17 13:47:09<br>好花不常开，好景不常在</p>
<p>2015-07-17 14:20:27<br>见不尽者，是天下之事；悟不尽者，是天下之理”</p>
<p>2015-07-22 13:01:01<br>万物的命运，皆是由无数个点所组成的一条曲线，没有人知道线的中间会发生什么，或是会遇到什么，只是所有的线，最终都会前往同一个终点，这个终点就是死亡，绝不存在例外，曲线中出现的任何一个点，也都不可能对终点产生影响。</p>
<p>2015-07-25 22:07:56<br>近代科学观念支持大爆炸形成宇宙的理论，“宇”和“宙”就是时间与空间的坐标，这和中国传统观念里“盘古开天地”之类的传说有些相似，据说以前只有一片混沌，清浊不分，从盘古产生时间的那一刻被称为“零秒”，而在“零秒坐标”出现之前，还没有时间存在。</p>
<p>2015-07-25 22:09:21<br>从前有句古话是“蝶梦庄周未可知”，是说庄周以为自己在梦中变为了蝴蝶，其实也有可能庄周自己才是蝴蝶做的一场梦，这句话可以用来比喻真实的不确定性，那些看得见摸得到的东西，却未必真实可信。</p>
<p>2015-07-26 17:44:31<br>说开天地怕、道破鬼神惊</p>
<p>2015-07-26 17:48:18<br>并不是出现了“原因”才会产生“结果”，而是结果造就了复杂的原因。没有结果的原因不能称为原因，正是由于结果的存在，才会使前边发生的事件成为原因。因果之间的关系就像一株参天大树，注定成为事实的结果是根，原因则是枝杈纵横交错的茂密树冠，事先掌握了结果的人，就能洞悉命运的规律。</p>
<p>2015-08-07 19:36:06<br>混沌定律，基本上分为三个部分。事物发展运行的轨迹好像是多元化的，存在着无数种可能性，不管你预先布置得如何周密，事到临头也总会出现意料之外的情况，所谓计划赶不上变化，是对第一定律的最好概括。第二定律说白了就是‘怕什么来什么’，你越是不想让它发生的事，它发生的概率就越大。比方说我有块面包，正面抹满了黄油，又不小心失手把它掉在了名贵的地毯上，面包正反两面朝下的概率看起来似乎差不多，其实不管面包掉落多少次，抹了黄油的那一面都会永远朝下，因为事情总是会往咱们最不想看到的方向发展，这既是摩非原理——宿命的重力。另外还有第三定律……”</p>
<p>2015-08-26 09:13:51<br>挫折只是成功者的勋章，疾风劲草，方显英雄本色，洪波汹涌，愈见生命不息。</p>
<p>多看笔记 来自多看阅读 for Kindle</p>
]]></content>
      
        <categories>
            
            <category> 读书笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 小说 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[《把时间当作朋友》读书笔记]]></title>
      <url>http://geosmart.github.io/2015/07/21/%E3%80%8A%E6%8A%8A%E6%97%B6%E9%97%B4%E5%BD%93%E4%BD%9C%E6%9C%8B%E5%8F%8B%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>把时间当作朋友李笑来-李笑来</p>
<p>We do not plan to fail, we fail to plan</p>
<hr>
<a id="more"></a>
<p>2015-06-12 18:00:14<br>柳比歇夫的日志，是“事件-时间日志”（event-time log）。他的方法要比李敖的方法更为高级。李敖的事件记录，往往只能记录事件的名称，是一种基于结果的记录；而柳比歇夫的“事件-时间日志”却是一种基于过程的记录。这里的细微差别是，基于过程的记录要比基于结果的记录只能更为详尽。</p>
<p>2015-06-12 18:01:22<br>“管理时间”是不可能的，那么解决方法就只能是，想尽一切办法真正了解自己，真正了解时间、精确地感知时间；而后再想尽一切办法使自己以及自己的行为与时间“合拍”，就是我的说法——“与时间做朋友”</p>
<p>2015-06-15 00:46:27<br>“We do not plan to fail, we fail to plan.”</p>
<p>2015-06-15 00:47:54<br>字典里说，所谓的成功就是达成预期目标</p>
<p>2015-06-15 00:48:14<br>“失败只有一种，就是半途而废。”<br>注: 希望为也能懂</p>
<p>2015-06-15 00:50:05<br>对像我这样的普通人来讲，证明我的目标现实可行的方法比较简单：1) 已经有人做到了；2) 我与那人没有太大的差距。</p>
<p>2015-06-15 08:04:30<br>时间的浪费，往往是因为1) 目标不现实或者目前暂时尚不可行；2) 为了达到目标而制定的实施策略有误。</p>
<p>2015-06-15 08:09:38<br>计划是必须的，目标当然应该是确定的。一般来讲，越是短期的目标，越容易清晰。越是清晰的目标越容易实现</p>
<p>2015-06-15 23:41:20<br>很多的时候，没必要做计划的原因有两个：除了前面提到过的“大多数计划其实非常简单”之外，另外一个是“初始状态下，我们往往实际上并没有能力去制定合理有效的计划”。因为做任何事情，我们都可能要经历相同的过程：逐步熟悉，小心摸索，失败失败再失败，认真反思，卷土重来，直至成功。而在最初甚至连基本的认知都没有的时候，制定出来的计划十有八九只不过是空谈<br>注: 走想停看</p>
<p>2015-06-15 23:47:00<br>除了“试错”、“观察”、“阅读”之外，“思考”，准确地说，“正确地思考”，才是获取真正意义上的知识的主要手段。</p>
<p>2015-06-18 08:01:37<br>写作能力在自学能力中占据着重要的地位。</p>
<p>2015-06-18 08:01:51<br>写出简捷、有效、朴素、准确、具体的说明性说理性文章的能力。</p>
<p>2015-06-18 08:09:11<br>无论如何，都不要也不应该用别人的错误惩罚自己，那么做不仅不对，并且愚蠢。</p>
<p>2015-06-18 21:29:47<br>热爱考试的理由很简单，它是通行证，它意味着机会，其他没有此通行证的人无法获得的机会。虽然有些人也许会用其他方式获得那个什么机会，但，既然你没有其他方式，就不要抱怨——反正抱怨没用。抱怨最浪费时间，即便抱怨得正确。举个极端的例子。如果这个社会确实不公平，你要是抱怨一下当然没什么不对的。可是，抱怨不仅要花费时间，还会引发负面情绪，使你丧失斗志。</p>
<p>2015-06-18 21:30:20<br>热爱考试的你，肯定应该有动力为了它做很多准备。首先要弄清楚这个考试对你的分量。对你很重要，那就要下苦功。</p>
<p>2015-06-18 21:33:03<br>如果，你是个完美主义者，总是想更上一层，那还有另外一个终极技巧——把你学会的东西教给别人。教是最好的方法。清楚明了地表述那些你自以为了解的东西并不像想象的那么容易。有的时候，你没能给别人讲清楚，可能是你自己没想明白。更多的时候，被教者的提问，往往会令你发现你的想法还有很多不全面的地方。不要吝啬你的时间，不要吝啬你的精力，更不要目光短浅，记住，教别人等于自己学，只有学好的人才可能教会别人。另外，随着时间的推移，你在知识上不吝共享的经历，最终会让你明白这是最好的助人为乐的方法，并且获得的永远只能是尊重。</p>
<p>2015-06-18 21:33:31<br>总结一下：</p>
<ol>
<li>要热爱考试，因为你喜欢通行证。</li>
<li>分辨考试的重要性。</li>
<li>提前很久开始准备重要的考试。</li>
<li>做题是最好的准备方法。</li>
<li>通过做题了解考试的重点、难点。</li>
<li>全面补习难点重点，并经常重新审视。</li>
<li>教是最好的学习方法。</li>
</ol>
<p>2015-06-19 09:23:33<br>笔记都起码有这样几个好处：<br>可以使自己保持参与状态。<br>提供一个完整的捕捉灵感、疑惑的机制。<br>可以用来与其他参与者沟通、讨论正确的信息。</p>
<h1 id="第五章-小心所谓“成功学”"><a href="#第五章-小心所谓“成功学”" class="headerlink" title="第五章: 小心所谓“成功学”"></a>第五章: 小心所谓“成功学”</h1><p>2015-06-22 22:24:56<br>最近《新周刊》[1] 有一篇不错的文章，标题是《有一种毒药叫成功》。对于“成功学”对“成功”庸俗而又过分简单化的定义，《新周刊》如此讽刺：<br>……在成功学的逻辑中，如果你没有赚到“豪宅、名车、年入百万”，如果你没有成为他人艳羡的成功人士，就证明你不行，你犯了“不成功罪”！<br>助你“实现人生价值”、“开发个人潜能”、“三个月赚到一百万”、“有车有房”、“三十五岁以前退休”……成功学泛滥于职场和网络，上进人群迷失在多款提升课程和短期培训班里，成功学大师满天飞，成功学培训蔚为大观成产业。<br>……当全民成功变成狂热风潮，成功上升为绝对真理般的、人人趋之若鹜的主流价值观，成功学就是一粒毒药，而信奉成功学的人就沦为牺牲品。</p>
<p>2015-06-22 22:30:32<br>我做完这件事之后所获得的欢乐和幸福是不是一定要建立在比较的基础上才可以获得的？然后标记出并优先实施那些无需比较就可以获得欢乐和幸福的行动方案。时间会一如既往地分分钟钟、岁岁年年地流逝，但，你会惊讶于你生活的变化。每一分钟，每一秒，每一天，每一年，时间的质量竟然会如此不同。</p>
<p>2015-06-22 22:30:46<br>马丁 塞利格曼——Positive Psychology的鼻祖。最近哈佛大学里窜红的那个“快乐学”教授，就可以算作是塞利格曼的传人。 [↩]</p>
<p>2015-06-24 21:32:19<br>资源不仅稀缺，并且分布很不均匀</p>
<p>2015-06-24 21:39:38<br>人类拥有的普遍的认知偏差之一就是：把成功揽到自己身上，把失败归咎于别人或者坏运气。（心理学上有个专门的名词：self-serving bias 。</p>
<p>2015-06-25 08:05:23<br>努力从失败者身上汲取经验。不要说模仿成功者，就算观察成功者很难。成功者很多，但是，你身边的真正的成功者却很少；成功背后的东西很难看清楚，所谓成功的真实性也很难判断，而成功者们又会有意无意的美化包装他们的经验，而这一切，都在干扰你的判断。但观察失败者却要相对容易得多，因为他们的失败往往是显然而确定的，而失败的原因往往很容易确定，尽管失败者会找各种各样的借口。并且，你身边的失败者数量，显然要多于成功者的数量，于是，你就有了更多的观察机会。</p>
<p>2015-06-25 08:07:42<br>从理性角度出发，所谓我们能体会的运气，只不过因小概率事件发生而产生的感受而已</p>
<p>2015-06-25 08:10:59<br>Shallow men believe in luck. Strong men believe in cause and effect.</p>
<p>2015-06-25 08:12:16<br>骤然临之而不惊， 无故加之而不怒</p>
<p>2015-06-25 21:19:30<br>尽管不应该盲目乐观，但一定不能悲观地生活。神奇的是，努力往往真的会改变一个人的运气。将近两千五百年前，塞涅卡（罗马哲学家、悲剧作家、政治家）就把这件事儿说得非常清楚“所谓的幸运就是当你准备好了的时候机会来了。”（Luck is what happens when preparation meets opportunity.）</p>
<p>2015-06-25 21:38:47<br>专心做可以提升自己的事情；学习并拥有更多更好的技能；成为一个值得交往的人；<br>• 学会独善其身，以不给他人制造麻烦为美德；用你的独立赢得尊重；<br>• 除非有特殊原因，应该尽量回避那些连在物质生活上都不能独善其身的人；那些精神生活上都不能独善其身的，就更应该回避了——尽管甄别起来比较困难；<br>• 真正关心一个朋友的意思是说，你情愿在他身上花费甚至浪费更多的时间；<br>• 记住，一个人的幸福程度，往往取决于他多大程度上可以脱离对外部世界的依附。</p>
<p>2015-06-26 18:25:22<br>每个人各不相同，有些人在工作学习上可以获得更多的乐趣，有的人在生活琐事中可以获得更得的幸福。</p>
<p>2015-06-29 08:07:10<br>凡是值得做的事情，都值得慢慢做——做很久很久。</p>
<p>2015-06-29 08:11:39<br>. 养成规律生活的习惯</p>
<p>2015-06-29 08:11:56<br>每天检查自己的时间表至少三次</p>
<p>2015-06-29 08:12:31<br>完成任何一项任务都要实际上花费比原计划更多的时间</p>
<p>2015-06-29 08:12:38<br>假定你永远都会遇到交通堵塞。</p>
<p>2015-06-29 08:13:11<br>意外总是发生的原因绝对不是因为你的运气格外差，而往往只不过是因为你考虑得不够周全。</p>
<p>2015-06-30 08:03:05<br>假定其他人都会迟到</p>
<p>2015-06-30 08:03:11<br>尽量不要因为别人迟到而责怪他们</p>
<p>2015-06-30 08:05:55<br>姑娘当初生我们的时候我们没有说愿意！</p>
<p>2014-01-01 11:11:39<br>在几乎所有的社会里，对每一个个体的心理健康最不利的，来自于整个社会的，也许就是对“自卑”的定义了。古今中外，几乎所有的社会里，“自卑”被都定义为是负面的，“自信”才是健康的，而“自负”也是负面的。其实，假想一下，在一个“感觉”自然就是准确的社会里，所有的“自卑”、“自信”、“自负”都是没有必要存在的概念了。然而现实却是我们生活在一个因“感觉”的本性而自然扭曲的世界。<br>为了自己的心理健康，很多的时候我们确实有必要漠视甚至忽略整个社会灌输给我们的观念——因为很多的时候那不过是“整个社会的扭曲的感觉”而已。所以，我在课堂上无数次提到自卑不是缺点。该自卑的时候就要自卑，这才是正常的。</p>
<p>2014-01-01 11:15:54<br>停止嘲弄他人。</p>
<p>2014-01-01 11:16:56<br>忘记自己的优点。</p>
<p>2014-01-01 11:20:24<br>。拿出一张纸，一支笔，罗列一下。左面罗列你的优点，右面罗列你的缺点——花上一天时间也不过分，因为你需要分辨“这个真的是我的优点么？”以及“这个真的是我的缺点么？”而后，再尝试着猜想一下别人是如何看待你的优点或者缺点的。甚至你可以旁敲侧击地去了解一下——</p>
<p>2014-01-01 11:21:06<br>我们描述一个事物的方式往往会限制我们对那个事物的了解。所以，有的时候，精巧恰当的比喻往往会仅仅因为不同的表述方法就会颠覆我们对同一事物的看法。</p>
<p>2014-01-01 11:23:52<br>马太福音里说，“他有的，就再给他，让他多余；他没有的，就连同他所有的，一并夺走。</p>
<p>2014-01-01 11:24:54<br>，时间不一定就是金钱。毕竟，不是每个人都有能力把时间转换成金钱，也不是所有人都可以把时间转换成同等高额的金钱。拿出纸笔、列一列，然后问问自己，“我的时间究竟可以标价多少？”——这就是一个人决心不再浪费时间的最有效的起点和动力。只有爱惜才可能产生节约的动力。</p>
<p>2014-01-03 03:06:38<br>急功近利是一个贬义词，多少是有些肤浅的。其实，急功近利是所有人的本性，只不过，只有少数人最终通过心智的力量彻底想清楚，事实上急功近利往往是一个风险高于回报的行为模式。</p>
<p>2014-01-03 03:08:40<br>这一刻之后的任何时间都充满了变数——保守的选择通常是避免风险的最佳行为模式</p>
<h1 id="第七章-真正的解决方案"><a href="#第七章-真正的解决方案" class="headerlink" title="第七章 真正的解决方案"></a>第七章 真正的解决方案</h1><p>2014-01-03 16:29:50<br>文章本天成，妙手偶得之”</p>
<p>2014-01-03 16:40:19<br>，贫穷，从整体上来看是“永存之困境”（persistent problem）。无论这世界发展成什么样子，都不可能彻底根除贫困，因为最终，所谓的贫困是相对的。</p>
<p>2014-01-04 03:12:58<br>耐心究竟从何而来呢？首先，所有的耐心都来自于了解。</p>
<p>2014-01-04 03:15:19<br>爱因斯坦确实曾用这样的一个比喻解释相对论：“一位先生和一位漂亮女孩在一起呆上一小时，他会感觉像一分钟；但如果让他在火炉子上呆上一分钟，他会感觉比一小时还长。这就是相对论。”但</p>
<p>2015-07-08 21:29:50<br>We can’t solve problems by using the same kind of thinking we used when we created them. — Albert Einstein<br>多看笔记 来自多看阅读 for Kindle</p>
]]></content>
      
        <categories>
            
            <category> 读书笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 鸡汤 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[《MacTalk·人生元编程》读书笔记]]></title>
      <url>http://geosmart.github.io/2015/07/21/%E3%80%8AMacTalk%C2%B7%E4%BA%BA%E7%94%9F%E5%85%83%E7%BC%96%E7%A8%8B%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>MacTalk·人生元编程</p>
<p>生命中遇见的每一本书，都不是偶然</p>
<hr>
<a id="more"></a>
<h1 id="生命中遇见的每一本书，都不是偶然"><a href="#生命中遇见的每一本书，都不是偶然" class="headerlink" title="生命中遇见的每一本书，都不是偶然"></a>生命中遇见的每一本书，都不是偶然</h1><p>2015-07-09 08:10:15<br>如果你问我是否取得了最后的成功，答案是‘当然没有！’如果是的话，生活将会变得令人厌烦。</p>
<p>2015-07-09 08:10:42<br>我们是幸运的，因为我们的心灵是如此不可预知；正因为如此，生活才充满了情趣。尽管如此，我们仍在进行努力来科学地了解我们自身……”</p>
<h1 id="怀念2007"><a href="#怀念2007" class="headerlink" title="怀念2007"></a>怀念2007</h1><p>2015-07-09 10:58:44<br>一个产品从无到有是困难的，从有到精是艰难的，而当你站上一个巅峰之后，哪怕是做最微小的改进和提升，都需要花费大量的人力物力，同时还要承受失败的风险。我们都知道，从平庸到优秀是容易的，从优秀到卓越是痛苦的，可能很多人、公司穷尽一生都无法达到卓越的境地。</p>
<h1 id="趣谈个人建站"><a href="#趣谈个人建站" class="headerlink" title="趣谈个人建站"></a>趣谈个人建站</h1><p>2015-07-13 11:39:40<br>我们真的不能一心多用吗？或者说并发带给我们的到底是效率的提升还是状态的下降</p>
<p>2015-07-13 11:43:30<br>任务的并行，上下文的切换，注意力的分散，都会让你的效率大打折扣，所以设计模式中的职责单一原则不是盖的，一个类尽可能只做一件事情，无论是效率还是后期维护都会好很多，人脑其实也是一样。</p>
<p>2015-07-13 11:45:10</p>
<ol>
<li>简单任务的并发是大脑天生的nature，每个人都在不自觉的应用。</li>
<li>在宽松的环境中让简单机械的任务和复杂有机的任务并行完成是非常不错的做法，提高效率节省时间。</li>
<li>在高危环境中（驾驶、高空作业等等）我们应该专心致志的只做当前的工作。</li>
<li>对于复杂任务，我们最好一件一件完成，即使有些人能够同时处理多重任务，那也需要长期的艰苦训练，比如郭靖君，你能否做到，就得看有没有周伯通那样的大哥！</li>
</ol>
<p>2015-07-13 11:47:17<br>大牛领会了返璞归真和万物生长的道理，知行合一，遇事抖抖衣袖，不溅起一片涟漪”</p>
<p>2015-07-13 12:25:02<br>坊间流传，普通程序员用bash，文艺程序员用zsh，XX程序员直接用原生的sh，我建议大家文艺一点，用zsh好一些，功能也最强大。目前各个版本的Linux默认的shell都是bash，如果你想用zsh，需要安装一下，如下：<br>sudo apt-get install zsh<br>具体的配置我就不介绍了，感兴趣的读者，可以参考<a href="http://leeiio.me/bash-to-zsh-for-mac/">http://leeiio.me/bash-to-zsh-for-mac/</a></p>
<p>2015-07-13 12:55:42<br>第一个十年我才华横溢，“贼光闪现”，令周边黯然失色；第二个十年，我终于“宝光现形”，不再去抢风头，反而与身边的美丽相得益彰；进入第三个十年，繁华落尽见真醇，我进入了“醇光初现”的阶段，真正体味到了境界之美。——台湾作家林清玄</p>
<h1 id="锤子和钉子"><a href="#锤子和钉子" class="headerlink" title="锤子和钉子"></a>锤子和钉子</h1><p>2015-07-20 08:15:26<br>Hater，这种人对自己不了解或没有勇气尝试的事物永远持否定态度，如果你发现一个人大部分时间在否定着什么，那么他们的意见不听也罢，甚至于那些鼓励的建议也仅仅是建议而已，仅供参考，因为最终不是那些提建议的人去做事和承担后果</p>
<p>2015-07-21 08:10:42<br>所有人都是在试错中成长，那些不犯错的人充满了各种幻觉，其实是因为他不再成长了。</p>
<p>2015-07-21 08:11:00<br>他们一定要给你泼冷水的。泼冷水的愿望之强烈，你无法想象。那种强烈借助了太多的力量：怀疑、嫉妒、恐惧、愤怒。而在表现的过程中却又包装上另外一层表皮：关怀、爱护、友爱、帮助。</p>
<p>2015-07-21 08:13:44<br>不管是谈恋爱、做项目、创业、投资都会面临这沉没成本的问题，基本的句式就是『我们已经投入了这么多……』『我们已经走了这么远……』『我们已经牺牲了这么多……』。纠结于过去的沉没成本，会让人感到痛苦和犹豫不决，该放手时要放手，</p>
<p>2015-07-21 08:15:36<br>你一直坚持着最后失败了，就是固执不懂变通。中途转向失败了，就是没有再坚持最后一公里。相反，如果你一直坚持着最后成事了，那就是无所畏惧一往无前；转向成功了，那就是灵活柔性随需应变。可见选择是一件多么艰难而奇妙的事。是沉没的成本还是沉默的坚持，都是你自己的判断和选择，有时候是命数，有时候是形式，只要是自己选择，接受就好了，只能这样。</p>
<p>2015-07-21 22:48:25<br>曾经有位古人说过，如果你手里有一把锤子，所有东西看上去都像钉子。还有一位今人说过，如果你有一个钉子，就会满大街找锤子！</p>
<p>多看笔记 来自多看阅读 for Kindle</p>
]]></content>
      
        <categories>
            
            <category> 读书笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 鸡汤 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[《三体》读书笔记]]></title>
      <url>http://geosmart.github.io/2015/07/21/%E3%80%8A%E4%B8%89%E4%BD%93%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>三体三部曲-刘慈欣  </p>
<p>给岁月以文明，给时光以生命。</p>
<hr>
<a id="more"></a>
<p>宇宙社会学：（1）生存是文明的第一需求；（2）文明不断增长和扩张，但宇宙中的物质总量不变。</p>
<p>【时间开始后约170亿年，我们的星星】</p>
<p>宇宙就是一座黑暗森林，每个文明都是带枪的猎人，像幽灵般潜行与林间，轻轻拨开挡路的树枝，竭力不让脚步发出一点儿声音，连呼吸都必须小心翼翼：他必须小心，因为林中到处都有与他一样潜行的猎人，如果他发现了别的生命，能做的只有一件事：开枪消灭之。在这片森林中，他人就是地狱，就是永恒的威胁，任何暴露自己存在的生命都将很快被消灭，这就是宇宙文明的图景，这就是对费米悖论的解释</p>
<p>2015-01-06 09:16:05<br>“城市就是森林，每一个男人都是猎手，每一个女人都是陷阱。”</p>
<p>2015-02-10 12:11:38<br>自由女神像基座上的埃玛·拉扎的诗原文为：把你们疲惫的人，你们贫穷的人，你们渴望呼吸自由空气的挤在一堆的人都给我/把那些无家可归、饱经风浪的人都送来/在这金色的大门旁，我要为他们把灯举起。</p>
<p>2015-02-10 13:57:09<br>给时光以生命，而不是给生命以时光。</p>
<p>2015-02-10 13:57:28<br>给岁月以文明，给时光以生命。</p>
<p>2015-02-11 21:58:25<br>精骛八极，心游万仞</p>
<p>2015-03-19 23:01:31<br>从科学角度讲，毁灭一词并不准确，没有真正毁掉什么，更没有灭掉什么，物质总量一点不少都还在，角动量也还在，只是物质的组合方式变了变，像一副扑克牌，仅仅重洗而已……可生命是一手同花顺，一洗什么都没了。”</p>
<p>2015-03-19 23:05:56<br>处于幼年的人类文明曾经打开家门向外看了一眼，外面无边的暗夜吓住了他，他面对黑暗中的广袤和深邃打了个寒战，紧紧地关上了门。</p>
<p>2015-03-31 20:09:40<br>这是一种放弃，她终于看清了，使自己这粒沙尘四处飘飞的，是怎样的天风；把自己这片小叶送向远方的，是怎样的大河。她彻底放弃了，让风吹透躯体，让阳光穿过灵魂。<br>多看笔记 来自多看阅读 for Kindle</p>
]]></content>
      
        <categories>
            
            <category> 读书笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 小说 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[xmanager实现CentOS远程控制]]></title>
      <url>http://geosmart.github.io/2015/07/15/xmanager%E5%AE%9E%E7%8E%B0CentOS%E8%BF%9C%E7%A8%8B%E6%8E%A7%E5%88%B6/</url>
      <content type="html"><![CDATA[<p>本文主要介绍通过Xmanager连接CentOS远程桌面时，在CentOS远程机器和Windows客户端需要做的一些配置。</p>
<hr>
<a id="more"></a>
<h1 id="Xmanager简介"><a href="#Xmanager简介" class="headerlink" title="Xmanager简介"></a>Xmanager简介</h1><p>Xmanager 全称Netsarang Xmanager，是国外一套非常优秀的远程监控软件。在UNIX/Linux和Windows网络环境中，Xmanager是较好的连通解决方案。通过Xmanager连接Linux远程桌面进行图形化管理其实就是利用了Xmanager套装里面的Xbrowser程序。<br>Linux远程图形化管理除了Xbrowser，还有同样优秀的VNC。</p>
<p>特点包括：<br>可通过Xcongfig工具设置多个Xmanager设置；<br>支持多用户的Windows终端环境；<br>支持多个IP地址；<br>支持本地资源数据库；<br>通过热键转换键盘映射；<br>支持多窗口下的Windows打印功能等</p>
<h1 id="CentOS远程机器配置"><a href="#CentOS远程机器配置" class="headerlink" title="CentOS远程机器配置"></a>CentOS远程机器配置</h1><ol>
<li>安装gdm<br>yum -y install gdm<br>配置系统为图形模式，打开/etc/inittab，修改为id:5:initdefault: (若已为5则不需修改)</li>
<li><p>启用图形化界面<br><code>vim /etc/inittab</code>，3改为5</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">id:5:initdefault:</div></pre></td></tr></table></figure>
</li>
<li><p>配置gdm参数<br><code>vim /etc/gdm/custom.conf</code>，在[security]和[xdmcp]字段下分别添加如下内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">[daemon]</div><div class="line">[security]</div><div class="line">AllowRemoteRoot=true</div><div class="line">[xdmcp]</div><div class="line">Port=177</div><div class="line">Enable=1</div><div class="line">[greeter]</div><div class="line">[chooser]</div><div class="line">[debug]</div></pre></td></tr></table></figure>
</li>
<li><p>防火墙设置</p>
</li>
</ol>
<ul>
<li><p>关闭防火墙<br>临时关闭：<code>service iptables stop</code><br>永久关闭：<code>checkcfg iptables off</code></p>
</li>
<li><p>在防火墙上打开udp协议177 端口<br><code>iptables -A INPUT -p tcp --dport 177 -j ACCEPT</code><br><code>service iptables save</code></p>
</li>
</ul>
<ol>
<li>重启机器<br><code>reboot</code></li>
</ol>
<h1 id="Windows客户端配置"><a href="#Windows客户端配置" class="headerlink" title="Windows客户端配置"></a>Windows客户端配置</h1><ol>
<li><p>XManager远程桌面连接<br>在Windows上打开XBrowser通过IP即可远程连接CentOS<br>Xbrowser&gt;工具&gt;选项&gt;添加主机&gt;连接</p>
</li>
<li><p>Xshell远程桌面连接，<br>Xshell隧道连接&gt;执行<code>gnome-panel</code>命令<br>备注：只能访问用户文件夹</p>
</li>
</ol>
<h1 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h1><p><img src="Xbrowser主界面.png" alt="Xbrowser主界面"><br><img src="Xbrowser远程控制.png" alt="Xbrowser远程控制"></p>
]]></content>
      
        <categories>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> Xmanager </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[开放虚拟化格式之OVF-OVA]]></title>
      <url>http://geosmart.github.io/2015/07/12/%E5%BC%80%E6%94%BE%E8%99%9A%E6%8B%9F%E5%8C%96%E6%A0%BC%E5%BC%8F%E4%B9%8BOVF-OVA/</url>
      <content type="html"><![CDATA[<p>遇到Sphere6.0 (esxi6 )导出的OVF虚拟机模板在Vmware WorkStation 9和VmWare WorkStation11中导入报错的问题，暂改成OVA格式进行数据交换。</p>
<hr>
<a id="more"></a>
<p>#问题描述<br><img src="errorInfo.png" alt="导入失败，未通过 OVF 规范一致性或虚拟硬件合规性检查。请单击“重试”放松 OVF 规范与虚拟硬件合规性检查，并重新尝试导入"></p>
<h2 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h2><p>以OVA格式进行数据交换<br>VMware导出时将后缀改为OVA后到处；ESXI导出时选OVA</p>
<p>#基础知识</p>
<h2 id="OVF"><a href="#OVF" class="headerlink" title="OVF"></a>OVF</h2><p>OVF（Open Virtualization Format：开放虚拟化格式 ）<br>OVF是一种开源的文件规范，它描述了一个开源、安全、有效、可拓展的便携式虚拟打包以及软件分布格式，它一般有几个部分组成，分别是ovf文件、mf文件、cert文件、vmdk文件和iso文件。</p>
<h2 id="OVA"><a href="#OVA" class="headerlink" title="OVA"></a>OVA</h2><p>OVA（Open Virtualization Appliance：开放虚拟化设备）<br>OVA包是一个单一的文件，所有必要的信息都封装在里面。OVA文件则采用.tar文件扩展名,包含了一个OVF 包中所有文件类型。这样OVA单一的文件格式使得它非常便携。</p>
]]></content>
      
        <categories>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> EXSI </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[磁盘阵列配置]]></title>
      <url>http://geosmart.github.io/2015/07/12/%E7%A3%81%E7%9B%98%E9%98%B5%E5%88%97%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<p>新购进一台戴尔塔式服务器，机器3*300G的硬盘默认已做RAID5配置，新增硬盘需配置磁盘阵列  </p>
<h1 id="RAID容量计算器"><a href="#RAID容量计算器" class="headerlink" title="RAID容量计算器"></a>RAID容量计算器</h1><p>配置前，可根据硬盘数和RAID级别，可计算配置后的硬盘实际可用容量<br>参考计算工具</p>
<ul>
<li><a href="http://www.ab126.com/web/2879.html">RAID容量计算器</a></li>
<li><a href="http://www.raid-calculator.com/default.aspx">raid-calculator</a></li>
</ul>
<hr>
<a id="more"></a>
<p>#RAID基础知识    </p>
<h2 id="RAID-0"><a href="#RAID-0" class="headerlink" title="RAID 0"></a>RAID 0</h2><p><img src="raid0.gif" alt="raid0"></p>
<ul>
<li>特点：高性能 低稳定性 中等成本</li>
<li>RAID0又称为Stripe（条带化）或Striping，它代表了所有RAID级别中最高的存储性能。</li>
<li>RAID0的缺点是不提供数据冗余，因此一旦用户数据损坏，损坏的数据将无法得到恢复。</li>
<li>RAID 0具有的特点，使其特别适用于对性能要求较高，而对数据安全不太在乎的领域，如图形工作站等。</li>
<li>对于个人用户，RAID 0也是提高硬盘存储性能的绝佳选择。</li>
</ul>
<h2 id="RAID-1"><a href="#RAID-1" class="headerlink" title="RAID 1"></a>RAID 1</h2><p><img src="raid1.gif" alt="raid1"></p>
<ul>
<li>特点：高稳定性 普通性能 中等成本</li>
<li>RAID 1又称为Mirror或Mirroring（镜像），它的宗旨是最大限度的保证用户数据的可用性和可修复性。 </li>
<li>RAID 1的操作方式是把用户写入硬盘的数据百分之百地自动复制到另外一个硬盘上。</li>
<li>Mirror虽不能提高存储性能，但由于其具有的高数据安全性，使其尤其适用于存放重要数据，如服务器和数据库存储等领域。</li>
</ul>
<h2 id="RAID-5"><a href="#RAID-5" class="headerlink" title="RAID 5"></a>RAID 5</h2><p><img src="raid5.gif" alt="raid5"></p>
<ul>
<li>特点：高性能 中等稳定性 中等成本</li>
<li>RAID 5 是一种存储性能、数据安全和存储成本兼顾的存储解决方案。 </li>
<li>RAID 5可以理解为是RAID 0和RAID 1的折衷方案。</li>
<li>RAID 5可以为系统提供数据安全保障，但保障程度要比Mirror低而磁盘空间利用率要比Mirror高。</li>
<li>RAID 5具有和RAID 0相近似的数据读取速度，只是多了一个奇偶校验信息，写入数据的速度比对单个磁盘进行写入操作稍慢。同时由于多个数据对应一个奇偶校验信息，RAID 5的磁盘空间利用率要比RAID 1高，存储成本相对较低。</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> RAID </tag>
            
            <tag> 硬件 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[nginx负载均衡参数配置]]></title>
      <url>http://geosmart.github.io/2015/07/12/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>Nginx服务器返回大量502Bad Gateway和504 Time-Out，代理服务器Jetty端存在大量CLOSE_WAIT和TIME_WAIT状态的连接<br><img src="502-504.png" alt="502-504"><br>错误信息查看口令：<br><code>netstat -n | awk &#39;/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}&#39;</code></p>
<h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><ol>
<li>Linux中TCP/IP内核参数 优化<br>编辑参数：<code>vi /etc/sysctl.conf</code><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">net.core.somaxconn = 4096</div><div class="line">net.ipv4.tcp_max_syn_backlog = 8192</div><div class="line">net.ipv4.tcp_syn_retries= 5</div><div class="line">net.ipv4.tcp_synack_retries = 5</div><div class="line">net.ipv4.tcp_abort_on_overflow=0</div><div class="line">net.ipv4.tcp_tw_reuse=1</div><div class="line">net.ipv4.tcp_tw_recycle=1 </div><div class="line">net.ipv4.tcp_timestamps=1</div><div class="line">net.ipv4.tcp_syncookies=1</div><div class="line">net.ipv4.tcp_max_tw_buckets=90000</div><div class="line">net.ipv4.tcp_fin_timeout=30</div><div class="line">net.ipv4.ip_local_port_range=10000 65000</div><div class="line">net.ipv4.tcp_keepalive_time=1200</div></pre></td></tr></table></figure>
</li>
</ol>
<p>让参数生效：<code>/sbin/sysctl -p</code></p>
<ol>
<li>Nginx配置参数<br>主要配置三个proxy_超时控制参数<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">upstream uadb_server&#123;   </div><div class="line">     server 192.168.1.81:8080  weight=1 max_fails=2 fail_timeout=0; </div><div class="line">     server 192.168.1.82:8080  weight=1 max_fails=2 fail_timeout=0;    </div><div class="line">&#125; </div><div class="line">server &#123;</div><div class="line">        listen       9090;</div><div class="line">        server_name  uadb_server;   </div><div class="line">        access_log  /var/log/nginx/uadb_server-access-ssl.log;</div><div class="line">        error_log  /var/log/nginx/uadb_server-error-ssl.log;</div><div class="line">        location /&#123; </div><div class="line">           proxy_pass http://uadb_server; </div><div class="line">           # time out settings</div><div class="line">           proxy_connect_timeout 60;</div><div class="line">           proxy_read_timeout  3600;</div><div class="line">           proxy_send_timeout  3600;</div><div class="line">           proxy_temp_file_write_size 64k;</div><div class="line">           proxy_redirect          off; </div><div class="line">        &#125; </div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="Nginx-upstream负载均衡-反向代理"><a href="#Nginx-upstream负载均衡-反向代理" class="headerlink" title="Nginx upstream负载均衡/反向代理"></a>Nginx upstream负载均衡/反向代理</h1><p><img src="proxy.png" alt="proxy">   </p>
<h2 id="upstream算法分析"><a href="#upstream算法分析" class="headerlink" title="upstream算法分析"></a>upstream算法分析</h2><ol>
<li>轮询每个请求按时间顺序分配到不同的后端服务器了，后端服务器down掉，自动切除；</li>
<li>weight：设定服务器权值：如weight=2，服务器性能不均时候使用。weight：默认为1，weight越大，负载的权重越大；</li>
<li>ip_hash ：每个请求按访问ip的hash结果分配，每个访客有固定的后端服务器，可以解决session问题；</li>
<li>fair（第三方）：按后端服务器的响应时间来分配，响应时间短的优先分配</li>
<li>url_hash (第三方)： 按访问的url的hash结果分配，使每个url定向到同一个后端服务器，后端为缓存服务器比较有效。</li>
</ol>
<h2 id="upstream参数介绍"><a href="#upstream参数介绍" class="headerlink" title="upstream参数介绍"></a>upstream参数介绍</h2><ol>
<li>down：当前的IP server暂时不参与负载，不进行反向代理；</li>
<li>max_fails：允许请求失败的次数默认为1，当超过最大次数时，返回proxy_next_upstream模块定义的错误；</li>
<li>fail_timeout：max_fails次失败后，暂停的时间；</li>
<li>backup：其它所有非backup机器down或者忙时候，请求backup机器，这台机器压力最轻。</li>
</ol>
<h1 id="netstat参数状态"><a href="#netstat参数状态" class="headerlink" title="netstat参数状态"></a>netstat参数状态</h1><p>查看口令：<code>netstat -an</code><br>参数说明：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">LISTEN：侦听来自远方的TCP端口的连接请求；</div><div class="line">SYN-SENT：在发送连接请求后等待匹配的连接请求；</div><div class="line">SYN-RECEIVED：在收到和发送一个连接请求后等待对方对连接请求的确认；</div><div class="line">ESTABLISHED：代表一个打开的连接，我们常用此作为并发连接数；</div><div class="line">FIN-WAIT-1：等待远程TCP连接中断请求，或先前的连接中断请求的确认；</div><div class="line">FIN-WAIT-2：从远程TCP等待连接中断请求；</div><div class="line">CLOSE-WAIT：等待从本地用户发来的连接中断请求；</div><div class="line">CLOSING：等待远程TCP对连接中断的确认；</div><div class="line">LAST-ACK：等待原来发向远程TCP的连接中断的确认；</div><div class="line">TIME-WAIT：等待足够的时间以确保远程TCP连接收到中断请求的确认；</div><div class="line">CLOSED：没有任何连接状态；</div></pre></td></tr></table></figure></p>
<h1 id="服务器TCP连接状态"><a href="#服务器TCP连接状态" class="headerlink" title="服务器TCP连接状态"></a>服务器TCP连接状态</h1><p>查看口令：<code>netstat -an|awk &#39;/^tcp/{++S[$NF]}END{for (a in S)print a,S[a]}&#39;</code></p>
<pre><code>CLOSED：没有连接活动或正在进行的；
LISTEN：服务器正在等待的进入呼叫；
SYN_RECV：一个连接请求已经到达，等待确认；
SYN_SENT：应用已经开始，打开一个连接；
ESTABLISHED：正常数据传输状态，也可以近似的理解为当前服务器的并发数；
FIN_WAIT1：应用已经完成；
FIN_WAIT2：另一边同意释放；
ITMED_WAIT：等待所有分组死掉；
CLOSING：两边同时尝试关闭；
TIME_WAIT：另一边已初始化一个释放；
LAST_ACK：等待所有分组死掉；
</code></pre>]]></content>
      
        <categories>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> Web服务器 </tag>
            
            <tag> Nginx </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[CentOS常用脚本]]></title>
      <url>http://geosmart.github.io/2015/07/06/centos%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC/</url>
      <content type="html"><![CDATA[<p>CentOS日常使用过程中积累的Shell脚本或Linux命令，持续维护更新  </p>
<a id="more"></a>
<h1 id="网络设置"><a href="#网络设置" class="headerlink" title="网络设置"></a>网络设置</h1><h2 id="HostName主机名"><a href="#HostName主机名" class="headerlink" title="HostName主机名"></a>HostName主机名</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">查看hostname</span></div><div class="line">hostname  </div><div class="line"><span class="meta">#</span><span class="bash">设置指定的域名解析地址</span></div><div class="line">/etc/hosts       </div><div class="line"><span class="meta">#</span><span class="bash"> 设置主机名和网络配置</span></div><div class="line">/etc/sysconfig/network</div></pre></td></tr></table></figure>
<h2 id="静态IP设置"><a href="#静态IP设置" class="headerlink" title="静态IP设置"></a>静态IP设置</h2><p><a href="static-ip-centos6.sh">下载 static-ip-centos6.sh</a><br>参数: <code>static-ip.sh &lt;hostname&gt; &lt;interface&gt; &lt;baseip&gt; &lt;ipaddress&gt; &lt;gateway/dns&gt;</code><br>示例<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">chmod +x  ./static-ip.sh &amp;&amp; ./static-ip.sh localhost eth0 192.168.1 81 1</div></pre></td></tr></table></figure></p>
<p><a href="static-ip-centos7.sh">下载 static-ip-centos7.sh</a><br>参数: 在文件中修改ip相关参数</p>
<p>手动设置IP  </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">临时设置IP</span></div><div class="line">ifconfig eth0 192.168.1.160</div><div class="line"><span class="meta">#</span><span class="bash"> 设置DNS  </span></div><div class="line">/etc/resolv.conf  </div><div class="line">临时设置IP</div><div class="line">ifconfig eth0 192.168.1.160</div></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">针对特定的网卡进行手动设置</span></div><div class="line">vim /etc/sysconfig/network-scripts/ifcfg-eth0</div><div class="line"></div><div class="line">DEVICE="eth0"</div><div class="line">BOOTPROTO="static"</div><div class="line">HWADDR="00:0C:29:86:3D:16"</div><div class="line">IPV6INIT="yes"</div><div class="line">NM_CONTROLLED="yes"</div><div class="line">ONBOOT="yes"</div><div class="line">TYPE="Ethernet"</div><div class="line">UUID="dcf18d86-45ea-4b5c-9627-e75b19b3b6e7"</div><div class="line">IPADDR=192.168.1.82</div><div class="line">NETMAST=255.255.255.0</div><div class="line">DNS1=192.168.1.1</div></pre></td></tr></table></figure>
<h2 id="集群环境下ssh免密码登陆认证脚本"><a href="#集群环境下ssh免密码登陆认证脚本" class="headerlink" title="集群环境下ssh免密码登陆认证脚本"></a>集群环境下ssh免密码登陆认证脚本</h2><p><a href="">todo-gitrepository</a></p>
<ol>
<li>确保各节点安装ssh,expect</li>
<li>把所有文件拷贝到主节点上</li>
<li>配置hosts.conf和slaves.conf</li>
<li>执行keygen_master</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">chmod +x keygen_master.sh</div><div class="line">./keygen_master.sh</div></pre></td></tr></table></figure>
<h1 id="PS查看进程"><a href="#PS查看进程" class="headerlink" title="PS查看进程"></a>PS查看进程</h1><p>通常用ps查看进程PID，kill终止进程</p>
<ul>
<li>grep 是搜索<br>例如：<code>ps -ef | grep java</code>表示查看所有进程里 CMD 是 java 的进程信息  </li>
<li>-aux 显示所有状态<br><code>ps -aux | grep java</code>  </li>
<li>kill 命令用于终止进程<br>例如： <code>kill -9 [PID]</code><br>-9 表示强迫进程立即停止</li>
</ul>
<h1 id="端口查看"><a href="#端口查看" class="headerlink" title="端口查看"></a>端口查看</h1><p>如查看80端口：<code>lsof -i tcp:80</code><br>列出所有端口：<code>netstat -ntlp</code></p>
<h1 id="nohup后台运行"><a href="#nohup后台运行" class="headerlink" title="nohup后台运行"></a>nohup后台运行</h1><p>后台运行test.jar<br><code>nohup java -jar test.jar</code><br>不输出nohup日志：&gt;/dev/null 2&gt;&amp;1 &amp;<br><code>nohup java -jar test.jar &gt;/dev/null 2&gt;&amp;1 &amp;</code></p>
<h1 id="重定向"><a href="#重定向" class="headerlink" title="重定向"></a>重定向</h1><ul>
<li>0 表示标准输入  </li>
<li>1 标准输出,在一般使用时，默认的是标准输出  </li>
<li>2 标准错误信息输出<br>可以用来指定需要重定向的标准输入或输出。例如，将某个程序的错误信息输出到log文件 中：./program 2&gt;log。这样标准输出还是在屏幕上，但是错误信息会输出到log文件中。另外，也可 以实现0，1，2之间的重定向。2&gt;&amp;1：将错误信息重定向到标准输出。</li>
<li>/dev/null<br>它就像一个无底洞，所有重定向到它的信息都会消失得无影无踪。当我们不需要回显程序的所有信息时，就可以将输出重定到/dev/null。</li>
</ul>
<h1 id="读取文件头-尾-实时内容"><a href="#读取文件头-尾-实时内容" class="headerlink" title="读取文件头/尾/实时内容"></a>读取文件头/尾/实时内容</h1><ul>
<li>head filename读取头部，使用命令head。默认显示文件 filename 的前十行内容<br><code>head -n 20 filename</code>：显示文件的前20行内容<br><code>head -n -20 filename</code>  ：若n后面的整数为负数时，如则表示列出除尾部的20行外的所有行    </li>
<li>tail filename 读取尾部，使用命令tail，使用方法同head相似<br><code>tail -n 20 filename</code>：显示文件的最后20行内容<br><code>tail -n +20 filename</code>：显示文件自第20行开始后的所有行（包括第20行）  </li>
<li><code>tail -f filename</code>：动态显示最新的文件内容<br>具体用法man head或man tail获取  </li>
</ul>
<h1 id="chkconfig问题"><a href="#chkconfig问题" class="headerlink" title="chkconfig问题"></a>chkconfig问题</h1><p>chkconfig –add myservice问题：service myservice does not support chkconfig<br>我们一般在脚本开头加入下面两句就好了<br><code>vim  /etc/init.d/myservice</code><br>添加下面两句到 #!/bin/bash 之后</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></div><div class="line"><span class="meta">#</span><span class="bash"> chkconfig: 2345 10 90</span></div><div class="line"><span class="meta">#</span><span class="bash"> description: myservice ....</span></div></pre></td></tr></table></figure>
<h1 id="图形化界面切换CentOS6"><a href="#图形化界面切换CentOS6" class="headerlink" title="图形化界面切换CentOS6"></a>图形化界面切换CentOS6</h1><p><code>vim /etc/inittab</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> Default runlevel. The runlevels used by RHS are:</span></div><div class="line"><span class="meta">#</span><span class="bash"> 0 - halt (Do NOT <span class="built_in">set</span> initdefault to this)          --停机</span></div><div class="line"><span class="meta">#</span><span class="bash"> 1 - Single user mode           --单用户模式</span></div><div class="line"><span class="meta">#</span><span class="bash"> 2 - Multiuser, without NFS (The same as 3, <span class="keyword">if</span> you <span class="keyword">do</span> not havenetworking)           --多用户模式，不支持NFS</span></div><div class="line"><span class="meta">#</span><span class="bash"> 3 - Full multiuser mode          --多用户模式     </span></div><div class="line"><span class="meta">#</span><span class="bash"> 4 - unused          --没有使用</span></div><div class="line"><span class="meta">#</span><span class="bash"> 5 - X11          --图形界面方式</span></div><div class="line"><span class="meta">#</span><span class="bash"> 6 - reboot (Do NOT <span class="built_in">set</span> initdefault to this)          --重新启动</span></div><div class="line"><span class="meta">#</span><span class="bash"> --默认运行等级是5</span></div><div class="line">id:5:initdefault:</div></pre></td></tr></table></figure>
<h1 id="图形化界面切换CentOS7"><a href="#图形化界面切换CentOS7" class="headerlink" title="图形化界面切换CentOS7"></a>图形化界面切换CentOS7</h1><p>使用systemd创建符号链接指向默认运行级别。</p>
<ol>
<li>首先删除已经存在的符号链接<br><code>rm /etc/systemd/system/default.target</code></li>
<li>默认级别转换为3(文本模式)<br><code>ln -sf /lib/systemd/system/multi-user.target /etc/systemd/system/default.target</code><br>或者默认级别转换为5(图形模式)<br><code>ln -sf /lib/systemd/system/graphical.target /etc/systemd/system/default.target</code></li>
<li>重启<br><code>reboot</code></li>
</ol>
<h1 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h1><h2 id="mkdir-新建目录"><a href="#mkdir-新建目录" class="headerlink" title="mkdir 新建目录"></a>mkdir 新建目录</h2><p>mkdir -p 无目录新建目录</p>
<h2 id="touch-新建文件"><a href="#touch-新建文件" class="headerlink" title="touch 新建文件"></a>touch 新建文件</h2><p>eg：<code>touch test.log</code></p>
<h2 id="追加文本到文件"><a href="#追加文本到文件" class="headerlink" title="追加文本到文件"></a>追加文本到文件</h2><p>eg：<code>echo &quot;/opt/cm/etc/init.d/cloudera-scm-server start&quot; &gt;&gt; /etc/rc.local</code></p>
<h2 id="rm-文件删除参数："><a href="#rm-文件删除参数：" class="headerlink" title="rm 文件删除参数："></a>rm 文件删除参数：</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">-r 就是向下递归，不管有多少级目录，一并删除</div><div class="line">-f 就是直接强行删除，不作任何提示的意思</div><div class="line">-rf 递归强制删除</div></pre></td></tr></table></figure>
<p>需要提醒的是：使用这个rm -rf的时候一定要格外小心，linux没有回收站的  </p>
<h2 id="tar文件解压"><a href="#tar文件解压" class="headerlink" title="tar文件解压"></a>tar文件解压</h2><p>tar在linux上是常用的打包、压缩、加压缩工具，他的参数很多，折里仅仅列举常用的压缩与解压缩参数   </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">-c ：create 建立压缩档案的参数；</div><div class="line">-x ： 解压缩压缩档案的参数；</div><div class="line">-z ： 是否需要用gzip压缩；</div><div class="line">-v： 压缩的过程中显示档案；</div><div class="line">-f： 置顶文档名，在f后面立即接文件名，不能再加参数</div><div class="line">1 将tgz文件解压到指定目录</div><div class="line">tar   zxvf    test.tgz  -C  指定目录</div><div class="line">比如将/source/kernel.tgz解压到  /source/linux-2.6.29 目录</div><div class="line">tar  zxvf  /source/kernel.tgz  -C /source/ linux-2.6.29</div></pre></td></tr></table></figure>
<h1 id="VIM操作"><a href="#VIM操作" class="headerlink" title="VIM操作"></a>VIM操作</h1><p><a href="http://www.eepw.com.cn/article/48018.htm">http://www.eepw.com.cn/article/48018.htm</a></p>
<p>vi删除*.swp临时文件删除<br>i插入<br>esc命令行<br>:底行（x或:wq保存）</p>
<h1 id="查找操作"><a href="#查找操作" class="headerlink" title="查找操作"></a>查找操作</h1><h2 id="find"><a href="#find" class="headerlink" title="find"></a>find</h2><p>find是最常见和最强大的查找命令，你可以用它找到任何你想找的文件。<br>find的使用格式如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">　　$ find &lt;指定目录&gt; &lt;指定条件&gt; &lt;指定动作&gt;</div><div class="line">　　- &lt;指定目录&gt;： 所要搜索的目录及其所有子目录。默认为当前目录。</div><div class="line">　　- &lt;指定条件&gt;： 所要搜索的文件的特征。</div><div class="line">　　- &lt;指定动作&gt;： 对搜索结果进行特定的处理。</div></pre></td></tr></table></figure></p>
<p>如果什么参数也不加，find默认搜索当前目录及其子目录，并且不过滤任何结果（也就是返回所有文件），将它们全都显示在屏幕上。<br>find的使用实例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">　　$ find . -name &quot;my*&quot;</div><div class="line">搜索当前目录（含子目录，以下同）中，所有文件名以my开头的文件。</div><div class="line">　　$ find . -name &quot;my*&quot; -ls</div><div class="line">搜索当前目录中，所有文件名以my开头的文件，并显示它们的详细信息。</div><div class="line">　　$ find . -type f -mmin -10</div><div class="line">搜索当前目录中，所有过去10分钟中更新过的普通文件。如果不加-type f参数，则搜索普通文件+特殊文件+目录。</div></pre></td></tr></table></figure></p>
<h2 id="locate"><a href="#locate" class="headerlink" title="locate"></a>locate</h2><p>locate命令其实是“find -name”的另一种写法，但是要比后者快得多，原因在于它不搜索具体目录，而是搜索一个数据库（/var/lib/locatedb），这个数据库中含有本地所有文件信息。Linux系统自动创建这个数据库，并且每天自动更新一次，所以使用locate命令查不到最新变动过的文件。为了避免这种情况，可以在使用locate之前，先使用updatedb命令，手动更新数据库。<br>locate命令的使用实例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">　　$ locate /etc/sh</div><div class="line">搜索etc目录下所有以sh开头的文件。</div><div class="line">　　$ locate ~/m</div><div class="line">搜索用户主目录下，所有以m开头的文件。</div><div class="line">　　$ locate -i ~/m</div><div class="line">搜索用户主目录下，所有以m开头的文件，并且忽略大小写。</div></pre></td></tr></table></figure>
<h2 id="whereis"><a href="#whereis" class="headerlink" title="whereis"></a>whereis</h2><p>whereis命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。<br>whereis命令的使用实例：<code>$ whereis grep</code></p>
<h2 id="which"><a href="#which" class="headerlink" title="which"></a>which</h2><p>which命令的作用是，在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。<br>which命令的使用实例：<code>$ which grep</code></p>
<h2 id="type"><a href="#type" class="headerlink" title="type"></a>type</h2><p>type命令其实不能算查找命令，它是用来区分某个命令到底是由shell自带的，还是由shell外部的独立二进制文件提供的。如果一个命令是外部命令，那么使用-p参数，会显示该命令的路径，相当于which命令。<br>type命令的使用实例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">　　$ type cd</div><div class="line">系统会提示，cd是shell的自带命令（build-in）。</div><div class="line">　　$ type grep</div><div class="line">系统会提示，grep是一个外部命令，并显示该命令的路径。</div><div class="line">　　$ type -p grep</div><div class="line">加上-p参数后，就相当于which命令。</div></pre></td></tr></table></figure>
<h1 id="系统时间"><a href="#系统时间" class="headerlink" title="系统时间"></a>系统时间</h1><ul>
<li>date 查看系统时间  </li>
<li>date -s 修改时间<br>如：date -s  03/04/2013（将系统日期设定为2013年03月04日）</li>
<li>date -s  110:38（将系统时间设定为上午 10:38）<br>修改完后执行：clock -w  ,强制将时间写入COMS！</li>
</ul>
<h1 id="chmod命令详解"><a href="#chmod命令详解" class="headerlink" title="chmod命令详解　　"></a>chmod命令详解　　</h1><p>使用权限：所有使用者<br>使用方式：chmod [-cfvR] [–help] [–version] mode file…<br>说明：<br>Linux/Unix 的档案存取权限分为三级 : 档案拥有者、群组、其他。利用 chmod 可以藉以控制档案如何被他人所存取。<br>mode ：权限设定字串，格式如下 ：[ugoa…][[+-=][rwxX]…][,…]，其中u 表示该档案的拥有者，g 表示与该档案的拥有者属于同一个群体(group)者，o 表示其他以外的人，a 表示这三者皆是。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">+ 表示增加权限、- 表示取消权限、= 表示唯一设定权限。</div><div class="line">r 表示可读取，w 表示可写入，x 表示可执行，X 表示只有当该档案是个子目录或者该档案已经被设定过为可执行。</div><div class="line">-c : 若该档案权限确实已经更改，才显示其更改动作</div><div class="line">-f : 若该档案权限无法被更改也不要显示错误讯息</div><div class="line">-v : 显示权限变更的详细资料</div><div class="line">-R : 对目前目录下的所有档案与子目录进行相同的权限变更(即以递回的方式逐个变更)</div><div class="line">--help : 显示辅助说明</div><div class="line">--version : 显示版本</div><div class="line">　　范例：</div><div class="line">　　将档案 file1.txt 设为所有人皆可读取</div><div class="line">chmod ugo+r file1.txt</div><div class="line">　　将档案 file1.txt 设为所有人皆可读取</div><div class="line">chmod a+r file1.txt</div><div class="line">　　将档案 file1.txt 与 file2.txt 设为该档案拥有者，与其所属同一个群体者可写入，但其他以外的人则不可写入</div><div class="line">chmod ug+w,o-w file1.txt file2.txt</div><div class="line">　　将 ex1.py 设定为只有该档案拥有者可以执行</div><div class="line">chmod u+x ex1.py</div><div class="line">　　将目前目录下的所有档案与子目录皆设为任何人可读取</div><div class="line">chmod -R a+r *</div><div class="line">　　此外chmod也可以用数字来表示权限如 chmod 777 file</div><div class="line">　　语法为：chmod abc file</div><div class="line">　　其中a,b,c各为一个数字，分别表示User、Group、及Other的权限。</div><div class="line">　　r=4，w=2，x=1</div><div class="line">　　若要rwx属性则4+2+1=7；</div><div class="line">　　若要rw-属性则4+2=6；</div><div class="line">　　若要r-x属性则4+1=7。</div><div class="line">　　范例：</div><div class="line">　　chmod a=rwx file 和 chmod 777 file 效果相同</div><div class="line">　　chmod ug=rwx,o=x file 和 chmod 771 file 效果相同</div><div class="line">　　若用chmod 4755 filename可使此程式具有root的权限</div></pre></td></tr></table></figure></p>
<h1 id="chown命令详解"><a href="#chown命令详解" class="headerlink" title="chown命令详解　　"></a>chown命令详解　　</h1><p>使用权限：root<br>使用方式：chown [-cfhvR] [–help] [–version] user[:group] file…<br>说明：Linux/Unix 是多人多工作业系统，所有的档案皆有拥有者。利用chown 可以将档案的拥有者加以改变。一般来说，这个指令只有是由系统管理者(root)所使用，一般使用者没有权限可以改变别人的档案拥有者，也没有权限可以自己的档案拥有者改设为别人。只有系统管理者(root)才有这样的权限。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">user : 新的档案拥有者的使用者</div><div class="line">IDgroup : 新的档案拥有者的使用者群体(group)</div><div class="line">-c : 若该档案拥有者确实已经更改，才显示其更改动作</div><div class="line">-f : 若该档案拥有者无法被更改也不要显示错误讯息</div><div class="line">-h : 只对于连结(link)进行变更，而非该 link 真正指向的档案</div><div class="line">-v : 显示拥有者变更的详细资料</div><div class="line">-R : 对目前目录下的所有档案与子目录进行相同的拥有者变更(即以递回的方式逐个变更)</div><div class="line">--help : 显示辅助说明</div><div class="line">--version : 显示版本</div><div class="line">　　范例：</div><div class="line">　　将档案 file1.txt 的拥有者设为 users 群体的使用者 jessie</div><div class="line">chown jessie:users file1.txt</div><div class="line">　　将目前目录下的所有档案与子目录的拥有者皆设为 users 群体的使用者 lamport</div><div class="line">chown -R lamport:users *</div><div class="line">-rw------- (600) -- 只有属主有读写权限。</div><div class="line">-rw-r--r-- (644) -- 只有属主有读写权限；而属组用户和其他用户只有读权限。</div><div class="line">-rwx------ (700) -- 只有属主有读、写、执行权限。</div><div class="line">-rwxr-xr-x (755) -- 属主有读、写、执行权限；而属组用户和其他用户只有读、执行权限。</div><div class="line">-rwx--x--x (711) -- 属主有读、写、执行权限；而属组用户和其他用户只有执行权限。</div><div class="line">-rw-rw-rw- (666) -- 所有用户都有文件读、写权限。这种做法不可取。</div><div class="line">-rwxrwxrwx (777) -- 所有用户都有读、写、执行权限。更不可取的做法。</div><div class="line">以下是对目录的两个普通设定：</div><div class="line">drwx------ (700) - 只有属主可在目录中读、写。</div><div class="line">drwxr-xr-x (755) - 所有用户可读该目录，但只有属主才能改变目录中的内容</div><div class="line">suid的代表数字是4，比如4755的结果是-rwsr-xr-x</div><div class="line">sgid的代表数字是2，比如6755的结果是-rwsr-sr-x</div><div class="line">sticky位代表数字是1，比如7755的结果是-rwsr-sr-t</div></pre></td></tr></table></figure></p>
<h1 id="scp命令详解"><a href="#scp命令详解" class="headerlink" title="scp命令详解　"></a>scp命令详解　</h1><h2 id="关于scp"><a href="#关于scp" class="headerlink" title="关于scp　"></a>关于scp　</h2><p>scp是secure copy的缩写，scp是linux系统下基于ssh登陆进行安全的远程文件拷贝命令。linux的scp命令可以在linux服务器之间复制文件和目录。</p>
<h2 id="scp命令的用途"><a href="#scp命令的用途" class="headerlink" title="scp命令的用途"></a>scp命令的用途</h2><p>scp在网络上不同的主机之间复制文件，它使用ssh安全协议传输数据，具有和ssh一样的验证机制，从而安全的远程拷贝文件。<br>scp命令基本格式：<code>scp [-1246BCpqrv] [-c cipher] [-F ssh_config] [-i identity_file]
[-l limit] [-o ssh_option] [-P port] [-S program]
[[user@]host1:]file1 [...] [[user@]host2:]file2</code></p>
<h2 id="scp命令的参数说明"><a href="#scp命令的参数说明" class="headerlink" title="scp命令的参数说明"></a>scp命令的参数说明</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">-1    强制scp命令使用协议ssh1</div><div class="line">-2    强制scp命令使用协议ssh2</div><div class="line">-4    强制scp命令只使用IPv4寻址</div><div class="line">-6    强制scp命令只使用IPv6寻址</div><div class="line">-B    使用批处理模式（传输过程中不询问传输口令或短语）</div><div class="line">-C    允许压缩。（将-C标志传递给ssh，从而打开压缩功能）</div><div class="line">-p 保留原文件的修改时间，访问时间和访问权限。</div><div class="line">-q    不显示传输进度条。</div><div class="line">-r    递归复制整个目录。</div><div class="line">-v 详细方式显示输出。scp和ssh(1)会显示出整个过程的调试信息。这些信息用于调试连接，验证和配置问题。</div><div class="line">-c cipher    以cipher将数据传输进行加密，这个选项将直接传递给ssh。</div><div class="line">-F ssh_config    指定一个替代的ssh配置文件，此参数直接传递给ssh。</div><div class="line">-i identity_file        从指定文件中读取传输时使用的密钥文件，此参数直接传递给ssh。</div><div class="line">-l limit    限定用户所能使用的带宽，以Kbit/s为单位。</div><div class="line">-o ssh_option    如果习惯于使用ssh_config(5)中的参数传递方式，</div><div class="line">-P port 注意是大写的P, port是指定数据传输用到的端口号</div><div class="line">-S program    指定加密传输时所使用的程序。此程序必须能够理解ssh(1)的选项。</div></pre></td></tr></table></figure>
<h2 id="从本地服务器复制到远程服务器"><a href="#从本地服务器复制到远程服务器" class="headerlink" title="从本地服务器复制到远程服务器"></a>从本地服务器复制到远程服务器</h2><p>复制文件命令格式：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">scp local_file remote_username@remote_ip:remote_folder</div><div class="line">scp local_file remote_username@remote_ip:remote_file</div><div class="line">scp local_file remote_ip:remote_folder</div><div class="line">scp local_file remote_ip:remote_file</div></pre></td></tr></table></figure></p>
<p>实例<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">scp /home/linux/soft/scp.zip root@www.mydomain.com:/home/linux/others/soft</div><div class="line">scp /home/linux/soft/scp.zip root@www.mydomain.com:/home/linux/others/soft/scp2.zip</div><div class="line">scp /home/linux/soft/scp.zip www.mydomain.com:/home/linux/others/soft</div><div class="line">scp /home/linux/soft/scp.zip www.mydomain.com:/home/linux/others/soft/scp2.zip</div></pre></td></tr></table></figure></p>
<p>复制目录命令格式：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scp -r local_folder remote_username@remote_ip:remote_folder</div><div class="line">scp -r local_folder remote_ip:remote_folder</div></pre></td></tr></table></figure></p>
<p>实例:将 本地 soft 目录 复制 到 远程 others 目录下，即复制后远程服务器上会有/home/linux/others/soft/ 目录<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scp -r /home/linux/soft/ root@www.mydomain.com:/home/linux/others/</div><div class="line">scp -r /home/linux/soft/ www.mydomain.com:/home/linux/others/</div></pre></td></tr></table></figure></p>
<h2 id="从远程服务器复制到本地服务器"><a href="#从远程服务器复制到本地服务器" class="headerlink" title="从远程服务器复制到本地服务器"></a>从远程服务器复制到本地服务器</h2><p>从远程复制到本地的scp命令与上面的命令雷同，只要将从本地复制到远程的命令后面2个参数互换顺序就行了。<br>例如<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scp root@www.mydomain.com:/home/linux/soft/scp.zip /home/linux/others/scp.zip</div><div class="line">scp  -r www.mydomain.com:/home/linux/soft/ /home/linux/others/</div></pre></td></tr></table></figure></p>
<h1 id="rpm命令"><a href="#rpm命令" class="headerlink" title="rpm命令"></a>rpm命令</h1><p>命令格式 rpm {-q|–query} [select-options] [query-options]</p>
<h1 id="yum命令"><a href="#yum命令" class="headerlink" title="yum命令"></a>yum命令</h1><h2 id="yum切换阿里云源"><a href="#yum切换阿里云源" class="headerlink" title="yum切换阿里云源"></a>yum切换阿里云源</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup</div><div class="line">wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</div><div class="line">yum clean all</div><div class="line">yum makecache</div></pre></td></tr></table></figure>
<h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h2><p><code>yum search {name}</code></p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p><code>yum install {name}</code></p>
]]></content>
      
        <categories>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> Shell </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[mongodb一键安装脚本]]></title>
      <url>http://geosmart.github.io/2015/07/01/mongodb%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/</url>
      <content type="html"><![CDATA[<p><img src="logo-mongodb.png" alt="">   </p>
<h2 id="准备内容"><a href="#准备内容" class="headerlink" title="准备内容"></a>准备内容</h2><ol>
<li><a href="http://fastdl.mongodb.org/linux/mongodb-linux-x86_64-2.6.3.tgz">mongodb安装包（官网版本：mongodb-linux-x86_64-2.6.3.tgz）</a><br>下载后并重命名为mongodb.tar.gz</li>
<li><a href="install-mongodb.sh">mongodb安装脚本</a></li>
</ol>
<h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><p>将文件复制到CentOS后进行安装</p>
<ol>
<li>CentOS路径：/tmp </li>
<li><p>执行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /tmp</div><div class="line">chmod +x install-mongodb.sh </div><div class="line">sudo ./install-mongodb.sh</div></pre></td></tr></table></figure>
</li>
<li><p>一路回车即可 </p>
</li>
</ol>
]]></content>
      
        <categories>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> MongoDB </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[日志分析工具]]></title>
      <url>http://geosmart.github.io/2015/06/30/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/</url>
      <content type="html"><![CDATA[<p>最近需要对多台Web服务器/Java客户端程序的日志进行分析，比较了一些开源的日志分析产工具，目前在用的有OtrosLogViewer（olv）和LogExpert</p>
<hr>
<a id="more"></a>
<h2 id="AWStats"><a href="#AWStats" class="headerlink" title="AWStats"></a>AWStats</h2><ul>
<li>基于Perl，开源、简洁、强大的网站日志分析工具<br>Free real-time logfile analyzer to get advanced statistics (GNU GPL).<br>AWStats is a free powerful and featureful tool that generates advanced web, streaming, ftp or mail server statistics, graphically. This log analyzer works as a CGI or from command line and shows you all possible information your log contains, in few graphical web pages. It uses a partial information file to be able to process large log files, often and quickly. It can analyze log files from all major server tools like Apache log files (NCSA combined/XLF/ELF log format or common/CLF log format), WebStar, IIS (W3C log format) and a lot of other web, proxy, wap, streaming servers, mail servers and some ftp servers.<br>Take a look at this comparison table for an idea on features and differences between most famous statistics tools (AWStats, Analog, Webalizer,…).<br>AWStats is a free software distributed under the GNU General Public License. You can have a look at this license chart to know what you can/can’t do.<br>As AWStats works from the command line but also as a CGI, it can work with all web hosting providers which allow Perl, CGI and log access.</li>
</ul>
<h2 id="OtrosLogViewer"><a href="#OtrosLogViewer" class="headerlink" title="OtrosLogViewer"></a>OtrosLogViewer</h2><ul>
<li>基于Java开发的，开源、强大、可自定义日志语法规则进行解析、UI友好，可拖拽http日志进行分析，好评</li>
<li>问题1：在windows下切换log会非常卡顿，linux下正常，暂未找到原因</li>
<li>问题2： illegal character in schema name at index xxx<br>  不能直接拖拽文件（如<a href="http://192.168.1.81:8080/logs/uadb/uadb.log），需拖拽浏览器页面（如http://192.168.1.81:8080/logs/uadb）中的日志链接">http://192.168.1.81:8080/logs/uadb/uadb.log），需拖拽浏览器页面（如http://192.168.1.81:8080/logs/uadb）中的日志链接</a></li>
<li>问题3 按<code>%d{yyyy-MM-dd HH\:mm\:ss,SSS} [%t] [%c] [%p] - %m%n</code>规则拆分行存在问题，存在多行并在一起</li>
</ul>
<p>Useful software for analysing applications logs and traces.</p>
<h2 id="LogExpert"><a href="#LogExpert" class="headerlink" title="LogExpert"></a>LogExpert</h2><ul>
<li>小而美的单机日志分析工具，好评<br>  You are a developer needing a nice tail application for MS Windows?<br>  You are in the need for a powerful logfile analysis tool?<br>  You love logfiles?<br>  You live in your logfiles?<br>  Or at least: you have to work with them?<br>  Download LogExpert if you answered “yes” to any of the questions above!</li>
</ul>
<h2 id="Log-Parser"><a href="#Log-Parser" class="headerlink" title="Log Parser"></a>Log Parser</h2><ul>
<li>基于.NET平台<br>  Log Parser is a powerful, versatile tool that provides universal query access to text-based data such as log files, XML files and CSV files, as well as key data sources on the Windows operating system such as the Event Log, the Registry, the file system, and Active Directory. You tell Log Parser what information you need and how you want it processed. The results of your query can be custom-formatted in text based output, or they can be persisted to more specialty targets like SQL, SYSLOG, or a chart. Most software is designed to accomplish a limited number of specific tasks. Log Parser is different… the number of ways it can be used is limited only by the needs and imagination of the user. The world is your database with Log Parser.</li>
</ul>
<h2 id="Chainsaw"><a href="#Chainsaw" class="headerlink" title="Chainsaw"></a>Chainsaw</h2><ul>
<li>虽是apache官方的专业Log4j分析工具，2004年就没更新了,差评！<br>  Chainsaw v2 is a companion application to Log4j written by members of the Log4j development community. Like a number of Open Source projects, this new version was built upon inspirations, ideas and creations of others. Chainsaw v2 has it’s roots from the original Chainsaw utility written by Oliver Burn, and with inspiration from the Log Factor 5 utility contributed by ThoughtWorks Inc.</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 日志分析 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[常用git命令]]></title>
      <url>http://geosmart.github.io/2015/06/30/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4/</url>
      <content type="html"><![CDATA[<p>用github来搭建个人技术笔记，少不了记录一些常用的git命令</p>
<hr>
<a id="more"></a>
<h1 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h1><p><a href="http://git-scm.com/book/zh/v2/%E8%B5%B7%E6%AD%A5-Git-%E5%9F%BA%E7%A1%80">Git基础</a><br><a href="http://yanminx.com/blog/understand-git-by-drawing">用爱一起画Git</a><br><a href="https://www.atlassian.com/git/tutorials/">参考教程</a>  </p>
<h1 id="克隆库"><a href="#克隆库" class="headerlink" title="克隆库"></a>克隆库</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/geosmart/geosmart.io</div></pre></td></tr></table></figure>
<h1 id="新建-‘gh-pages’分支，会自动生成github-pages"><a href="#新建-‘gh-pages’分支，会自动生成github-pages" class="headerlink" title="新建 ‘gh-pages’分支，会自动生成github pages"></a>新建 ‘gh-pages’分支，会自动生成github pages</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git checkout --orphan gh-pages</div></pre></td></tr></table></figure>
<h1 id="本地提交"><a href="#本地提交" class="headerlink" title="本地提交"></a>本地提交</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git commit -a -m &quot;commit message&quot;</div></pre></td></tr></table></figure>
<h1 id="初始版本提交"><a href="#初始版本提交" class="headerlink" title="初始版本提交"></a>初始版本提交</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">git push --set-upstream origin master</div><div class="line">或</div><div class="line">git push origin master</div></pre></td></tr></table></figure>
<h1 id="推送到服务器"><a href="#推送到服务器" class="headerlink" title="推送到服务器"></a>推送到服务器</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">git push origin  </div><div class="line">```  </div><div class="line">#   git同步配置</div></pre></td></tr></table></figure>
<p>git sync<br>git config –global credential.helper store<br>git config –global push.default matching<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">#  git bash记住密码</div><div class="line">## 设置环境变量</div><div class="line">在windows中添加一个HOME环境变量，变量名:HOME,变量值：%USERPROFILE%</div><div class="line">## 创建git用户名和密码存储文件</div><div class="line">进入%HOME%目录，新建一个名为 &quot;_netrc&quot; 的文件，文件中内容格式如下：</div><div class="line">```yaml</div><div class="line">machine &#123;git account name&#125;.github.com</div><div class="line">login your-usernmae</div><div class="line">password your-password</div></pre></td></tr></table></figure></p>
<p>重新打开git bash即可，无需再输入用户名和密码</p>
<h1 id="查看git配置"><a href="#查看git配置" class="headerlink" title="查看git配置"></a>查看git配置</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git config --list</div></pre></td></tr></table></figure>
<h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="CAfile-C-Program-Files-Git-mingw64-ssl-certs-ca-bundle-crt"><a href="#CAfile-C-Program-Files-Git-mingw64-ssl-certs-ca-bundle-crt" class="headerlink" title="CAfile: C:/Program Files/Git/mingw64/ssl/certs/ca-bundle.crt"></a>CAfile: C:/Program Files/Git/mingw64/ssl/certs/ca-bundle.crt</h2><p>You have to fix the path to bin/curl-ca-bundle.crt. I had to specify the absolute path, using back-slashes:<br><code>git config --system http.sslcainfo &quot;C:\Program Files (x86)\git\bin\curl-ca-bundle.crt&quot;``
or — not really recommended — you may choose to switch off SSL checks completely by executing:</code>git config –system http.sslverify false`</p>
]]></content>
      
        <categories>
            
            <category> 版本控制 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Git </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[LNMP安装]]></title>
      <url>http://geosmart.github.io/2015/06/30/lnmp%E5%AE%89%E8%A3%85/</url>
      <content type="html"><![CDATA[<p>具体参考<a href="http://lnmp.org/">LNMP一键安装官网</a></p>
<h2 id="NMP环境配置"><a href="#NMP环境配置" class="headerlink" title="NMP环境配置"></a>NMP环境配置</h2><p>LNMP:Linux+Nginx+Mysql+PHP</p>
<h2 id="LNMP相关软件安装目录"><a href="#LNMP相关软件安装目录" class="headerlink" title="LNMP相关软件安装目录"></a>LNMP相关软件安装目录</h2><p>Nginx 目录: /usr/local/nginx/<br>MySQL 目录 : /usr/local/mysql/<br>MySQL数据库所在目录：/usr/local/mysql/var/<br>MariaDB 目录 : /usr/local/mariadb/<br>MariaDB数据库所在目录：/usr/local/mariadb/var/<br>PHP目录 : /usr/local/php/<br>PHPMyAdmin目录 : 0.9版为/home/wwwroot/phpmyadmin/ 1.0版为 /home/wwwroot/default/phpmyadmin/ 强烈建议将此目录重命名为其不容易猜到的名字。phpmyadmin可自己从官网下载新版替换。<br>默认网站目录 : 0.9版为 /home/wwwroot/ 1.0版为 /home/wwwroot/default/<br>Nginx日志目录：/home/wwwlogs/<br>/root/vhost.sh添加的虚拟主机配置文件所在目录：/usr/local/nginx/conf/vhost/<br>PureFtpd 目录：/usr/local/pureftpd/<br>PureFtpd web管理目录： 0.9版为/home/wwwroot/default/ftp/ 1.0版为 /home/wwwroot/default/ftp/<br>Proftpd 目录：/usr/local/proftpd/<br>Redis 目录：/usr/local/redis/</p>
<p>##一键安装<br>下载<br><code>wget  --no-check-certificate https://api.sinas3.com/v1/SAE_lnmp/soft/lnmp1.2-full.tar.gz</code><br>一键下载安装<br><code>wget -c http://soft.vpser.net/lnmp/lnmp1.2-full.tar.gz &amp;&amp; tar zxf lnmp1.2-full.tar.gz &amp;&amp; cd lnmp1.2-full &amp;&amp; ./install.sh lnmp</code></p>
<p>离线安装<br><code>cd /tmp/lnmp &amp;&amp; tar zxf lnmp1.2-full.tar.gz &amp;&amp; cd lnmp1.2-full &amp;&amp; ./install.sh lnmp</code><br>网络情况10M带宽耗时：45分钟</p>
]]></content>
      
        <categories>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> Web服务器 </tag>
            
            <tag> LNMP </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hexo安装]]></title>
      <url>http://geosmart.github.io/2015/06/30/hexo%E5%AE%89%E8%A3%85/</url>
      <content type="html"><![CDATA[<h1 id="hexo环境搭建"><a href="#hexo环境搭建" class="headerlink" title="hexo环境搭建"></a>hexo环境搭建</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">npm install -g hexo-cli</div><div class="line">hexo init</div><div class="line">npm install</div><div class="line">npm install hexo-deployer-git --save</div><div class="line">npm install hexo-server --save</div><div class="line">npm install hexo-generator-sitemap --save</div><div class="line">npm install hexo-generator-feed --save</div><div class="line">npm install hexo-toc --save</div><div class="line">npm install hexo-html-minifier --save</div></pre></td></tr></table></figure>
<h1 id="可选插件"><a href="#可选插件" class="headerlink" title="可选插件"></a>可选插件</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">npm un hexo-renderer-marked --save</div><div class="line">npm i hexo-renderer-markdown-it --save</div></pre></td></tr></table></figure>
<h1 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">hexo g (generate)</div><div class="line">hexo s (server)</div><div class="line">hexo clean (clear public)</div><div class="line">hexo n  [layout] &lt;title &gt;(new post)</div><div class="line">eg:hexo n draft title</div><div class="line">hexo publish [layout] &lt;title&gt;</div><div class="line">eg:hexo publish draft title</div><div class="line">hexo d (deploy)</div><div class="line">hexo d -g (generate and deploy)</div><div class="line"></div><div class="line">hexo g</div><div class="line">hexo s</div></pre></td></tr></table></figure>
<h1 id="配置评论插件"><a href="#配置评论插件" class="headerlink" title="配置评论插件"></a>配置评论插件</h1><p>多说挂了，换gitment,参考<a href="https://imsun.net/posts/gitment-introduction/">Gitment：使用 GitHub Issues 搭建评论系统</a></p>
<h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><h2 id="hexo部署错误"><a href="#hexo部署错误" class="headerlink" title="hexo部署错误"></a>hexo部署错误</h2><p>错误日志：Error: spawn git ENOENT<br>解决方案：<br>方案1）添加环境变量C:\Program Files (x86)\Git\bin;C:\Program Files (x86)\Git\libexec\git-core<br>方案2）安装github windows&gt;在项目中Open in Gitshell&gt;执行hexo d -g</p>
]]></content>
      
        <categories>
            
            <category> 工具 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 博客 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[zabbix-server安装脚本]]></title>
      <url>http://geosmart.github.io/2015/06/30/zabbix-server%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/</url>
      <content type="html"><![CDATA[<h1 id="关于zabbix"><a href="#关于zabbix" class="headerlink" title="关于zabbix"></a>关于zabbix</h1><ul>
<li>zabbix是一个基于WEB界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案，能监视各种网络参数，保证服务器系统的安全运营；并提供灵活的通知机制以让系统工程师快速定位/解决存在的各种问题。zabbix由2部分构成，zabbix server与可选组件zabbix agent。</li>
<li>zabbix server可以通过SNMP，zabbix agent，ping，端口监视等方法提供对远程服务器/网络状态的监视，数据收集等功能。</li>
<li>zabbix agent需要安装在被监视的目标服务器上，它主要完成对硬件信息或与操作系统有关的内存，CPU等信息的收集。</li>
</ul>
<hr>
<a id="more"></a>
<p><img src="zabbix.png" alt="zabbix">  </p>
<h1 id="准备内容"><a href="#准备内容" class="headerlink" title="准备内容"></a>准备内容</h1><ol>
<li>LNMP/LNAP环境安装</li>
<li><a href="http://sourceforge.net/projects/zabbix/files/ZABBIX%20Latest%20Stable/2.2.9/zabbix-2.2.9.tar.gz/download">zabbix安装包（官网版本：zabbix-2.2.9.tar.gz）</a></li>
<li><a href="install-zabbix_server.sh">zabbix安装脚本</a> </li>
<li><a href="clear-zabbix_his.sh">zabbix清空历史监控数据脚本</a> </li>
</ol>
<h1 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h1><ol>
<li>PHP参数配置<br>为安装zabbix监控WebUI，需要预先配置php<br><code>vim /usr/local/php/etc/php.ini</code>查找配置下列参数：<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">memory_limit = 128M</div><div class="line">post_max_size = 50M</div><div class="line">upload_max_filesize =50M</div><div class="line">max_execution_time = 600</div><div class="line">max_input_time = 600</div><div class="line">date.timezone = Asia/Shanghai</div></pre></td></tr></table></figure>
</li>
</ol>
<p>修改后执行<code>service php-fpm restart</code></p>
<ol>
<li>修改zabbix_server程序的磁盘路径<br>修改zabbix_server主程序路径<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># vim /usr/local/zabbix/misc/init.d/tru64/zabbix_server</span></div><div class="line">DAEMON=/usr/<span class="built_in">local</span>/zabbix/sbin/zabbix_server</div></pre></td></tr></table></figure>
</li>
</ol>
<p>添加下面两句到<code>#!/bin/bash</code>之后，解决<code>service myservicedoes not support chkconfig</code>问题<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># chkconfig: 2345 10 90 </span></div><div class="line"><span class="comment"># description:zabbix....</span></div></pre></td></tr></table></figure></p>
<ol>
<li>编辑zabbix_server配置文件<br><code>vim /usr/local/zabbix/etc/zabbix_server.conf</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">DBHost=localhost</div><div class="line">DBName = zabbix </div><div class="line">DBPassword =zabbix  </div><div class="line">DBUser = zabbix  </div><div class="line">LogFile=/tmp/zabbix_server.log</div></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li>添加zabbix服务Service端口（不能重复操作）</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">cat &gt;&gt;/etc/services&lt;&lt;EOF</div><div class="line">zabbix-agent 10050/tcp Zabbix Agent</div><div class="line">zabbix-agent 10050/udp Zabbix Agent</div><div class="line">zabbix-trapper 10051/tcp Zabbix Trapper</div><div class="line">zabbix-trapper 10051/udp Zabbix Trapper</div><div class="line">EOF</div></pre></td></tr></table></figure>
<ol>
<li><p>Mysql中新建Zabbix数据库</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">mysql -uroot -proot</div><div class="line">create database zabbix;</div><div class="line">grant all privileges on zabbix.* to zabbix@localhost identified by &apos;zabbix&apos;;</div><div class="line">quit</div><div class="line">``` </div><div class="line"></div><div class="line">6. 执行安装脚本</div><div class="line">``` bash </div><div class="line">cd /usr/local/zabbix</div><div class="line">chmod +x configure</div><div class="line">cd /usr/local/zabbix/script</div><div class="line">chmod +x install-zabbix_server.sh </div><div class="line">sudo ./install-zabbix_server.sh</div><div class="line">```  </div><div class="line"></div><div class="line"># 相关操作</div><div class="line">1. zabbix网站中的启用中文后乱码问题</div><div class="line">* 在zabbix网站目录下的include/locales.inc.php文件中启用中文（&apos;display&apos;=true）</div><div class="line">* 在windows下控制面板-&gt;字体-&gt;选择一种中文字库例如“楷体”，把它拷贝到zabbix的web端的fonts目录下例如：/var/www/html/zabbix/fonts，并且把TTF后缀改为ttf</div><div class="line">* 修改zabbix的web端/include/defines.inc.php，如下</div><div class="line">``` php</div><div class="line">//define(&apos;ZBX_GRAPH_FONT_NAME&apos;, &apos;DejaVuSans&apos;); // origin name</div><div class="line">define(&apos;ZBX_GRAPH_FONT_NAME&apos;, &apos;simkai&apos;); // custom  font name</div><div class="line">``` </div><div class="line">2. 若zabbix的host无法访问，考虑防火墙是否需要关闭/加入信任端口</div><div class="line"></div><div class="line">``` bash</div><div class="line">#查看防火墙状态</div><div class="line">service iptables status </div><div class="line">#关闭防火墙 </div><div class="line">service iptables stop </div><div class="line">#永久关闭防火墙 </div><div class="line">chkconfig   iptables off</div></pre></td></tr></table></figure>
</li>
<li><p>编译问题<br>‘aclocal-1.14’ is missing on your system.You should only need it if you modified ‘acinclude.m4’ or ‘configure.ac’ or m4 files included by ‘configure.ac’.<br>解决方法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">touch configure.ac aclocal.m4 configure Makefile.am Makefile.in</div><div class="line">make</div></pre></td></tr></table></figure>
</li>
<li><p>查看zabbix服务是否已启动</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">netstat -utlnp | grep zabbix </div><div class="line">```    </div><div class="line"></div><div class="line">5. 配置文件更新后，需重启客户端服务</div><div class="line">``` bash</div><div class="line">service zabbix_server restart</div></pre></td></tr></table></figure>
</li>
<li><p>zabbix web配置简略，贴几张效果图<br><img src="filter.png" alt="zabbix监控"><br><img src="cpu.png" alt="zabbix监控CPU"><br><img src="network.png" alt="zabbix监控网络"></p>
</li>
</ol>
]]></content>
      
        <categories>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> 监控 </tag>
            
            <tag> Zabbix </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[zabbix-agent安装脚本]]></title>
      <url>http://geosmart.github.io/2015/06/29/zabbix-agent%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/</url>
      <content type="html"><![CDATA[<p><img src="zabbix.png" alt="zabbix"> </p>
<h1 id="准备内容"><a href="#准备内容" class="headerlink" title="准备内容"></a>准备内容</h1><ol>
<li><a href="http://sourceforge.net/projects/zabbix/files/ZABBIX%20Latest%20Stable/2.2.9/zabbix-2.2.9.tar.gz/download">zabbix安装包（官网版本：zabbix-2.2.9.tar.gz）</a></li>
<li>yum groupinstall “Development tools”</li>
<li><a href="install-zabbix_agent.sh">zabbix安装脚本</a> </li>
</ol>
<p> cd /tmp &amp;&amp; tar -zxf  zabbix.gz</p>
<h1 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h1><ol>
<li>修改zabbix_server程序的磁盘路径<br>修改zabbix_server主程序路径<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># vim /usr/local/zabbix/misc/init.d/tru64/zabbix_server</span></div><div class="line">DAEMON=/usr/<span class="built_in">local</span>/zabbix/sbin/zabbix_server</div></pre></td></tr></table></figure>
</li>
</ol>
<p>添加下面两句到<code>#!/bin/bash</code>之后，解决<code>service myservicedoes not support chkconfig</code>问题<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># chkconfig: 2345 10 90 </span></div><div class="line"><span class="comment"># description:zabbix....</span></div></pre></td></tr></table></figure></p>
<ol>
<li><p>编辑zabbix_agentd配置文件<br><code>vim /usr/local/zabbix/etc/zabbix_agentd.conf</code> </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">LogFile=/tmp/zabbix_agentd.log </div><div class="line"><span class="comment">#服务端IP  </span></div><div class="line">Server=192.168.1.80</div><div class="line"><span class="comment">#服务端IP   </span></div><div class="line">ServerActive= 192.168.1.80</div><div class="line"><span class="comment">#客户端IP与zabbix-web配置上的hostName一致   </span></div><div class="line">Hostname=localhost</div><div class="line">UnsafeUserParameters=1</div></pre></td></tr></table></figure>
</li>
<li><p>执行安装脚本</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/zabbix/script/install-zabbix_agentd.sh</div><div class="line">chmod +x install-zabbix_agentd.sh </div><div class="line">sudo ./install-zabbix_agentd.sh</div></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="相关操作"><a href="#相关操作" class="headerlink" title="相关操作"></a>相关操作</h1><ol>
<li><p>若zabbix的host无法访问，考虑防火墙是否需要关闭/加入信任端口</p>
<pre><code class="bash"><span class="comment">#查看防火墙状态</span>
service iptables status 
<span class="comment">#关闭防火墙 </span>
service iptables stop  
<span class="comment">#永久关闭防火墙 </span>
chkconfig   iptables off
</code></pre>
</li>
<li><p>查看zabbix服务是否已启动</p>
<pre><code class="bash">netstat -utlnp | grep zabbix
</code></pre>
</li>
<li><p>配置文件更新后，需重启客户端服务</p>
<pre><code class="bash">service zabbix_agentd restart
</code></pre>
</li>
</ol>
]]></content>
      
        <categories>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> 监控 </tag>
            
            <tag> Zabbix </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[mongodb手动安装脚本]]></title>
      <url>http://geosmart.github.io/2015/06/28/mongodb%E6%89%8B%E5%8A%A8%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/</url>
      <content type="html"><![CDATA[<p><img src="nosql.png" alt="nosql">   </p>
<h1 id="准备事项"><a href="#准备事项" class="headerlink" title="准备事项"></a>准备事项</h1><h2 id="下载安装包文件（二进制编译版）"><a href="#下载安装包文件（二进制编译版）" class="headerlink" title="下载安装包文件（二进制编译版）"></a>下载安装包文件（二进制编译版）</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">mkdir -p /usr/<span class="built_in">local</span>/mongodb</div><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/mongodb</div><div class="line">wget http://fastdl.mongodb.org/linux/mongodb-linux-x86_64-2.6.3.tgz</div><div class="line">tar -zvxf mongodb-linux-x86_64-2.6.3.tgz</div></pre></td></tr></table></figure>
<h2 id="重命名-gt-新建数据-日志目录"><a href="#重命名-gt-新建数据-日志目录" class="headerlink" title="重命名&gt;新建数据/日志目录"></a>重命名&gt;新建数据/日志目录</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mv mongodb-linux-x86_64-2.6.3 mongodb</div><div class="line">mkdir data</div><div class="line">mkdir <span class="built_in">log</span></div></pre></td></tr></table></figure>
<h1 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h1><p>CentOs中配置path环境变量,确保mongodb的bin目录包含在path环境变量中。</p>
<h2 id="配置PATH"><a href="#配置PATH" class="headerlink" title="配置PATH"></a>配置PATH</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">vim /etc/profile</div><div class="line">　　<span class="comment">#set for mongodb</span></div><div class="line">　　<span class="built_in">export</span> MONGODB_HOME=/usr/<span class="built_in">local</span>/mongodb</div><div class="line">　　<span class="built_in">export</span> PATH=<span class="variable">$MONGODB_HOME</span>/bin:<span class="variable">$PATH</span></div></pre></td></tr></table></figure>
<h2 id="查看当前PATH"><a href="#查看当前PATH" class="headerlink" title="查看当前PATH"></a>查看当前PATH</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">echo</span> <span class="variable">$PATH</span></div></pre></td></tr></table></figure>
<h2 id="让环境变量生效"><a href="#让环境变量生效" class="headerlink" title="让环境变量生效"></a>让环境变量生效</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">source</span> /etc/profile</div><div class="line">//验证环境变量是否生效</div><div class="line">mongod -version</div><div class="line"><span class="built_in">echo</span> <span class="variable">$PATH</span></div><div class="line">```  </div><div class="line"></div><div class="line"><span class="comment">## 添加CentOS开机启动项</span></div></pre></td></tr></table></figure>
<p>vim  /etc/rc.d/rc.local<br>//将mongodb启动命令手动追加到本文件中：<br>/usr/local/mongodb/bin/mongod –dbpath /usr/local/mongodb/data –logpath /usr/local/mongodb/log/mongodb.log –maxConns=2000  –fork –smallfiles<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"># 启动MongoDB</div><div class="line">## 配置文件形式</div><div class="line">``` bash</div><div class="line">vim  /usr/local/mongodb/mongodb.conf</div><div class="line">dbpath=/usr/local/mongodb/data</div><div class="line">logpath=/usr/local/mongodb/log/mongodb.log</div><div class="line">logappend=true</div><div class="line">port=27017</div><div class="line">fork=true</div><div class="line">noauth=true</div><div class="line">journal=true</div><div class="line">smallfiles=true</div><div class="line">```  </div><div class="line"></div><div class="line">## 命令行形式</div><div class="line">``` Bash</div><div class="line">/usr/local/mongodb/bin/mongod --dbpath /usr/local/mongodb/data --logpath /usr/local/mongodb/log/mongodb.log  --fork --smallfiles</div><div class="line">//可选：--auth</div></pre></td></tr></table></figure></p>
<h1 id="增加用户"><a href="#增加用户" class="headerlink" title="增加用户"></a>增加用户</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">useradd mongodb -M -s /sbin/nologin</div></pre></td></tr></table></figure>
<h1 id="启动服务-测试服务状态"><a href="#启动服务-测试服务状态" class="headerlink" title="启动服务/测试服务状态"></a>启动服务/测试服务状态</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">service mongod start</div><div class="line">service mongod status</div><div class="line">shutdown -r now</div><div class="line">service mongod status</div><div class="line">mongo admin</div><div class="line">show dbs；</div><div class="line">db.test.find();</div><div class="line"><span class="built_in">exit</span></div></pre></td></tr></table></figure>
<h1 id="部署问题记录"><a href="#部署问题记录" class="headerlink" title="部署问题记录"></a>部署问题记录</h1><h2 id="MongoVUE不能连接"><a href="#MongoVUE不能连接" class="headerlink" title="MongoVUE不能连接"></a>MongoVUE不能连接</h2><p>将27017端口加入信任列表；局域网测试直接关闭防火墙<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">//关闭防火墙</div><div class="line">service iptables stop</div><div class="line">//开启</div><div class="line">chkconfig iptables on</div><div class="line">//关闭</div><div class="line">chkconfig iptables off</div><div class="line">//查询TCP连接情况</div><div class="line"> netstat -n | awk <span class="string">'/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;'</span></div><div class="line">//查询端口占用情况：</div><div class="line"> netstat   -anp   |   grep  portno</div><div class="line">//（例如：netstat –apn | grep 80）</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> 数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> MongoDB </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[jdk安装脚本]]></title>
      <url>http://geosmart.github.io/2015/06/28/jdk%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/</url>
      <content type="html"><![CDATA[<h2 id="准备内容"><a href="#准备内容" class="headerlink" title="准备内容"></a>准备内容</h2><ol>
<li><a href="http://download.oracle.com/otn-pub/java/jdk/7u80-b15/jdk-7u80-linux-x64.tar.gz">jdk7 X64安装包（官网版本：jdk-7u80-linux-x64.tar.gz）</a><br>下载后并重命名为jetty.tar.gz</li>
<li><a href="install-jdk.sh">jdk安装脚本</a></li>
</ol>
<h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><p>将文件复制到CentOS后进行安装</p>
<ol>
<li>CentOS路径：/tmp/jdk</li>
<li>执行</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="built_in">cd</span> /tmp/jdk</div><div class="line">chmod +x install-jdk.sh</div><div class="line">sudo ./install-jdk.sh</div></pre></td></tr></table></figure>
<ol>
<li>一路回车即可</li>
</ol>
<p>#附件 install-jdk.sh<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="meta">#!/bin/sh</span></div><div class="line">BASEDIR=$(<span class="built_in">cd</span> `dirname <span class="variable">$0</span>`; <span class="built_in">pwd</span>)</div><div class="line"></div><div class="line"><span class="comment">#jdk-7u80-linux-x64</span></div><div class="line"><span class="built_in">read</span>  -p <span class="string">"Please select java tar package full path path[/tmp/jdk.tar.gz] "</span> INSTALL_FILE</div><div class="line"><span class="keyword">if</span> [ ! -f <span class="string">"<span class="variable">$INSTALL_FILE</span>"</span> ]; <span class="keyword">then</span></div><div class="line">trueINSTALL_FILE=<span class="string">"/tmp/jdk.tar.gz"</span></div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line"><span class="comment"># Set install path</span></div><div class="line"><span class="built_in">read</span>  -p <span class="string">"Please select java install path path[/usr/local/java]: "</span> INSTALL_PATH</div><div class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$INSTALL_PATH</span>"</span> = <span class="string">""</span> ]; <span class="keyword">then</span></div><div class="line">trueINSTALL_PATH=<span class="string">"/usr/local/java"</span></div><div class="line"><span class="keyword">fi</span></div><div class="line"><span class="keyword">if</span> [ ! -d <span class="variable">$INSTALL_PATH</span> ]; <span class="keyword">then</span></div><div class="line">    <span class="built_in">echo</span> <span class="string">"mkdir <span class="variable">$INSTALL_PATH</span>"</span></div><div class="line">    mkdir -p <span class="variable">$INSTALL_PATH</span></div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line"><span class="built_in">echo</span> <span class="string">"uncompress <span class="variable">$INSTALL_FILE</span> to <span class="variable">$INSTALL_PATH</span>"</span></div><div class="line"><span class="keyword">if</span> [ -w <span class="variable">$INSTALL_PATH</span> ]; <span class="keyword">then</span></div><div class="line">  tar -zxvf <span class="variable">$INSTALL_FILE</span> -C <span class="variable">$INSTALL_PATH</span> --strip-components=1</div><div class="line"><span class="keyword">else</span></div><div class="line">  sudo tar -zxvf <span class="variable">$INSTALL_FILE</span> -C <span class="variable">$INSTALL_PATH</span> --strip-components=1</div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="built_in">echo</span> <span class="string">"Setting java environment..."</span></div><div class="line"><span class="built_in">echo</span> <span class="string">"export JAVA_HOME=<span class="variable">$INSTALL_PATH</span>"</span> | sudo tee -a /etc/profile</div><div class="line"></div><div class="line">JAVA_HOME=<span class="variable">$INSTALL_PATH</span></div><div class="line"><span class="comment">#FIXME</span></div><div class="line"><span class="built_in">echo</span> <span class="string">"export CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/lib/tools.jar:<span class="variable">$JAVA_HOME</span>/lib/dt.jar"</span> | sudo tee -a /etc/profile</div><div class="line"><span class="built_in">echo</span> <span class="string">'export PATH=$JAVA_HOME/bin:$PATH'</span> | sudo tee -a /etc/profile</div><div class="line"></div><div class="line"><span class="built_in">echo</span> <span class="string">"refresh java environment..."</span></div><div class="line"><span class="comment">#TODO what does "."  do? the same as "source" command?</span></div><div class="line">. /etc/profile</div><div class="line"><span class="built_in">source</span> /etc/profile</div><div class="line"></div><div class="line">java -version</div><div class="line"><span class="keyword">if</span> [ <span class="string">"$?"</span> = <span class="string">"0"</span> ]; <span class="keyword">then</span></div><div class="line"><span class="built_in">echo</span> -e <span class="string">"\033[32m Installed, please source /etc/profile or relogin. \033[0m"</span></div><div class="line"><span class="keyword">else</span></div><div class="line"><span class="built_in">echo</span> -e <span class="string">"\033[31m Install failed. \033[0m"</span></div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line"><span class="built_in">unset</span> BASEDIR</div><div class="line"><span class="built_in">unset</span> INSTALL_PATH</div><div class="line"><span class="built_in">unset</span> INSTALL_FILE</div><div class="line"></div><div class="line"><span class="built_in">exit</span> 0</div></pre></td></tr></table></figure></p>
<ol>
<li>卸载JDK</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash">查看系统已安装的jdk</span></div><div class="line">rpm -qa|grep jdk</div><div class="line">java-1.7.0-openjdk-1.7.0.45-2.4.3.3.el6.x86_64</div><div class="line"><span class="meta">#</span><span class="bash">卸载指定版本的jdk</span></div><div class="line">rpm -e --nodeps  java-1.7.0-openjdk-1.7.0.45-2.4.3.3.el6.x86_64</div><div class="line"><span class="meta">#</span><span class="bash"> 删除JAVA_HOME，CLASSPATH等相关环境变量</span></div><div class="line">vim /etc/profile</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> 运维 </tag>
            
            <tag> J2EE </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[jetty手动安装脚本]]></title>
      <url>http://geosmart.github.io/2015/06/28/jetty%E6%89%8B%E5%8A%A8%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/</url>
      <content type="html"><![CDATA[<p>##安装步骤<br>将文件复制到CentOS后进行安装</p>
<h3 id="下载解压Jetty"><a href="#下载解压Jetty" class="headerlink" title="下载解压Jetty"></a>下载解压Jetty</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /tmp</div><div class="line">wget http://eclipse.org/downloads/download.php?file=/jetty/stable-9/dist/jetty-distribution-9.3.0.v20150612.tar.gz&amp;r=1</div><div class="line">tar -xzvf  jetty-distribution-9.3.0.v20150612.tar.gz</div><div class="line">mv jetty-distribution-9.1.1.v20140108 /usr/<span class="built_in">local</span>/jetty</div></pre></td></tr></table></figure>
<h3 id="新建用户-gt-配置jetty所属权限"><a href="#新建用户-gt-配置jetty所属权限" class="headerlink" title="新建用户&gt;配置jetty所属权限"></a>新建用户&gt;配置jetty所属权限</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">useradd -m jetty</div><div class="line">chown -R jetty:jetty /usr/<span class="built_in">local</span>/jetty/</div></pre></td></tr></table></figure>
<h3 id="安装到系统服务"><a href="#安装到系统服务" class="headerlink" title="安装到系统服务"></a>安装到系统服务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ln -s /usr/<span class="built_in">local</span>/jetty/bin/jetty.sh /etc/init.d/jetty</div><div class="line">chkconfig --add jetty</div><div class="line">chkconfig --level 345 jetty on</div></pre></td></tr></table></figure>
<h3 id="编辑启动脚本"><a href="#编辑启动脚本" class="headerlink" title="编辑启动脚本"></a>编辑启动脚本</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">vim /etc/default/jetty</div><div class="line">JETTY_HOME=/usr/<span class="built_in">local</span>/jetty</div><div class="line">JETTY_USER=jetty</div><div class="line">JETTY_PORT=8080</div><div class="line">JETTY_LOGS=/usr/<span class="built_in">local</span>/jetty/logs/</div></pre></td></tr></table></figure>
<h3 id="启动服务-gt-测试"><a href="#启动服务-gt-测试" class="headerlink" title="启动服务&gt;测试"></a>启动服务&gt;测试</h3><pre><code class="bash">service jetty start
curl localhost:8080
</code></pre>
<h3 id="常用操作指令"><a href="#常用操作指令" class="headerlink" title="常用操作指令"></a>常用操作指令</h3><pre><code class="bash">jetty [-d] {start|stop|run|restart|check|supervise} [ CONFIGS ... ]
</code></pre>
]]></content>
      
        <categories>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> Web服务器 </tag>
            
            <tag> Jetty </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[jetty一键安装脚本]]></title>
      <url>http://geosmart.github.io/2015/06/28/jetty%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/</url>
      <content type="html"><![CDATA[<h2 id="准备内容"><a href="#准备内容" class="headerlink" title="准备内容"></a>准备内容</h2><ol>
<li><a href="http://download.eclipse.org/jetty/9.2.11.v20150529/dist/jetty-distribution-9.2.11.v20150529.tar.gz">jetty安装包（官网版本：jetty-distribution-9.2.11.v20150529.tar）</a><br>下载后并重命名为jetty.tar.gz</li>
<li><a href="install-jetty.sh">jetty安装脚本</a></li>
<li>已安装JDK1.7</li>
</ol>
<h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><p>将文件复制到CentOS后进行安装</p>
<ol>
<li>CentOS路径：/tmp/jetty</li>
<li><p>执行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /tmp/jetty</div><div class="line">chmod +x install-jetty.sh</div><div class="line">sudo ./install-jetty.sh</div></pre></td></tr></table></figure>
</li>
<li><p>一路回车即可</p>
</li>
</ol>
]]></content>
      
        <categories>
            
            <category> 运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> Web服务器 </tag>
            
            <tag> Jetty </tag>
            
        </tags>
        
    </entry>
    
  
  
</search>
